{"Episode reward": -99.19693633276094, "Episode length": 999, "Policy Loss": -12.543252944946289, "Value Loss": 0.02818349003791809, "_runtime": 12.580559253692627, "_timestamp": 1585077277.2721646, "_step": 0}
{"Episode reward": -92.36809371892936, "Episode length": 999, "Policy Loss": -11.749013900756836, "Value Loss": 0.025528933852910995, "_runtime": 13.687207460403442, "_timestamp": 1585077278.3788128, "_step": 1}
{"Episode reward": -107.26952334639932, "Episode length": 999, "Policy Loss": -14.042867660522461, "Value Loss": 0.033921342343091965, "_runtime": 14.817691564559937, "_timestamp": 1585077279.509297, "_step": 2}
{"Episode reward": -99.84930479890123, "Episode length": 999, "Policy Loss": -12.888799667358398, "Value Loss": 0.03294077888131142, "_runtime": 15.923360824584961, "_timestamp": 1585077280.6149662, "_step": 3}
{"Episode reward": -103.98480813337754, "Episode length": 999, "Policy Loss": -13.307462692260742, "Value Loss": 0.03050190769135952, "_runtime": 17.035799264907837, "_timestamp": 1585077281.7274046, "_step": 4}
{"Episode reward": -104.31404255112463, "Episode length": 999, "Policy Loss": -13.489712715148926, "Value Loss": 0.03473040461540222, "_runtime": 18.182228088378906, "_timestamp": 1585077282.8738334, "_step": 5}
{"Episode reward": -104.19337402499119, "Episode length": 999, "Policy Loss": -13.562752723693848, "Value Loss": 0.030454838648438454, "_runtime": 19.372496604919434, "_timestamp": 1585077284.064102, "_step": 6}
{"Episode reward": -99.46263082275141, "Episode length": 999, "Policy Loss": -12.675040245056152, "Value Loss": 0.02835771255195141, "_runtime": 20.468925714492798, "_timestamp": 1585077285.160531, "_step": 7}
{"Episode reward": -105.36346427838575, "Episode length": 999, "Policy Loss": -13.703621864318848, "Value Loss": 0.03186151012778282, "_runtime": 21.656887531280518, "_timestamp": 1585077286.3484929, "_step": 8}
{"Episode reward": -104.53645306767929, "Episode length": 999, "Policy Loss": -13.51462173461914, "Value Loss": 0.0328521803021431, "_runtime": 22.812674522399902, "_timestamp": 1585077287.5042799, "_step": 9}
{"Episode reward": -102.83900753077522, "Episode length": 999, "Policy Loss": -13.434039115905762, "Value Loss": 0.03247669339179993, "_runtime": 23.95337176322937, "_timestamp": 1585077288.644977, "_step": 10}
{"Episode reward": -108.35128563959357, "Episode length": 999, "Policy Loss": -14.2489013671875, "Value Loss": 0.04019652679562569, "_runtime": 25.116878271102905, "_timestamp": 1585077289.8084836, "_step": 11}
{"Episode reward": -103.46076660765975, "Episode length": 999, "Policy Loss": -13.57754898071289, "Value Loss": 0.03041268326342106, "_runtime": 26.232544898986816, "_timestamp": 1585077290.9241502, "_step": 12}
{"Episode reward": -93.7393462430404, "Episode length": 999, "Policy Loss": -11.66353988647461, "Value Loss": 0.026672985404729843, "_runtime": 27.364314079284668, "_timestamp": 1585077292.0559194, "_step": 13}
{"Episode reward": -109.3182038699924, "Episode length": 999, "Policy Loss": -14.583468437194824, "Value Loss": 0.03500473499298096, "_runtime": 28.49760413169861, "_timestamp": 1585077293.1892095, "_step": 14}
{"Episode reward": -96.8962902071032, "Episode length": 999, "Policy Loss": -12.591730117797852, "Value Loss": 0.027125634253025055, "_runtime": 29.611889123916626, "_timestamp": 1585077294.3034945, "_step": 15}
{"Episode reward": -97.80267015933363, "Episode length": 999, "Policy Loss": -12.574040412902832, "Value Loss": 0.02828710339963436, "_runtime": 30.706901788711548, "_timestamp": 1585077295.398507, "_step": 16}
{"Episode reward": -99.58627966655227, "Episode length": 999, "Policy Loss": -12.74379825592041, "Value Loss": 0.032939761877059937, "_runtime": 31.84658455848694, "_timestamp": 1585077296.53819, "_step": 17}
{"Episode reward": -101.92543985927668, "Episode length": 999, "Policy Loss": -13.06741714477539, "Value Loss": 0.029731297865509987, "_runtime": 32.97431778907776, "_timestamp": 1585077297.665923, "_step": 18}
{"Episode reward": -96.07132444232658, "Episode length": 999, "Policy Loss": -12.319826126098633, "Value Loss": 0.030553065240383148, "_runtime": 34.104955196380615, "_timestamp": 1585077298.7965605, "_step": 19}
{"Episode reward": -95.5756277084301, "Episode length": 999, "Policy Loss": -12.257346153259277, "Value Loss": 0.0267434474080801, "_runtime": 35.28972864151001, "_timestamp": 1585077299.981334, "_step": 20}
{"Episode reward": -100.78230602858758, "Episode length": 999, "Policy Loss": -12.963379859924316, "Value Loss": 0.03516140952706337, "_runtime": 36.43667721748352, "_timestamp": 1585077301.1282825, "_step": 21}
{"Episode reward": -103.6160446994967, "Episode length": 999, "Policy Loss": -13.549415588378906, "Value Loss": 0.029081100597977638, "_runtime": 37.59087657928467, "_timestamp": 1585077302.282482, "_step": 22}
{"Episode reward": -99.16241223367153, "Episode length": 999, "Policy Loss": -12.676121711730957, "Value Loss": 0.027656003832817078, "_runtime": 38.77011775970459, "_timestamp": 1585077303.461723, "_step": 23}
{"Episode reward": -106.95680462084984, "Episode length": 999, "Policy Loss": -14.056880950927734, "Value Loss": 0.03507514297962189, "_runtime": 39.90606999397278, "_timestamp": 1585077304.5976753, "_step": 24}
{"Episode reward": -102.91811444366274, "Episode length": 999, "Policy Loss": -13.530832290649414, "Value Loss": 0.03307244926691055, "_runtime": 41.05892539024353, "_timestamp": 1585077305.7505307, "_step": 25}
{"Episode reward": -108.69168401972868, "Episode length": 999, "Policy Loss": -14.491262435913086, "Value Loss": 0.03619996830821037, "_runtime": 42.18731331825256, "_timestamp": 1585077306.8789186, "_step": 26}
{"Episode reward": -102.9082989460219, "Episode length": 999, "Policy Loss": -13.303597450256348, "Value Loss": 0.03159143403172493, "_runtime": 43.356972455978394, "_timestamp": 1585077308.0485778, "_step": 27}
{"Episode reward": -103.24027355344336, "Episode length": 999, "Policy Loss": -13.4248685836792, "Value Loss": 0.03340188041329384, "_runtime": 44.4987428188324, "_timestamp": 1585077309.1903481, "_step": 28}
{"Episode reward": -108.27808557168728, "Episode length": 999, "Policy Loss": -14.256282806396484, "Value Loss": 0.03960786387324333, "_runtime": 45.62035393714905, "_timestamp": 1585077310.3119593, "_step": 29}
{"Episode reward": -99.55179957122927, "Episode length": 999, "Policy Loss": -12.811546325683594, "Value Loss": 0.028807049617171288, "_runtime": 46.771554708480835, "_timestamp": 1585077311.46316, "_step": 30}
{"Episode reward": -100.23856884306332, "Episode length": 999, "Policy Loss": -12.685844421386719, "Value Loss": 0.03221786394715309, "_runtime": 47.98321485519409, "_timestamp": 1585077312.6748202, "_step": 31}
{"Episode reward": -104.30129687177583, "Episode length": 999, "Policy Loss": -13.490424156188965, "Value Loss": 0.03501574322581291, "_runtime": 49.098050594329834, "_timestamp": 1585077313.789656, "_step": 32}
{"Episode reward": -110.51192280465301, "Episode length": 999, "Policy Loss": -14.721291542053223, "Value Loss": 0.03550675883889198, "_runtime": 50.20481610298157, "_timestamp": 1585077314.8964214, "_step": 33}
{"Episode reward": -101.57599523933952, "Episode length": 999, "Policy Loss": -13.257268905639648, "Value Loss": 0.029688527807593346, "_runtime": 51.33748531341553, "_timestamp": 1585077316.0290906, "_step": 34}
{"Episode reward": -102.56549772894513, "Episode length": 999, "Policy Loss": -13.385547637939453, "Value Loss": 0.0324072428047657, "_runtime": 52.45364809036255, "_timestamp": 1585077317.1452534, "_step": 35}
{"Episode reward": -106.76615116876054, "Episode length": 999, "Policy Loss": -14.033729553222656, "Value Loss": 0.03322920948266983, "_runtime": 53.59760928153992, "_timestamp": 1585077318.2892146, "_step": 36}
{"Episode reward": -108.12511283600485, "Episode length": 999, "Policy Loss": -14.354485511779785, "Value Loss": 0.03753010183572769, "_runtime": 54.691938400268555, "_timestamp": 1585077319.3835437, "_step": 37}
{"Episode reward": -98.27520413317328, "Episode length": 999, "Policy Loss": -12.597342491149902, "Value Loss": 0.02853875607252121, "_runtime": 55.80854392051697, "_timestamp": 1585077320.5001493, "_step": 38}
{"Episode reward": -97.85508776675928, "Episode length": 999, "Policy Loss": -12.439085006713867, "Value Loss": 0.02803526446223259, "_runtime": 56.95152401924133, "_timestamp": 1585077321.6431293, "_step": 39}
{"Episode reward": -95.80711058299148, "Episode length": 999, "Policy Loss": -12.026315689086914, "Value Loss": 0.02660227380692959, "_runtime": 58.04161834716797, "_timestamp": 1585077322.7332237, "_step": 40}
{"Episode reward": -104.84965658716169, "Episode length": 999, "Policy Loss": -13.562053680419922, "Value Loss": 0.033428892493247986, "_runtime": 59.18430829048157, "_timestamp": 1585077323.8759136, "_step": 41}
{"Episode reward": -100.13910920670956, "Episode length": 999, "Policy Loss": -12.80076789855957, "Value Loss": 0.033450085669755936, "_runtime": 60.29896783828735, "_timestamp": 1585077324.9905732, "_step": 42}
{"Episode reward": -98.48794727998052, "Episode length": 999, "Policy Loss": -12.538800239562988, "Value Loss": 0.031760137528181076, "_runtime": 61.46549940109253, "_timestamp": 1585077326.1571047, "_step": 43}
{"Episode reward": -103.61315157048622, "Episode length": 999, "Policy Loss": -13.233073234558105, "Value Loss": 0.030912043526768684, "_runtime": 62.61690545082092, "_timestamp": 1585077327.3085108, "_step": 44}
{"Episode reward": -103.77008411776968, "Episode length": 999, "Policy Loss": -13.37336254119873, "Value Loss": 0.032301828265190125, "_runtime": 63.73893880844116, "_timestamp": 1585077328.4305441, "_step": 45}
{"Episode reward": -107.38165486610374, "Episode length": 999, "Policy Loss": -14.308454513549805, "Value Loss": 0.03824106231331825, "_runtime": 64.86696577072144, "_timestamp": 1585077329.558571, "_step": 46}
{"Episode reward": -98.9115776683693, "Episode length": 999, "Policy Loss": -12.701254844665527, "Value Loss": 0.030232766643166542, "_runtime": 65.99463081359863, "_timestamp": 1585077330.6862361, "_step": 47}
{"Episode reward": -91.08093448432433, "Episode length": 999, "Policy Loss": -11.468448638916016, "Value Loss": 0.027038684114813805, "_runtime": 67.11563014984131, "_timestamp": 1585077331.8072355, "_step": 48}
{"Episode reward": -104.27542884290908, "Episode length": 999, "Policy Loss": -13.796270370483398, "Value Loss": 0.03534222021698952, "_runtime": 68.23066186904907, "_timestamp": 1585077332.9222672, "_step": 49}
{"Episode reward": -102.40740553930573, "Episode length": 999, "Policy Loss": -13.099937438964844, "Value Loss": 0.03425920754671097, "_runtime": 69.36981654167175, "_timestamp": 1585077334.0614219, "_step": 50}
{"Episode reward": -95.04917621480253, "Episode length": 999, "Policy Loss": -12.005558967590332, "Value Loss": 0.027158016338944435, "_runtime": 70.46143794059753, "_timestamp": 1585077335.1530433, "_step": 51}
{"Episode reward": -101.35157083386551, "Episode length": 999, "Policy Loss": -13.165473937988281, "Value Loss": 0.03319399803876877, "_runtime": 71.62067651748657, "_timestamp": 1585077336.3122818, "_step": 52}
{"Episode reward": -92.38997248536586, "Episode length": 999, "Policy Loss": -11.704631805419922, "Value Loss": 0.02437693253159523, "_runtime": 72.7539849281311, "_timestamp": 1585077337.4455903, "_step": 53}
{"Episode reward": -100.03835860249096, "Episode length": 999, "Policy Loss": -13.133545875549316, "Value Loss": 0.03020600415766239, "_runtime": 73.87789607048035, "_timestamp": 1585077338.5695014, "_step": 54}
{"Episode reward": -99.34127417991053, "Episode length": 999, "Policy Loss": -12.643745422363281, "Value Loss": 0.02831360325217247, "_runtime": 75.04584550857544, "_timestamp": 1585077339.7374508, "_step": 55}
{"Episode reward": -112.19943376175125, "Episode length": 999, "Policy Loss": -15.119874000549316, "Value Loss": 0.03578456491231918, "_runtime": 76.24813604354858, "_timestamp": 1585077340.9397414, "_step": 56}
{"Episode reward": -101.39664033348897, "Episode length": 999, "Policy Loss": -13.25261116027832, "Value Loss": 0.030782070010900497, "_runtime": 77.38145089149475, "_timestamp": 1585077342.0730562, "_step": 57}
{"Episode reward": -109.21986821062805, "Episode length": 999, "Policy Loss": -14.602230072021484, "Value Loss": 0.03380782529711723, "_runtime": 78.52269458770752, "_timestamp": 1585077343.2143, "_step": 58}
{"Episode reward": -98.6591760337077, "Episode length": 999, "Policy Loss": -12.582149505615234, "Value Loss": 0.02816810831427574, "_runtime": 79.62980127334595, "_timestamp": 1585077344.3214066, "_step": 59}
{"Episode reward": -109.50066209734455, "Episode length": 999, "Policy Loss": -14.951026916503906, "Value Loss": 0.03758975490927696, "_runtime": 80.73356866836548, "_timestamp": 1585077345.425174, "_step": 60}
{"Episode reward": -95.09824440993087, "Episode length": 999, "Policy Loss": -12.04492473602295, "Value Loss": 0.02965153381228447, "_runtime": 81.92527770996094, "_timestamp": 1585077346.616883, "_step": 61}
{"Episode reward": -104.4725635154052, "Episode length": 999, "Policy Loss": -13.709810256958008, "Value Loss": 0.031204132363200188, "_runtime": 83.08299541473389, "_timestamp": 1585077347.7746007, "_step": 62}
{"Episode reward": -93.85840010741866, "Episode length": 999, "Policy Loss": -11.87766170501709, "Value Loss": 0.024469202384352684, "_runtime": 84.21537685394287, "_timestamp": 1585077348.9069822, "_step": 63}
{"Episode reward": -95.64910228157879, "Episode length": 999, "Policy Loss": -12.297356605529785, "Value Loss": 0.028423016890883446, "_runtime": 85.3527524471283, "_timestamp": 1585077350.0443578, "_step": 64}
{"Episode reward": -100.93780152796832, "Episode length": 999, "Policy Loss": -12.861787796020508, "Value Loss": 0.031395066529512405, "_runtime": 86.46350836753845, "_timestamp": 1585077351.1551137, "_step": 65}
{"Episode reward": -99.29571495994648, "Episode length": 999, "Policy Loss": -12.96871280670166, "Value Loss": 0.027030428871512413, "_runtime": 87.59336519241333, "_timestamp": 1585077352.2849705, "_step": 66}
{"Episode reward": -95.31879489336693, "Episode length": 999, "Policy Loss": -11.91358757019043, "Value Loss": 0.026120280846953392, "_runtime": 88.72561073303223, "_timestamp": 1585077353.417216, "_step": 67}
{"Episode reward": -92.23414427307613, "Episode length": 999, "Policy Loss": -11.420005798339844, "Value Loss": 0.02535424195230007, "_runtime": 89.83752393722534, "_timestamp": 1585077354.5291293, "_step": 68}
{"Episode reward": -103.38001598039074, "Episode length": 999, "Policy Loss": -13.577362060546875, "Value Loss": 0.03207837790250778, "_runtime": 91.01217436790466, "_timestamp": 1585077355.7037797, "_step": 69}
{"Episode reward": -102.36048546519989, "Episode length": 999, "Policy Loss": -13.559184074401855, "Value Loss": 0.028644302859902382, "_runtime": 92.1552381515503, "_timestamp": 1585077356.8468435, "_step": 70}
{"Episode reward": -103.74946380226619, "Episode length": 999, "Policy Loss": -13.593029022216797, "Value Loss": 0.032195113599300385, "_runtime": 93.32352948188782, "_timestamp": 1585077358.0151348, "_step": 71}
{"Episode reward": -98.56122307561874, "Episode length": 999, "Policy Loss": -12.611888885498047, "Value Loss": 0.02905704267323017, "_runtime": 94.5128104686737, "_timestamp": 1585077359.2044158, "_step": 72}
{"Episode reward": -98.44599404285856, "Episode length": 999, "Policy Loss": -12.589959144592285, "Value Loss": 0.030490774661302567, "_runtime": 95.69776844978333, "_timestamp": 1585077360.3893738, "_step": 73}
{"Episode reward": -100.68827316722401, "Episode length": 999, "Policy Loss": -12.905508995056152, "Value Loss": 0.030484508723020554, "_runtime": 96.85260057449341, "_timestamp": 1585077361.544206, "_step": 74}
{"Episode reward": -103.09054283994705, "Episode length": 999, "Policy Loss": -13.565840721130371, "Value Loss": 0.030324235558509827, "_runtime": 97.97611904144287, "_timestamp": 1585077362.6677244, "_step": 75}
{"Episode reward": -98.26544649262739, "Episode length": 999, "Policy Loss": -12.576103210449219, "Value Loss": 0.03199945017695427, "_runtime": 99.11145234107971, "_timestamp": 1585077363.8030577, "_step": 76}
{"Episode reward": -104.12283006116458, "Episode length": 999, "Policy Loss": -13.564270973205566, "Value Loss": 0.029789891093969345, "_runtime": 100.22935175895691, "_timestamp": 1585077364.920957, "_step": 77}
{"Episode reward": -95.27159362764249, "Episode length": 999, "Policy Loss": -12.1890230178833, "Value Loss": 0.0271445345133543, "_runtime": 101.38016986846924, "_timestamp": 1585077366.0717752, "_step": 78}
{"Episode reward": -107.39255311769429, "Episode length": 999, "Policy Loss": -14.49338150024414, "Value Loss": 0.035191792994737625, "_runtime": 102.5220627784729, "_timestamp": 1585077367.213668, "_step": 79}
{"Episode reward": -99.52890002507928, "Episode length": 999, "Policy Loss": -12.727712631225586, "Value Loss": 0.03035937435925007, "_runtime": 103.66668224334717, "_timestamp": 1585077368.3582876, "_step": 80}
{"Episode reward": -102.2945155329501, "Episode length": 999, "Policy Loss": -13.201508522033691, "Value Loss": 0.030987391248345375, "_runtime": 104.81773209571838, "_timestamp": 1585077369.5093374, "_step": 81}
{"Episode reward": -97.70582104671502, "Episode length": 999, "Policy Loss": -12.5964937210083, "Value Loss": 0.02945372276008129, "_runtime": 105.9386727809906, "_timestamp": 1585077370.630278, "_step": 82}
{"Episode reward": -105.94824684015511, "Episode length": 999, "Policy Loss": -14.090082168579102, "Value Loss": 0.031746648252010345, "_runtime": 107.07736253738403, "_timestamp": 1585077371.7689679, "_step": 83}
{"Episode reward": -92.2357464271985, "Episode length": 999, "Policy Loss": -11.697463989257812, "Value Loss": 0.02521914429962635, "_runtime": 108.31310248374939, "_timestamp": 1585077373.0047078, "_step": 84}
{"Episode reward": -105.79257117414267, "Episode length": 999, "Policy Loss": -13.936297416687012, "Value Loss": 0.03370729461312294, "_runtime": 109.46529173851013, "_timestamp": 1585077374.156897, "_step": 85}
{"Episode reward": -104.81811339247272, "Episode length": 999, "Policy Loss": -13.842268943786621, "Value Loss": 0.034585438668727875, "_runtime": 110.58586835861206, "_timestamp": 1585077375.2774737, "_step": 86}
{"Episode reward": -104.97879360377911, "Episode length": 999, "Policy Loss": -13.773873329162598, "Value Loss": 0.03195905312895775, "_runtime": 111.75841093063354, "_timestamp": 1585077376.4500163, "_step": 87}
{"Episode reward": -97.8905614896406, "Episode length": 999, "Policy Loss": -12.413249969482422, "Value Loss": 0.029386339709162712, "_runtime": 112.94982266426086, "_timestamp": 1585077377.641428, "_step": 88}
{"Episode reward": -108.48080591074554, "Episode length": 999, "Policy Loss": -14.423059463500977, "Value Loss": 0.034640971571207047, "_runtime": 114.12646746635437, "_timestamp": 1585077378.8180728, "_step": 89}
{"Episode reward": -97.29833527366881, "Episode length": 999, "Policy Loss": -12.297965049743652, "Value Loss": 0.029781289398670197, "_runtime": 115.27145910263062, "_timestamp": 1585077379.9630644, "_step": 90}
{"Episode reward": -105.64305159811133, "Episode length": 999, "Policy Loss": -13.73779010772705, "Value Loss": 0.032307419925928116, "_runtime": 116.42844438552856, "_timestamp": 1585077381.1200497, "_step": 91}
{"Episode reward": -99.73052340857286, "Episode length": 999, "Policy Loss": -12.781866073608398, "Value Loss": 0.03155573457479477, "_runtime": 117.56968379020691, "_timestamp": 1585077382.2612891, "_step": 92}
{"Episode reward": -103.41662580971733, "Episode length": 999, "Policy Loss": -13.69881534576416, "Value Loss": 0.033896081149578094, "_runtime": 118.74678492546082, "_timestamp": 1585077383.4383903, "_step": 93}
{"Episode reward": -105.72429098693061, "Episode length": 999, "Policy Loss": -13.80123233795166, "Value Loss": 0.03098304755985737, "_runtime": 119.92182755470276, "_timestamp": 1585077384.613433, "_step": 94}
{"Episode reward": -95.93128777342037, "Episode length": 999, "Policy Loss": -11.915017127990723, "Value Loss": 0.026521116495132446, "_runtime": 121.11896753311157, "_timestamp": 1585077385.8105729, "_step": 95}
{"Episode reward": -94.60008507574096, "Episode length": 999, "Policy Loss": -12.044827461242676, "Value Loss": 0.02722991071641445, "_runtime": 122.31053066253662, "_timestamp": 1585077387.002136, "_step": 96}
{"Episode reward": -103.61221476416854, "Episode length": 999, "Policy Loss": -13.644142150878906, "Value Loss": 0.0313703790307045, "_runtime": 123.47574663162231, "_timestamp": 1585077388.167352, "_step": 97}
{"Episode reward": -95.5185058654811, "Episode length": 999, "Policy Loss": -12.256895065307617, "Value Loss": 0.028762253001332283, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125, 535.71923828125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-298.82843017578125, -286.0753173828125, -273.3221740722656, -260.5690612792969, -247.81593322753906, -235.06280517578125, -222.30967712402344, -209.55654907226562, -196.80343627929688, -184.05029296875, -171.29718017578125, -158.54405212402344, -145.79092407226562, -133.0377960205078, -120.28468322753906, -107.53155517578125, -94.77842712402344, -82.02529907226562, -69.27217102050781, -56.51905822753906, -43.76593017578125, -31.012786865234375, -18.259674072265625, -5.506561279296875, 7.24658203125, 19.99969482421875, 32.752838134765625, 45.505950927734375, 58.259063720703125, 71.01220703125, 83.76531982421875, 96.51846313476562, 109.27157592773438, 122.02468872070312, 134.77783203125, 147.53094482421875, 160.28408813476562, 173.03720092773438, 185.79031372070312, 198.54345703125, 211.29656982421875, 224.0496826171875, 236.8028564453125, 249.55596923828125, 262.30908203125, 275.06219482421875, 287.8153076171875, 300.5684814453125, 313.32159423828125, 326.07470703125, 338.82781982421875, 351.5809326171875, 364.3341064453125, 377.08721923828125, 389.84033203125, 402.59344482421875, 415.3465576171875, 428.0997314453125, 440.85284423828125, 453.60595703125, 466.35906982421875, 479.1121826171875, 491.8653564453125, 504.61846923828125, 517.37158203125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-293.6783142089844, -285.0786437988281, -276.4789733886719, -267.8792724609375, -259.27960205078125, -250.679931640625, -242.08026123046875, -233.4805908203125, -224.8809051513672, -216.28121948242188, -207.68154907226562, -199.08187866210938, -190.48220825195312, -181.8825225830078, -173.28285217285156, -164.68316650390625, -156.08349609375, -147.48382568359375, -138.88414001464844, -130.2844696044922, -121.68478393554688, -113.08511352539062, -104.48544311523438, -95.88575744628906, -87.28608703613281, -78.68641662597656, -70.08673095703125, -61.487060546875, -52.88739013671875, -44.28770446777344, -35.688018798828125, -27.088348388671875, -18.488677978515625, -9.889007568359375, -1.289337158203125, 7.31036376953125, 15.9100341796875, 24.50970458984375, 33.109375, 41.70904541015625, 50.308746337890625, 58.908416748046875, 67.50808715820312, 76.10775756835938, 84.70742797851562, 93.30709838867188, 101.90679931640625, 110.5064697265625, 119.10614013671875, 127.705810546875, 136.30548095703125, 144.90518188476562, 153.50485229492188, 162.10452270507812, 170.70419311523438, 179.30386352539062, 187.90353393554688, 196.50323486328125, 205.1029052734375, 213.70257568359375, 222.30227661132812, 230.90194702148438, 239.50161743164062, 248.10128784179688, 256.7009582519531]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 8.0, 5.0, 6.0, 7.0, 5.0, 13.0, 11.0, 14.0, 10.0, 13.0, 18.0, 11.0, 25.0, 47.0, 48.0, 40.0, 38.0, 22.0, 29.0, 31.0, 16.0, 15.0, 14.0, 3.0, 7.0, 6.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-258.2201232910156, -250.65875244140625, -243.09738159179688, -235.53602600097656, -227.9746551513672, -220.4132843017578, -212.8519287109375, -205.29055786132812, -197.72918701171875, -190.16781616210938, -182.6064453125, -175.0450897216797, -167.4837188720703, -159.92234802246094, -152.36099243164062, -144.79962158203125, -137.23825073242188, -129.6768798828125, -122.11550903320312, -114.55415344238281, -106.99278259277344, -99.43141174316406, -91.87005615234375, -84.30868530273438, -76.747314453125, -69.18594360351562, -61.62457275390625, -54.06321716308594, -46.50184631347656, -38.94047546386719, -31.379119873046875, -23.8177490234375, -16.256378173828125, -8.69500732421875, -1.133636474609375, 6.427734375, 13.989105224609375, 21.550445556640625, 29.11181640625, 36.673187255859375, 44.23455810546875, 51.795928955078125, 59.3572998046875, 66.91867065429688, 74.48001098632812, 82.0413818359375, 89.60275268554688, 97.16412353515625, 104.72549438476562, 112.286865234375, 119.84823608398438, 127.40960693359375, 134.97097778320312, 142.53231811523438, 150.09368896484375, 157.65505981445312, 165.2164306640625, 172.77780151367188, 180.33917236328125, 187.90054321289062, 195.46188354492188, 203.02325439453125, 210.58462524414062, 218.14599609375, 225.70736694335938]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-113.10986328125, -108.12821960449219, -103.14656829833984, -98.1649169921875, -93.18327331542969, -88.20162963867188, -83.21997833251953, -78.23832702636719, -73.25668334960938, -68.27503967285156, -63.29338836669922, -58.31174087524414, -53.33009338378906, -48.34844970703125, -43.366798400878906, -38.38514709472656, -33.40350341796875, -28.421859741210938, -23.440208435058594, -18.45855712890625, -13.476913452148438, -8.495269775390625, -3.5136184692382812, 1.4680328369140625, 6.449676513671875, 11.431320190429688, 16.4129638671875, 21.394622802734375, 26.376266479492188, 31.35791015625, 36.339569091796875, 41.32121276855469, 46.3028564453125, 51.28450012207031, 56.266143798828125, 61.247802734375, 66.22944641113281, 71.21109008789062, 76.1927490234375, 81.17439270019531, 86.15603637695312, 91.13768005371094, 96.11932373046875, 101.10098266601562, 106.08262634277344, 111.06427001953125, 116.04592895507812, 121.02757263183594, 126.00921630859375, 130.99085998535156, 135.97250366210938, 140.95416259765625, 145.935791015625, 150.91744995117188, 155.89910888671875, 160.8807373046875, 165.86239624023438, 170.84405517578125, 175.82568359375, 180.80734252929688, 185.78900146484375, 190.7706298828125, 195.75228881835938, 200.73391723632812, 205.715576171875]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 32.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-135.41751098632812, -132.15431213378906, -128.89109802246094, -125.62789154052734, -122.36468505859375, -119.10148620605469, -115.83827209472656, -112.5750732421875, -109.3118667602539, -106.04866027832031, -102.78545379638672, -99.52224731445312, -96.25904083251953, -92.99583435058594, -89.73263549804688, -86.46942138671875, -83.20622253417969, -79.94300842285156, -76.6798095703125, -73.4166030883789, -70.15339660644531, -66.89019012451172, -63.626983642578125, -60.36377716064453, -57.10057067871094, -53.837364196777344, -50.57415771484375, -47.31095886230469, -44.047752380371094, -40.7845458984375, -37.521339416503906, -34.25813293457031, -30.99492645263672, -27.731719970703125, -24.46851348876953, -21.205307006835938, -17.942100524902344, -14.67889404296875, -11.415695190429688, -8.152488708496094, -4.8892822265625, -1.626068115234375, 1.6371307373046875, 4.90032958984375, 8.163543701171875, 11.426742553710938, 14.689956665039062, 17.953155517578125, 21.21636962890625, 24.479568481445312, 27.742782592773438, 31.0059814453125, 34.269195556640625, 37.53239440917969, 40.79559326171875, 44.058807373046875, 47.32200622558594, 50.58522033691406, 53.848419189453125, 57.11163330078125, 60.37483215332031, 63.63804626464844, 66.9012451171875, 70.16445922851562, 73.42765808105469]}, "_runtime": 124.60407376289368, "_timestamp": 1585077389.295679, "_step": 98}
{"Episode reward": -98.04101271358417, "Episode length": 999, "Policy Loss": -12.470027923583984, "Value Loss": 0.02600873075425625, "_runtime": 125.7421932220459, "_timestamp": 1585077390.4337986, "_step": 99}
{"Episode reward": -101.02424349729847, "Episode length": 999, "Policy Loss": -13.179636001586914, "Value Loss": 0.03232075646519661, "_runtime": 126.86477279663086, "_timestamp": 1585077391.5563781, "_step": 100}
{"Episode reward": -94.38704586165777, "Episode length": 999, "Policy Loss": -11.697656631469727, "Value Loss": 0.027388347312808037, "_runtime": 127.998215675354, "_timestamp": 1585077392.689821, "_step": 101}
{"Episode reward": -95.46359552244735, "Episode length": 999, "Policy Loss": -12.00384521484375, "Value Loss": 0.026845194399356842, "_runtime": 129.14991354942322, "_timestamp": 1585077393.8415189, "_step": 102}
{"Episode reward": -99.48962739625763, "Episode length": 999, "Policy Loss": -12.691579818725586, "Value Loss": 0.028496213257312775, "_runtime": 130.26155257225037, "_timestamp": 1585077394.953158, "_step": 103}
{"Episode reward": -104.41335163259784, "Episode length": 999, "Policy Loss": -13.659723281860352, "Value Loss": 0.03153059259057045, "_runtime": 131.41420936584473, "_timestamp": 1585077396.1058147, "_step": 104}
{"Episode reward": -99.83469221702615, "Episode length": 999, "Policy Loss": -12.651248931884766, "Value Loss": 0.03005068562924862, "_runtime": 132.60235714912415, "_timestamp": 1585077397.2939625, "_step": 105}
{"Episode reward": -101.42294235275084, "Episode length": 999, "Policy Loss": -13.031525611877441, "Value Loss": 0.030580513179302216, "_runtime": 133.75724530220032, "_timestamp": 1585077398.4488506, "_step": 106}
{"Episode reward": -106.52531646458011, "Episode length": 999, "Policy Loss": -14.074105262756348, "Value Loss": 0.03146234154701233, "_runtime": 134.89163517951965, "_timestamp": 1585077399.5832405, "_step": 107}
{"Episode reward": -105.09610696973577, "Episode length": 999, "Policy Loss": -13.877911567687988, "Value Loss": 0.03417669236660004, "_runtime": 136.05654954910278, "_timestamp": 1585077400.7481549, "_step": 108}
{"Episode reward": -100.83298727201056, "Episode length": 999, "Policy Loss": -12.798711776733398, "Value Loss": 0.028519857674837112, "_runtime": 137.2240755558014, "_timestamp": 1585077401.915681, "_step": 109}
{"Episode reward": -98.32745601205681, "Episode length": 999, "Policy Loss": -12.47152042388916, "Value Loss": 0.03120848350226879, "_runtime": 138.42579245567322, "_timestamp": 1585077403.1173978, "_step": 110}
{"Episode reward": -96.39735039587346, "Episode length": 999, "Policy Loss": -12.190730094909668, "Value Loss": 0.028029704466462135, "_runtime": 139.57427549362183, "_timestamp": 1585077404.2658808, "_step": 111}
{"Episode reward": -103.97787997284473, "Episode length": 999, "Policy Loss": -13.841377258300781, "Value Loss": 0.03320833668112755, "_runtime": 140.75602746009827, "_timestamp": 1585077405.4476328, "_step": 112}
{"Episode reward": -101.25140879046862, "Episode length": 999, "Policy Loss": -13.310620307922363, "Value Loss": 0.030871722847223282, "_runtime": 141.93364691734314, "_timestamp": 1585077406.6252522, "_step": 113}
{"Episode reward": -97.77316035329409, "Episode length": 999, "Policy Loss": -12.445656776428223, "Value Loss": 0.031074192374944687, "_runtime": 143.07892394065857, "_timestamp": 1585077407.7705293, "_step": 114}
{"Episode reward": -96.67449720912671, "Episode length": 999, "Policy Loss": -12.257148742675781, "Value Loss": 0.026376711204648018, "_runtime": 144.25531649589539, "_timestamp": 1585077408.9469218, "_step": 115}
{"Episode reward": -98.40493482991393, "Episode length": 999, "Policy Loss": -12.620966911315918, "Value Loss": 0.028696049004793167, "_runtime": 145.43059706687927, "_timestamp": 1585077410.1222024, "_step": 116}
{"Episode reward": -92.72489340364965, "Episode length": 999, "Policy Loss": -11.597795486450195, "Value Loss": 0.0245567187666893, "_runtime": 146.59848976135254, "_timestamp": 1585077411.290095, "_step": 117}
{"Episode reward": -108.51780227397451, "Episode length": 999, "Policy Loss": -14.361735343933105, "Value Loss": 0.03735095635056496, "_runtime": 147.75709629058838, "_timestamp": 1585077412.4487016, "_step": 118}
{"Episode reward": -103.21303435074302, "Episode length": 999, "Policy Loss": -13.42022705078125, "Value Loss": 0.03317819535732269, "_runtime": 148.86772274971008, "_timestamp": 1585077413.559328, "_step": 119}
{"Episode reward": -100.05867287113972, "Episode length": 999, "Policy Loss": -12.67326545715332, "Value Loss": 0.03228390961885452, "_runtime": 150.04501938819885, "_timestamp": 1585077414.7366247, "_step": 120}
{"Episode reward": -96.99062047958652, "Episode length": 999, "Policy Loss": -12.327380180358887, "Value Loss": 0.03146408125758171, "_runtime": 151.18218350410461, "_timestamp": 1585077415.8737888, "_step": 121}
{"Episode reward": -95.68856744430899, "Episode length": 999, "Policy Loss": -11.899335861206055, "Value Loss": 0.02909950166940689, "_runtime": 152.3897864818573, "_timestamp": 1585077417.0813918, "_step": 122}
{"Episode reward": -109.21258725352756, "Episode length": 999, "Policy Loss": -14.50272274017334, "Value Loss": 0.03469252958893776, "_runtime": 153.54280257225037, "_timestamp": 1585077418.234408, "_step": 123}
{"Episode reward": -94.51045864418771, "Episode length": 999, "Policy Loss": -12.034835815429688, "Value Loss": 0.029214195907115936, "_runtime": 154.6966848373413, "_timestamp": 1585077419.3882902, "_step": 124}
{"Episode reward": -97.67806607516196, "Episode length": 999, "Policy Loss": -12.392339706420898, "Value Loss": 0.02785058133304119, "_runtime": 155.833092212677, "_timestamp": 1585077420.5246975, "_step": 125}
{"Episode reward": -100.78670761234429, "Episode length": 999, "Policy Loss": -12.947367668151855, "Value Loss": 0.03014066256582737, "_runtime": 156.9496669769287, "_timestamp": 1585077421.6412723, "_step": 126}
{"Episode reward": -98.77501576470871, "Episode length": 999, "Policy Loss": -12.687889099121094, "Value Loss": 0.028166573494672775, "_runtime": 158.12054800987244, "_timestamp": 1585077422.8121533, "_step": 127}
{"Episode reward": -104.3809442444691, "Episode length": 999, "Policy Loss": -13.590797424316406, "Value Loss": 0.033989399671554565, "_runtime": 159.31255292892456, "_timestamp": 1585077424.0041583, "_step": 128}
{"Episode reward": -109.42996489177622, "Episode length": 999, "Policy Loss": -14.249532699584961, "Value Loss": 0.03568728268146515, "_runtime": 160.42894005775452, "_timestamp": 1585077425.1205454, "_step": 129}
{"Episode reward": -96.86738473118608, "Episode length": 999, "Policy Loss": -12.399713516235352, "Value Loss": 0.027974333614110947, "_runtime": 161.59535765647888, "_timestamp": 1585077426.286963, "_step": 130}
{"Episode reward": -104.30514102536462, "Episode length": 999, "Policy Loss": -13.68454360961914, "Value Loss": 0.0332762785255909, "_runtime": 162.75103068351746, "_timestamp": 1585077427.442636, "_step": 131}
{"Episode reward": -100.21498977005533, "Episode length": 999, "Policy Loss": -12.992363929748535, "Value Loss": 0.031898949295282364, "_runtime": 163.90734028816223, "_timestamp": 1585077428.5989456, "_step": 132}
{"Episode reward": -100.95513820409283, "Episode length": 999, "Policy Loss": -13.219018936157227, "Value Loss": 0.03107881173491478, "_runtime": 165.08926439285278, "_timestamp": 1585077429.7808697, "_step": 133}
{"Episode reward": -93.98214431047988, "Episode length": 999, "Policy Loss": -11.788187980651855, "Value Loss": 0.028737306594848633, "_runtime": 166.22124528884888, "_timestamp": 1585077430.9128506, "_step": 134}
{"Episode reward": -104.08974902838774, "Episode length": 999, "Policy Loss": -13.616922378540039, "Value Loss": 0.032984647899866104, "_runtime": 167.35953736305237, "_timestamp": 1585077432.0511427, "_step": 135}
{"Episode reward": -104.44573204926692, "Episode length": 999, "Policy Loss": -13.425470352172852, "Value Loss": 0.03228652477264404, "_runtime": 168.52796459197998, "_timestamp": 1585077433.21957, "_step": 136}
{"Episode reward": -109.51671748690198, "Episode length": 999, "Policy Loss": -14.42734432220459, "Value Loss": 0.035100385546684265, "_runtime": 169.65991020202637, "_timestamp": 1585077434.3515155, "_step": 137}
{"Episode reward": -101.96025071498792, "Episode length": 999, "Policy Loss": -13.202835083007812, "Value Loss": 0.028634212911128998, "_runtime": 170.79080200195312, "_timestamp": 1585077435.4824073, "_step": 138}
{"Episode reward": -97.85939428851572, "Episode length": 999, "Policy Loss": -12.228909492492676, "Value Loss": 0.02911265753209591, "_runtime": 171.9665400981903, "_timestamp": 1585077436.6581454, "_step": 139}
{"Episode reward": -102.18113144603369, "Episode length": 999, "Policy Loss": -13.466989517211914, "Value Loss": 0.030423035845160484, "_runtime": 173.10909962654114, "_timestamp": 1585077437.800705, "_step": 140}
{"Episode reward": -104.59787567284681, "Episode length": 999, "Policy Loss": -14.080408096313477, "Value Loss": 0.03026059828698635, "_runtime": 174.27119398117065, "_timestamp": 1585077438.9627993, "_step": 141}
{"Episode reward": -107.4084947875667, "Episode length": 999, "Policy Loss": -14.207965850830078, "Value Loss": 0.03480279818177223, "_runtime": 175.4211916923523, "_timestamp": 1585077440.112797, "_step": 142}
{"Episode reward": -104.32601074388458, "Episode length": 999, "Policy Loss": -13.598133087158203, "Value Loss": 0.034363988786935806, "_runtime": 176.56687879562378, "_timestamp": 1585077441.2584841, "_step": 143}
{"Episode reward": -96.66642075308695, "Episode length": 999, "Policy Loss": -12.245262145996094, "Value Loss": 0.02681235782802105, "_runtime": 177.76575469970703, "_timestamp": 1585077442.45736, "_step": 144}
{"Episode reward": -100.97380118237982, "Episode length": 999, "Policy Loss": -12.919541358947754, "Value Loss": 0.030513739213347435, "_runtime": 178.8664710521698, "_timestamp": 1585077443.5580764, "_step": 145}
{"Episode reward": -97.74827371126281, "Episode length": 999, "Policy Loss": -12.475916862487793, "Value Loss": 0.028938187286257744, "_runtime": 179.97207355499268, "_timestamp": 1585077444.663679, "_step": 146}
{"Episode reward": -98.86398394480659, "Episode length": 999, "Policy Loss": -12.408978462219238, "Value Loss": 0.029713915660977364, "_runtime": 181.09774708747864, "_timestamp": 1585077445.7893524, "_step": 147}
{"Episode reward": -99.19899483033049, "Episode length": 999, "Policy Loss": -12.647377014160156, "Value Loss": 0.02837371826171875, "_runtime": 182.27321767807007, "_timestamp": 1585077446.964823, "_step": 148}
{"Episode reward": -112.48165477512981, "Episode length": 999, "Policy Loss": -15.2791166305542, "Value Loss": 0.041419606655836105, "_runtime": 183.44409942626953, "_timestamp": 1585077448.1357048, "_step": 149}
{"Episode reward": -108.06555547304043, "Episode length": 999, "Policy Loss": -14.095295906066895, "Value Loss": 0.035109151154756546, "_runtime": 184.55707931518555, "_timestamp": 1585077449.2486846, "_step": 150}
{"Episode reward": -98.88592570173654, "Episode length": 999, "Policy Loss": -12.615540504455566, "Value Loss": 0.029025357216596603, "_runtime": 185.68316435813904, "_timestamp": 1585077450.3747697, "_step": 151}
{"Episode reward": -97.75745748325967, "Episode length": 999, "Policy Loss": -12.471963882446289, "Value Loss": 0.02574644610285759, "_runtime": 186.83056688308716, "_timestamp": 1585077451.5221722, "_step": 152}
{"Episode reward": -105.21413243310658, "Episode length": 999, "Policy Loss": -13.57810115814209, "Value Loss": 0.031950533390045166, "_runtime": 187.96883463859558, "_timestamp": 1585077452.66044, "_step": 153}
{"Episode reward": -103.36779477470517, "Episode length": 999, "Policy Loss": -13.225452423095703, "Value Loss": 0.030023634433746338, "_runtime": 189.1002185344696, "_timestamp": 1585077453.7918239, "_step": 154}
{"Episode reward": -103.45093262278017, "Episode length": 999, "Policy Loss": -13.174086570739746, "Value Loss": 0.0302481260150671, "_runtime": 190.2344195842743, "_timestamp": 1585077454.926025, "_step": 155}
{"Episode reward": -102.41632853704331, "Episode length": 999, "Policy Loss": -13.252102851867676, "Value Loss": 0.032125793397426605, "_runtime": 191.43542289733887, "_timestamp": 1585077456.1270282, "_step": 156}
{"Episode reward": -101.32413254069871, "Episode length": 999, "Policy Loss": -12.87502670288086, "Value Loss": 0.029383184388279915, "_runtime": 192.5876488685608, "_timestamp": 1585077457.2792542, "_step": 157}
{"Episode reward": -95.33410383579096, "Episode length": 999, "Policy Loss": -11.972825050354004, "Value Loss": 0.02745725028216839, "_runtime": 193.7373378276825, "_timestamp": 1585077458.4289432, "_step": 158}
{"Episode reward": -98.93787905099975, "Episode length": 999, "Policy Loss": -12.6167631149292, "Value Loss": 0.02762461267411709, "_runtime": 194.88245129585266, "_timestamp": 1585077459.5740566, "_step": 159}
{"Episode reward": -109.04885537921277, "Episode length": 999, "Policy Loss": -14.396866798400879, "Value Loss": 0.03450538218021393, "_runtime": 196.01925086975098, "_timestamp": 1585077460.7108562, "_step": 160}
{"Episode reward": -89.25474879953697, "Episode length": 999, "Policy Loss": -11.00747299194336, "Value Loss": 0.024966560304164886, "_runtime": 197.14011240005493, "_timestamp": 1585077461.8317177, "_step": 161}
{"Episode reward": -102.89351666665978, "Episode length": 999, "Policy Loss": -13.462578773498535, "Value Loss": 0.03370481729507446, "_runtime": 198.25190210342407, "_timestamp": 1585077462.9435074, "_step": 162}
{"Episode reward": -98.40605884570103, "Episode length": 999, "Policy Loss": -12.632786750793457, "Value Loss": 0.030403917655348778, "_runtime": 199.4284451007843, "_timestamp": 1585077464.1200504, "_step": 163}
{"Episode reward": -102.90522903798612, "Episode length": 999, "Policy Loss": -13.095664024353027, "Value Loss": 0.031331777572631836, "_runtime": 200.53359532356262, "_timestamp": 1585077465.2252007, "_step": 164}
{"Episode reward": -94.13052449435355, "Episode length": 999, "Policy Loss": -11.76520824432373, "Value Loss": 0.027555489912629128, "_runtime": 201.72782278060913, "_timestamp": 1585077466.419428, "_step": 165}
{"Episode reward": -108.53874955413207, "Episode length": 999, "Policy Loss": -14.254154205322266, "Value Loss": 0.03464539349079132, "_runtime": 202.87054181098938, "_timestamp": 1585077467.5621471, "_step": 166}
{"Episode reward": -97.48049390514561, "Episode length": 999, "Policy Loss": -12.246729850769043, "Value Loss": 0.02687932550907135, "_runtime": 204.05411958694458, "_timestamp": 1585077468.745725, "_step": 167}
{"Episode reward": -102.9394409448077, "Episode length": 999, "Policy Loss": -13.485711097717285, "Value Loss": 0.029946187511086464, "_runtime": 205.21444606781006, "_timestamp": 1585077469.9060514, "_step": 168}
{"Episode reward": -104.55542905552166, "Episode length": 999, "Policy Loss": -13.733074188232422, "Value Loss": 0.03340081498026848, "_runtime": 206.34247207641602, "_timestamp": 1585077471.0340774, "_step": 169}
{"Episode reward": -102.73846616088807, "Episode length": 999, "Policy Loss": -13.275198936462402, "Value Loss": 0.029882794246077538, "_runtime": 207.51299953460693, "_timestamp": 1585077472.2046049, "_step": 170}
{"Episode reward": -97.4338765910541, "Episode length": 999, "Policy Loss": -12.55942440032959, "Value Loss": 0.030079573392868042, "_runtime": 208.63470458984375, "_timestamp": 1585077473.32631, "_step": 171}
{"Episode reward": -97.8501761389858, "Episode length": 999, "Policy Loss": -12.366965293884277, "Value Loss": 0.031409796327352524, "_runtime": 209.76599788665771, "_timestamp": 1585077474.4576032, "_step": 172}
{"Episode reward": -96.86618830023787, "Episode length": 999, "Policy Loss": -12.604175567626953, "Value Loss": 0.030659319832921028, "_runtime": 210.88821649551392, "_timestamp": 1585077475.5798218, "_step": 173}
{"Episode reward": -98.74285243061884, "Episode length": 999, "Policy Loss": -12.463571548461914, "Value Loss": 0.027491599321365356, "_runtime": 212.03668332099915, "_timestamp": 1585077476.7282887, "_step": 174}
{"Episode reward": -111.06198111465517, "Episode length": 999, "Policy Loss": -14.607076644897461, "Value Loss": 0.03746558353304863, "_runtime": 213.22961401939392, "_timestamp": 1585077477.9212193, "_step": 175}
{"Episode reward": -102.88001918699567, "Episode length": 999, "Policy Loss": -13.222550392150879, "Value Loss": 0.032677821815013885, "_runtime": 214.4216594696045, "_timestamp": 1585077479.1132648, "_step": 176}
{"Episode reward": -96.58093602348855, "Episode length": 999, "Policy Loss": -12.264420509338379, "Value Loss": 0.026984650641679764, "_runtime": 215.56130290031433, "_timestamp": 1585077480.2529082, "_step": 177}
{"Episode reward": -93.32451025163121, "Episode length": 999, "Policy Loss": -11.717578887939453, "Value Loss": 0.026663968339562416, "_runtime": 216.71723866462708, "_timestamp": 1585077481.408844, "_step": 178}
{"Episode reward": -97.0620335500424, "Episode length": 999, "Policy Loss": -12.394647598266602, "Value Loss": 0.030854757875204086, "_runtime": 217.86338019371033, "_timestamp": 1585077482.5549855, "_step": 179}
{"Episode reward": -99.11360324835923, "Episode length": 999, "Policy Loss": -12.419646263122559, "Value Loss": 0.030586743727326393, "_runtime": 218.97462034225464, "_timestamp": 1585077483.6662257, "_step": 180}
{"Episode reward": -101.2030847574658, "Episode length": 999, "Policy Loss": -13.12013053894043, "Value Loss": 0.03134830296039581, "_runtime": 220.1067521572113, "_timestamp": 1585077484.7983575, "_step": 181}
{"Episode reward": -100.42809268806613, "Episode length": 999, "Policy Loss": -12.696695327758789, "Value Loss": 0.031556881964206696, "_runtime": 221.26870107650757, "_timestamp": 1585077485.9603064, "_step": 182}
{"Episode reward": -97.87089572901695, "Episode length": 999, "Policy Loss": -12.5206880569458, "Value Loss": 0.03074217587709427, "_runtime": 222.39869284629822, "_timestamp": 1585077487.0902982, "_step": 183}
{"Episode reward": -105.10151828250501, "Episode length": 999, "Policy Loss": -13.913985252380371, "Value Loss": 0.03292908892035484, "_runtime": 223.55909299850464, "_timestamp": 1585077488.2506983, "_step": 184}
{"Episode reward": -102.95543772140442, "Episode length": 999, "Policy Loss": -13.22899341583252, "Value Loss": 0.03169611096382141, "_runtime": 224.6588432788849, "_timestamp": 1585077489.3504486, "_step": 185}
{"Episode reward": -100.41055537955292, "Episode length": 999, "Policy Loss": -12.724031448364258, "Value Loss": 0.02951420657336712, "_runtime": 225.77931022644043, "_timestamp": 1585077490.4709156, "_step": 186}
{"Episode reward": -101.62036916020128, "Episode length": 999, "Policy Loss": -12.757096290588379, "Value Loss": 0.03311725705862045, "_runtime": 226.90303778648376, "_timestamp": 1585077491.594643, "_step": 187}
{"Episode reward": -112.67042090381536, "Episode length": 999, "Policy Loss": -14.873809814453125, "Value Loss": 0.036992039531469345, "_runtime": 228.02684140205383, "_timestamp": 1585077492.7184467, "_step": 188}
{"Episode reward": -97.69643760290384, "Episode length": 999, "Policy Loss": -12.588764190673828, "Value Loss": 0.029406333342194557, "_runtime": 229.20143795013428, "_timestamp": 1585077493.8930433, "_step": 189}
{"Episode reward": -100.03038055746703, "Episode length": 999, "Policy Loss": -13.014548301696777, "Value Loss": 0.02891809493303299, "_runtime": 230.31008315086365, "_timestamp": 1585077495.0016885, "_step": 190}
{"Episode reward": -94.76310272005824, "Episode length": 999, "Policy Loss": -11.848139762878418, "Value Loss": 0.027031902223825455, "_runtime": 231.43761372566223, "_timestamp": 1585077496.129219, "_step": 191}
{"Episode reward": -103.09598993242292, "Episode length": 999, "Policy Loss": -13.424559593200684, "Value Loss": 0.03326931223273277, "_runtime": 232.56232023239136, "_timestamp": 1585077497.2539256, "_step": 192}
{"Episode reward": -97.97423191472123, "Episode length": 999, "Policy Loss": -12.43431568145752, "Value Loss": 0.029098642989993095, "_runtime": 233.72947549819946, "_timestamp": 1585077498.4210808, "_step": 193}
{"Episode reward": -104.98614629300683, "Episode length": 999, "Policy Loss": -13.898931503295898, "Value Loss": 0.032931990921497345, "_runtime": 234.846129655838, "_timestamp": 1585077499.537735, "_step": 194}
{"Episode reward": -108.61441554414472, "Episode length": 999, "Policy Loss": -14.543354988098145, "Value Loss": 0.035479605197906494, "_runtime": 235.97329330444336, "_timestamp": 1585077500.6648986, "_step": 195}
{"Episode reward": -108.63454725617571, "Episode length": 999, "Policy Loss": -14.198084831237793, "Value Loss": 0.03351312503218651, "_runtime": 237.095694065094, "_timestamp": 1585077501.7872994, "_step": 196}
{"Episode reward": -100.67860410698461, "Episode length": 999, "Policy Loss": -12.92180061340332, "Value Loss": 0.031210804358124733, "_runtime": 238.2156822681427, "_timestamp": 1585077502.9072876, "_step": 197}
{"Episode reward": -104.53831945217597, "Episode length": 999, "Policy Loss": -13.594385147094727, "Value Loss": 0.03244777396321297, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422, 251.9753875732422]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-141.38491821289062, -135.3969268798828, -129.40895080566406, -123.42095947265625, -117.43297576904297, -111.44499206542969, -105.45700073242188, -99.4690170288086, -93.48103332519531, -87.49304962158203, -81.50506591796875, -75.51707458496094, -69.52909088134766, -63.541107177734375, -57.55311584472656, -51.56513214111328, -45.5771484375, -39.58916473388672, -33.60118103027344, -27.613189697265625, -21.625205993652344, -15.637222290039062, -9.64923095703125, -3.6612548828125, 2.3267364501953125, 8.314727783203125, 14.302703857421875, 20.290695190429688, 26.2786865234375, 32.26666259765625, 38.25465393066406, 44.24263000488281, 50.230621337890625, 56.21861267089844, 62.20658874511719, 68.194580078125, 74.18255615234375, 80.17054748535156, 86.15853881835938, 92.14651489257812, 98.13450622558594, 104.12249755859375, 110.1104736328125, 116.09844970703125, 122.08645629882812, 128.07443237304688, 134.06240844726562, 140.0504150390625, 146.03839111328125, 152.0263671875, 158.01437377929688, 164.00234985351562, 169.99032592773438, 175.97833251953125, 181.96630859375, 187.95428466796875, 193.94229125976562, 199.93026733398438, 205.91824340820312, 211.90621948242188, 217.89422607421875, 223.8822021484375, 229.87017822265625, 235.85818481445312, 241.84616088867188]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-138.4301300048828, -134.3828582763672, -130.33560180664062, -126.288330078125, -122.24105834960938, -118.19379425048828, -114.14653015136719, -110.09925842285156, -106.05198669433594, -102.00472259521484, -97.95745849609375, -93.91018676757812, -89.86292266845703, -85.81565856933594, -81.76838684082031, -77.72111511230469, -73.6738510131836, -69.6265869140625, -65.57931518554688, -61.53205108642578, -57.484779357910156, -53.43751525878906, -49.39024353027344, -45.342979431152344, -41.29571533203125, -37.248443603515625, -33.20117950439453, -29.153907775878906, -25.106643676757812, -21.059371948242188, -17.012107849121094, -12.964836120605469, -8.917572021484375, -4.87030029296875, -0.8230438232421875, 3.2242279052734375, 7.2714996337890625, 11.318771362304688, 15.36602783203125, 19.413299560546875, 23.4605712890625, 27.507827758789062, 31.555099487304688, 35.60237121582031, 39.64964294433594, 43.6968994140625, 47.744171142578125, 51.79144287109375, 55.83869934082031, 59.88597106933594, 63.93324279785156, 67.98051452636719, 72.02777099609375, 76.07504272460938, 80.122314453125, 84.16958618164062, 88.21684265136719, 92.26411437988281, 96.31138610839844, 100.358642578125, 104.40591430664062, 108.45318603515625, 112.50045776367188, 116.54771423339844, 120.59498596191406]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 5.0, 7.0, 6.0, 4.0, 8.0, 8.0, 12.0, 12.0, 13.0, 9.0, 11.0, 17.0, 16.0, 20.0, 47.0, 42.0, 47.0, 35.0, 25.0, 25.0, 30.0, 19.0, 11.0, 17.0, 5.0, 8.0, 3.0, 6.0, 2.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-119.24505615234375, -115.7586898803711, -112.27233123779297, -108.78596496582031, -105.29960632324219, -101.81324005126953, -98.3268814086914, -94.84051513671875, -91.35415649414062, -87.86779022216797, -84.38142395019531, -80.89506530761719, -77.40870666503906, -73.9223403930664, -70.43597412109375, -66.94961547851562, -63.463253021240234, -59.976890563964844, -56.49052810668945, -53.00416564941406, -49.517799377441406, -46.03144073486328, -42.545074462890625, -39.0587158203125, -35.572349548339844, -32.08599090576172, -28.599624633789062, -25.113265991210938, -21.62689971923828, -18.140541076660156, -14.6541748046875, -11.167816162109375, -7.681449890136719, -4.1950836181640625, -0.7087249755859375, 2.7776412963867188, 6.263999938964844, 9.7503662109375, 13.236724853515625, 16.72308349609375, 20.209457397460938, 23.695816040039062, 27.182174682617188, 30.668533325195312, 34.1549072265625, 37.641265869140625, 41.12762451171875, 44.613983154296875, 48.10035705566406, 51.58671569824219, 55.07307434082031, 58.5594482421875, 62.045806884765625, 65.53216552734375, 69.01852416992188, 72.50489807128906, 75.99125671386719, 79.47761535644531, 82.96397399902344, 86.45034790039062, 89.93670654296875, 93.42306518554688, 96.909423828125, 100.39579772949219, 103.88215637207031]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-57.065956115722656, -54.629615783691406, -52.193275451660156, -49.756935119628906, -47.320594787597656, -44.884254455566406, -42.44791793823242, -40.01157760620117, -37.57523727416992, -35.13889694213867, -32.70255661010742, -30.266218185424805, -27.829877853393555, -25.393537521362305, -22.957199096679688, -20.520858764648438, -18.084518432617188, -15.648178100585938, -13.211837768554688, -10.775497436523438, -8.339157104492188, -5.902820587158203, -3.466480255126953, -1.0301399230957031, 1.4062004089355469, 3.842540740966797, 6.278881072998047, 8.715217590332031, 11.151557922363281, 13.587898254394531, 16.02423858642578, 18.46057891845703, 20.89691925048828, 23.33325958251953, 25.76959991455078, 28.20594024658203, 30.64228057861328, 33.07862091064453, 35.51496124267578, 37.95130157470703, 40.38764190673828, 42.823974609375, 45.26031494140625, 47.6966552734375, 50.13299560546875, 52.5693359375, 55.00567626953125, 57.4420166015625, 59.87835693359375, 62.314697265625, 64.75103759765625, 67.1873779296875, 69.62371826171875, 72.06005096435547, 74.49639129638672, 76.93273162841797, 79.36907196044922, 81.80541229248047, 84.24175262451172, 86.67809295654297, 89.11443328857422, 91.55077362060547, 93.98711395263672, 96.42345428466797, 98.85979461669922]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 11.0, 12.0, 7.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-55.90864562988281, -54.519737243652344, -53.130828857421875, -51.741920471191406, -50.35301208496094, -48.964107513427734, -47.575199127197266, -46.1862907409668, -44.79738235473633, -43.40847396850586, -42.01956558227539, -40.63066101074219, -39.24175262451172, -37.85284423828125, -36.46393585205078, -35.07502746582031, -33.686119079589844, -32.297210693359375, -30.908302307128906, -29.51939582824707, -28.1304874420166, -26.741579055786133, -25.352672576904297, -23.963764190673828, -22.57485580444336, -21.18594741821289, -19.797039031982422, -18.408130645751953, -17.01922607421875, -15.630317687988281, -14.241409301757812, -12.852500915527344, -11.463592529296875, -10.074684143066406, -8.685775756835938, -7.296867370605469, -5.907958984375, -4.519054412841797, -3.130146026611328, -1.7412376403808594, -0.3523292541503906, 1.0365791320800781, 2.425487518310547, 3.8143959045410156, 5.203300476074219, 6.5922088623046875, 7.981117248535156, 9.370025634765625, 10.758934020996094, 12.147842407226562, 13.536750793457031, 14.9256591796875, 16.31456756591797, 17.703475952148438, 19.092384338378906, 20.481292724609375, 21.870193481445312, 23.25910186767578, 24.64801025390625, 26.03691864013672, 27.425827026367188, 28.814735412597656, 30.203643798828125, 31.592552185058594, 32.98146057128906]}, "_runtime": 239.34813594818115, "_timestamp": 1585077504.0397413, "_step": 198}
{"Episode reward": -102.28382922691006, "Episode length": 999, "Policy Loss": -13.043985366821289, "Value Loss": 0.02842748537659645, "_runtime": 240.5092625617981, "_timestamp": 1585077505.200868, "_step": 199}
{"Episode reward": -99.22325514087157, "Episode length": 999, "Policy Loss": -12.848289489746094, "Value Loss": 0.030790502205491066, "_runtime": 241.70035529136658, "_timestamp": 1585077506.3919606, "_step": 200}
{"Episode reward": -103.81004236543016, "Episode length": 999, "Policy Loss": -13.627275466918945, "Value Loss": 0.03192882984876633, "_runtime": 242.8300461769104, "_timestamp": 1585077507.5216515, "_step": 201}
{"Episode reward": -99.49084420976702, "Episode length": 999, "Policy Loss": -12.791403770446777, "Value Loss": 0.027598701417446136, "_runtime": 243.99843549728394, "_timestamp": 1585077508.6900408, "_step": 202}
{"Episode reward": -109.45401620989361, "Episode length": 999, "Policy Loss": -14.673911094665527, "Value Loss": 0.03584462031722069, "_runtime": 245.18912625312805, "_timestamp": 1585077509.8807316, "_step": 203}
{"Episode reward": -104.39807063489746, "Episode length": 999, "Policy Loss": -13.522785186767578, "Value Loss": 0.03332287818193436, "_runtime": 246.29186964035034, "_timestamp": 1585077510.983475, "_step": 204}
{"Episode reward": -108.27370069255026, "Episode length": 999, "Policy Loss": -14.324429512023926, "Value Loss": 0.034252483397722244, "_runtime": 247.46999979019165, "_timestamp": 1585077512.1616051, "_step": 205}
{"Episode reward": -104.88884580675523, "Episode length": 999, "Policy Loss": -13.71261215209961, "Value Loss": 0.03455305099487305, "_runtime": 248.64316582679749, "_timestamp": 1585077513.3347712, "_step": 206}
{"Episode reward": -92.75078456092095, "Episode length": 999, "Policy Loss": -11.722627639770508, "Value Loss": 0.025608988478779793, "_runtime": 249.75785994529724, "_timestamp": 1585077514.4494653, "_step": 207}
{"Episode reward": -95.5386729198489, "Episode length": 999, "Policy Loss": -11.808490753173828, "Value Loss": 0.028184615075588226, "_runtime": 250.86390447616577, "_timestamp": 1585077515.5555098, "_step": 208}
{"Episode reward": -97.20204387066353, "Episode length": 999, "Policy Loss": -12.194097518920898, "Value Loss": 0.025940945371985435, "_runtime": 251.988995552063, "_timestamp": 1585077516.680601, "_step": 209}
{"Episode reward": -96.63115197862962, "Episode length": 999, "Policy Loss": -12.135437965393066, "Value Loss": 0.027432486414909363, "_runtime": 253.1162977218628, "_timestamp": 1585077517.807903, "_step": 210}
{"Episode reward": -98.92706563431842, "Episode length": 999, "Policy Loss": -12.737812995910645, "Value Loss": 0.028698755428195, "_runtime": 254.30687832832336, "_timestamp": 1585077518.9984837, "_step": 211}
{"Episode reward": -100.20465762411096, "Episode length": 999, "Policy Loss": -12.876411437988281, "Value Loss": 0.030492404475808144, "_runtime": 255.41611433029175, "_timestamp": 1585077520.1077197, "_step": 212}
{"Episode reward": -99.35840194189791, "Episode length": 999, "Policy Loss": -12.5794677734375, "Value Loss": 0.029046054929494858, "_runtime": 256.54012417793274, "_timestamp": 1585077521.2317295, "_step": 213}
{"Episode reward": -102.7181053890646, "Episode length": 999, "Policy Loss": -13.139565467834473, "Value Loss": 0.033222395926713943, "_runtime": 257.6941661834717, "_timestamp": 1585077522.3857715, "_step": 214}
{"Episode reward": -110.83030168109235, "Episode length": 999, "Policy Loss": -14.61496353149414, "Value Loss": 0.03828318417072296, "_runtime": 258.8046667575836, "_timestamp": 1585077523.496272, "_step": 215}
{"Episode reward": -104.86572144334086, "Episode length": 999, "Policy Loss": -13.651350975036621, "Value Loss": 0.03425475209951401, "_runtime": 259.4246506690979, "_timestamp": 1585077524.116256, "_step": 216}
{"Episode reward": 41.98894437282863, "Episode length": 553, "Policy Loss": 13.902124404907227, "Value Loss": 18.047090530395508, "_runtime": 260.546103477478, "_timestamp": 1585077525.2377088, "_step": 217}
{"Episode reward": -107.5175565319725, "Episode length": 999, "Policy Loss": -14.095307350158691, "Value Loss": 0.03405894339084625, "_runtime": 261.7103006839752, "_timestamp": 1585077526.401906, "_step": 218}
{"Episode reward": -101.78616166295191, "Episode length": 999, "Policy Loss": -13.099435806274414, "Value Loss": 0.032879918813705444, "_runtime": 262.8590669631958, "_timestamp": 1585077527.5506723, "_step": 219}
{"Episode reward": -99.12892627926922, "Episode length": 999, "Policy Loss": -12.714814186096191, "Value Loss": 0.028606122359633446, "_runtime": 263.96965289115906, "_timestamp": 1585077528.6612582, "_step": 220}
{"Episode reward": -100.43650530688132, "Episode length": 999, "Policy Loss": -12.817634582519531, "Value Loss": 0.030356649309396744, "_runtime": 265.127592086792, "_timestamp": 1585077529.8191974, "_step": 221}
{"Episode reward": -104.60966362514844, "Episode length": 999, "Policy Loss": -13.575590133666992, "Value Loss": 0.03249603509902954, "_runtime": 266.22222805023193, "_timestamp": 1585077530.9138334, "_step": 222}
{"Episode reward": -107.80584914758745, "Episode length": 999, "Policy Loss": -14.021729469299316, "Value Loss": 0.036275118589401245, "_runtime": 267.37768030166626, "_timestamp": 1585077532.0692856, "_step": 223}
{"Episode reward": -101.89495807498938, "Episode length": 999, "Policy Loss": -13.349794387817383, "Value Loss": 0.03110487386584282, "_runtime": 268.5125823020935, "_timestamp": 1585077533.2041876, "_step": 224}
{"Episode reward": -101.715743994602, "Episode length": 999, "Policy Loss": -12.991169929504395, "Value Loss": 0.031054003164172173, "_runtime": 269.64671659469604, "_timestamp": 1585077534.338322, "_step": 225}
{"Episode reward": -101.52691661559354, "Episode length": 999, "Policy Loss": -13.029559135437012, "Value Loss": 0.029693737626075745, "_runtime": 270.7354190349579, "_timestamp": 1585077535.4270244, "_step": 226}
{"Episode reward": -105.18566833339483, "Episode length": 999, "Policy Loss": -13.888754844665527, "Value Loss": 0.032489113509655, "_runtime": 271.9263732433319, "_timestamp": 1585077536.6179786, "_step": 227}
{"Episode reward": -96.38535138224897, "Episode length": 999, "Policy Loss": -12.32795524597168, "Value Loss": 0.028015905991196632, "_runtime": 273.040913105011, "_timestamp": 1585077537.7325184, "_step": 228}
{"Episode reward": -93.38065892881895, "Episode length": 999, "Policy Loss": -11.848783493041992, "Value Loss": 0.025725049898028374, "_runtime": 274.1828546524048, "_timestamp": 1585077538.87446, "_step": 229}
{"Episode reward": -101.92623254124508, "Episode length": 999, "Policy Loss": -13.14829158782959, "Value Loss": 0.03162781521677971, "_runtime": 275.36247968673706, "_timestamp": 1585077540.054085, "_step": 230}
{"Episode reward": -100.74357924880826, "Episode length": 999, "Policy Loss": -12.962926864624023, "Value Loss": 0.03431757166981697, "_runtime": 276.50577116012573, "_timestamp": 1585077541.1973765, "_step": 231}
{"Episode reward": -90.99881502797417, "Episode length": 999, "Policy Loss": -11.447226524353027, "Value Loss": 0.026975532993674278, "_runtime": 277.65919756889343, "_timestamp": 1585077542.350803, "_step": 232}
{"Episode reward": -108.09457208817142, "Episode length": 999, "Policy Loss": -14.258084297180176, "Value Loss": 0.034419964998960495, "_runtime": 278.78484320640564, "_timestamp": 1585077543.4764485, "_step": 233}
{"Episode reward": -100.40382749273213, "Episode length": 999, "Policy Loss": -13.030501365661621, "Value Loss": 0.024931611493229866, "_runtime": 279.898312330246, "_timestamp": 1585077544.5899177, "_step": 234}
{"Episode reward": -104.90743459020233, "Episode length": 999, "Policy Loss": -13.77695369720459, "Value Loss": 0.03400909900665283, "_runtime": 281.0608582496643, "_timestamp": 1585077545.7524636, "_step": 235}
{"Episode reward": -102.07834383840954, "Episode length": 999, "Policy Loss": -13.143898010253906, "Value Loss": 0.030538955703377724, "_runtime": 282.18599820137024, "_timestamp": 1585077546.8776035, "_step": 236}
{"Episode reward": -101.24863129718412, "Episode length": 999, "Policy Loss": -13.07909870147705, "Value Loss": 0.029831115156412125, "_runtime": 283.3067445755005, "_timestamp": 1585077547.99835, "_step": 237}
{"Episode reward": -95.17921068225974, "Episode length": 999, "Policy Loss": -12.04482364654541, "Value Loss": 0.0292993001639843, "_runtime": 284.43318915367126, "_timestamp": 1585077549.1247945, "_step": 238}
{"Episode reward": -104.72020696225565, "Episode length": 999, "Policy Loss": -13.97906494140625, "Value Loss": 0.029402311891317368, "_runtime": 285.5878930091858, "_timestamp": 1585077550.2794983, "_step": 239}
{"Episode reward": -105.48926214016505, "Episode length": 999, "Policy Loss": -13.883564949035645, "Value Loss": 0.034297164529561996, "_runtime": 286.73802375793457, "_timestamp": 1585077551.429629, "_step": 240}
{"Episode reward": -99.80518971830098, "Episode length": 999, "Policy Loss": -12.655816078186035, "Value Loss": 0.028857773169875145, "_runtime": 287.9387323856354, "_timestamp": 1585077552.6303377, "_step": 241}
{"Episode reward": -105.19819187196347, "Episode length": 999, "Policy Loss": -14.170970916748047, "Value Loss": 0.03235998749732971, "_runtime": 289.09574723243713, "_timestamp": 1585077553.7873526, "_step": 242}
{"Episode reward": -104.53081121382311, "Episode length": 999, "Policy Loss": -13.553123474121094, "Value Loss": 0.03400324657559395, "_runtime": 290.200896024704, "_timestamp": 1585077554.8925014, "_step": 243}
{"Episode reward": -105.76273960150625, "Episode length": 999, "Policy Loss": -13.831686973571777, "Value Loss": 0.03380437195301056, "_runtime": 291.346195936203, "_timestamp": 1585077556.0378013, "_step": 244}
{"Episode reward": -109.58499441057269, "Episode length": 999, "Policy Loss": -14.582653045654297, "Value Loss": 0.03538807854056358, "_runtime": 292.5342891216278, "_timestamp": 1585077557.2258945, "_step": 245}
{"Episode reward": -107.76532704313873, "Episode length": 999, "Policy Loss": -14.043559074401855, "Value Loss": 0.03533077985048294, "_runtime": 293.667111158371, "_timestamp": 1585077558.3587165, "_step": 246}
{"Episode reward": -98.70208075943349, "Episode length": 999, "Policy Loss": -12.650186538696289, "Value Loss": 0.03153587505221367, "_runtime": 294.80957865715027, "_timestamp": 1585077559.501184, "_step": 247}
{"Episode reward": -93.34641938345696, "Episode length": 999, "Policy Loss": -11.819457054138184, "Value Loss": 0.0272917989641428, "_runtime": 295.9408814907074, "_timestamp": 1585077560.6324868, "_step": 248}
{"Episode reward": -103.33813165851916, "Episode length": 999, "Policy Loss": -13.618199348449707, "Value Loss": 0.03237181529402733, "_runtime": 297.056747674942, "_timestamp": 1585077561.748353, "_step": 249}
{"Episode reward": -105.43574993898336, "Episode length": 999, "Policy Loss": -13.854764938354492, "Value Loss": 0.036950286477804184, "_runtime": 298.1751878261566, "_timestamp": 1585077562.8667932, "_step": 250}
{"Episode reward": -99.08109158068092, "Episode length": 999, "Policy Loss": -12.8864107131958, "Value Loss": 0.026943789795041084, "_runtime": 299.35332345962524, "_timestamp": 1585077564.0449288, "_step": 251}
{"Episode reward": -98.4397933100309, "Episode length": 999, "Policy Loss": -12.586462020874023, "Value Loss": 0.029581790789961815, "_runtime": 300.49620366096497, "_timestamp": 1585077565.187809, "_step": 252}
{"Episode reward": -91.63411993068755, "Episode length": 999, "Policy Loss": -11.227497100830078, "Value Loss": 0.024607239291071892, "_runtime": 301.68431091308594, "_timestamp": 1585077566.3759162, "_step": 253}
{"Episode reward": -96.35086788594256, "Episode length": 999, "Policy Loss": -12.428648948669434, "Value Loss": 0.02853449620306492, "_runtime": 302.8383765220642, "_timestamp": 1585077567.5299819, "_step": 254}
{"Episode reward": -98.89210052116734, "Episode length": 999, "Policy Loss": -12.691916465759277, "Value Loss": 0.02702830173075199, "_runtime": 303.9609749317169, "_timestamp": 1585077568.6525803, "_step": 255}
{"Episode reward": -99.31171492020314, "Episode length": 999, "Policy Loss": -12.527514457702637, "Value Loss": 0.03224898874759674, "_runtime": 305.1688828468323, "_timestamp": 1585077569.8604882, "_step": 256}
{"Episode reward": -94.73066922022998, "Episode length": 999, "Policy Loss": -12.172712326049805, "Value Loss": 0.027126101776957512, "_runtime": 306.34525322914124, "_timestamp": 1585077571.0368586, "_step": 257}
{"Episode reward": -99.74148052123165, "Episode length": 999, "Policy Loss": -12.895322799682617, "Value Loss": 0.029182061553001404, "_runtime": 307.5400688648224, "_timestamp": 1585077572.2316742, "_step": 258}
{"Episode reward": -100.22137075372063, "Episode length": 999, "Policy Loss": -12.745342254638672, "Value Loss": 0.030337480828166008, "_runtime": 308.69627237319946, "_timestamp": 1585077573.3878777, "_step": 259}
{"Episode reward": -99.54284525901292, "Episode length": 999, "Policy Loss": -12.95515251159668, "Value Loss": 0.02884812466800213, "_runtime": 309.8494324684143, "_timestamp": 1585077574.5410378, "_step": 260}
{"Episode reward": -105.83477104064863, "Episode length": 999, "Policy Loss": -13.824788093566895, "Value Loss": 0.035435520112514496, "_runtime": 310.9984369277954, "_timestamp": 1585077575.6900423, "_step": 261}
{"Episode reward": -97.3451550018665, "Episode length": 999, "Policy Loss": -12.10610580444336, "Value Loss": 0.0297686867415905, "_runtime": 312.1664867401123, "_timestamp": 1585077576.858092, "_step": 262}
{"Episode reward": -105.44036394807793, "Episode length": 999, "Policy Loss": -13.89316463470459, "Value Loss": 0.03225211054086685, "_runtime": 313.34937262535095, "_timestamp": 1585077578.040978, "_step": 263}
{"Episode reward": -94.04147216450438, "Episode length": 999, "Policy Loss": -11.919791221618652, "Value Loss": 0.026600463315844536, "_runtime": 314.51434326171875, "_timestamp": 1585077579.2059486, "_step": 264}
{"Episode reward": -96.38016753775757, "Episode length": 999, "Policy Loss": -12.14698600769043, "Value Loss": 0.029501643031835556, "_runtime": 315.65480756759644, "_timestamp": 1585077580.346413, "_step": 265}
{"Episode reward": -92.14679997457259, "Episode length": 999, "Policy Loss": -11.5557279586792, "Value Loss": 0.023796727880835533, "_runtime": 316.822012424469, "_timestamp": 1585077581.5136178, "_step": 266}
{"Episode reward": -92.86924476598047, "Episode length": 999, "Policy Loss": -11.501675605773926, "Value Loss": 0.02480875700712204, "_runtime": 317.95188546180725, "_timestamp": 1585077582.6434908, "_step": 267}
{"Episode reward": -99.12468969105716, "Episode length": 999, "Policy Loss": -12.832938194274902, "Value Loss": 0.029337184503674507, "_runtime": 319.08517122268677, "_timestamp": 1585077583.7767766, "_step": 268}
{"Episode reward": -105.59539178474827, "Episode length": 999, "Policy Loss": -14.02120304107666, "Value Loss": 0.032394882291555405, "_runtime": 320.2072606086731, "_timestamp": 1585077584.898866, "_step": 269}
{"Episode reward": -99.03706707955726, "Episode length": 999, "Policy Loss": -12.899392127990723, "Value Loss": 0.030004363507032394, "_runtime": 321.3488233089447, "_timestamp": 1585077586.0404286, "_step": 270}
{"Episode reward": -101.41837387219468, "Episode length": 999, "Policy Loss": -12.85840892791748, "Value Loss": 0.030988328158855438, "_runtime": 322.54556345939636, "_timestamp": 1585077587.2371688, "_step": 271}
{"Episode reward": -106.07540331539317, "Episode length": 999, "Policy Loss": -14.080533027648926, "Value Loss": 0.03403112664818764, "_runtime": 323.6976594924927, "_timestamp": 1585077588.3892648, "_step": 272}
{"Episode reward": -107.80202659064862, "Episode length": 999, "Policy Loss": -14.138294219970703, "Value Loss": 0.03737159073352814, "_runtime": 324.84948801994324, "_timestamp": 1585077589.5410933, "_step": 273}
{"Episode reward": -97.77311133192684, "Episode length": 999, "Policy Loss": -12.186666488647461, "Value Loss": 0.02729697711765766, "_runtime": 325.9793453216553, "_timestamp": 1585077590.6709507, "_step": 274}
{"Episode reward": -94.77467691582449, "Episode length": 999, "Policy Loss": -11.795866966247559, "Value Loss": 0.026171108707785606, "_runtime": 327.12271904945374, "_timestamp": 1585077591.8143244, "_step": 275}
{"Episode reward": -98.55456193579946, "Episode length": 999, "Policy Loss": -12.63748836517334, "Value Loss": 0.0266701802611351, "_runtime": 328.2460947036743, "_timestamp": 1585077592.9377, "_step": 276}
{"Episode reward": -109.61062432940876, "Episode length": 999, "Policy Loss": -14.560090065002441, "Value Loss": 0.038218818604946136, "_runtime": 329.3849627971649, "_timestamp": 1585077594.0765681, "_step": 277}
{"Episode reward": -98.68736403566558, "Episode length": 999, "Policy Loss": -12.551567077636719, "Value Loss": 0.030999038368463516, "_runtime": 330.49684596061707, "_timestamp": 1585077595.1884513, "_step": 278}
{"Episode reward": -96.02486811632751, "Episode length": 999, "Policy Loss": -12.246682167053223, "Value Loss": 0.025648972019553185, "_runtime": 331.6748332977295, "_timestamp": 1585077596.3664386, "_step": 279}
{"Episode reward": -112.93561844203887, "Episode length": 999, "Policy Loss": -15.323287010192871, "Value Loss": 0.03796761855483055, "_runtime": 332.84518551826477, "_timestamp": 1585077597.5367908, "_step": 280}
{"Episode reward": -94.14153992270668, "Episode length": 999, "Policy Loss": -11.717827796936035, "Value Loss": 0.027261976152658463, "_runtime": 333.96158170700073, "_timestamp": 1585077598.653187, "_step": 281}
{"Episode reward": -95.78601960782089, "Episode length": 999, "Policy Loss": -12.257574081420898, "Value Loss": 0.030295902863144875, "_runtime": 335.1052143573761, "_timestamp": 1585077599.7968197, "_step": 282}
{"Episode reward": -95.03693530668234, "Episode length": 999, "Policy Loss": -12.196518898010254, "Value Loss": 0.02711336687207222, "_runtime": 336.25830698013306, "_timestamp": 1585077600.9499123, "_step": 283}
{"Episode reward": -105.33284241482579, "Episode length": 999, "Policy Loss": -13.653359413146973, "Value Loss": 0.03157347813248634, "_runtime": 337.37836718559265, "_timestamp": 1585077602.0699725, "_step": 284}
{"Episode reward": -96.41116624791252, "Episode length": 999, "Policy Loss": -12.278348922729492, "Value Loss": 0.024447176605463028, "_runtime": 338.558158159256, "_timestamp": 1585077603.2497635, "_step": 285}
{"Episode reward": -103.89842038563467, "Episode length": 999, "Policy Loss": -13.523791313171387, "Value Loss": 0.030697111040353775, "_runtime": 339.7166750431061, "_timestamp": 1585077604.4082804, "_step": 286}
{"Episode reward": -93.04435460371083, "Episode length": 999, "Policy Loss": -11.698514938354492, "Value Loss": 0.022971082478761673, "_runtime": 340.84282064437866, "_timestamp": 1585077605.534426, "_step": 287}
{"Episode reward": -97.41619531018398, "Episode length": 999, "Policy Loss": -12.480083465576172, "Value Loss": 0.02998860366642475, "_runtime": 341.97183418273926, "_timestamp": 1585077606.6634395, "_step": 288}
{"Episode reward": -94.95265625024177, "Episode length": 999, "Policy Loss": -12.038298606872559, "Value Loss": 0.025931341573596, "_runtime": 343.11431646347046, "_timestamp": 1585077607.8059218, "_step": 289}
{"Episode reward": -99.89406630319127, "Episode length": 999, "Policy Loss": -12.79096508026123, "Value Loss": 0.028243819251656532, "_runtime": 344.26937103271484, "_timestamp": 1585077608.9609764, "_step": 290}
{"Episode reward": -98.73196878023279, "Episode length": 999, "Policy Loss": -12.68189811706543, "Value Loss": 0.032230403274297714, "_runtime": 345.43576192855835, "_timestamp": 1585077610.1273673, "_step": 291}
{"Episode reward": -99.7908266563296, "Episode length": 999, "Policy Loss": -12.875898361206055, "Value Loss": 0.02941804565489292, "_runtime": 346.5938928127289, "_timestamp": 1585077611.2854981, "_step": 292}
{"Episode reward": -100.53364281714514, "Episode length": 999, "Policy Loss": -12.910059928894043, "Value Loss": 0.028757229447364807, "_runtime": 347.77531695365906, "_timestamp": 1585077612.4669223, "_step": 293}
{"Episode reward": -104.85561056755563, "Episode length": 999, "Policy Loss": -13.792176246643066, "Value Loss": 0.03839819133281708, "_runtime": 348.89163184165955, "_timestamp": 1585077613.5832372, "_step": 294}
{"Episode reward": -99.55124931306452, "Episode length": 999, "Policy Loss": -12.61933422088623, "Value Loss": 0.031725019216537476, "_runtime": 350.0231862068176, "_timestamp": 1585077614.7147915, "_step": 295}
{"Episode reward": -100.13197369423051, "Episode length": 999, "Policy Loss": -12.848252296447754, "Value Loss": 0.031506795436143875, "_runtime": 351.1370265483856, "_timestamp": 1585077615.8286319, "_step": 296}
{"Episode reward": -93.51533753119364, "Episode length": 999, "Policy Loss": -11.806159973144531, "Value Loss": 0.02474978379905224, "_runtime": 352.2885398864746, "_timestamp": 1585077616.9801452, "_step": 297}
{"Episode reward": -97.13001153171713, "Episode length": 999, "Policy Loss": -12.554397583007812, "Value Loss": 0.02693924494087696, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469, -94.22453308105469]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-91.78274536132812, -89.52944946289062, -87.27615356445312, -85.02285766601562, -82.76956176757812, -80.51627349853516, -78.26297760009766, -76.00968170166016, -73.75638580322266, -71.50308990478516, -69.24979400634766, -66.99650573730469, -64.74320983886719, -62.48991012573242, -60.23661804199219, -57.98332214355469, -55.73002624511719, -53.47673034667969, -51.22343444824219, -48.97014236450195, -46.71684646606445, -44.46355056762695, -42.21025848388672, -39.95696258544922, -37.70366668701172, -35.45037078857422, -33.19707489013672, -30.943782806396484, -28.690486907958984, -26.43719482421875, -24.18389892578125, -21.93060302734375, -19.67730712890625, -17.42401123046875, -15.17071533203125, -12.91741943359375, -10.66412353515625, -8.410835266113281, -6.157539367675781, -3.9042434692382812, -1.6509475708007812, 0.6023483276367188, 2.8556442260742188, 5.108940124511719, 7.3622283935546875, 9.615524291992188, 11.868820190429688, 14.122116088867188, 16.375411987304688, 18.628707885742188, 20.882003784179688, 23.135299682617188, 25.388595581054688, 27.641883850097656, 29.895179748535156, 32.148475646972656, 34.401771545410156, 36.655059814453125, 38.908355712890625, 41.161651611328125, 43.414947509765625, 45.668243408203125, 47.921539306640625, 50.174835205078125, 52.428131103515625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-45.21664047241211, -43.70396041870117, -42.191280364990234, -40.6786003112793, -39.165924072265625, -37.65324401855469, -36.14056396484375, -34.62788391113281, -33.115203857421875, -31.602523803710938, -30.08984375, -28.577165603637695, -27.064485549926758, -25.55180549621582, -24.039127349853516, -22.526447296142578, -21.01376724243164, -19.501087188720703, -17.988407135009766, -16.47572898864746, -14.963048934936523, -13.450368881225586, -11.937690734863281, -10.425010681152344, -8.912330627441406, -7.399650573730469, -5.886970520019531, -4.374290466308594, -2.861614227294922, -1.3489341735839844, 0.16374588012695312, 1.6764259338378906, 3.189105987548828, 4.701786041259766, 6.214466094970703, 7.727146148681641, 9.239826202392578, 10.75250244140625, 12.265182495117188, 13.777862548828125, 15.290542602539062, 16.80322265625, 18.315902709960938, 19.82857894897461, 21.341259002685547, 22.853939056396484, 24.366619110107422, 25.87929916381836, 27.391979217529297, 28.904659271240234, 30.417339324951172, 31.93001937866211, 33.44269943237305, 34.955379486083984, 36.46805953979492, 37.98073959350586, 39.493412017822266, 41.0060920715332, 42.51877212524414, 44.03145217895508, 45.544132232666016, 47.05681228637695, 48.56949234008789, 50.08217239379883, 51.594852447509766]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 6.0, 2.0, 7.0, 2.0, 5.0, 1.0, 5.0, 3.0, 10.0, 2.0, 11.0, 14.0, 18.0, 26.0, 31.0, 29.0, 37.0, 37.0, 43.0, 54.0, 23.0, 15.0, 17.0, 15.0, 11.0, 12.0, 10.0, 13.0, 6.0, 9.0, 3.0, 8.0, 4.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-41.19239807128906, -39.81434631347656, -38.4362907409668, -37.0582389831543, -35.68018341064453, -34.30213165283203, -32.92407989501953, -31.546024322509766, -30.167970657348633, -28.7899169921875, -27.411863327026367, -26.033809661865234, -24.655757904052734, -23.2777042388916, -21.89965057373047, -20.521596908569336, -19.143543243408203, -17.76548957824707, -16.387435913085938, -15.009382247924805, -13.631328582763672, -12.253276824951172, -10.875223159790039, -9.497169494628906, -8.119117736816406, -6.741062164306641, -5.363010406494141, -3.984954833984375, -2.606903076171875, -1.2288475036621094, 0.14920425415039062, 1.5272598266601562, 2.9053115844726562, 4.283363342285156, 5.661418914794922, 7.039470672607422, 8.417526245117188, 9.795578002929688, 11.173633575439453, 12.551685333251953, 13.929740905761719, 15.307792663574219, 16.68584442138672, 18.063899993896484, 19.441951751708984, 20.82000732421875, 22.19805908203125, 23.57611083984375, 24.95416259765625, 26.33222198486328, 27.71027374267578, 29.08832550048828, 30.46637725830078, 31.844436645507812, 33.22248840332031, 34.60054016113281, 35.97859191894531, 37.35664367675781, 38.734703063964844, 40.112754821777344, 41.490806579589844, 42.868858337402344, 44.246917724609375, 45.624969482421875, 47.003021240234375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-37.04845428466797, -36.162315368652344, -35.27617645263672, -34.39003372192383, -33.5038948059082, -32.61775588989258, -31.731616973876953, -30.845478057861328, -29.95933723449707, -29.073196411132812, -28.187057495117188, -27.300918579101562, -26.414779663085938, -25.52863883972168, -24.642499923706055, -23.756359100341797, -22.870220184326172, -21.984081268310547, -21.09794044494629, -20.211801528930664, -19.325660705566406, -18.43952178955078, -17.553382873535156, -16.6672420501709, -15.781103134155273, -14.894964218139648, -14.00882339477539, -13.122684478759766, -12.23654556274414, -11.350404739379883, -10.464265823364258, -9.578125, -8.691986083984375, -7.80584716796875, -6.919706344604492, -6.033567428588867, -5.147426605224609, -4.261287689208984, -3.3751487731933594, -2.4890098571777344, -1.6028671264648438, -0.7167282104492188, 0.16941070556640625, 1.0555496215820312, 1.9416885375976562, 2.8278274536132812, 3.713970184326172, 4.600109100341797, 5.486248016357422, 6.372386932373047, 7.258525848388672, 8.144668579101562, 9.030807495117188, 9.916946411132812, 10.803085327148438, 11.689224243164062, 12.575363159179688, 13.461505889892578, 14.347644805908203, 15.233783721923828, 16.119922637939453, 17.006061553955078, 17.89220428466797, 18.778343200683594, 19.66448211669922]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 10.0, 17.0, 5.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-14.189621925354004, -13.55278205871582, -12.91594123840332, -12.279101371765137, -11.642260551452637, -11.005420684814453, -10.368579864501953, -9.73173999786377, -9.094900131225586, -8.458059310913086, -7.821218967437744, -7.184378623962402, -6.547538757324219, -5.910697937011719, -5.273858070373535, -4.637017250061035, -4.000177383422852, -3.363337516784668, -2.726496696472168, -2.0896568298339844, -1.4528160095214844, -0.8159761428833008, -0.17913532257080078, 0.4577045440673828, 1.0945444107055664, 1.7313852310180664, 2.3682260513305664, 3.0050649642944336, 3.6419057846069336, 4.278746604919434, 4.915587425231934, 5.552426338195801, 6.189267158508301, 6.826107978820801, 7.462946891784668, 8.099787712097168, 8.736628532409668, 9.373469352722168, 10.010308265686035, 10.647149085998535, 11.283989906311035, 11.920828819274902, 12.557669639587402, 13.194510459899902, 13.831351280212402, 14.46819019317627, 15.10503101348877, 15.74187183380127, 16.378711700439453, 17.015552520751953, 17.652393341064453, 18.289234161376953, 18.926074981689453, 19.562915802001953, 20.199752807617188, 20.836593627929688, 21.473434448242188, 22.110275268554688, 22.747116088867188, 23.383956909179688, 24.020797729492188, 24.657634735107422, 25.294475555419922, 25.931316375732422, 26.568157196044922]}, "_runtime": 353.43742179870605, "_timestamp": 1585077618.1290271, "_step": 298}
{"Episode reward": -94.72344920847951, "Episode length": 999, "Policy Loss": -11.927300453186035, "Value Loss": 0.028024796396493912, "_runtime": 354.5409400463104, "_timestamp": 1585077619.2325454, "_step": 299}
{"Episode reward": -94.26782461322203, "Episode length": 999, "Policy Loss": -11.911943435668945, "Value Loss": 0.024699917063117027, "_runtime": 355.68086433410645, "_timestamp": 1585077620.3724697, "_step": 300}
{"Episode reward": -106.51684166505524, "Episode length": 999, "Policy Loss": -14.113824844360352, "Value Loss": 0.03301234915852547, "_runtime": 356.85550594329834, "_timestamp": 1585077621.5471113, "_step": 301}
{"Episode reward": -100.38330761384056, "Episode length": 999, "Policy Loss": -12.946166038513184, "Value Loss": 0.02881580963730812, "_runtime": 358.0087366104126, "_timestamp": 1585077622.700342, "_step": 302}
{"Episode reward": -104.1900090290907, "Episode length": 999, "Policy Loss": -13.49811840057373, "Value Loss": 0.03272019326686859, "_runtime": 359.15384244918823, "_timestamp": 1585077623.8454478, "_step": 303}
{"Episode reward": -103.31063405973693, "Episode length": 999, "Policy Loss": -13.53365421295166, "Value Loss": 0.032326214015483856, "_runtime": 360.28082370758057, "_timestamp": 1585077624.972429, "_step": 304}
{"Episode reward": -96.77966271563304, "Episode length": 999, "Policy Loss": -12.412097930908203, "Value Loss": 0.02899952419102192, "_runtime": 361.46387481689453, "_timestamp": 1585077626.1554801, "_step": 305}
{"Episode reward": -102.30022208753537, "Episode length": 999, "Policy Loss": -13.48073673248291, "Value Loss": 0.033397119492292404, "_runtime": 362.66035509109497, "_timestamp": 1585077627.3519604, "_step": 306}
{"Episode reward": -103.30054104161302, "Episode length": 999, "Policy Loss": -13.431859970092773, "Value Loss": 0.0311159435659647, "_runtime": 363.79485297203064, "_timestamp": 1585077628.4864583, "_step": 307}
{"Episode reward": -101.43999497636639, "Episode length": 999, "Policy Loss": -13.179149627685547, "Value Loss": 0.0341806560754776, "_runtime": 364.9171504974365, "_timestamp": 1585077629.6087558, "_step": 308}
{"Episode reward": -103.97156436258093, "Episode length": 999, "Policy Loss": -13.564398765563965, "Value Loss": 0.03393629565834999, "_runtime": 366.03051710128784, "_timestamp": 1585077630.7221224, "_step": 309}
{"Episode reward": -97.87955020092988, "Episode length": 999, "Policy Loss": -12.676077842712402, "Value Loss": 0.02861921489238739, "_runtime": 367.15986585617065, "_timestamp": 1585077631.8514712, "_step": 310}
{"Episode reward": -105.71753324090544, "Episode length": 999, "Policy Loss": -13.86428165435791, "Value Loss": 0.033293742686510086, "_runtime": 368.2825152873993, "_timestamp": 1585077632.9741206, "_step": 311}
{"Episode reward": -98.17725881919475, "Episode length": 999, "Policy Loss": -12.455766677856445, "Value Loss": 0.028814973309636116, "_runtime": 369.4383759498596, "_timestamp": 1585077634.1299813, "_step": 312}
{"Episode reward": -95.8574772528045, "Episode length": 999, "Policy Loss": -12.195596694946289, "Value Loss": 0.0246253851801157, "_runtime": 370.5543165206909, "_timestamp": 1585077635.2459219, "_step": 313}
{"Episode reward": -93.6054024933173, "Episode length": 999, "Policy Loss": -11.936627388000488, "Value Loss": 0.02558787725865841, "_runtime": 371.70505452156067, "_timestamp": 1585077636.3966599, "_step": 314}
{"Episode reward": -92.25647904517781, "Episode length": 999, "Policy Loss": -11.697920799255371, "Value Loss": 0.026401055976748466, "_runtime": 372.86645555496216, "_timestamp": 1585077637.558061, "_step": 315}
{"Episode reward": -89.81278995812394, "Episode length": 999, "Policy Loss": -11.067821502685547, "Value Loss": 0.026172161102294922, "_runtime": 374.09237241744995, "_timestamp": 1585077638.7839777, "_step": 316}
{"Episode reward": -94.87055222376864, "Episode length": 999, "Policy Loss": -11.994080543518066, "Value Loss": 0.026977932080626488, "_runtime": 375.27544808387756, "_timestamp": 1585077639.9670534, "_step": 317}
{"Episode reward": -101.86663258860939, "Episode length": 999, "Policy Loss": -13.346502304077148, "Value Loss": 0.030062885954976082, "_runtime": 376.4120659828186, "_timestamp": 1585077641.1036713, "_step": 318}
{"Episode reward": -92.56428720553458, "Episode length": 999, "Policy Loss": -11.64381217956543, "Value Loss": 0.0247323140501976, "_runtime": 377.5889890193939, "_timestamp": 1585077642.2805943, "_step": 319}
{"Episode reward": -94.48334613991055, "Episode length": 999, "Policy Loss": -12.040596961975098, "Value Loss": 0.02553359791636467, "_runtime": 378.73724246025085, "_timestamp": 1585077643.4288478, "_step": 320}
{"Episode reward": -98.19493336422657, "Episode length": 999, "Policy Loss": -12.564896583557129, "Value Loss": 0.030053259804844856, "_runtime": 379.87518882751465, "_timestamp": 1585077644.5667942, "_step": 321}
{"Episode reward": -96.47320094127403, "Episode length": 999, "Policy Loss": -12.312212944030762, "Value Loss": 0.027861308306455612, "_runtime": 381.0040843486786, "_timestamp": 1585077645.6956897, "_step": 322}
{"Episode reward": -96.78399994391197, "Episode length": 999, "Policy Loss": -12.552922248840332, "Value Loss": 0.02801859751343727, "_runtime": 382.1941020488739, "_timestamp": 1585077646.8857074, "_step": 323}
{"Episode reward": -106.89703987583874, "Episode length": 999, "Policy Loss": -14.098094940185547, "Value Loss": 0.033682651817798615, "_runtime": 383.3657703399658, "_timestamp": 1585077648.0573757, "_step": 324}
{"Episode reward": -97.50281408589363, "Episode length": 999, "Policy Loss": -12.431848526000977, "Value Loss": 0.028156518936157227, "_runtime": 384.575021982193, "_timestamp": 1585077649.2666273, "_step": 325}
{"Episode reward": -101.0795461127227, "Episode length": 999, "Policy Loss": -13.086176872253418, "Value Loss": 0.028779208660125732, "_runtime": 385.7067081928253, "_timestamp": 1585077650.3983135, "_step": 326}
{"Episode reward": -102.3820608860212, "Episode length": 999, "Policy Loss": -13.231016159057617, "Value Loss": 0.0317639485001564, "_runtime": 386.8395049571991, "_timestamp": 1585077651.5311103, "_step": 327}
{"Episode reward": -95.40205890274504, "Episode length": 999, "Policy Loss": -12.260920524597168, "Value Loss": 0.027765532955527306, "_runtime": 387.9587802886963, "_timestamp": 1585077652.6503856, "_step": 328}
{"Episode reward": -107.43689381429357, "Episode length": 999, "Policy Loss": -14.153432846069336, "Value Loss": 0.03562674671411514, "_runtime": 389.06590843200684, "_timestamp": 1585077653.7575138, "_step": 329}
{"Episode reward": -98.36918096431955, "Episode length": 999, "Policy Loss": -12.511397361755371, "Value Loss": 0.03104366920888424, "_runtime": 390.167364358902, "_timestamp": 1585077654.8589697, "_step": 330}
{"Episode reward": -97.74534355589353, "Episode length": 999, "Policy Loss": -12.481125831604004, "Value Loss": 0.028872109949588776, "_runtime": 391.282199382782, "_timestamp": 1585077655.9738047, "_step": 331}
{"Episode reward": -93.530428118648, "Episode length": 999, "Policy Loss": -11.926399230957031, "Value Loss": 0.025711029767990112, "_runtime": 392.4108986854553, "_timestamp": 1585077657.102504, "_step": 332}
{"Episode reward": -101.61811585502218, "Episode length": 999, "Policy Loss": -13.135300636291504, "Value Loss": 0.030390972271561623, "_runtime": 393.55382347106934, "_timestamp": 1585077658.2454288, "_step": 333}
{"Episode reward": -95.00355211434173, "Episode length": 999, "Policy Loss": -12.045232772827148, "Value Loss": 0.026275189593434334, "_runtime": 394.65917897224426, "_timestamp": 1585077659.3507843, "_step": 334}
{"Episode reward": -100.5597902776768, "Episode length": 999, "Policy Loss": -12.878240585327148, "Value Loss": 0.031319472938776016, "_runtime": 395.7888171672821, "_timestamp": 1585077660.4804225, "_step": 335}
{"Episode reward": -104.41445877683594, "Episode length": 999, "Policy Loss": -13.602739334106445, "Value Loss": 0.03433028608560562, "_runtime": 396.925128698349, "_timestamp": 1585077661.616734, "_step": 336}
{"Episode reward": -107.79265698492871, "Episode length": 999, "Policy Loss": -14.357572555541992, "Value Loss": 0.03450155258178711, "_runtime": 398.04288506507874, "_timestamp": 1585077662.7344904, "_step": 337}
{"Episode reward": -102.54829197139594, "Episode length": 999, "Policy Loss": -13.388531684875488, "Value Loss": 0.03204866871237755, "_runtime": 399.1577606201172, "_timestamp": 1585077663.849366, "_step": 338}
{"Episode reward": -99.0194815876352, "Episode length": 999, "Policy Loss": -12.809072494506836, "Value Loss": 0.026760058477520943, "_runtime": 400.32547545433044, "_timestamp": 1585077665.0170808, "_step": 339}
{"Episode reward": -96.97556436774694, "Episode length": 999, "Policy Loss": -12.255451202392578, "Value Loss": 0.029089493677020073, "_runtime": 401.4627630710602, "_timestamp": 1585077666.1543684, "_step": 340}
{"Episode reward": -107.06236362377442, "Episode length": 999, "Policy Loss": -14.378223419189453, "Value Loss": 0.0336897037923336, "_runtime": 402.61761927604675, "_timestamp": 1585077667.3092246, "_step": 341}
{"Episode reward": -97.31988738296802, "Episode length": 999, "Policy Loss": -12.49441146850586, "Value Loss": 0.02626023441553116, "_runtime": 403.72594714164734, "_timestamp": 1585077668.4175525, "_step": 342}
{"Episode reward": -93.78321147908616, "Episode length": 999, "Policy Loss": -11.760194778442383, "Value Loss": 0.027148758992552757, "_runtime": 404.8334720134735, "_timestamp": 1585077669.5250773, "_step": 343}
{"Episode reward": -99.92657648928684, "Episode length": 999, "Policy Loss": -13.042552947998047, "Value Loss": 0.031374797224998474, "_runtime": 405.9531216621399, "_timestamp": 1585077670.644727, "_step": 344}
{"Episode reward": -100.50667852538004, "Episode length": 999, "Policy Loss": -12.903443336486816, "Value Loss": 0.03331843018531799, "_runtime": 407.0626184940338, "_timestamp": 1585077671.7542238, "_step": 345}
{"Episode reward": -103.5650164541437, "Episode length": 999, "Policy Loss": -13.79416275024414, "Value Loss": 0.03155934810638428, "_runtime": 408.21786403656006, "_timestamp": 1585077672.9094694, "_step": 346}
{"Episode reward": -102.91921563306633, "Episode length": 999, "Policy Loss": -13.421189308166504, "Value Loss": 0.0318518802523613, "_runtime": 409.35213899612427, "_timestamp": 1585077674.0437443, "_step": 347}
{"Episode reward": -101.34567673074618, "Episode length": 999, "Policy Loss": -13.172927856445312, "Value Loss": 0.03193720057606697, "_runtime": 410.4749870300293, "_timestamp": 1585077675.1665924, "_step": 348}
{"Episode reward": -104.78002369025133, "Episode length": 999, "Policy Loss": -13.911417007446289, "Value Loss": 0.035575080662965775, "_runtime": 411.68303394317627, "_timestamp": 1585077676.3746393, "_step": 349}
{"Episode reward": -101.7394850149346, "Episode length": 999, "Policy Loss": -13.086979866027832, "Value Loss": 0.029711998999118805, "_runtime": 412.8201777935028, "_timestamp": 1585077677.5117831, "_step": 350}
{"Episode reward": -104.13775893213807, "Episode length": 999, "Policy Loss": -13.575206756591797, "Value Loss": 0.031565066426992416, "_runtime": 414.0119433403015, "_timestamp": 1585077678.7035487, "_step": 351}
{"Episode reward": -107.23007159919841, "Episode length": 999, "Policy Loss": -13.831080436706543, "Value Loss": 0.03754376620054245, "_runtime": 415.19726634025574, "_timestamp": 1585077679.8888717, "_step": 352}
{"Episode reward": -103.7377250382596, "Episode length": 999, "Policy Loss": -13.725720405578613, "Value Loss": 0.03356445953249931, "_runtime": 416.3224787712097, "_timestamp": 1585077681.014084, "_step": 353}
{"Episode reward": -101.83753968679277, "Episode length": 999, "Policy Loss": -13.2144193649292, "Value Loss": 0.030133631080389023, "_runtime": 417.47601890563965, "_timestamp": 1585077682.1676242, "_step": 354}
{"Episode reward": -102.93444986360839, "Episode length": 999, "Policy Loss": -13.492254257202148, "Value Loss": 0.03163296356797218, "_runtime": 418.6482515335083, "_timestamp": 1585077683.3398569, "_step": 355}
{"Episode reward": -101.69310955909764, "Episode length": 999, "Policy Loss": -13.241971969604492, "Value Loss": 0.030382685363292694, "_runtime": 419.84264755249023, "_timestamp": 1585077684.534253, "_step": 356}
{"Episode reward": -96.79377996652796, "Episode length": 999, "Policy Loss": -12.168758392333984, "Value Loss": 0.026958376169204712, "_runtime": 420.95696210861206, "_timestamp": 1585077685.6485674, "_step": 357}
{"Episode reward": -97.61976613228086, "Episode length": 999, "Policy Loss": -12.256011962890625, "Value Loss": 0.030123388394713402, "_runtime": 422.085081577301, "_timestamp": 1585077686.776687, "_step": 358}
{"Episode reward": -99.33674597272964, "Episode length": 999, "Policy Loss": -12.928664207458496, "Value Loss": 0.02863636240363121, "_runtime": 423.1952061653137, "_timestamp": 1585077687.8868115, "_step": 359}
{"Episode reward": -99.71612801169695, "Episode length": 999, "Policy Loss": -13.069424629211426, "Value Loss": 0.032340094447135925, "_runtime": 424.3543176651001, "_timestamp": 1585077689.045923, "_step": 360}
{"Episode reward": -98.77720952105263, "Episode length": 999, "Policy Loss": -12.852781295776367, "Value Loss": 0.028938278555870056, "_runtime": 425.4734642505646, "_timestamp": 1585077690.1650696, "_step": 361}
{"Episode reward": -97.36647293947402, "Episode length": 999, "Policy Loss": -12.487066268920898, "Value Loss": 0.029221490025520325, "_runtime": 426.60640239715576, "_timestamp": 1585077691.2980077, "_step": 362}
{"Episode reward": -100.51708316253502, "Episode length": 999, "Policy Loss": -12.92719554901123, "Value Loss": 0.03124571219086647, "_runtime": 427.7469620704651, "_timestamp": 1585077692.4385674, "_step": 363}
{"Episode reward": -98.74471077700747, "Episode length": 999, "Policy Loss": -12.800804138183594, "Value Loss": 0.031026769429445267, "_runtime": 428.85440039634705, "_timestamp": 1585077693.5460057, "_step": 364}
{"Episode reward": -100.96686899739124, "Episode length": 999, "Policy Loss": -13.043709754943848, "Value Loss": 0.031030014157295227, "_runtime": 429.96906328201294, "_timestamp": 1585077694.6606686, "_step": 365}
{"Episode reward": -99.33314937297156, "Episode length": 999, "Policy Loss": -12.733677864074707, "Value Loss": 0.029038764536380768, "_runtime": 431.08371472358704, "_timestamp": 1585077695.77532, "_step": 366}
{"Episode reward": -100.41692388030107, "Episode length": 999, "Policy Loss": -12.766828536987305, "Value Loss": 0.03097360208630562, "_runtime": 432.21094512939453, "_timestamp": 1585077696.9025505, "_step": 367}
{"Episode reward": -97.89612081526877, "Episode length": 999, "Policy Loss": -12.468701362609863, "Value Loss": 0.03157668933272362, "_runtime": 433.36347579956055, "_timestamp": 1585077698.0550811, "_step": 368}
{"Episode reward": -107.58837042493066, "Episode length": 999, "Policy Loss": -13.95192813873291, "Value Loss": 0.03301364928483963, "_runtime": 434.5371844768524, "_timestamp": 1585077699.2287898, "_step": 369}
{"Episode reward": -98.7737342988679, "Episode length": 999, "Policy Loss": -12.82934284210205, "Value Loss": 0.02775115892291069, "_runtime": 435.681512594223, "_timestamp": 1585077700.373118, "_step": 370}
{"Episode reward": -103.60689558325254, "Episode length": 999, "Policy Loss": -13.520116806030273, "Value Loss": 0.03028910979628563, "_runtime": 436.8419990539551, "_timestamp": 1585077701.5336044, "_step": 371}
{"Episode reward": -98.7153472499128, "Episode length": 999, "Policy Loss": -12.497782707214355, "Value Loss": 0.028878076002001762, "_runtime": 438.0028622150421, "_timestamp": 1585077702.6944675, "_step": 372}
{"Episode reward": -105.98243730653334, "Episode length": 999, "Policy Loss": -13.882689476013184, "Value Loss": 0.03201886638998985, "_runtime": 439.1127414703369, "_timestamp": 1585077703.8043468, "_step": 373}
{"Episode reward": -91.01825635393025, "Episode length": 999, "Policy Loss": -11.201861381530762, "Value Loss": 0.02382473088800907, "_runtime": 440.2227256298065, "_timestamp": 1585077704.914331, "_step": 374}
{"Episode reward": -100.32641365391618, "Episode length": 999, "Policy Loss": -12.835025787353516, "Value Loss": 0.030890081077814102, "_runtime": 441.35206031799316, "_timestamp": 1585077706.0436656, "_step": 375}
{"Episode reward": -102.5130054320985, "Episode length": 999, "Policy Loss": -13.194751739501953, "Value Loss": 0.03222651407122612, "_runtime": 442.484482049942, "_timestamp": 1585077707.1760874, "_step": 376}
{"Episode reward": -106.5706819384506, "Episode length": 999, "Policy Loss": -13.946212768554688, "Value Loss": 0.042211342602968216, "_runtime": 443.6241545677185, "_timestamp": 1585077708.31576, "_step": 377}
{"Episode reward": -101.15048737019951, "Episode length": 999, "Policy Loss": -13.130197525024414, "Value Loss": 0.030432837083935738, "_runtime": 444.80520844459534, "_timestamp": 1585077709.4968138, "_step": 378}
{"Episode reward": -95.57306779585956, "Episode length": 999, "Policy Loss": -12.24052619934082, "Value Loss": 0.0278208889067173, "_runtime": 445.97781348228455, "_timestamp": 1585077710.6694188, "_step": 379}
{"Episode reward": -95.4401108622458, "Episode length": 999, "Policy Loss": -12.279189109802246, "Value Loss": 0.029364632442593575, "_runtime": 447.1210765838623, "_timestamp": 1585077711.812682, "_step": 380}
{"Episode reward": -97.26371952237055, "Episode length": 999, "Policy Loss": -12.183893203735352, "Value Loss": 0.027262263000011444, "_runtime": 448.2878227233887, "_timestamp": 1585077712.979428, "_step": 381}
{"Episode reward": -100.17652833716082, "Episode length": 999, "Policy Loss": -12.915675163269043, "Value Loss": 0.03204404562711716, "_runtime": 449.4329516887665, "_timestamp": 1585077714.124557, "_step": 382}
{"Episode reward": -98.54828375749892, "Episode length": 999, "Policy Loss": -12.616683959960938, "Value Loss": 0.027019940316677094, "_runtime": 450.5774004459381, "_timestamp": 1585077715.2690058, "_step": 383}
{"Episode reward": -104.17940273687051, "Episode length": 999, "Policy Loss": -13.710941314697266, "Value Loss": 0.03234422951936722, "_runtime": 451.7631776332855, "_timestamp": 1585077716.454783, "_step": 384}
{"Episode reward": -96.74055734285076, "Episode length": 999, "Policy Loss": -12.044403076171875, "Value Loss": 0.027664508670568466, "_runtime": 452.9075207710266, "_timestamp": 1585077717.599126, "_step": 385}
{"Episode reward": -96.86974688046601, "Episode length": 999, "Policy Loss": -12.296013832092285, "Value Loss": 0.027020538225769997, "_runtime": 454.0173623561859, "_timestamp": 1585077718.7089677, "_step": 386}
{"Episode reward": -101.8630823894364, "Episode length": 999, "Policy Loss": -13.298548698425293, "Value Loss": 0.03440924361348152, "_runtime": 455.18056893348694, "_timestamp": 1585077719.8721743, "_step": 387}
{"Episode reward": -99.23180615989955, "Episode length": 999, "Policy Loss": -12.577868461608887, "Value Loss": 0.03291092440485954, "_runtime": 456.3298637866974, "_timestamp": 1585077721.021469, "_step": 388}
{"Episode reward": -102.59412963557983, "Episode length": 999, "Policy Loss": -13.198189735412598, "Value Loss": 0.031972166150808334, "_runtime": 457.4936501979828, "_timestamp": 1585077722.1852555, "_step": 389}
{"Episode reward": -95.41865332173882, "Episode length": 999, "Policy Loss": -11.904092788696289, "Value Loss": 0.024403374642133713, "_runtime": 458.623188495636, "_timestamp": 1585077723.3147938, "_step": 390}
{"Episode reward": -96.35360369906412, "Episode length": 999, "Policy Loss": -12.369853973388672, "Value Loss": 0.03175181522965431, "_runtime": 459.7360074520111, "_timestamp": 1585077724.4276128, "_step": 391}
{"Episode reward": -96.60592998131311, "Episode length": 999, "Policy Loss": -12.411688804626465, "Value Loss": 0.026992512866854668, "_runtime": 460.8444435596466, "_timestamp": 1585077725.536049, "_step": 392}
{"Episode reward": -103.66850215523621, "Episode length": 999, "Policy Loss": -13.76074504852295, "Value Loss": 0.028455950319767, "_runtime": 461.97034430503845, "_timestamp": 1585077726.6619496, "_step": 393}
{"Episode reward": -100.38247713534311, "Episode length": 999, "Policy Loss": -12.841292381286621, "Value Loss": 0.033610519021749496, "_runtime": 463.0835771560669, "_timestamp": 1585077727.7751825, "_step": 394}
{"Episode reward": -102.2341035214099, "Episode length": 999, "Policy Loss": -13.11637020111084, "Value Loss": 0.028892546892166138, "_runtime": 464.23149490356445, "_timestamp": 1585077728.9231002, "_step": 395}
{"Episode reward": -98.76764876870332, "Episode length": 999, "Policy Loss": -12.875186920166016, "Value Loss": 0.028639154508709908, "_runtime": 465.3578679561615, "_timestamp": 1585077730.0494733, "_step": 396}
{"Episode reward": -98.93780023218028, "Episode length": 999, "Policy Loss": -12.647624015808105, "Value Loss": 0.02876119501888752, "_runtime": 466.4769563674927, "_timestamp": 1585077731.1685617, "_step": 397}
{"Episode reward": -93.66290240033003, "Episode length": 999, "Policy Loss": -11.675247192382812, "Value Loss": 0.02658008225262165, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188, -156.28952026367188]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-143.35289001464844, -139.77688598632812, -136.2008819580078, -132.62486267089844, -129.04885864257812, -125.47285461425781, -121.8968505859375, -118.32084655761719, -114.74483489990234, -111.1688232421875, -107.59281921386719, -104.01681518554688, -100.44081115722656, -96.86479949951172, -93.2887954711914, -89.71278381347656, -86.13677978515625, -82.56077575683594, -78.9847640991211, -75.40876007080078, -71.83274841308594, -68.25674438476562, -64.68074035644531, -61.10472869873047, -57.528724670410156, -53.952720642089844, -50.376708984375, -46.80070495605469, -43.224700927734375, -39.64868927001953, -36.07268524169922, -32.496673583984375, -28.920669555664062, -25.34466552734375, -21.768653869628906, -18.192649841308594, -14.61663818359375, -11.040634155273438, -7.464630126953125, -3.8886260986328125, -0.3126068115234375, 3.263397216796875, 6.8394012451171875, 10.4154052734375, 13.991409301757812, 17.567413330078125, 21.1434326171875, 24.719436645507812, 28.295440673828125, 31.871444702148438, 35.44744873046875, 39.023468017578125, 42.59947204589844, 46.17547607421875, 49.75148010253906, 53.327484130859375, 56.90348815917969, 60.47950744628906, 64.05551147460938, 67.63151550292969, 71.20751953125, 74.78352355957031, 78.35954284667969, 81.935546875, 85.51155090332031]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-74.89564514160156, -72.38775634765625, -69.87987518310547, -67.37198638916016, -64.86409759521484, -62.35621643066406, -59.84832763671875, -57.3404426574707, -54.832557678222656, -52.324668884277344, -49.8167839050293, -47.30889892578125, -44.80101013183594, -42.29312515258789, -39.785240173339844, -37.27735137939453, -34.769466400146484, -32.26158142089844, -29.753692626953125, -27.245807647705078, -24.73792266845703, -22.23003387451172, -19.722148895263672, -17.214263916015625, -14.706375122070312, -12.198490142822266, -9.690605163574219, -7.182716369628906, -4.674835205078125, -2.1669464111328125, 0.3409423828125, 2.8488235473632812, 5.356712341308594, 7.864601135253906, 10.372482299804688, 12.88037109375, 15.388259887695312, 17.896141052246094, 20.404029846191406, 22.91191864013672, 25.4197998046875, 27.927688598632812, 30.435577392578125, 32.943458557128906, 35.45134735107422, 37.95923614501953, 40.46711730957031, 42.975006103515625, 45.48289489746094, 47.99077606201172, 50.49866485595703, 53.00654602050781, 55.514434814453125, 58.02232360839844, 60.53021240234375, 63.03810119628906, 65.54597473144531, 68.05386352539062, 70.56175231933594, 73.06964111328125, 75.57752990722656, 78.08541870117188, 80.59329223632812, 83.10118103027344, 85.60906982421875]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 5.0, 4.0, 6.0, 3.0, 1.0, 5.0, 3.0, 4.0, 7.0, 9.0, 17.0, 10.0, 18.0, 30.0, 25.0, 23.0, 36.0, 45.0, 39.0, 49.0, 21.0, 14.0, 20.0, 8.0, 10.0, 13.0, 10.0, 15.0, 9.0, 2.0, 10.0, 3.0, 9.0, 6.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-61.07582092285156, -59.03069305419922, -56.985565185546875, -54.9404411315918, -52.89531326293945, -50.85018539428711, -48.80506134033203, -46.75993347167969, -44.714805603027344, -42.669677734375, -40.624549865722656, -38.57942581176758, -36.534297943115234, -34.48917007446289, -32.44404602050781, -30.39891815185547, -28.353790283203125, -26.30866241455078, -24.263534545898438, -22.21841049194336, -20.173282623291016, -18.128154754638672, -16.083030700683594, -14.03790283203125, -11.992774963378906, -9.947647094726562, -7.902519226074219, -5.857395172119141, -3.812267303466797, -1.7671394348144531, 0.277984619140625, 2.3231124877929688, 4.3682403564453125, 6.413368225097656, 8.45849609375, 10.503623962402344, 12.548751831054688, 14.5938720703125, 16.638999938964844, 18.684127807617188, 20.72925567626953, 22.774383544921875, 24.81951141357422, 26.864639282226562, 28.909759521484375, 30.95488739013672, 33.00001525878906, 35.045143127441406, 37.09027099609375, 39.135398864746094, 41.18052673339844, 43.22565460205078, 45.270782470703125, 47.31590270996094, 49.36103057861328, 51.406158447265625, 53.45128631591797, 55.49641418457031, 57.541542053222656, 59.586669921875, 61.63179016113281, 63.676918029785156, 65.7220458984375, 67.76718139648438, 69.81230163574219]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-58.9704704284668, -57.521785736083984, -56.07310104370117, -54.62441635131836, -53.17572784423828, -51.72704315185547, -50.278358459472656, -48.829673767089844, -47.38098907470703, -45.93230438232422, -44.483619689941406, -43.034934997558594, -41.58625030517578, -40.13756561279297, -38.68887710571289, -37.24019241333008, -35.791507720947266, -34.34282302856445, -32.89413833618164, -31.445451736450195, -29.996767044067383, -28.54808235168457, -27.099395751953125, -25.650711059570312, -24.2020263671875, -22.753341674804688, -21.304656982421875, -19.855972290039062, -18.407283782958984, -16.958599090576172, -15.50991439819336, -14.061229705810547, -12.612545013427734, -11.163860321044922, -9.71517562866211, -8.266490936279297, -6.817806243896484, -5.369117736816406, -3.9204330444335938, -2.4717483520507812, -1.0230636596679688, 0.42562103271484375, 1.8743057250976562, 3.3229904174804688, 4.771678924560547, 6.220363616943359, 7.669048309326172, 9.117733001708984, 10.566417694091797, 12.01510238647461, 13.463787078857422, 14.912471771240234, 16.361156463623047, 17.80984115600586, 19.258525848388672, 20.707210540771484, 22.155902862548828, 23.60458755493164, 25.053272247314453, 26.501956939697266, 27.950641632080078, 29.39932632446289, 30.848011016845703, 32.296695709228516, 33.74538040161133]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 13.0, 8.0, 9.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-14.522046089172363, -13.862316131591797, -13.20258617401123, -12.542856216430664, -11.883126258850098, -11.223396301269531, -10.563667297363281, -9.903936386108398, -9.244207382202148, -8.584476470947266, -7.924746990203857, -7.265017032623291, -6.605287551879883, -5.945557594299316, -5.28582763671875, -4.626097679138184, -3.966367721557617, -3.306637763977051, -2.6469078063964844, -1.987177848815918, -1.3274478912353516, -0.6677179336547852, -0.00798797607421875, 0.6517419815063477, 1.3114709854125977, 1.9712018966674805, 2.6309309005737305, 3.2906618118286133, 3.9503908157348633, 4.610121726989746, 5.269850730895996, 5.929581642150879, 6.589310646057129, 7.249039649963379, 7.908770561218262, 8.568499565124512, 9.228230476379395, 9.887959480285645, 10.547690391540527, 11.207419395446777, 11.86715030670166, 12.52687931060791, 13.186610221862793, 13.846339225769043, 14.506070137023926, 15.165799140930176, 15.825530052185059, 16.485260009765625, 17.144989013671875, 17.804718017578125, 18.46445083618164, 19.12417984008789, 19.78390884399414, 20.44363784790039, 21.103370666503906, 21.763099670410156, 22.422828674316406, 23.082557678222656, 23.742290496826172, 24.402019500732422, 25.061748504638672, 25.721477508544922, 26.381210327148438, 27.040939331054688, 27.700668334960938]}, "_runtime": 467.61998748779297, "_timestamp": 1585077732.3115928, "_step": 398}
{"Episode reward": -99.38865334806485, "Episode length": 999, "Policy Loss": -12.901667594909668, "Value Loss": 0.030947325751185417, "_runtime": 468.76434302330017, "_timestamp": 1585077733.4559484, "_step": 399}
{"Episode reward": -99.77747265410245, "Episode length": 999, "Policy Loss": -12.667810440063477, "Value Loss": 0.029860742390155792, "_runtime": 469.86878418922424, "_timestamp": 1585077734.5603895, "_step": 400}
{"Episode reward": -101.16369677096998, "Episode length": 999, "Policy Loss": -13.318168640136719, "Value Loss": 0.03514117747545242, "_runtime": 470.998455286026, "_timestamp": 1585077735.6900606, "_step": 401}
{"Episode reward": -95.94378721359061, "Episode length": 999, "Policy Loss": -11.96156120300293, "Value Loss": 0.02610643580555916, "_runtime": 472.15541315078735, "_timestamp": 1585077736.8470185, "_step": 402}
{"Episode reward": -98.57064842727323, "Episode length": 999, "Policy Loss": -12.656258583068848, "Value Loss": 0.028624121099710464, "_runtime": 473.3099341392517, "_timestamp": 1585077738.0015395, "_step": 403}
{"Episode reward": -93.67446499769328, "Episode length": 999, "Policy Loss": -11.772738456726074, "Value Loss": 0.029306506738066673, "_runtime": 474.4490625858307, "_timestamp": 1585077739.140668, "_step": 404}
{"Episode reward": -97.33525026288542, "Episode length": 999, "Policy Loss": -12.386091232299805, "Value Loss": 0.028395038098096848, "_runtime": 475.65255641937256, "_timestamp": 1585077740.3441617, "_step": 405}
{"Episode reward": -100.92926689907394, "Episode length": 999, "Policy Loss": -13.080378532409668, "Value Loss": 0.029110092669725418, "_runtime": 476.8229513168335, "_timestamp": 1585077741.5145566, "_step": 406}
{"Episode reward": -92.77293344222316, "Episode length": 999, "Policy Loss": -11.591012001037598, "Value Loss": 0.025539759546518326, "_runtime": 477.9503996372223, "_timestamp": 1585077742.642005, "_step": 407}
{"Episode reward": -96.11257007283223, "Episode length": 999, "Policy Loss": -12.306093215942383, "Value Loss": 0.02806040644645691, "_runtime": 479.0976212024689, "_timestamp": 1585077743.7892265, "_step": 408}
{"Episode reward": -99.5700061339171, "Episode length": 999, "Policy Loss": -12.811652183532715, "Value Loss": 0.028522640466690063, "_runtime": 480.2264173030853, "_timestamp": 1585077744.9180226, "_step": 409}
{"Episode reward": -102.75454985654396, "Episode length": 999, "Policy Loss": -13.392829895019531, "Value Loss": 0.030951466411352158, "_runtime": 481.3735604286194, "_timestamp": 1585077746.0651658, "_step": 410}
{"Episode reward": -92.96209388571384, "Episode length": 999, "Policy Loss": -11.86939811706543, "Value Loss": 0.026115939021110535, "_runtime": 482.53502774238586, "_timestamp": 1585077747.226633, "_step": 411}
{"Episode reward": -99.78367020872633, "Episode length": 999, "Policy Loss": -12.871630668640137, "Value Loss": 0.029653387144207954, "_runtime": 483.68108081817627, "_timestamp": 1585077748.3726861, "_step": 412}
{"Episode reward": -99.61284479357533, "Episode length": 999, "Policy Loss": -12.968854904174805, "Value Loss": 0.029920106753706932, "_runtime": 484.7913646697998, "_timestamp": 1585077749.48297, "_step": 413}
{"Episode reward": -97.38731301919044, "Episode length": 999, "Policy Loss": -12.294690132141113, "Value Loss": 0.02839825488626957, "_runtime": 485.911363363266, "_timestamp": 1585077750.6029687, "_step": 414}
{"Episode reward": -102.0330242112926, "Episode length": 999, "Policy Loss": -13.283515930175781, "Value Loss": 0.02967027761042118, "_runtime": 487.040372133255, "_timestamp": 1585077751.7319775, "_step": 415}
{"Episode reward": -104.66558980723403, "Episode length": 999, "Policy Loss": -13.626121520996094, "Value Loss": 0.03161736950278282, "_runtime": 488.1597776412964, "_timestamp": 1585077752.851383, "_step": 416}
{"Episode reward": -100.309299349601, "Episode length": 999, "Policy Loss": -13.158110618591309, "Value Loss": 0.031073233112692833, "_runtime": 489.2752866744995, "_timestamp": 1585077753.966892, "_step": 417}
{"Episode reward": -92.28928583241934, "Episode length": 999, "Policy Loss": -11.391095161437988, "Value Loss": 0.025129538029432297, "_runtime": 490.3787715435028, "_timestamp": 1585077755.0703769, "_step": 418}
{"Episode reward": -102.24126049713557, "Episode length": 999, "Policy Loss": -13.260600090026855, "Value Loss": 0.030270256102085114, "_runtime": 491.5585153102875, "_timestamp": 1585077756.2501206, "_step": 419}
{"Episode reward": -103.46718437794944, "Episode length": 999, "Policy Loss": -13.558695793151855, "Value Loss": 0.03426804021000862, "_runtime": 492.710209608078, "_timestamp": 1585077757.401815, "_step": 420}
{"Episode reward": -97.82950951489717, "Episode length": 999, "Policy Loss": -12.785100936889648, "Value Loss": 0.027351394295692444, "_runtime": 493.85941982269287, "_timestamp": 1585077758.5510252, "_step": 421}
{"Episode reward": -96.79454156295726, "Episode length": 999, "Policy Loss": -12.351649284362793, "Value Loss": 0.02990398183465004, "_runtime": 495.0290787220001, "_timestamp": 1585077759.720684, "_step": 422}
{"Episode reward": -107.09787602740722, "Episode length": 999, "Policy Loss": -14.01637077331543, "Value Loss": 0.03852938488125801, "_runtime": 496.1211829185486, "_timestamp": 1585077760.8127882, "_step": 423}
{"Episode reward": -95.2310466749563, "Episode length": 999, "Policy Loss": -12.076462745666504, "Value Loss": 0.02774810418486595, "_runtime": 497.24123764038086, "_timestamp": 1585077761.932843, "_step": 424}
{"Episode reward": -98.89981774534179, "Episode length": 999, "Policy Loss": -12.577821731567383, "Value Loss": 0.02900756523013115, "_runtime": 498.37743854522705, "_timestamp": 1585077763.0690439, "_step": 425}
{"Episode reward": -100.70860173113944, "Episode length": 999, "Policy Loss": -12.885838508605957, "Value Loss": 0.031033281236886978, "_runtime": 499.5025782585144, "_timestamp": 1585077764.1941836, "_step": 426}
{"Episode reward": -93.72024471531512, "Episode length": 999, "Policy Loss": -11.520227432250977, "Value Loss": 0.028063643723726273, "_runtime": 500.61290431022644, "_timestamp": 1585077765.3045096, "_step": 427}
{"Episode reward": -89.47922572922153, "Episode length": 999, "Policy Loss": -10.944586753845215, "Value Loss": 0.024485785514116287, "_runtime": 501.8078637123108, "_timestamp": 1585077766.499469, "_step": 428}
{"Episode reward": -103.11244274434618, "Episode length": 999, "Policy Loss": -13.316089630126953, "Value Loss": 0.03152246028184891, "_runtime": 502.94498920440674, "_timestamp": 1585077767.6365945, "_step": 429}
{"Episode reward": -97.42852920427936, "Episode length": 999, "Policy Loss": -12.206075668334961, "Value Loss": 0.030374392867088318, "_runtime": 504.11568427085876, "_timestamp": 1585077768.8072896, "_step": 430}
{"Episode reward": -109.40387895884939, "Episode length": 999, "Policy Loss": -14.487905502319336, "Value Loss": 0.0398377850651741, "_runtime": 505.2671594619751, "_timestamp": 1585077769.9587648, "_step": 431}
{"Episode reward": -102.86325326796086, "Episode length": 999, "Policy Loss": -13.444275856018066, "Value Loss": 0.03199584409594536, "_runtime": 506.39899039268494, "_timestamp": 1585077771.0905957, "_step": 432}
{"Episode reward": -94.72304973215172, "Episode length": 999, "Policy Loss": -11.931148529052734, "Value Loss": 0.027504755184054375, "_runtime": 507.5862419605255, "_timestamp": 1585077772.2778473, "_step": 433}
{"Episode reward": -93.04427536167837, "Episode length": 999, "Policy Loss": -11.73743724822998, "Value Loss": 0.023968001827597618, "_runtime": 508.7230279445648, "_timestamp": 1585077773.4146333, "_step": 434}
{"Episode reward": -106.08606122567207, "Episode length": 999, "Policy Loss": -14.031620025634766, "Value Loss": 0.03348967432975769, "_runtime": 509.85561203956604, "_timestamp": 1585077774.5472174, "_step": 435}
{"Episode reward": -101.15774383994184, "Episode length": 999, "Policy Loss": -12.958070755004883, "Value Loss": 0.029495123773813248, "_runtime": 511.00140833854675, "_timestamp": 1585077775.6930137, "_step": 436}
{"Episode reward": -100.39025851542645, "Episode length": 999, "Policy Loss": -12.829258918762207, "Value Loss": 0.029165511950850487, "_runtime": 512.179221868515, "_timestamp": 1585077776.8708272, "_step": 437}
{"Episode reward": -106.40513071407166, "Episode length": 999, "Policy Loss": -13.890954971313477, "Value Loss": 0.03594330698251724, "_runtime": 513.3138563632965, "_timestamp": 1585077778.0054617, "_step": 438}
{"Episode reward": -101.3017398015711, "Episode length": 999, "Policy Loss": -13.002691268920898, "Value Loss": 0.029951363801956177, "_runtime": 514.5280537605286, "_timestamp": 1585077779.219659, "_step": 439}
{"Episode reward": -104.10841352457973, "Episode length": 999, "Policy Loss": -13.605541229248047, "Value Loss": 0.032841335982084274, "_runtime": 515.6657326221466, "_timestamp": 1585077780.357338, "_step": 440}
{"Episode reward": -102.90868843637875, "Episode length": 999, "Policy Loss": -13.421696662902832, "Value Loss": 0.030123692005872726, "_runtime": 516.8612260818481, "_timestamp": 1585077781.5528314, "_step": 441}
{"Episode reward": -107.70964462324874, "Episode length": 999, "Policy Loss": -14.142495155334473, "Value Loss": 0.033613450825214386, "_runtime": 517.985657453537, "_timestamp": 1585077782.6772628, "_step": 442}
{"Episode reward": -97.67715778975023, "Episode length": 999, "Policy Loss": -12.552513122558594, "Value Loss": 0.025697436183691025, "_runtime": 519.1391065120697, "_timestamp": 1585077783.8307118, "_step": 443}
{"Episode reward": -104.74014450495918, "Episode length": 999, "Policy Loss": -13.541603088378906, "Value Loss": 0.034078121185302734, "_runtime": 520.2627594470978, "_timestamp": 1585077784.9543648, "_step": 444}
{"Episode reward": -94.80633066789547, "Episode length": 999, "Policy Loss": -11.954063415527344, "Value Loss": 0.03053964115679264, "_runtime": 521.422385931015, "_timestamp": 1585077786.1139913, "_step": 445}
{"Episode reward": -98.46856403001178, "Episode length": 999, "Policy Loss": -12.579763412475586, "Value Loss": 0.030135871842503548, "_runtime": 522.6110646724701, "_timestamp": 1585077787.30267, "_step": 446}
{"Episode reward": -93.1981031262554, "Episode length": 999, "Policy Loss": -11.746824264526367, "Value Loss": 0.0258344616740942, "_runtime": 523.7422518730164, "_timestamp": 1585077788.4338572, "_step": 447}
{"Episode reward": -99.06674630551059, "Episode length": 999, "Policy Loss": -12.827017784118652, "Value Loss": 0.02737460471689701, "_runtime": 524.8991053104401, "_timestamp": 1585077789.5907106, "_step": 448}
{"Episode reward": -97.23836835501628, "Episode length": 999, "Policy Loss": -12.532600402832031, "Value Loss": 0.030145717784762383, "_runtime": 526.0200967788696, "_timestamp": 1585077790.711702, "_step": 449}
{"Episode reward": -101.77550470785214, "Episode length": 999, "Policy Loss": -13.174813270568848, "Value Loss": 0.030267274007201195, "_runtime": 527.1473462581635, "_timestamp": 1585077791.8389516, "_step": 450}
{"Episode reward": -90.66292594308541, "Episode length": 999, "Policy Loss": -11.208704948425293, "Value Loss": 0.02346023917198181, "_runtime": 528.275571346283, "_timestamp": 1585077792.9671767, "_step": 451}
{"Episode reward": -90.66663256411185, "Episode length": 999, "Policy Loss": -11.283231735229492, "Value Loss": 0.028990739956498146, "_runtime": 529.4251127243042, "_timestamp": 1585077794.116718, "_step": 452}
{"Episode reward": -99.00156219013476, "Episode length": 999, "Policy Loss": -12.508600234985352, "Value Loss": 0.030813025310635567, "_runtime": 530.5676321983337, "_timestamp": 1585077795.2592375, "_step": 453}
{"Episode reward": -94.1642835051634, "Episode length": 999, "Policy Loss": -11.912219047546387, "Value Loss": 0.026555843651294708, "_runtime": 531.7202734947205, "_timestamp": 1585077796.4118788, "_step": 454}
{"Episode reward": -104.72342822367294, "Episode length": 999, "Policy Loss": -13.938097953796387, "Value Loss": 0.03413884714245796, "_runtime": 532.8607294559479, "_timestamp": 1585077797.5523348, "_step": 455}
{"Episode reward": -103.25772416746644, "Episode length": 999, "Policy Loss": -13.641857147216797, "Value Loss": 0.030760305002331734, "_runtime": 534.0298266410828, "_timestamp": 1585077798.721432, "_step": 456}
{"Episode reward": -109.43063683455513, "Episode length": 999, "Policy Loss": -14.756871223449707, "Value Loss": 0.03705333545804024, "_runtime": 535.176506280899, "_timestamp": 1585077799.8681116, "_step": 457}
{"Episode reward": -101.97679989886339, "Episode length": 999, "Policy Loss": -13.352340698242188, "Value Loss": 0.030612347647547722, "_runtime": 536.2624142169952, "_timestamp": 1585077800.9540195, "_step": 458}
{"Episode reward": -95.00847151879925, "Episode length": 999, "Policy Loss": -11.968127250671387, "Value Loss": 0.030130134895443916, "_runtime": 537.3747165203094, "_timestamp": 1585077802.0663218, "_step": 459}
{"Episode reward": -105.3117961389808, "Episode length": 999, "Policy Loss": -13.984561920166016, "Value Loss": 0.03353198245167732, "_runtime": 538.5000493526459, "_timestamp": 1585077803.1916547, "_step": 460}
{"Episode reward": -97.75697568300563, "Episode length": 999, "Policy Loss": -12.488271713256836, "Value Loss": 0.03166159614920616, "_runtime": 539.5968415737152, "_timestamp": 1585077804.288447, "_step": 461}
{"Episode reward": -95.16319778849022, "Episode length": 999, "Policy Loss": -12.05705738067627, "Value Loss": 0.02436988800764084, "_runtime": 540.7026460170746, "_timestamp": 1585077805.3942513, "_step": 462}
{"Episode reward": -98.15850758379929, "Episode length": 999, "Policy Loss": -12.473565101623535, "Value Loss": 0.027688968926668167, "_runtime": 541.8369619846344, "_timestamp": 1585077806.5285673, "_step": 463}
{"Episode reward": -97.35723101641558, "Episode length": 999, "Policy Loss": -12.14190673828125, "Value Loss": 0.028050437569618225, "_runtime": 542.8499569892883, "_timestamp": 1585077807.5415623, "_step": 464}
{"Episode reward": 14.220316703401679, "Episode length": 885, "Policy Loss": 4.046435356140137, "Value Loss": 11.34397029876709, "_runtime": 543.9593253135681, "_timestamp": 1585077808.6509306, "_step": 465}
{"Episode reward": -109.07857623487565, "Episode length": 999, "Policy Loss": -14.470998764038086, "Value Loss": 0.0381147563457489, "_runtime": 545.0944540500641, "_timestamp": 1585077809.7860594, "_step": 466}
{"Episode reward": -101.9158079876939, "Episode length": 999, "Policy Loss": -13.18665599822998, "Value Loss": 0.03147765249013901, "_runtime": 546.2097525596619, "_timestamp": 1585077810.901358, "_step": 467}
{"Episode reward": -103.89638571262907, "Episode length": 999, "Policy Loss": -13.401631355285645, "Value Loss": 0.030558396130800247, "_runtime": 547.347752571106, "_timestamp": 1585077812.039358, "_step": 468}
{"Episode reward": -97.42081111682052, "Episode length": 999, "Policy Loss": -12.268736839294434, "Value Loss": 0.02883300743997097, "_runtime": 548.4987671375275, "_timestamp": 1585077813.1903725, "_step": 469}
{"Episode reward": -96.02941113000892, "Episode length": 999, "Policy Loss": -12.346108436584473, "Value Loss": 0.02667650207877159, "_runtime": 549.6158487796783, "_timestamp": 1585077814.307454, "_step": 470}
{"Episode reward": -95.47924593612305, "Episode length": 999, "Policy Loss": -12.010979652404785, "Value Loss": 0.028259335085749626, "_runtime": 550.7362654209137, "_timestamp": 1585077815.4278708, "_step": 471}
{"Episode reward": -100.9264242443705, "Episode length": 999, "Policy Loss": -12.726480484008789, "Value Loss": 0.030365340411663055, "_runtime": 551.9607889652252, "_timestamp": 1585077816.6523943, "_step": 472}
{"Episode reward": -99.49344622910621, "Episode length": 999, "Policy Loss": -12.677787780761719, "Value Loss": 0.02946138009428978, "_runtime": 553.1039559841156, "_timestamp": 1585077817.7955613, "_step": 473}
{"Episode reward": -90.77453582892825, "Episode length": 999, "Policy Loss": -11.381210327148438, "Value Loss": 0.024132298305630684, "_runtime": 554.279967546463, "_timestamp": 1585077818.9715729, "_step": 474}
{"Episode reward": -100.45991483186411, "Episode length": 999, "Policy Loss": -13.05510425567627, "Value Loss": 0.027389580383896828, "_runtime": 555.4497995376587, "_timestamp": 1585077820.1414049, "_step": 475}
{"Episode reward": -91.28828943635716, "Episode length": 999, "Policy Loss": -11.28808879852295, "Value Loss": 0.02481686882674694, "_runtime": 556.3629126548767, "_timestamp": 1585077821.054518, "_step": 476}
{"Episode reward": 25.53321302480697, "Episode length": 812, "Policy Loss": 5.973858833312988, "Value Loss": 12.350879669189453, "_runtime": 557.5166342258453, "_timestamp": 1585077822.2082396, "_step": 477}
{"Episode reward": -91.72164783194714, "Episode length": 999, "Policy Loss": -11.590173721313477, "Value Loss": 0.02445918507874012, "_runtime": 558.6576857566833, "_timestamp": 1585077823.349291, "_step": 478}
{"Episode reward": -97.680589544135, "Episode length": 999, "Policy Loss": -12.489619255065918, "Value Loss": 0.028617508709430695, "_runtime": 559.7710649967194, "_timestamp": 1585077824.4626703, "_step": 479}
{"Episode reward": -105.74603334368331, "Episode length": 999, "Policy Loss": -13.879158973693848, "Value Loss": 0.03353402018547058, "_runtime": 560.8933184146881, "_timestamp": 1585077825.5849237, "_step": 480}
{"Episode reward": -100.13817947280208, "Episode length": 999, "Policy Loss": -13.077661514282227, "Value Loss": 0.03175952658057213, "_runtime": 562.0132796764374, "_timestamp": 1585077826.704885, "_step": 481}
{"Episode reward": -95.2541947977206, "Episode length": 999, "Policy Loss": -11.887361526489258, "Value Loss": 0.026321427896618843, "_runtime": 563.1348135471344, "_timestamp": 1585077827.8264189, "_step": 482}
{"Episode reward": -86.5452487061353, "Episode length": 999, "Policy Loss": -10.5983304977417, "Value Loss": 0.020533280447125435, "_runtime": 564.2858004570007, "_timestamp": 1585077828.9774058, "_step": 483}
{"Episode reward": -98.44165108715349, "Episode length": 999, "Policy Loss": -12.720428466796875, "Value Loss": 0.028456712141633034, "_runtime": 565.4159331321716, "_timestamp": 1585077830.1075385, "_step": 484}
{"Episode reward": -98.78893024648956, "Episode length": 999, "Policy Loss": -12.762401580810547, "Value Loss": 0.027102990075945854, "_runtime": 566.1321496963501, "_timestamp": 1585077830.823755, "_step": 485}
{"Episode reward": 24.370830061368096, "Episode length": 627, "Policy Loss": 8.803730010986328, "Value Loss": 16.014253616333008, "_runtime": 567.2535645961761, "_timestamp": 1585077831.94517, "_step": 486}
{"Episode reward": -104.93931547699749, "Episode length": 999, "Policy Loss": -13.836027145385742, "Value Loss": 0.030277010053396225, "_runtime": 568.4200069904327, "_timestamp": 1585077833.1116123, "_step": 487}
{"Episode reward": -101.24789338506964, "Episode length": 999, "Policy Loss": -13.123373985290527, "Value Loss": 0.030056320130825043, "_runtime": 569.5520522594452, "_timestamp": 1585077834.2436576, "_step": 488}
{"Episode reward": -105.9450530598505, "Episode length": 999, "Policy Loss": -13.74852466583252, "Value Loss": 0.03366777300834656, "_runtime": 570.6823630332947, "_timestamp": 1585077835.3739684, "_step": 489}
{"Episode reward": -101.48925720385786, "Episode length": 999, "Policy Loss": -13.16061019897461, "Value Loss": 0.030407734215259552, "_runtime": 571.8893046379089, "_timestamp": 1585077836.58091, "_step": 490}
{"Episode reward": 5.846405207867164, "Episode length": 975, "Policy Loss": 1.2478971481323242, "Value Loss": 10.286555290222168, "_runtime": 573.0048825740814, "_timestamp": 1585077837.696488, "_step": 491}
{"Episode reward": -100.63491135863931, "Episode length": 999, "Policy Loss": -12.951066970825195, "Value Loss": 0.027868518605828285, "_runtime": 574.1567869186401, "_timestamp": 1585077838.8483922, "_step": 492}
{"Episode reward": -95.72303699886953, "Episode length": 999, "Policy Loss": -12.222692489624023, "Value Loss": 0.026536906138062477, "_runtime": 575.2757782936096, "_timestamp": 1585077839.9673836, "_step": 493}
{"Episode reward": -104.4298487175127, "Episode length": 999, "Policy Loss": -13.846736907958984, "Value Loss": 0.0324946753680706, "_runtime": 576.3930339813232, "_timestamp": 1585077841.0846393, "_step": 494}
{"Episode reward": -95.10975128377319, "Episode length": 999, "Policy Loss": -12.02318286895752, "Value Loss": 0.026933271437883377, "_runtime": 577.5159387588501, "_timestamp": 1585077842.207544, "_step": 495}
{"Episode reward": -104.43842890647167, "Episode length": 999, "Policy Loss": -13.828509330749512, "Value Loss": 0.030658794566988945, "_runtime": 578.35511302948, "_timestamp": 1585077843.0467184, "_step": 496}
{"Episode reward": 19.045291573795836, "Episode length": 753, "Policy Loss": 5.342714309692383, "Value Loss": 13.331443786621094, "_runtime": 579.4779562950134, "_timestamp": 1585077844.1695616, "_step": 497}
{"Episode reward": -104.6816935516562, "Episode length": 999, "Policy Loss": -13.857933044433594, "Value Loss": 0.03313283622264862, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062, -210.05093383789062]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-194.81881713867188, -190.0306396484375, -185.24246215820312, -180.45428466796875, -175.66610717773438, -170.8779296875, -166.08975219726562, -161.3015899658203, -156.51341247558594, -151.72523498535156, -146.9370574951172, -142.1488800048828, -137.36070251464844, -132.57252502441406, -127.78435516357422, -122.99617767333984, -118.20800018310547, -113.4198226928711, -108.63164520263672, -103.84347534179688, -99.0552978515625, -94.26712036132812, -89.47894287109375, -84.69076538085938, -79.902587890625, -75.11441802978516, -70.32624053955078, -65.53807067871094, -60.74989318847656, -55.96171569824219, -51.17353820800781, -46.38536071777344, -41.59718322753906, -36.80900573730469, -32.02082824707031, -27.232650756835938, -22.444473266601562, -17.656295776367188, -12.868133544921875, -8.0799560546875, -3.291778564453125, 1.49639892578125, 6.284576416015625, 11.07275390625, 15.860931396484375, 20.64910888671875, 25.437286376953125, 30.2254638671875, 35.013641357421875, 39.80180358886719, 44.58998107910156, 49.37815856933594, 54.16633605957031, 58.95451354980469, 63.74267578125, 68.53085327148438, 73.31903076171875, 78.10720825195312, 82.8953857421875, 87.68356323242188, 92.47174072265625, 97.25991821289062, 102.048095703125, 106.83627319335938, 111.62445068359375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-101.38470458984375, -98.03845977783203, -94.69221496582031, -91.3459701538086, -87.99972534179688, -84.65348815917969, -81.30724334716797, -77.96099853515625, -74.61475372314453, -71.26850891113281, -67.9222640991211, -64.57601928710938, -61.22977828979492, -57.8835334777832, -54.53729248046875, -51.19104766845703, -47.84480285644531, -44.498558044433594, -41.152313232421875, -37.80607223510742, -34.45982360839844, -31.11358642578125, -27.76734161376953, -24.421096801757812, -21.074851989746094, -17.728607177734375, -14.382362365722656, -11.036117553710938, -7.68988037109375, -4.343635559082031, -0.9973907470703125, 2.3488540649414062, 5.695098876953125, 9.041343688964844, 12.387588500976562, 15.733833312988281, 19.080078125, 22.426315307617188, 25.772560119628906, 29.118804931640625, 32.465057373046875, 35.81129455566406, 39.15753173828125, 42.5037841796875, 45.85002136230469, 49.19627380371094, 52.542510986328125, 55.888763427734375, 59.23500061035156, 62.58123779296875, 65.927490234375, 69.27372741699219, 72.61997985839844, 75.96621704101562, 79.31246948242188, 82.65870666503906, 86.00494384765625, 89.3511962890625, 92.69743347167969, 96.04368591308594, 99.38992309570312, 102.73617553710938, 106.08241271972656, 109.42866516113281, 112.77490234375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 6.0, 0.0, 6.0, 7.0, 3.0, 7.0, 14.0, 13.0, 28.0, 31.0, 25.0, 37.0, 46.0, 28.0, 55.0, 32.0, 17.0, 19.0, 14.0, 10.0, 11.0, 16.0, 11.0, 8.0, 6.0, 6.0, 7.0, 5.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-91.47823333740234, -88.45867156982422, -85.43910217285156, -82.41954040527344, -79.39997100830078, -76.38040924072266, -73.36083984375, -70.34127807617188, -67.32171630859375, -64.3021469116211, -61.2825813293457, -58.26301574707031, -55.24345397949219, -52.2238883972168, -49.204322814941406, -46.184757232666016, -43.165191650390625, -40.145626068115234, -37.126060485839844, -34.10649490356445, -31.086929321289062, -28.067367553710938, -25.04779815673828, -22.028236389160156, -19.00867462158203, -15.989105224609375, -12.96954345703125, -9.949974060058594, -6.930412292480469, -3.9108428955078125, -0.8912811279296875, 2.1282882690429688, 5.147850036621094, 8.167411804199219, 11.186981201171875, 14.20654296875, 17.226112365722656, 20.24567413330078, 23.265243530273438, 26.284805297851562, 29.30437469482422, 32.323936462402344, 35.34349822998047, 38.363059997558594, 41.38263702392578, 44.402198791503906, 47.42176055908203, 50.441322326660156, 53.46088409423828, 56.48046112060547, 59.500022888183594, 62.51958465576172, 65.53914642333984, 68.55872344970703, 71.57828521728516, 74.59784698486328, 77.6174087524414, 80.63697052001953, 83.65654754638672, 86.67610931396484, 89.69567108154297, 92.7152328491211, 95.73480987548828, 98.7543716430664, 101.77393341064453]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-81.45325469970703, -79.52223205566406, -77.5912094116211, -75.66018676757812, -73.72915649414062, -71.79813385009766, -69.86711120605469, -67.93608856201172, -66.00506591796875, -64.07403564453125, -62.14301681518555, -60.21199035644531, -58.280967712402344, -56.349945068359375, -54.418922424316406, -52.48789978027344, -50.5568733215332, -48.625850677490234, -46.69482421875, -44.76380157470703, -42.83277893066406, -40.90175247192383, -38.97072982788086, -37.03970718383789, -35.108680725097656, -33.17765808105469, -31.24663543701172, -29.31561279296875, -27.384586334228516, -25.453563690185547, -23.522541046142578, -21.591514587402344, -19.660491943359375, -17.729469299316406, -15.798446655273438, -13.867424011230469, -11.936393737792969, -10.00537109375, -8.074348449707031, -6.1433258056640625, -4.212303161621094, -2.281280517578125, -0.350250244140625, 1.5807723999023438, 3.5117950439453125, 5.442817687988281, 7.37384033203125, 9.304862976074219, 11.235893249511719, 13.166915893554688, 15.097938537597656, 17.028961181640625, 18.959983825683594, 20.891006469726562, 22.82202911376953, 24.75305938720703, 26.68408203125, 28.61510467529297, 30.546127319335938, 32.477149963378906, 34.408172607421875, 36.339202880859375, 38.270225524902344, 40.20124816894531, 42.13227081298828]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 28.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-29.271753311157227, -27.924880981445312, -26.578006744384766, -25.23113441467285, -23.884262084960938, -22.537389755249023, -21.19051742553711, -19.843643188476562, -18.49677085876465, -17.149898529052734, -15.803025245666504, -14.456151962280273, -13.10927963256836, -11.762407302856445, -10.415533065795898, -9.068660736083984, -7.72178840637207, -6.374916076660156, -5.028043746948242, -3.6811695098876953, -2.3342971801757812, -0.9874248504638672, 0.3594493865966797, 1.7063217163085938, 3.053194046020508, 4.400068283081055, 5.746938705444336, 7.093812942504883, 8.44068717956543, 9.787557601928711, 11.134431838989258, 12.481302261352539, 13.828176498413086, 15.175050735473633, 16.521921157836914, 17.86879539489746, 19.215665817260742, 20.56254005432129, 21.909414291381836, 23.256284713745117, 24.603158950805664, 25.95003318786621, 27.296903610229492, 28.64377784729004, 29.990652084350586, 31.337522506713867, 32.68439483642578, 34.03126525878906, 35.378143310546875, 36.725013732910156, 38.07189178466797, 39.41876220703125, 40.76563262939453, 42.112510681152344, 43.459381103515625, 44.806251525878906, 46.15312957763672, 47.5, 48.84687042236328, 50.19374084472656, 51.540618896484375, 52.887489318847656, 54.23435974121094, 55.58123779296875, 56.92810821533203]}, "_runtime": 580.5981729030609, "_timestamp": 1585077845.2897782, "_step": 498}
{"Episode reward": -100.43097465203485, "Episode length": 999, "Policy Loss": -12.626520156860352, "Value Loss": 0.0326315313577652, "_runtime": 581.7817471027374, "_timestamp": 1585077846.4733524, "_step": 499}
{"Episode reward": -98.18009779362582, "Episode length": 999, "Policy Loss": -12.349806785583496, "Value Loss": 0.028427712619304657, "_runtime": 581.7817471027374, "_timestamp": 1585077846.4733524, "_step": 500}
