{"Episode reward": -99.19845567384967, "Episode length": 999, "Policy Loss": -0.5343167185783386, "Value Loss": 0.028208650648593903, "_runtime": 12.488348007202148, "_timestamp": 1585135847.9453816, "_step": 0}
{"Episode reward": -92.10941581965601, "Episode length": 999, "Policy Loss": -0.521060049533844, "Value Loss": 0.024877388030290604, "_runtime": 13.593510150909424, "_timestamp": 1585135849.0505438, "_step": 1}
{"Episode reward": -106.41668895545058, "Episode length": 999, "Policy Loss": -0.5682902932167053, "Value Loss": 0.032339438796043396, "_runtime": 14.701286315917969, "_timestamp": 1585135850.15832, "_step": 2}
{"Episode reward": -99.76215268786909, "Episode length": 999, "Policy Loss": -0.5406347513198853, "Value Loss": 0.033236902207136154, "_runtime": 15.843648910522461, "_timestamp": 1585135851.3006825, "_step": 3}
{"Episode reward": -103.75800548504574, "Episode length": 999, "Policy Loss": -0.5525805354118347, "Value Loss": 0.030647793784737587, "_runtime": 16.96774125099182, "_timestamp": 1585135852.424775, "_step": 4}
{"Episode reward": -104.35796379447983, "Episode length": 999, "Policy Loss": -0.5469940900802612, "Value Loss": 0.034731343388557434, "_runtime": 18.080718994140625, "_timestamp": 1585135853.5377526, "_step": 5}
{"Episode reward": -104.0042044268566, "Episode length": 999, "Policy Loss": -0.5499295592308044, "Value Loss": 0.031197354197502136, "_runtime": 19.241437196731567, "_timestamp": 1585135854.6984708, "_step": 6}
{"Episode reward": -99.28203131651473, "Episode length": 999, "Policy Loss": -0.5458012819290161, "Value Loss": 0.02809550240635872, "_runtime": 20.385124444961548, "_timestamp": 1585135855.842158, "_step": 7}
{"Episode reward": -105.35331766617027, "Episode length": 999, "Policy Loss": -0.5547835826873779, "Value Loss": 0.03190949931740761, "_runtime": 21.55167555809021, "_timestamp": 1585135857.0087092, "_step": 8}
{"Episode reward": -104.39315174639744, "Episode length": 999, "Policy Loss": -0.5609885454177856, "Value Loss": 0.03284722939133644, "_runtime": 22.725720643997192, "_timestamp": 1585135858.1827543, "_step": 9}
{"Episode reward": -102.77850322612076, "Episode length": 999, "Policy Loss": -0.5468655228614807, "Value Loss": 0.0325029157102108, "_runtime": 23.860995769500732, "_timestamp": 1585135859.3180294, "_step": 10}
{"Episode reward": -108.05342736228599, "Episode length": 999, "Policy Loss": -0.5725783109664917, "Value Loss": 0.03779524564743042, "_runtime": 24.98201847076416, "_timestamp": 1585135860.439052, "_step": 11}
{"Episode reward": -103.04765851705181, "Episode length": 999, "Policy Loss": -0.5509259700775146, "Value Loss": 0.030303161591291428, "_runtime": 26.155117511749268, "_timestamp": 1585135861.6121511, "_step": 12}
{"Episode reward": -93.55301547043112, "Episode length": 999, "Policy Loss": -0.5208379626274109, "Value Loss": 0.0266276765614748, "_runtime": 27.32549810409546, "_timestamp": 1585135862.7825317, "_step": 13}
{"Episode reward": -109.2027639957591, "Episode length": 999, "Policy Loss": -0.5699855089187622, "Value Loss": 0.03484877571463585, "_runtime": 28.459992170333862, "_timestamp": 1585135863.9170258, "_step": 14}
{"Episode reward": -96.92042313515944, "Episode length": 999, "Policy Loss": -0.5259456038475037, "Value Loss": 0.027098460122942924, "_runtime": 29.572169303894043, "_timestamp": 1585135865.029203, "_step": 15}
{"Episode reward": -97.68808502378852, "Episode length": 999, "Policy Loss": -0.5363863706588745, "Value Loss": 0.028516307473182678, "_runtime": 30.72922682762146, "_timestamp": 1585135866.1862605, "_step": 16}
{"Episode reward": -99.46962415596876, "Episode length": 999, "Policy Loss": -0.5413123965263367, "Value Loss": 0.03293335810303688, "_runtime": 31.89595937728882, "_timestamp": 1585135867.352993, "_step": 17}
{"Episode reward": -101.44209604207117, "Episode length": 999, "Policy Loss": -0.5531525015830994, "Value Loss": 0.0297401063144207, "_runtime": 33.023979902267456, "_timestamp": 1585135868.4810135, "_step": 18}
{"Episode reward": -96.00854778642926, "Episode length": 999, "Policy Loss": -0.5286415815353394, "Value Loss": 0.03061201423406601, "_runtime": 34.16079592704773, "_timestamp": 1585135869.6178296, "_step": 19}
{"Episode reward": -95.46418572588826, "Episode length": 999, "Policy Loss": -0.5245727896690369, "Value Loss": 0.026672793552279472, "_runtime": 35.278581857681274, "_timestamp": 1585135870.7356155, "_step": 20}
{"Episode reward": -100.65452290395102, "Episode length": 999, "Policy Loss": -0.5408354997634888, "Value Loss": 0.03536112233996391, "_runtime": 36.4118595123291, "_timestamp": 1585135871.8688931, "_step": 21}
{"Episode reward": -103.51303666803453, "Episode length": 999, "Policy Loss": -0.5529574751853943, "Value Loss": 0.028935641050338745, "_runtime": 37.52635216712952, "_timestamp": 1585135872.9833858, "_step": 22}
{"Episode reward": -99.06769543325092, "Episode length": 999, "Policy Loss": -0.5459036231040955, "Value Loss": 0.027500564232468605, "_runtime": 38.6884822845459, "_timestamp": 1585135874.145516, "_step": 23}
{"Episode reward": -106.93589667924036, "Episode length": 999, "Policy Loss": -0.5580562353134155, "Value Loss": 0.034823108464479446, "_runtime": 39.81016731262207, "_timestamp": 1585135875.267201, "_step": 24}
{"Episode reward": -102.7459788086038, "Episode length": 999, "Policy Loss": -0.5510538816452026, "Value Loss": 0.032436568289995193, "_runtime": 40.99357008934021, "_timestamp": 1585135876.4506037, "_step": 25}
{"Episode reward": -108.54445452235115, "Episode length": 999, "Policy Loss": -0.5757536888122559, "Value Loss": 0.03618382290005684, "_runtime": 42.16016745567322, "_timestamp": 1585135877.617201, "_step": 26}
{"Episode reward": -102.6351090313044, "Episode length": 999, "Policy Loss": -0.5533213019371033, "Value Loss": 0.031062988564372063, "_runtime": 43.31342172622681, "_timestamp": 1585135878.7704554, "_step": 27}
{"Episode reward": -103.29886906388084, "Episode length": 999, "Policy Loss": -0.5586822628974915, "Value Loss": 0.03223839029669762, "_runtime": 44.50395226478577, "_timestamp": 1585135879.960986, "_step": 28}
{"Episode reward": -108.13917160126897, "Episode length": 999, "Policy Loss": -0.5686330795288086, "Value Loss": 0.03950483724474907, "_runtime": 45.62652039527893, "_timestamp": 1585135881.083554, "_step": 29}
{"Episode reward": -99.51068495536143, "Episode length": 999, "Policy Loss": -0.5412610173225403, "Value Loss": 0.028854265809059143, "_runtime": 46.771737575531006, "_timestamp": 1585135882.2287712, "_step": 30}
{"Episode reward": -99.79891197865828, "Episode length": 999, "Policy Loss": -0.5348870754241943, "Value Loss": 0.03263390436768532, "_runtime": 47.90778636932373, "_timestamp": 1585135883.36482, "_step": 31}
{"Episode reward": -104.33559445316281, "Episode length": 999, "Policy Loss": -0.5483301281929016, "Value Loss": 0.03501424565911293, "_runtime": 49.02429008483887, "_timestamp": 1585135884.4813237, "_step": 32}
{"Episode reward": -110.41797948284263, "Episode length": 999, "Policy Loss": -0.578251302242279, "Value Loss": 0.03536909818649292, "_runtime": 50.152787923812866, "_timestamp": 1585135885.6098216, "_step": 33}
{"Episode reward": -101.6297391329183, "Episode length": 999, "Policy Loss": -0.551020622253418, "Value Loss": 0.02965991199016571, "_runtime": 51.31719517707825, "_timestamp": 1585135886.7742288, "_step": 34}
{"Episode reward": -102.28913788395587, "Episode length": 999, "Policy Loss": -0.545887291431427, "Value Loss": 0.03152887523174286, "_runtime": 52.44992923736572, "_timestamp": 1585135887.9069629, "_step": 35}
{"Episode reward": -106.97257500601069, "Episode length": 999, "Policy Loss": -0.5661088824272156, "Value Loss": 0.033220600336790085, "_runtime": 53.60463619232178, "_timestamp": 1585135889.0616698, "_step": 36}
{"Episode reward": -108.37024653951275, "Episode length": 999, "Policy Loss": -0.5720493197441101, "Value Loss": 0.037819407880306244, "_runtime": 54.72890114784241, "_timestamp": 1585135890.1859348, "_step": 37}
{"Episode reward": -98.20811695582645, "Episode length": 999, "Policy Loss": -0.5399239659309387, "Value Loss": 0.028907937929034233, "_runtime": 55.88880014419556, "_timestamp": 1585135891.3458338, "_step": 38}
{"Episode reward": -97.98548541377853, "Episode length": 999, "Policy Loss": -0.5407711863517761, "Value Loss": 0.028147485107183456, "_runtime": 57.073965072631836, "_timestamp": 1585135892.5309987, "_step": 39}
{"Episode reward": -95.9583724154583, "Episode length": 999, "Policy Loss": -0.533355176448822, "Value Loss": 0.02661184035241604, "_runtime": 58.18942093849182, "_timestamp": 1585135893.6464546, "_step": 40}
{"Episode reward": -105.11007915561552, "Episode length": 999, "Policy Loss": -0.5501174926757812, "Value Loss": 0.03334660828113556, "_runtime": 59.298585176467896, "_timestamp": 1585135894.7556188, "_step": 41}
{"Episode reward": -100.32277277057369, "Episode length": 999, "Policy Loss": -0.5316181182861328, "Value Loss": 0.033936530351638794, "_runtime": 60.43060803413391, "_timestamp": 1585135895.8876417, "_step": 42}
{"Episode reward": -98.52509735914603, "Episode length": 999, "Policy Loss": -0.5397909879684448, "Value Loss": 0.03199411556124687, "_runtime": 61.57025647163391, "_timestamp": 1585135897.02729, "_step": 43}
{"Episode reward": -103.54927026474321, "Episode length": 999, "Policy Loss": -0.5557994246482849, "Value Loss": 0.030735662207007408, "_runtime": 62.72068381309509, "_timestamp": 1585135898.1777174, "_step": 44}
{"Episode reward": -103.93586707643676, "Episode length": 999, "Policy Loss": -0.549477756023407, "Value Loss": 0.03262842074036598, "_runtime": 63.859806537628174, "_timestamp": 1585135899.3168402, "_step": 45}
{"Episode reward": -107.65370607659327, "Episode length": 999, "Policy Loss": -0.555963397026062, "Value Loss": 0.03836642578244209, "_runtime": 65.03906345367432, "_timestamp": 1585135900.496097, "_step": 46}
{"Episode reward": -98.85647931281139, "Episode length": 999, "Policy Loss": -0.5400449633598328, "Value Loss": 0.028981558978557587, "_runtime": 66.1582601070404, "_timestamp": 1585135901.6152937, "_step": 47}
{"Episode reward": -91.1567594509359, "Episode length": 999, "Policy Loss": -0.5122902393341064, "Value Loss": 0.027128122746944427, "_runtime": 67.27334523200989, "_timestamp": 1585135902.7303789, "_step": 48}
{"Episode reward": -104.3713277629672, "Episode length": 999, "Policy Loss": -0.5471137762069702, "Value Loss": 0.03544408828020096, "_runtime": 68.38326382637024, "_timestamp": 1585135903.8402975, "_step": 49}
{"Episode reward": -102.55520990522561, "Episode length": 999, "Policy Loss": -0.5494892001152039, "Value Loss": 0.03447704762220383, "_runtime": 69.4987895488739, "_timestamp": 1585135904.9558232, "_step": 50}
{"Episode reward": -94.9249920948682, "Episode length": 999, "Policy Loss": -0.5310894846916199, "Value Loss": 0.02762819081544876, "_runtime": 70.6517882347107, "_timestamp": 1585135906.1088219, "_step": 51}
{"Episode reward": -101.80549011154525, "Episode length": 999, "Policy Loss": -0.5484632849693298, "Value Loss": 0.03345924988389015, "_runtime": 71.78114652633667, "_timestamp": 1585135907.2381802, "_step": 52}
{"Episode reward": -92.47758936704538, "Episode length": 999, "Policy Loss": -0.5142701864242554, "Value Loss": 0.02442735992372036, "_runtime": 72.89858984947205, "_timestamp": 1585135908.3556235, "_step": 53}
{"Episode reward": -100.12542820988993, "Episode length": 999, "Policy Loss": -0.5338189005851746, "Value Loss": 0.029975788667798042, "_runtime": 74.02773213386536, "_timestamp": 1585135909.4847658, "_step": 54}
{"Episode reward": -99.53558507817708, "Episode length": 999, "Policy Loss": -0.5378875136375427, "Value Loss": 0.028384936973452568, "_runtime": 75.15888953208923, "_timestamp": 1585135910.6159232, "_step": 55}
{"Episode reward": -112.62514829888951, "Episode length": 999, "Policy Loss": -0.5802091360092163, "Value Loss": 0.0357719250023365, "_runtime": 76.32275748252869, "_timestamp": 1585135911.779791, "_step": 56}
{"Episode reward": -101.47056679891809, "Episode length": 999, "Policy Loss": -0.5417989492416382, "Value Loss": 0.031067464500665665, "_runtime": 77.45086193084717, "_timestamp": 1585135912.9078956, "_step": 57}
{"Episode reward": -110.03477733740806, "Episode length": 999, "Policy Loss": -0.5722626447677612, "Value Loss": 0.03427065536379814, "_runtime": 78.61461901664734, "_timestamp": 1585135914.0716527, "_step": 58}
{"Episode reward": -98.9740811041791, "Episode length": 999, "Policy Loss": -0.5399177074432373, "Value Loss": 0.02798336185514927, "_runtime": 79.71996712684631, "_timestamp": 1585135915.1770008, "_step": 59}
{"Episode reward": -109.73945080315195, "Episode length": 999, "Policy Loss": -0.5783208608627319, "Value Loss": 0.0377681590616703, "_runtime": 80.89409184455872, "_timestamp": 1585135916.3511255, "_step": 60}
{"Episode reward": -94.96500497121677, "Episode length": 999, "Policy Loss": -0.5322468280792236, "Value Loss": 0.028622549027204514, "_runtime": 82.05178761482239, "_timestamp": 1585135917.5088212, "_step": 61}
{"Episode reward": -104.86312121665387, "Episode length": 999, "Policy Loss": -0.5518463850021362, "Value Loss": 0.03134668245911598, "_runtime": 83.17373728752136, "_timestamp": 1585135918.630771, "_step": 62}
{"Episode reward": -94.19920528389436, "Episode length": 999, "Policy Loss": -0.5291502475738525, "Value Loss": 0.024916628375649452, "_runtime": 84.34001922607422, "_timestamp": 1585135919.7970529, "_step": 63}
{"Episode reward": -95.8027607156652, "Episode length": 999, "Policy Loss": -0.5248292684555054, "Value Loss": 0.027606405317783356, "_runtime": 85.45548462867737, "_timestamp": 1585135920.9125183, "_step": 64}
{"Episode reward": -100.79426564541433, "Episode length": 999, "Policy Loss": -0.551820695400238, "Value Loss": 0.031150802969932556, "_runtime": 86.60337805747986, "_timestamp": 1585135922.0604117, "_step": 65}
{"Episode reward": -99.93380042087904, "Episode length": 999, "Policy Loss": -0.5438712239265442, "Value Loss": 0.027530450373888016, "_runtime": 87.76065278053284, "_timestamp": 1585135923.2176864, "_step": 66}
{"Episode reward": -95.46634423685859, "Episode length": 999, "Policy Loss": -0.5306044816970825, "Value Loss": 0.026372944936156273, "_runtime": 88.91583013534546, "_timestamp": 1585135924.3728638, "_step": 67}
{"Episode reward": -92.44807825489339, "Episode length": 999, "Policy Loss": -0.5194500684738159, "Value Loss": 0.0255811158567667, "_runtime": 90.0355167388916, "_timestamp": 1585135925.4925504, "_step": 68}
{"Episode reward": -103.89178330746697, "Episode length": 999, "Policy Loss": -0.5524783134460449, "Value Loss": 0.032166123390197754, "_runtime": 91.20092868804932, "_timestamp": 1585135926.6579623, "_step": 69}
{"Episode reward": -102.341973038107, "Episode length": 999, "Policy Loss": -0.5561112761497498, "Value Loss": 0.028523899614810944, "_runtime": 92.3326849937439, "_timestamp": 1585135927.7897186, "_step": 70}
{"Episode reward": -104.03279537761706, "Episode length": 999, "Policy Loss": -0.5548281073570251, "Value Loss": 0.0325981006026268, "_runtime": 93.49169206619263, "_timestamp": 1585135928.9487257, "_step": 71}
{"Episode reward": -98.8320054662393, "Episode length": 999, "Policy Loss": -0.53965824842453, "Value Loss": 0.029605060815811157, "_runtime": 94.679692029953, "_timestamp": 1585135930.1367257, "_step": 72}
{"Episode reward": -99.10865681393821, "Episode length": 999, "Policy Loss": -0.5429630875587463, "Value Loss": 0.03092331998050213, "_runtime": 95.72507762908936, "_timestamp": 1585135931.1821113, "_step": 73}
{"Episode reward": 10.422697929157025, "Episode length": 898, "Policy Loss": -0.29977667331695557, "Value Loss": 11.172796249389648, "_runtime": 96.88959980010986, "_timestamp": 1585135932.3466334, "_step": 74}
{"Episode reward": -107.91783816535293, "Episode length": 999, "Policy Loss": -0.5622950196266174, "Value Loss": 0.03401883319020271, "_runtime": 98.01032304763794, "_timestamp": 1585135933.4673567, "_step": 75}
{"Episode reward": -98.57427507880638, "Episode length": 999, "Policy Loss": -0.5454822778701782, "Value Loss": 0.031990401446819305, "_runtime": 99.16896891593933, "_timestamp": 1585135934.6260026, "_step": 76}
{"Episode reward": -105.60136407796816, "Episode length": 999, "Policy Loss": -0.5632420778274536, "Value Loss": 0.03118298575282097, "_runtime": 100.31293845176697, "_timestamp": 1585135935.769972, "_step": 77}
{"Episode reward": -97.43241122895685, "Episode length": 999, "Policy Loss": -0.5360214710235596, "Value Loss": 0.028985759243369102, "_runtime": 101.45661902427673, "_timestamp": 1585135936.9136527, "_step": 78}
{"Episode reward": -105.5030811753347, "Episode length": 999, "Policy Loss": -0.5531154870986938, "Value Loss": 0.03471137583255768, "_runtime": 102.63242101669312, "_timestamp": 1585135938.0894547, "_step": 79}
{"Episode reward": -98.43565420625606, "Episode length": 999, "Policy Loss": -0.5404444336891174, "Value Loss": 0.02954942360520363, "_runtime": 103.7640426158905, "_timestamp": 1585135939.2210763, "_step": 80}
{"Episode reward": -104.40632592399162, "Episode length": 999, "Policy Loss": -0.5582326054573059, "Value Loss": 0.03245719522237778, "_runtime": 104.88862180709839, "_timestamp": 1585135940.3456554, "_step": 81}
{"Episode reward": -98.58035001720371, "Episode length": 999, "Policy Loss": -0.5381792783737183, "Value Loss": 0.029611146077513695, "_runtime": 106.04025387763977, "_timestamp": 1585135941.4972875, "_step": 82}
{"Episode reward": -104.62912406818401, "Episode length": 999, "Policy Loss": -0.5631988644599915, "Value Loss": 0.03070986270904541, "_runtime": 107.1649079322815, "_timestamp": 1585135942.6219416, "_step": 83}
{"Episode reward": -94.7222072177726, "Episode length": 999, "Policy Loss": -0.5276268720626831, "Value Loss": 0.02759646251797676, "_runtime": 108.27642607688904, "_timestamp": 1585135943.7334597, "_step": 84}
{"Episode reward": -105.98634015602569, "Episode length": 999, "Policy Loss": -0.5674574375152588, "Value Loss": 0.03226342797279358, "_runtime": 109.42075300216675, "_timestamp": 1585135944.8777866, "_step": 85}
{"Episode reward": -104.09126618818381, "Episode length": 999, "Policy Loss": -0.551580011844635, "Value Loss": 0.034113287925720215, "_runtime": 110.56782484054565, "_timestamp": 1585135946.0248585, "_step": 86}
{"Episode reward": -104.39675396574023, "Episode length": 999, "Policy Loss": -0.5580304861068726, "Value Loss": 0.03168775886297226, "_runtime": 111.69316959381104, "_timestamp": 1585135947.1502032, "_step": 87}
{"Episode reward": -102.57805314789366, "Episode length": 999, "Policy Loss": -0.5535627007484436, "Value Loss": 0.033869918435811996, "_runtime": 112.83566427230835, "_timestamp": 1585135948.292698, "_step": 88}
{"Episode reward": -108.82527672709327, "Episode length": 999, "Policy Loss": -0.5731834173202515, "Value Loss": 0.03519204258918762, "_runtime": 114.08617830276489, "_timestamp": 1585135949.543212, "_step": 89}
{"Episode reward": -99.05744468583029, "Episode length": 999, "Policy Loss": -0.5426210761070251, "Value Loss": 0.030487501993775368, "_runtime": 115.22359228134155, "_timestamp": 1585135950.680626, "_step": 90}
{"Episode reward": -103.23802278494021, "Episode length": 999, "Policy Loss": -0.5560051798820496, "Value Loss": 0.03091663494706154, "_runtime": 116.40321230888367, "_timestamp": 1585135951.860246, "_step": 91}
{"Episode reward": -106.40347185860702, "Episode length": 999, "Policy Loss": -0.5503870844841003, "Value Loss": 0.03446206450462341, "_runtime": 117.5230176448822, "_timestamp": 1585135952.9800513, "_step": 92}
{"Episode reward": -98.55093607020845, "Episode length": 999, "Policy Loss": -0.5491547584533691, "Value Loss": 0.03067638725042343, "_runtime": 118.65370321273804, "_timestamp": 1585135954.1107368, "_step": 93}
{"Episode reward": -113.02287311391507, "Episode length": 999, "Policy Loss": -0.5854729413986206, "Value Loss": 0.036172498017549515, "_runtime": 119.79431796073914, "_timestamp": 1585135955.2513516, "_step": 94}
{"Episode reward": -96.77732063574977, "Episode length": 999, "Policy Loss": -0.5378682613372803, "Value Loss": 0.027571991086006165, "_runtime": 120.96662735939026, "_timestamp": 1585135956.423661, "_step": 95}
{"Episode reward": -93.75003433762596, "Episode length": 999, "Policy Loss": -0.5320075750350952, "Value Loss": 0.025847727432847023, "_runtime": 122.10116052627563, "_timestamp": 1585135957.5581942, "_step": 96}
{"Episode reward": -105.48892573886883, "Episode length": 999, "Policy Loss": -0.5659497976303101, "Value Loss": 0.029533350840210915, "_runtime": 123.2537751197815, "_timestamp": 1585135958.7108088, "_step": 97}
{"Episode reward": -97.91013268047108, "Episode length": 999, "Policy Loss": -0.5321942567825317, "Value Loss": 0.03115290030837059, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055, 14.428876876831055]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.257852554321289, -7.902828216552734, -7.54780387878418, -7.192779541015625, -6.83775520324707, -6.482730865478516, -6.127706527709961, -5.772682189941406, -5.417657852172852, -5.062633514404297, -4.707609176635742, -4.3525848388671875, -3.997560977935791, -3.6425366401672363, -3.2875123023986816, -2.932487964630127, -2.5774636268615723, -2.2224392890930176, -1.867414951324463, -1.5123906135559082, -1.1573662757873535, -0.8023419380187988, -0.44731760025024414, -0.09229373931884766, 0.26273059844970703, 0.6177549362182617, 0.9727792739868164, 1.327803611755371, 1.6828279495239258, 2.0378522872924805, 2.392876625061035, 2.74790096282959, 3.1029253005981445, 3.457949638366699, 3.812973976135254, 4.167998313903809, 4.523022651672363, 4.878046989440918, 5.233071327209473, 5.588095664978027, 5.943120002746582, 6.298144340515137, 6.653168678283691, 7.008193016052246, 7.363217353820801, 7.7182416915893555, 8.073265075683594, 8.428289413452148, 8.783313751220703, 9.138338088989258, 9.493362426757812, 9.848386764526367, 10.203411102294922, 10.558435440063477, 10.913459777832031, 11.268484115600586, 11.62350845336914, 11.978532791137695, 12.33355712890625, 12.688581466674805, 13.04360580444336, 13.398630142211914, 13.753654479980469, 14.108678817749023, 14.463703155517578]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7.937747478485107, -7.705896854400635, -7.47404670715332, -7.242196083068848, -7.010345458984375, -6.778494834899902, -6.54664421081543, -6.314794063568115, -6.082943439483643, -5.85109281539917, -5.6192426681518555, -5.387392044067383, -5.15554141998291, -4.9236907958984375, -4.691840171813965, -4.45999002456665, -4.228139400482178, -3.996288776397705, -3.7644381523132324, -3.532588005065918, -3.3007373809814453, -3.0688867568969727, -2.837036609649658, -2.6051859855651855, -2.373335361480713, -2.1414847373962402, -1.9096341133117676, -1.6777839660644531, -1.4459333419799805, -1.2140827178955078, -0.9822325706481934, -0.7503819465637207, -0.518531322479248, -0.2866806983947754, -0.054830074310302734, 0.17702054977416992, 0.4088711738586426, 0.6407208442687988, 0.8725714683532715, 1.1044220924377441, 1.3362727165222168, 1.5681233406066895, 1.799973964691162, 2.0318245887756348, 2.263674259185791, 2.4955248832702637, 2.7273755073547363, 2.959226131439209, 3.1910767555236816, 3.4229273796081543, 3.654778003692627, 3.8866286277770996, 4.118479251861572, 4.3503289222717285, 4.582179546356201, 4.814030170440674, 5.0458807945251465, 5.277731418609619, 5.509582042694092, 5.7414326667785645, 5.973282337188721, 6.205132961273193, 6.436983585357666, 6.668834209442139, 6.900684833526611]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 6.0, 6.0, 4.0, 7.0, 6.0, 15.0, 11.0, 11.0, 10.0, 14.0, 16.0, 15.0, 24.0, 49.0, 46.0, 38.0, 33.0, 29.0, 28.0, 30.0, 21.0, 12.0, 14.0, 3.0, 7.0, 7.0, 3.0, 4.0, 2.0, 2.0, 4.0, 8.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0], "bins": [-7.130731582641602, -6.922452926635742, -6.714174270629883, -6.505895614624023, -6.297617435455322, -6.089338779449463, -5.8810601234436035, -5.672781467437744, -5.464503288269043, -5.256224632263184, -5.047945976257324, -4.839667320251465, -4.6313886642456055, -4.423110008239746, -4.214831352233887, -4.0065531730651855, -3.798274517059326, -3.589995861053467, -3.3817174434661865, -3.173438787460327, -2.965160369873047, -2.7568817138671875, -2.548603057861328, -2.3403244018554688, -2.1320457458496094, -1.9237675666809082, -1.7154889106750488, -1.5072102546691895, -1.29893159866333, -1.0906529426574707, -0.8823747634887695, -0.6740961074829102, -0.4658174514770508, -0.2575387954711914, -0.04926013946533203, 0.15901803970336914, 0.3672966957092285, 0.5755753517150879, 0.7838540077209473, 0.9921321868896484, 1.2004108428955078, 1.4086894989013672, 1.6169681549072266, 1.825246810913086, 2.0335254669189453, 2.2418041229248047, 2.450082778930664, 2.6583614349365234, 2.866640090942383, 3.074917793273926, 3.283196449279785, 3.4914751052856445, 3.699753761291504, 3.9080324172973633, 4.116311073303223, 4.324589729309082, 4.532868385314941, 4.741147041320801, 4.94942569732666, 5.157703399658203, 5.3659820556640625, 5.574260711669922, 5.782539367675781, 5.990818023681641, 6.1990966796875]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-3.016228675842285, -2.882211685180664, -2.748194694519043, -2.614177703857422, -2.480160713195801, -2.3461437225341797, -2.2121264934539795, -2.0781095027923584, -1.9440925121307373, -1.8100755214691162, -1.6760585308074951, -1.5420414209365845, -1.4080244302749634, -1.2740074396133423, -1.1399903297424316, -1.0059733390808105, -0.8719563484191895, -0.7379393577575684, -0.6039223670959473, -0.46990537643432617, -0.3358883857727051, -0.20187115669250488, -0.06785416603088379, 0.0661628246307373, 0.2001798152923584, 0.3341968059539795, 0.4682137966156006, 0.6022307872772217, 0.7362480163574219, 0.870265007019043, 1.004281997680664, 1.1382989883422852, 1.2723159790039062, 1.4063329696655273, 1.5403499603271484, 1.6743669509887695, 1.8083839416503906, 1.9424009323120117, 2.076417922973633, 2.210434913635254, 2.344451904296875, 2.4784693717956543, 2.6124863624572754, 2.7465033531188965, 2.8805203437805176, 3.0145373344421387, 3.1485543251037598, 3.282571315765381, 3.416588306427002, 3.550605297088623, 3.684622287750244, 3.8186392784118652, 3.9526562690734863, 4.086673259735107, 4.2206902503967285, 4.35470724105835, 4.488724708557129, 4.62274169921875, 4.756758689880371, 4.890775680541992, 5.024792671203613, 5.158809661865234, 5.2928266525268555, 5.426843643188477, 5.560860633850098]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 29.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-4.081511974334717, -3.98342227935791, -3.8853325843811035, -3.787242889404297, -3.6891534328460693, -3.5910637378692627, -3.492974042892456, -3.3948843479156494, -3.2967946529388428, -3.1987051963806152, -3.1006155014038086, -3.002525806427002, -2.9044361114501953, -2.8063464164733887, -2.708256721496582, -2.6101670265197754, -2.5120773315429688, -2.413987636566162, -2.3158981800079346, -2.217808485031128, -2.1197187900543213, -2.0216290950775146, -1.923539400100708, -1.8254499435424805, -1.7273602485656738, -1.6292705535888672, -1.5311808586120605, -1.433091163635254, -1.3350014686584473, -1.2369120121002197, -1.138822317123413, -1.0407326221466064, -0.9426429271697998, -0.8445532321929932, -0.7464635372161865, -0.6483738422393799, -0.5502843856811523, -0.4521946907043457, -0.35410499572753906, -0.2560153007507324, -0.15792560577392578, -0.05983591079711914, 0.0382537841796875, 0.13634347915649414, 0.23443317413330078, 0.3325223922729492, 0.43061208724975586, 0.5287017822265625, 0.6267914772033691, 0.7248811721801758, 0.8229708671569824, 0.9210605621337891, 1.0191502571105957, 1.1172399520874023, 1.215329647064209, 1.3134193420410156, 1.4115090370178223, 1.509598731994629, 1.6076879501342773, 1.705777645111084, 1.8038673400878906, 1.9019570350646973, 2.000046730041504, 2.0981364250183105, 2.196226119995117]}, "_runtime": 124.43239068984985, "_timestamp": 1585135959.8894243, "_step": 98}
{"Episode reward": -95.57825008446243, "Episode length": 999, "Policy Loss": -0.5320509672164917, "Value Loss": 0.02487274818122387, "_runtime": 125.54702877998352, "_timestamp": 1585135961.0040624, "_step": 99}
{"Episode reward": -103.35781282983905, "Episode length": 999, "Policy Loss": -0.5549010038375854, "Value Loss": 0.03355037048459053, "_runtime": 126.68774724006653, "_timestamp": 1585135962.1447809, "_step": 100}
{"Episode reward": -95.66593171136316, "Episode length": 999, "Policy Loss": -0.5344808101654053, "Value Loss": 0.02877085842192173, "_runtime": 127.87688612937927, "_timestamp": 1585135963.3339198, "_step": 101}
{"Episode reward": -97.25786644531289, "Episode length": 999, "Policy Loss": -0.5412518978118896, "Value Loss": 0.02704261988401413, "_runtime": 128.9929141998291, "_timestamp": 1585135964.4499478, "_step": 102}
{"Episode reward": -99.79224757326584, "Episode length": 999, "Policy Loss": -0.5444380044937134, "Value Loss": 0.030916497111320496, "_runtime": 130.1347794532776, "_timestamp": 1585135965.591813, "_step": 103}
{"Episode reward": -104.49868316133157, "Episode length": 999, "Policy Loss": -0.5555402636528015, "Value Loss": 0.0312904454767704, "_runtime": 131.29199266433716, "_timestamp": 1585135966.7490263, "_step": 104}
{"Episode reward": -102.74381691200503, "Episode length": 999, "Policy Loss": -0.5465784668922424, "Value Loss": 0.030130477622151375, "_runtime": 132.43440008163452, "_timestamp": 1585135967.8914337, "_step": 105}
{"Episode reward": -103.10440640329584, "Episode length": 999, "Policy Loss": -0.5519792437553406, "Value Loss": 0.03105451725423336, "_runtime": 133.6658821105957, "_timestamp": 1585135969.1229157, "_step": 106}
{"Episode reward": -105.39423078967384, "Episode length": 999, "Policy Loss": -0.5648657083511353, "Value Loss": 0.03207879140973091, "_runtime": 134.83696389198303, "_timestamp": 1585135970.2939975, "_step": 107}
{"Episode reward": -105.0663680754071, "Episode length": 999, "Policy Loss": -0.5638148188591003, "Value Loss": 0.03286166489124298, "_runtime": 135.99632692337036, "_timestamp": 1585135971.4533606, "_step": 108}
{"Episode reward": -104.17018070953233, "Episode length": 999, "Policy Loss": -0.5580145120620728, "Value Loss": 0.03175409510731697, "_runtime": 137.17823767662048, "_timestamp": 1585135972.6352713, "_step": 109}
{"Episode reward": -98.89415095294507, "Episode length": 999, "Policy Loss": -0.5503696799278259, "Value Loss": 0.03175041824579239, "_runtime": 138.29793000221252, "_timestamp": 1585135973.7549636, "_step": 110}
{"Episode reward": -100.1246308475386, "Episode length": 999, "Policy Loss": -0.5462985038757324, "Value Loss": 0.02999228425323963, "_runtime": 139.40799164772034, "_timestamp": 1585135974.8650253, "_step": 111}
{"Episode reward": -103.00538890666309, "Episode length": 999, "Policy Loss": -0.5528801083564758, "Value Loss": 0.03442664444446564, "_runtime": 140.53084421157837, "_timestamp": 1585135975.9878778, "_step": 112}
{"Episode reward": -103.13023587930437, "Episode length": 999, "Policy Loss": -0.554762065410614, "Value Loss": 0.03141017258167267, "_runtime": 141.62597799301147, "_timestamp": 1585135977.0830116, "_step": 113}
{"Episode reward": 3.5044384768241486, "Episode length": 968, "Policy Loss": -0.2626718282699585, "Value Loss": 10.333550453186035, "_runtime": 142.78543162345886, "_timestamp": 1585135978.2424653, "_step": 114}
{"Episode reward": -100.64462449858654, "Episode length": 999, "Policy Loss": -0.5554220080375671, "Value Loss": 0.028249220922589302, "_runtime": 143.89172410964966, "_timestamp": 1585135979.3487577, "_step": 115}
{"Episode reward": -97.09049954994224, "Episode length": 999, "Policy Loss": -0.5231710076332092, "Value Loss": 0.028045788407325745, "_runtime": 145.0387134552002, "_timestamp": 1585135980.495747, "_step": 116}
{"Episode reward": -96.76483161534199, "Episode length": 999, "Policy Loss": -0.54575115442276, "Value Loss": 0.026592815294861794, "_runtime": 146.16610860824585, "_timestamp": 1585135981.6231422, "_step": 117}
{"Episode reward": -109.49125963340951, "Episode length": 999, "Policy Loss": -0.5837242007255554, "Value Loss": 0.03759487345814705, "_runtime": 147.32045459747314, "_timestamp": 1585135982.7774882, "_step": 118}
{"Episode reward": -102.52501208699852, "Episode length": 999, "Policy Loss": -0.5551934242248535, "Value Loss": 0.03303282707929611, "_runtime": 148.46231961250305, "_timestamp": 1585135983.9193532, "_step": 119}
{"Episode reward": -102.421748695136, "Episode length": 999, "Policy Loss": -0.5514788627624512, "Value Loss": 0.03338061645627022, "_runtime": 149.58702683448792, "_timestamp": 1585135985.0440605, "_step": 120}
{"Episode reward": -102.17099164871878, "Episode length": 999, "Policy Loss": -0.5684629082679749, "Value Loss": 0.03380874916911125, "_runtime": 150.75407028198242, "_timestamp": 1585135986.211104, "_step": 121}
{"Episode reward": -97.22183679247628, "Episode length": 999, "Policy Loss": -0.5365174412727356, "Value Loss": 0.03075646422803402, "_runtime": 151.91391229629517, "_timestamp": 1585135987.370946, "_step": 122}
{"Episode reward": -108.93265871738174, "Episode length": 999, "Policy Loss": -0.5785213112831116, "Value Loss": 0.03396626561880112, "_runtime": 153.07111525535583, "_timestamp": 1585135988.528149, "_step": 123}
{"Episode reward": -98.94206823606274, "Episode length": 999, "Policy Loss": -0.5457440614700317, "Value Loss": 0.031282100826501846, "_runtime": 154.23123216629028, "_timestamp": 1585135989.6882658, "_step": 124}
{"Episode reward": -102.24766925115529, "Episode length": 999, "Policy Loss": -0.548154890537262, "Value Loss": 0.030039871111512184, "_runtime": 155.372620344162, "_timestamp": 1585135990.829654, "_step": 125}
{"Episode reward": -101.98976137994589, "Episode length": 999, "Policy Loss": -0.5482450127601624, "Value Loss": 0.031248437240719795, "_runtime": 156.5122799873352, "_timestamp": 1585135991.9693136, "_step": 126}
{"Episode reward": -99.24903271759989, "Episode length": 999, "Policy Loss": -0.5429174304008484, "Value Loss": 0.028223222121596336, "_runtime": 157.6769199371338, "_timestamp": 1585135993.1339536, "_step": 127}
{"Episode reward": -109.01477276733291, "Episode length": 999, "Policy Loss": -0.5697021484375, "Value Loss": 0.03649618849158287, "_runtime": 158.81323432922363, "_timestamp": 1585135994.270268, "_step": 128}
{"Episode reward": -109.24889628887047, "Episode length": 999, "Policy Loss": -0.5739256739616394, "Value Loss": 0.03652201220393181, "_runtime": 159.91784811019897, "_timestamp": 1585135995.3748817, "_step": 129}
{"Episode reward": -104.87053386565985, "Episode length": 999, "Policy Loss": -0.5550798177719116, "Value Loss": 0.034288667142391205, "_runtime": 161.06267547607422, "_timestamp": 1585135996.519709, "_step": 130}
{"Episode reward": -101.97165144622721, "Episode length": 999, "Policy Loss": -0.5440697073936462, "Value Loss": 0.032832853496074677, "_runtime": 162.20165133476257, "_timestamp": 1585135997.658685, "_step": 131}
{"Episode reward": -106.70107087785992, "Episode length": 999, "Policy Loss": -0.5581424236297607, "Value Loss": 0.037105023860931396, "_runtime": 163.36336660385132, "_timestamp": 1585135998.8204002, "_step": 132}
{"Episode reward": -106.67082752856508, "Episode length": 999, "Policy Loss": -0.5644832253456116, "Value Loss": 0.034642294049263, "_runtime": 164.53890323638916, "_timestamp": 1585135999.9959369, "_step": 133}
{"Episode reward": -97.10057667743757, "Episode length": 999, "Policy Loss": -0.5264960527420044, "Value Loss": 0.030128372833132744, "_runtime": 165.7188515663147, "_timestamp": 1585136001.1758852, "_step": 134}
{"Episode reward": -106.06838532092677, "Episode length": 999, "Policy Loss": -0.5672073364257812, "Value Loss": 0.03244725614786148, "_runtime": 166.8561999797821, "_timestamp": 1585136002.3132336, "_step": 135}
{"Episode reward": -108.46202402197096, "Episode length": 999, "Policy Loss": -0.5749766826629639, "Value Loss": 0.034305594861507416, "_runtime": 167.9928057193756, "_timestamp": 1585136003.4498394, "_step": 136}
{"Episode reward": -111.92557635910575, "Episode length": 999, "Policy Loss": -0.5933621525764465, "Value Loss": 0.0379127599298954, "_runtime": 169.14349627494812, "_timestamp": 1585136004.60053, "_step": 137}
{"Episode reward": -106.25823399295678, "Episode length": 999, "Policy Loss": -0.5632732510566711, "Value Loss": 0.03043951280415058, "_runtime": 170.3181450366974, "_timestamp": 1585136005.7751787, "_step": 138}
{"Episode reward": -99.769794038537, "Episode length": 999, "Policy Loss": -0.5363375544548035, "Value Loss": 0.030126897618174553, "_runtime": 171.4884328842163, "_timestamp": 1585136006.9454665, "_step": 139}
{"Episode reward": -108.76857665801286, "Episode length": 999, "Policy Loss": -0.5705520510673523, "Value Loss": 0.034161265939474106, "_runtime": 172.65097880363464, "_timestamp": 1585136008.1080124, "_step": 140}
{"Episode reward": -104.46644289153866, "Episode length": 999, "Policy Loss": -0.5643490552902222, "Value Loss": 0.030541323125362396, "_runtime": 173.76785135269165, "_timestamp": 1585136009.224885, "_step": 141}
{"Episode reward": -107.8509392483973, "Episode length": 999, "Policy Loss": -0.577386200428009, "Value Loss": 0.0357358492910862, "_runtime": 174.90220308303833, "_timestamp": 1585136010.3592367, "_step": 142}
{"Episode reward": -108.61918362730674, "Episode length": 999, "Policy Loss": -0.5676647424697876, "Value Loss": 0.03445598483085632, "_runtime": 176.06617784500122, "_timestamp": 1585136011.5232115, "_step": 143}
{"Episode reward": -100.98301077513977, "Episode length": 999, "Policy Loss": -0.5558964014053345, "Value Loss": 0.03169369325041771, "_runtime": 177.21083116531372, "_timestamp": 1585136012.6678648, "_step": 144}
{"Episode reward": -98.16700469765817, "Episode length": 999, "Policy Loss": -0.5470350384712219, "Value Loss": 0.029346032068133354, "_runtime": 178.3754107952118, "_timestamp": 1585136013.8324444, "_step": 145}
{"Episode reward": -102.14023842255949, "Episode length": 999, "Policy Loss": -0.5506476759910583, "Value Loss": 0.033673595637083054, "_runtime": 179.47642397880554, "_timestamp": 1585136014.9334576, "_step": 146}
{"Episode reward": -99.81213903629924, "Episode length": 999, "Policy Loss": -0.5403709411621094, "Value Loss": 0.030672114342451096, "_runtime": 180.6195604801178, "_timestamp": 1585136016.076594, "_step": 147}
{"Episode reward": -102.38118905762089, "Episode length": 999, "Policy Loss": -0.5491336584091187, "Value Loss": 0.030061015859246254, "_runtime": 181.79011416435242, "_timestamp": 1585136017.2471478, "_step": 148}
{"Episode reward": -113.22340706823196, "Episode length": 999, "Policy Loss": -0.591093122959137, "Value Loss": 0.03937700763344765, "_runtime": 182.93633937835693, "_timestamp": 1585136018.393373, "_step": 149}
{"Episode reward": -110.34755030446743, "Episode length": 999, "Policy Loss": -0.571009635925293, "Value Loss": 0.036920610815286636, "_runtime": 184.05423521995544, "_timestamp": 1585136019.5112689, "_step": 150}
{"Episode reward": -104.95877370073713, "Episode length": 999, "Policy Loss": -0.553604006767273, "Value Loss": 0.032454561442136765, "_runtime": 185.19979596138, "_timestamp": 1585136020.6568296, "_step": 151}
{"Episode reward": -106.19187474896017, "Episode length": 999, "Policy Loss": -0.5640023350715637, "Value Loss": 0.030898984521627426, "_runtime": 186.34918475151062, "_timestamp": 1585136021.8062184, "_step": 152}
{"Episode reward": -102.5046262654315, "Episode length": 999, "Policy Loss": -0.5553438663482666, "Value Loss": 0.03162932023406029, "_runtime": 187.50240063667297, "_timestamp": 1585136022.9594343, "_step": 153}
{"Episode reward": -108.12650236102695, "Episode length": 999, "Policy Loss": -0.5781263113021851, "Value Loss": 0.0313754603266716, "_runtime": 188.66917634010315, "_timestamp": 1585136024.12621, "_step": 154}
{"Episode reward": -106.44130085003765, "Episode length": 999, "Policy Loss": -0.5566449761390686, "Value Loss": 0.03333524242043495, "_runtime": 189.77083539962769, "_timestamp": 1585136025.227869, "_step": 155}
{"Episode reward": -108.4018059978903, "Episode length": 999, "Policy Loss": -0.5813469290733337, "Value Loss": 0.03535228595137596, "_runtime": 190.94974660873413, "_timestamp": 1585136026.4067802, "_step": 156}
{"Episode reward": -104.12167885103473, "Episode length": 999, "Policy Loss": -0.5543959736824036, "Value Loss": 0.030929943546652794, "_runtime": 192.10257577896118, "_timestamp": 1585136027.5596094, "_step": 157}
{"Episode reward": -96.85232696874411, "Episode length": 999, "Policy Loss": -0.5316566228866577, "Value Loss": 0.027219101786613464, "_runtime": 193.23870873451233, "_timestamp": 1585136028.6957424, "_step": 158}
{"Episode reward": -105.30691611168693, "Episode length": 999, "Policy Loss": -0.558173656463623, "Value Loss": 0.032890159636735916, "_runtime": 194.38969349861145, "_timestamp": 1585136029.8467271, "_step": 159}
{"Episode reward": -108.74719748672509, "Episode length": 999, "Policy Loss": -0.5803630948066711, "Value Loss": 0.03327971696853638, "_runtime": 195.49001908302307, "_timestamp": 1585136030.9470527, "_step": 160}
{"Episode reward": -91.93253006212652, "Episode length": 999, "Policy Loss": -0.515693724155426, "Value Loss": 0.02469561994075775, "_runtime": 196.61462879180908, "_timestamp": 1585136032.0716624, "_step": 161}
{"Episode reward": -102.40624832713425, "Episode length": 999, "Policy Loss": -0.5514829158782959, "Value Loss": 0.03415277600288391, "_runtime": 197.78092527389526, "_timestamp": 1585136033.237959, "_step": 162}
{"Episode reward": -100.11325022685085, "Episode length": 999, "Policy Loss": -0.5463348627090454, "Value Loss": 0.030960604548454285, "_runtime": 198.88740849494934, "_timestamp": 1585136034.3444421, "_step": 163}
{"Episode reward": -105.68194852884831, "Episode length": 999, "Policy Loss": -0.5683157444000244, "Value Loss": 0.03270741179585457, "_runtime": 199.99396419525146, "_timestamp": 1585136035.4509978, "_step": 164}
{"Episode reward": -98.6950489449351, "Episode length": 999, "Policy Loss": -0.5370161533355713, "Value Loss": 0.031035451218485832, "_runtime": 201.16037559509277, "_timestamp": 1585136036.6174092, "_step": 165}
{"Episode reward": -112.34703241794735, "Episode length": 999, "Policy Loss": -0.5920708775520325, "Value Loss": 0.03631649166345596, "_runtime": 202.28716921806335, "_timestamp": 1585136037.7442029, "_step": 166}
{"Episode reward": -100.05139708358399, "Episode length": 999, "Policy Loss": -0.5401386618614197, "Value Loss": 0.02756354957818985, "_runtime": 203.42397379875183, "_timestamp": 1585136038.8810074, "_step": 167}
{"Episode reward": -109.60223789865177, "Episode length": 999, "Policy Loss": -0.5723790526390076, "Value Loss": 0.03521624952554703, "_runtime": 204.59286832809448, "_timestamp": 1585136040.049902, "_step": 168}
{"Episode reward": -104.87584614578411, "Episode length": 999, "Policy Loss": -0.5664691925048828, "Value Loss": 0.03329496085643768, "_runtime": 205.74391865730286, "_timestamp": 1585136041.2009523, "_step": 169}
{"Episode reward": -106.91220543017657, "Episode length": 999, "Policy Loss": -0.5622227787971497, "Value Loss": 0.03404265269637108, "_runtime": 206.93270111083984, "_timestamp": 1585136042.3897347, "_step": 170}
{"Episode reward": -101.22113870955577, "Episode length": 999, "Policy Loss": -0.557025671005249, "Value Loss": 0.031876496970653534, "_runtime": 208.05495738983154, "_timestamp": 1585136043.511991, "_step": 171}
{"Episode reward": -98.58015887372756, "Episode length": 999, "Policy Loss": -0.5402612686157227, "Value Loss": 0.031548306345939636, "_runtime": 209.23540806770325, "_timestamp": 1585136044.6924417, "_step": 172}
{"Episode reward": -101.80383049260082, "Episode length": 999, "Policy Loss": -0.543172299861908, "Value Loss": 0.03206243738532066, "_runtime": 210.38447451591492, "_timestamp": 1585136045.8415082, "_step": 173}
{"Episode reward": -100.01981156985593, "Episode length": 999, "Policy Loss": -0.5442119240760803, "Value Loss": 0.031959179788827896, "_runtime": 211.54895281791687, "_timestamp": 1585136047.0059865, "_step": 174}
{"Episode reward": -115.56036766331142, "Episode length": 999, "Policy Loss": -0.596320629119873, "Value Loss": 0.04004185274243355, "_runtime": 212.6870300769806, "_timestamp": 1585136048.1440637, "_step": 175}
{"Episode reward": -108.84946010842354, "Episode length": 999, "Policy Loss": -0.5784147381782532, "Value Loss": 0.0359988659620285, "_runtime": 213.83904361724854, "_timestamp": 1585136049.2960773, "_step": 176}
{"Episode reward": -98.54298527224996, "Episode length": 999, "Policy Loss": -0.5297437906265259, "Value Loss": 0.027911225333809853, "_runtime": 214.98273372650146, "_timestamp": 1585136050.4397674, "_step": 177}
{"Episode reward": -99.16211645281503, "Episode length": 999, "Policy Loss": -0.5461076498031616, "Value Loss": 0.031411562114953995, "_runtime": 216.11416006088257, "_timestamp": 1585136051.5711937, "_step": 178}
{"Episode reward": -96.38315548930368, "Episode length": 999, "Policy Loss": -0.5345597267150879, "Value Loss": 0.0299626886844635, "_runtime": 217.23214888572693, "_timestamp": 1585136052.6891825, "_step": 179}
{"Episode reward": -104.46874582171485, "Episode length": 999, "Policy Loss": -0.5523490905761719, "Value Loss": 0.03558942675590515, "_runtime": 218.38930702209473, "_timestamp": 1585136053.8463407, "_step": 180}
{"Episode reward": -104.30233694003468, "Episode length": 999, "Policy Loss": -0.5554041862487793, "Value Loss": 0.03462702035903931, "_runtime": 219.52033114433289, "_timestamp": 1585136054.9773648, "_step": 181}
{"Episode reward": -104.02047800752135, "Episode length": 999, "Policy Loss": -0.5603160858154297, "Value Loss": 0.03211686760187149, "_runtime": 220.68740153312683, "_timestamp": 1585136056.1444352, "_step": 182}
{"Episode reward": -102.32053536173497, "Episode length": 999, "Policy Loss": -0.5613019466400146, "Value Loss": 0.03237423673272133, "_runtime": 221.81803345680237, "_timestamp": 1585136057.275067, "_step": 183}
{"Episode reward": -105.35295689777745, "Episode length": 999, "Policy Loss": -0.5638954639434814, "Value Loss": 0.03368844464421272, "_runtime": 222.9389090538025, "_timestamp": 1585136058.3959427, "_step": 184}
{"Episode reward": -110.51552270035569, "Episode length": 999, "Policy Loss": -0.5776589512825012, "Value Loss": 0.03777771815657616, "_runtime": 224.05213332176208, "_timestamp": 1585136059.509167, "_step": 185}
{"Episode reward": -103.11624768849518, "Episode length": 999, "Policy Loss": -0.5588911771774292, "Value Loss": 0.03047204576432705, "_runtime": 225.17259073257446, "_timestamp": 1585136060.6296244, "_step": 186}
{"Episode reward": -103.31772918901572, "Episode length": 999, "Policy Loss": -0.5564922094345093, "Value Loss": 0.03457479178905487, "_runtime": 226.29403614997864, "_timestamp": 1585136061.7510698, "_step": 187}
{"Episode reward": -118.5691546612715, "Episode length": 999, "Policy Loss": -0.6084050536155701, "Value Loss": 0.03913693130016327, "_runtime": 227.40333533287048, "_timestamp": 1585136062.860369, "_step": 188}
{"Episode reward": -102.35303598376363, "Episode length": 999, "Policy Loss": -0.5601991415023804, "Value Loss": 0.03424227982759476, "_runtime": 228.63436675071716, "_timestamp": 1585136064.0914004, "_step": 189}
{"Episode reward": -105.03584885381363, "Episode length": 999, "Policy Loss": -0.5651815533638, "Value Loss": 0.031166020780801773, "_runtime": 229.73520708084106, "_timestamp": 1585136065.1922407, "_step": 190}
{"Episode reward": -101.00737851652437, "Episode length": 999, "Policy Loss": -0.5481096506118774, "Value Loss": 0.030300967395305634, "_runtime": 230.91874241828918, "_timestamp": 1585136066.375776, "_step": 191}
{"Episode reward": -100.95587715982091, "Episode length": 999, "Policy Loss": -0.5479830503463745, "Value Loss": 0.03194562718272209, "_runtime": 232.0650668144226, "_timestamp": 1585136067.5221004, "_step": 192}
{"Episode reward": -101.04443962215845, "Episode length": 999, "Policy Loss": -0.5423060059547424, "Value Loss": 0.030850861221551895, "_runtime": 233.1854817867279, "_timestamp": 1585136068.6425154, "_step": 193}
{"Episode reward": -108.19747395341979, "Episode length": 999, "Policy Loss": -0.5723130702972412, "Value Loss": 0.03498973697423935, "_runtime": 234.35039520263672, "_timestamp": 1585136069.8074288, "_step": 194}
{"Episode reward": -114.59818967427869, "Episode length": 999, "Policy Loss": -0.5955015420913696, "Value Loss": 0.03990079089999199, "_runtime": 235.49768948554993, "_timestamp": 1585136070.9547231, "_step": 195}
{"Episode reward": -111.48679661397705, "Episode length": 999, "Policy Loss": -0.5892062783241272, "Value Loss": 0.035954274237155914, "_runtime": 236.62901663780212, "_timestamp": 1585136072.0860503, "_step": 196}
{"Episode reward": -104.56663253631669, "Episode length": 999, "Policy Loss": -0.5532646775245667, "Value Loss": 0.03256107494235039, "_runtime": 237.776620388031, "_timestamp": 1585136073.233654, "_step": 197}
{"Episode reward": -104.27111693359154, "Episode length": 999, "Policy Loss": -0.5562103390693665, "Value Loss": 0.03285564109683037, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514, -0.12925517559051514]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7159749865531921, -0.6920598745346069, -0.668144702911377, -0.644229531288147, -0.6203144192695618, -0.5963993072509766, -0.5724841356277466, -0.5485689640045166, -0.5246538519859314, -0.5007387399673462, -0.4768235683441162, -0.4529084265232086, -0.428993284702301, -0.40507814288139343, -0.38116300106048584, -0.35724785923957825, -0.33333271741867065, -0.30941757559776306, -0.28550243377685547, -0.2615872919559479, -0.23767215013504028, -0.2137569785118103, -0.1898418664932251, -0.1659267544746399, -0.1420115828514099, -0.11809641122817993, -0.09418129920959473, -0.07026618719100952, -0.04635101556777954, -0.02243584394454956, 0.0014792680740356445, 0.02539438009262085, 0.04930955171585083, 0.07322472333908081, 0.09713983535766602, 0.12105494737625122, 0.1449701189994812, 0.16888529062271118, 0.1928004026412964, 0.2167155146598816, 0.24063068628311157, 0.26454585790634155, 0.28846102952957153, 0.31237608194351196, 0.33629125356674194, 0.3602064251899719, 0.38412147760391235, 0.40803664922714233, 0.4319518208503723, 0.4558669924736023, 0.4797821640968323, 0.5036972165107727, 0.5276123881340027, 0.5515275597572327, 0.5754426121711731, 0.5993577837944031, 0.6232729554176331, 0.647188127040863, 0.671103298664093, 0.6950183510780334, 0.7189335227012634, 0.7428486943244934, 0.7667637467384338, 0.7906789183616638, 0.8145940899848938]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.31344932317733765, -0.30717360973358154, -0.30089789628982544, -0.29462218284606934, -0.28834646940231323, -0.28207075595855713, -0.275795042514801, -0.2695193290710449, -0.2632436156272888, -0.2569679021835327, -0.2506921887397766, -0.2444164752960205, -0.2381407618522644, -0.2318650484085083, -0.2255893349647522, -0.2193136215209961, -0.21303790807724, -0.2067621946334839, -0.20048648118972778, -0.19421076774597168, -0.18793505430221558, -0.18165934085845947, -0.17538362741470337, -0.16910791397094727, -0.16283220052719116, -0.15655648708343506, -0.15028077363967896, -0.14400506019592285, -0.13772934675216675, -0.13145363330841064, -0.12517791986465454, -0.11890220642089844, -0.11262649297714233, -0.10635077953338623, -0.10007506608963013, -0.09379935264587402, -0.08752363920211792, -0.08124792575836182, -0.07497221231460571, -0.06869649887084961, -0.062420785427093506, -0.0561450719833374, -0.0498693585395813, -0.043593645095825195, -0.03731793165206909, -0.03104221820831299, -0.024766504764556885, -0.01849079132080078, -0.012215077877044678, -0.005939364433288574, 0.0003363490104675293, 0.006612062454223633, 0.012887775897979736, 0.01916348934173584, 0.025439202785491943, 0.03171491622924805, 0.03799062967300415, 0.044266343116760254, 0.05054205656051636, 0.05681777000427246, 0.06309348344802856, 0.06936919689178467, 0.07564491033554077, 0.08192062377929688, 0.08819633722305298]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 5.0, 5.0, 3.0, 6.0, 2.0, 15.0, 11.0, 11.0, 17.0, 13.0, 28.0, 31.0, 44.0, 55.0, 59.0, 40.0, 32.0, 16.0, 15.0, 12.0, 7.0, 8.0, 8.0, 5.0, 7.0, 4.0, 1.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.46451032161712646, -0.4498607814311981, -0.4352112412452698, -0.42056167125701904, -0.4059121310710907, -0.39126259088516235, -0.376613050699234, -0.36196351051330566, -0.3473139703273773, -0.332664430141449, -0.31801486015319824, -0.3033653497695923, -0.28871577978134155, -0.2740662395954132, -0.25941669940948486, -0.24476714432239532, -0.23011760413646698, -0.21546806395053864, -0.2008185088634491, -0.18616896867752075, -0.1715194284915924, -0.15686988830566406, -0.14222034811973572, -0.12757077813148499, -0.11292123794555664, -0.0982716977596283, -0.08362215757369995, -0.0689726173877716, -0.05432307720184326, -0.03967350721359253, -0.025023967027664185, -0.01037442684173584, 0.004275113344192505, 0.01892465353012085, 0.033574193716049194, 0.04822373390197754, 0.06287330389022827, 0.07752281427383423, 0.09217238426208496, 0.1068219542503357, 0.12147146463394165, 0.13612103462219238, 0.15077054500579834, 0.16542011499404907, 0.18006962537765503, 0.19471919536590576, 0.2093687653541565, 0.22401827573776245, 0.23866784572601318, 0.25331735610961914, 0.2679669260978699, 0.28261643648147583, 0.29726600646972656, 0.3119155764579773, 0.32656508684158325, 0.341214656829834, 0.35586416721343994, 0.3705137372016907, 0.3851633071899414, 0.39981281757354736, 0.4144623875617981, 0.42911189794540405, 0.4437614679336548, 0.45841097831726074, 0.4730605483055115]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.2733907699584961, -0.26717182993888855, -0.260952889919281, -0.25473397970199585, -0.2485150396823883, -0.24229609966278076, -0.23607715964317322, -0.22985823452472687, -0.22363930940628052, -0.21742036938667297, -0.21120142936706543, -0.20498250424861908, -0.19876356422901154, -0.19254463911056519, -0.18632569909095764, -0.1801067590713501, -0.17388783395290375, -0.1676689088344574, -0.16144996881484985, -0.1552310287952423, -0.14901210367679596, -0.14279316365718842, -0.13657423853874207, -0.13035529851913452, -0.12413635849952698, -0.11791743338108063, -0.11169849336147308, -0.10547956824302673, -0.09926062822341919, -0.09304170310497284, -0.0868227630853653, -0.08060383796691895, -0.0743848979473114, -0.06816595792770386, -0.06194703280925751, -0.05572809278964996, -0.04950916767120361, -0.04329022765159607, -0.03707130253314972, -0.030852362513542175, -0.024633437395095825, -0.01841449737548828, -0.012195557355880737, -0.005976617336273193, 0.0002422928810119629, 0.006461232900619507, 0.01268017292022705, 0.018899112939834595, 0.02511805295944214, 0.031336963176727295, 0.03755590319633484, 0.04377484321594238, 0.04999378323554993, 0.05621269345283508, 0.06243163347244263, 0.06865057349205017, 0.07486951351165771, 0.08108845353126526, 0.08730736374855042, 0.09352630376815796, 0.0997452437877655, 0.10596418380737305, 0.1121830940246582, 0.11840203404426575, 0.12462097406387329]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 6.0, 5.0, 8.0, 3.0, 3.0, 5.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.8439139723777771, -0.8230818510055542, -0.8022497296333313, -0.7814176082611084, -0.7605855464935303, -0.7397534251213074, -0.7189213037490845, -0.6980891823768616, -0.6772570610046387, -0.6564249396324158, -0.6355928182601929, -0.6147607564926147, -0.5939285755157471, -0.573096513748169, -0.552264392375946, -0.5314322710037231, -0.5106001496315002, -0.48976802825927734, -0.46893590688705444, -0.44810381531715393, -0.42727169394493103, -0.40643957257270813, -0.3856074810028076, -0.3647753596305847, -0.3439432382583618, -0.3231111168861389, -0.302278995513916, -0.2814468741416931, -0.260614812374115, -0.2397826910018921, -0.2189505696296692, -0.1981184482574463, -0.1772863268852234, -0.1564542055130005, -0.1356220841407776, -0.11478996276855469, -0.09395784139633179, -0.07312577962875366, -0.05229365825653076, -0.03146153688430786, -0.010629415512084961, 0.01020270586013794, 0.03103482723236084, 0.05186694860458374, 0.07269901037216187, 0.09353113174438477, 0.11436325311660767, 0.13519537448883057, 0.15602749586105347, 0.1768595576286316, 0.19769173860549927, 0.2185238003730774, 0.23935598134994507, 0.2601880431175232, 0.28102022409439087, 0.301852285861969, 0.3226843476295471, 0.3435165286064148, 0.3643485903739929, 0.3851807713508606, 0.4060128331184387, 0.4268450140953064, 0.4476770758628845, 0.4685092568397522, 0.4893413186073303]}, "_runtime": 238.9014072418213, "_timestamp": 1585136074.3584409, "_step": 198}
{"Episode reward": -109.31859792864091, "Episode length": 999, "Policy Loss": -0.5774317383766174, "Value Loss": 0.031059768050909042, "_runtime": 240.01664233207703, "_timestamp": 1585136075.473676, "_step": 199}
{"Episode reward": -103.89416261694173, "Episode length": 999, "Policy Loss": -0.5641624331474304, "Value Loss": 0.03429845720529556, "_runtime": 241.18271398544312, "_timestamp": 1585136076.6397476, "_step": 200}
{"Episode reward": -108.07278750954436, "Episode length": 999, "Policy Loss": -0.570460855960846, "Value Loss": 0.035075947642326355, "_runtime": 242.31370067596436, "_timestamp": 1585136077.7707343, "_step": 201}
{"Episode reward": -96.8036609992144, "Episode length": 999, "Policy Loss": -0.5372937321662903, "Value Loss": 0.026286710053682327, "_runtime": 243.45994067192078, "_timestamp": 1585136078.9169743, "_step": 202}
{"Episode reward": -114.94637498495551, "Episode length": 999, "Policy Loss": -0.6108507513999939, "Value Loss": 0.03881902992725372, "_runtime": 244.64559507369995, "_timestamp": 1585136080.1026287, "_step": 203}
{"Episode reward": -108.64808549002996, "Episode length": 999, "Policy Loss": -0.575971782207489, "Value Loss": 0.03594338521361351, "_runtime": 245.78336906433105, "_timestamp": 1585136081.2404027, "_step": 204}
{"Episode reward": -110.80345120220565, "Episode length": 999, "Policy Loss": -0.589745283126831, "Value Loss": 0.035364724695682526, "_runtime": 246.94980239868164, "_timestamp": 1585136082.406836, "_step": 205}
{"Episode reward": -109.94854924383122, "Episode length": 999, "Policy Loss": -0.5879895687103271, "Value Loss": 0.03753996267914772, "_runtime": 248.1269235610962, "_timestamp": 1585136083.5839572, "_step": 206}
{"Episode reward": -98.03127388510582, "Episode length": 999, "Policy Loss": -0.5408461093902588, "Value Loss": 0.02740762196481228, "_runtime": 249.23657369613647, "_timestamp": 1585136084.6936073, "_step": 207}
{"Episode reward": -95.36211559690574, "Episode length": 999, "Policy Loss": -0.5263693928718567, "Value Loss": 0.029090259224176407, "_runtime": 250.37943649291992, "_timestamp": 1585136085.8364701, "_step": 208}
{"Episode reward": -104.61992251221237, "Episode length": 999, "Policy Loss": -0.5520665645599365, "Value Loss": 0.029902491718530655, "_runtime": 251.5055091381073, "_timestamp": 1585136086.9625428, "_step": 209}
{"Episode reward": -99.09344529610046, "Episode length": 999, "Policy Loss": -0.5446312427520752, "Value Loss": 0.0301867313683033, "_runtime": 252.647442817688, "_timestamp": 1585136088.1044765, "_step": 210}
{"Episode reward": -101.72473402197919, "Episode length": 999, "Policy Loss": -0.5581168532371521, "Value Loss": 0.030144816264510155, "_runtime": 253.76696467399597, "_timestamp": 1585136089.2239983, "_step": 211}
{"Episode reward": -106.05940961757392, "Episode length": 999, "Policy Loss": -0.5648379325866699, "Value Loss": 0.03362935036420822, "_runtime": 254.91210842132568, "_timestamp": 1585136090.369142, "_step": 212}
{"Episode reward": -103.70665424049103, "Episode length": 999, "Policy Loss": -0.5595481991767883, "Value Loss": 0.03094371408224106, "_runtime": 256.07189750671387, "_timestamp": 1585136091.5289311, "_step": 213}
{"Episode reward": -107.43554192314431, "Episode length": 999, "Policy Loss": -0.5752549767494202, "Value Loss": 0.03709128871560097, "_runtime": 257.191029548645, "_timestamp": 1585136092.6480632, "_step": 214}
{"Episode reward": -111.62421633736604, "Episode length": 999, "Policy Loss": -0.5851418972015381, "Value Loss": 0.036784734576940536, "_runtime": 258.3219208717346, "_timestamp": 1585136093.7789545, "_step": 215}
{"Episode reward": -110.88353021404389, "Episode length": 999, "Policy Loss": -0.5867328643798828, "Value Loss": 0.036391012370586395, "_runtime": 259.13267040252686, "_timestamp": 1585136094.589704, "_step": 216}
{"Episode reward": 25.40387694425698, "Episode length": 691, "Policy Loss": -0.37033984065055847, "Value Loss": 14.457846641540527, "_runtime": 260.3027448654175, "_timestamp": 1585136095.7597785, "_step": 217}
{"Episode reward": -111.67434866563798, "Episode length": 999, "Policy Loss": -0.5820218920707703, "Value Loss": 0.03716212138533592, "_runtime": 261.4414234161377, "_timestamp": 1585136096.898457, "_step": 218}
{"Episode reward": -105.30276656516006, "Episode length": 999, "Policy Loss": -0.5713280439376831, "Value Loss": 0.03329947590827942, "_runtime": 262.6020460128784, "_timestamp": 1585136098.0590796, "_step": 219}
{"Episode reward": -103.92188182145316, "Episode length": 999, "Policy Loss": -0.559440553188324, "Value Loss": 0.03171381726861, "_runtime": 263.76458263397217, "_timestamp": 1585136099.2216163, "_step": 220}
{"Episode reward": -103.71156959239373, "Episode length": 999, "Policy Loss": -0.5577296614646912, "Value Loss": 0.03257664293050766, "_runtime": 264.8806459903717, "_timestamp": 1585136100.3376796, "_step": 221}
{"Episode reward": -108.43416831910478, "Episode length": 999, "Policy Loss": -0.5742545127868652, "Value Loss": 0.035148609429597855, "_runtime": 266.01007199287415, "_timestamp": 1585136101.4671056, "_step": 222}
{"Episode reward": -111.62589395513103, "Episode length": 999, "Policy Loss": -0.5829752087593079, "Value Loss": 0.039405398070812225, "_runtime": 267.1555325984955, "_timestamp": 1585136102.6125662, "_step": 223}
{"Episode reward": -105.06266653892024, "Episode length": 999, "Policy Loss": -0.5675284266471863, "Value Loss": 0.032467443495988846, "_runtime": 268.2877881526947, "_timestamp": 1585136103.7448218, "_step": 224}
{"Episode reward": -105.83504100448206, "Episode length": 999, "Policy Loss": -0.5729775428771973, "Value Loss": 0.033000409603118896, "_runtime": 269.4025514125824, "_timestamp": 1585136104.859585, "_step": 225}
{"Episode reward": -104.31329726010847, "Episode length": 999, "Policy Loss": -0.5673505067825317, "Value Loss": 0.030661718919873238, "_runtime": 270.5347216129303, "_timestamp": 1585136105.9917552, "_step": 226}
{"Episode reward": -109.1619555143754, "Episode length": 999, "Policy Loss": -0.5708118081092834, "Value Loss": 0.03469352424144745, "_runtime": 271.73355627059937, "_timestamp": 1585136107.19059, "_step": 227}
{"Episode reward": -98.68930849492227, "Episode length": 999, "Policy Loss": -0.5476717948913574, "Value Loss": 0.02964678965508938, "_runtime": 272.88717770576477, "_timestamp": 1585136108.3442113, "_step": 228}
{"Episode reward": -96.26566320347511, "Episode length": 999, "Policy Loss": -0.5354451537132263, "Value Loss": 0.027285611256957054, "_runtime": 274.04958629608154, "_timestamp": 1585136109.50662, "_step": 229}
{"Episode reward": -105.33360313131375, "Episode length": 999, "Policy Loss": -0.5703476667404175, "Value Loss": 0.03310493752360344, "_runtime": 275.2094991207123, "_timestamp": 1585136110.6665328, "_step": 230}
{"Episode reward": -103.257329724049, "Episode length": 999, "Policy Loss": -0.5555458664894104, "Value Loss": 0.036002714186906815, "_runtime": 276.3381941318512, "_timestamp": 1585136111.7952278, "_step": 231}
{"Episode reward": -93.5259212684113, "Episode length": 999, "Policy Loss": -0.5311008095741272, "Value Loss": 0.028524694964289665, "_runtime": 277.4553508758545, "_timestamp": 1585136112.9123845, "_step": 232}
{"Episode reward": -112.03218994823047, "Episode length": 999, "Policy Loss": -0.5942445397377014, "Value Loss": 0.03707683086395264, "_runtime": 278.61778926849365, "_timestamp": 1585136114.074823, "_step": 233}
{"Episode reward": -103.18009732789235, "Episode length": 999, "Policy Loss": -0.5620893836021423, "Value Loss": 0.02611602656543255, "_runtime": 279.726594209671, "_timestamp": 1585136115.1836278, "_step": 234}
{"Episode reward": -108.37269350076596, "Episode length": 999, "Policy Loss": -0.5770744681358337, "Value Loss": 0.03569010645151138, "_runtime": 280.9048089981079, "_timestamp": 1585136116.3618426, "_step": 235}
{"Episode reward": -105.70602624231596, "Episode length": 999, "Policy Loss": -0.5699715614318848, "Value Loss": 0.032787878066301346, "_runtime": 282.04754877090454, "_timestamp": 1585136117.5045824, "_step": 236}
{"Episode reward": -105.32518598442365, "Episode length": 999, "Policy Loss": -0.5662891268730164, "Value Loss": 0.03212647885084152, "_runtime": 283.16407585144043, "_timestamp": 1585136118.6211095, "_step": 237}
{"Episode reward": -98.08620283049876, "Episode length": 999, "Policy Loss": -0.5421464443206787, "Value Loss": 0.030712531879544258, "_runtime": 284.34283661842346, "_timestamp": 1585136119.7998703, "_step": 238}
{"Episode reward": -108.76480621935593, "Episode length": 999, "Policy Loss": -0.5760301351547241, "Value Loss": 0.03133580461144447, "_runtime": 285.5294280052185, "_timestamp": 1585136120.9864616, "_step": 239}
{"Episode reward": -109.08973961852408, "Episode length": 999, "Policy Loss": -0.5822216272354126, "Value Loss": 0.03517729416489601, "_runtime": 286.73157143592834, "_timestamp": 1585136122.188605, "_step": 240}
{"Episode reward": -101.77360058419457, "Episode length": 999, "Policy Loss": -0.5514205098152161, "Value Loss": 0.030700508505105972, "_runtime": 287.87151432037354, "_timestamp": 1585136123.328548, "_step": 241}
{"Episode reward": -108.36645724425102, "Episode length": 999, "Policy Loss": -0.5806836485862732, "Value Loss": 0.03383508697152138, "_runtime": 289.0139102935791, "_timestamp": 1585136124.470944, "_step": 242}
{"Episode reward": -108.65441137758802, "Episode length": 999, "Policy Loss": -0.5780894756317139, "Value Loss": 0.03886314854025841, "_runtime": 290.1404194831848, "_timestamp": 1585136125.597453, "_step": 243}
{"Episode reward": -108.84931692045217, "Episode length": 999, "Policy Loss": -0.5815014243125916, "Value Loss": 0.03569142520427704, "_runtime": 291.2656946182251, "_timestamp": 1585136126.7227283, "_step": 244}
{"Episode reward": -113.36844233411168, "Episode length": 999, "Policy Loss": -0.5947967171669006, "Value Loss": 0.0369194857776165, "_runtime": 292.4019012451172, "_timestamp": 1585136127.8589349, "_step": 245}
{"Episode reward": -112.0635183578912, "Episode length": 999, "Policy Loss": -0.591637372970581, "Value Loss": 0.03913787379860878, "_runtime": 293.5541670322418, "_timestamp": 1585136129.0112007, "_step": 246}
{"Episode reward": -100.59693659442348, "Episode length": 999, "Policy Loss": -0.5541890859603882, "Value Loss": 0.032243769615888596, "_runtime": 294.67394161224365, "_timestamp": 1585136130.1309752, "_step": 247}
{"Episode reward": -96.4055355999395, "Episode length": 999, "Policy Loss": -0.5339522957801819, "Value Loss": 0.029258958995342255, "_runtime": 295.819153547287, "_timestamp": 1585136131.2761872, "_step": 248}
{"Episode reward": -106.37138750025403, "Episode length": 999, "Policy Loss": -0.5748510956764221, "Value Loss": 0.035090550780296326, "_runtime": 296.9697413444519, "_timestamp": 1585136132.426775, "_step": 249}
{"Episode reward": -107.76677406993151, "Episode length": 999, "Policy Loss": -0.5738916397094727, "Value Loss": 0.03808538615703583, "_runtime": 298.0812168121338, "_timestamp": 1585136133.5382504, "_step": 250}
{"Episode reward": -101.39819947482661, "Episode length": 999, "Policy Loss": -0.5539529323577881, "Value Loss": 0.027727490290999413, "_runtime": 299.23820447921753, "_timestamp": 1585136134.695238, "_step": 251}
{"Episode reward": -103.84253726925982, "Episode length": 999, "Policy Loss": -0.5652350783348083, "Value Loss": 0.030521081760525703, "_runtime": 300.36825823783875, "_timestamp": 1585136135.8252919, "_step": 252}
{"Episode reward": -92.99878832639654, "Episode length": 999, "Policy Loss": -0.5296424031257629, "Value Loss": 0.025050943717360497, "_runtime": 301.53479290008545, "_timestamp": 1585136136.9918265, "_step": 253}
{"Episode reward": -99.09374830640408, "Episode length": 999, "Policy Loss": -0.547177791595459, "Value Loss": 0.03066345863044262, "_runtime": 302.71200919151306, "_timestamp": 1585136138.1690428, "_step": 254}
{"Episode reward": -103.31440801229155, "Episode length": 999, "Policy Loss": -0.5570119619369507, "Value Loss": 0.030250921845436096, "_runtime": 303.83443212509155, "_timestamp": 1585136139.2914658, "_step": 255}
{"Episode reward": -102.46519601786906, "Episode length": 999, "Policy Loss": -0.5549481511116028, "Value Loss": 0.03376150131225586, "_runtime": 305.0313928127289, "_timestamp": 1585136140.4884264, "_step": 256}
{"Episode reward": -98.02911442855049, "Episode length": 999, "Policy Loss": -0.5516443252563477, "Value Loss": 0.028840119019150734, "_runtime": 306.15482926368713, "_timestamp": 1585136141.611863, "_step": 257}
{"Episode reward": -103.3693345550305, "Episode length": 999, "Policy Loss": -0.5628595352172852, "Value Loss": 0.031254641711711884, "_runtime": 307.3084330558777, "_timestamp": 1585136142.7654667, "_step": 258}
{"Episode reward": -102.46400784586423, "Episode length": 999, "Policy Loss": -0.5585166215896606, "Value Loss": 0.03262355923652649, "_runtime": 308.4488000869751, "_timestamp": 1585136143.9058337, "_step": 259}
{"Episode reward": -104.1541048563112, "Episode length": 999, "Policy Loss": -0.5681814551353455, "Value Loss": 0.03147061541676521, "_runtime": 309.58519673347473, "_timestamp": 1585136145.0422304, "_step": 260}
{"Episode reward": -108.4368863974085, "Episode length": 999, "Policy Loss": -0.5765389800071716, "Value Loss": 0.03664609044790268, "_runtime": 310.72475385665894, "_timestamp": 1585136146.1817875, "_step": 261}
{"Episode reward": -102.26424696683105, "Episode length": 999, "Policy Loss": -0.5588696599006653, "Value Loss": 0.03216121345758438, "_runtime": 311.904935836792, "_timestamp": 1585136147.3619695, "_step": 262}
{"Episode reward": -106.89362946793236, "Episode length": 999, "Policy Loss": -0.5740926861763, "Value Loss": 0.03277517110109329, "_runtime": 313.02378940582275, "_timestamp": 1585136148.480823, "_step": 263}
{"Episode reward": -98.62054047161182, "Episode length": 999, "Policy Loss": -0.5443246960639954, "Value Loss": 0.02881566621363163, "_runtime": 314.1456367969513, "_timestamp": 1585136149.6026704, "_step": 264}
{"Episode reward": -99.15543710810668, "Episode length": 999, "Policy Loss": -0.5617043972015381, "Value Loss": 0.030465083196759224, "_runtime": 315.2686924934387, "_timestamp": 1585136150.7257261, "_step": 265}
{"Episode reward": -95.06346418056917, "Episode length": 999, "Policy Loss": -0.5360178351402283, "Value Loss": 0.025317411869764328, "_runtime": 316.4027237892151, "_timestamp": 1585136151.8597574, "_step": 266}
{"Episode reward": -93.84768927128573, "Episode length": 999, "Policy Loss": -0.5275400280952454, "Value Loss": 0.02469779923558235, "_runtime": 317.55414867401123, "_timestamp": 1585136153.0111823, "_step": 267}
{"Episode reward": -99.58818668504432, "Episode length": 999, "Policy Loss": -0.5553643107414246, "Value Loss": 0.02791391685605049, "_runtime": 318.71562695503235, "_timestamp": 1585136154.1726606, "_step": 268}
{"Episode reward": -109.26722251347506, "Episode length": 999, "Policy Loss": -0.5754019021987915, "Value Loss": 0.0342087522149086, "_runtime": 319.82455682754517, "_timestamp": 1585136155.2815905, "_step": 269}
{"Episode reward": -101.65661843487989, "Episode length": 999, "Policy Loss": -0.5526612401008606, "Value Loss": 0.0308274757117033, "_runtime": 321.0215163230896, "_timestamp": 1585136156.47855, "_step": 270}
{"Episode reward": -104.21866891194422, "Episode length": 999, "Policy Loss": -0.5702086091041565, "Value Loss": 0.03384672850370407, "_runtime": 322.1663360595703, "_timestamp": 1585136157.6233697, "_step": 271}
{"Episode reward": -107.94147810479514, "Episode length": 999, "Policy Loss": -0.5848885774612427, "Value Loss": 0.03498896583914757, "_runtime": 323.2838189601898, "_timestamp": 1585136158.7408526, "_step": 272}
{"Episode reward": -109.52593560073103, "Episode length": 999, "Policy Loss": -0.5864437818527222, "Value Loss": 0.03991230949759483, "_runtime": 324.46430134773254, "_timestamp": 1585136159.921335, "_step": 273}
{"Episode reward": -100.70076582721744, "Episode length": 999, "Policy Loss": -0.5476441383361816, "Value Loss": 0.028589682653546333, "_runtime": 325.62165093421936, "_timestamp": 1585136161.0786846, "_step": 274}
{"Episode reward": -97.50274145695812, "Episode length": 999, "Policy Loss": -0.5370776057243347, "Value Loss": 0.027760997414588928, "_runtime": 326.7592673301697, "_timestamp": 1585136162.216301, "_step": 275}
{"Episode reward": -102.94063279567642, "Episode length": 999, "Policy Loss": -0.5570762753486633, "Value Loss": 0.02946259267628193, "_runtime": 327.9138717651367, "_timestamp": 1585136163.3709054, "_step": 276}
{"Episode reward": -111.44626253115028, "Episode length": 999, "Policy Loss": -0.5884442329406738, "Value Loss": 0.038745634257793427, "_runtime": 329.04592633247375, "_timestamp": 1585136164.50296, "_step": 277}
{"Episode reward": -101.24375713924255, "Episode length": 999, "Policy Loss": -0.5499184131622314, "Value Loss": 0.031116938218474388, "_runtime": 330.1925811767578, "_timestamp": 1585136165.6496148, "_step": 278}
{"Episode reward": -99.97147069138745, "Episode length": 999, "Policy Loss": -0.5506461262702942, "Value Loss": 0.02784491516649723, "_runtime": 331.3198616504669, "_timestamp": 1585136166.7768953, "_step": 279}
{"Episode reward": -115.08793038992503, "Episode length": 999, "Policy Loss": -0.6056690216064453, "Value Loss": 0.03920993581414223, "_runtime": 332.46640968322754, "_timestamp": 1585136167.9234433, "_step": 280}
{"Episode reward": -97.12134417501298, "Episode length": 999, "Policy Loss": -0.5453548431396484, "Value Loss": 0.02927880361676216, "_runtime": 333.611008644104, "_timestamp": 1585136169.0680423, "_step": 281}
{"Episode reward": -100.10975076811539, "Episode length": 999, "Policy Loss": -0.5553569197654724, "Value Loss": 0.0336446613073349, "_runtime": 334.73929142951965, "_timestamp": 1585136170.196325, "_step": 282}
{"Episode reward": -100.00966662263495, "Episode length": 999, "Policy Loss": -0.549284815788269, "Value Loss": 0.03007035329937935, "_runtime": 335.898282289505, "_timestamp": 1585136171.355316, "_step": 283}
{"Episode reward": -107.33280774028923, "Episode length": 999, "Policy Loss": -0.5836312174797058, "Value Loss": 0.031929709017276764, "_runtime": 337.05641746520996, "_timestamp": 1585136172.513451, "_step": 284}
{"Episode reward": -99.93365334957922, "Episode length": 999, "Policy Loss": -0.5491795539855957, "Value Loss": 0.027001623064279556, "_runtime": 338.17207407951355, "_timestamp": 1585136173.6291077, "_step": 285}
{"Episode reward": -106.47813510707144, "Episode length": 999, "Policy Loss": -0.5741736888885498, "Value Loss": 0.032404378056526184, "_runtime": 339.2922394275665, "_timestamp": 1585136174.749273, "_step": 286}
{"Episode reward": -95.39539436883561, "Episode length": 999, "Policy Loss": -0.5405195951461792, "Value Loss": 0.024106083437800407, "_runtime": 340.42614817619324, "_timestamp": 1585136175.8831818, "_step": 287}
{"Episode reward": -99.54291021308397, "Episode length": 999, "Policy Loss": -0.5544838309288025, "Value Loss": 0.0309013482183218, "_runtime": 341.56787157058716, "_timestamp": 1585136177.0249052, "_step": 288}
{"Episode reward": -98.93711534383927, "Episode length": 999, "Policy Loss": -0.5578423142433167, "Value Loss": 0.02731899544596672, "_runtime": 342.7580375671387, "_timestamp": 1585136178.2150712, "_step": 289}
{"Episode reward": -101.69171488459024, "Episode length": 999, "Policy Loss": -0.5596903562545776, "Value Loss": 0.028864363208413124, "_runtime": 343.86207914352417, "_timestamp": 1585136179.3191128, "_step": 290}
{"Episode reward": -101.50115351842032, "Episode length": 999, "Policy Loss": -0.5581905841827393, "Value Loss": 0.03409701585769653, "_runtime": 345.0171284675598, "_timestamp": 1585136180.474162, "_step": 291}
{"Episode reward": -102.7513379207156, "Episode length": 999, "Policy Loss": -0.5626932382583618, "Value Loss": 0.031238297000527382, "_runtime": 346.1641798019409, "_timestamp": 1585136181.6212134, "_step": 292}
{"Episode reward": -104.10002395516175, "Episode length": 999, "Policy Loss": -0.5664042830467224, "Value Loss": 0.03007754124701023, "_runtime": 347.329776763916, "_timestamp": 1585136182.7868104, "_step": 293}
{"Episode reward": -107.14580144195935, "Episode length": 999, "Policy Loss": -0.5752934217453003, "Value Loss": 0.03858848288655281, "_runtime": 348.4866421222687, "_timestamp": 1585136183.9436758, "_step": 294}
{"Episode reward": -102.78478363254011, "Episode length": 999, "Policy Loss": -0.5609689354896545, "Value Loss": 0.0334426686167717, "_runtime": 349.6045880317688, "_timestamp": 1585136185.0616217, "_step": 295}
{"Episode reward": -103.46305494492246, "Episode length": 999, "Policy Loss": -0.5701489448547363, "Value Loss": 0.03271232172846794, "_runtime": 350.7549088001251, "_timestamp": 1585136186.2119424, "_step": 296}
{"Episode reward": -96.52870621439443, "Episode length": 999, "Policy Loss": -0.5480608344078064, "Value Loss": 0.026832373812794685, "_runtime": 351.8890709877014, "_timestamp": 1585136187.3461046, "_step": 297}
{"Episode reward": -98.39910444052434, "Episode length": 999, "Policy Loss": -0.5523729920387268, "Value Loss": 0.028496460989117622, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643, -6.257015705108643]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6.0906982421875, -5.93983268737793, -5.788967132568359, -5.638102054595947, -5.487236499786377, -5.336370944976807, -5.1855058670043945, -5.034640312194824, -4.883774757385254, -4.732909202575684, -4.582043647766113, -4.431178569793701, -4.280313014984131, -4.1294474601745605, -3.9785821437835693, -3.827716827392578, -3.676851272583008, -3.5259857177734375, -3.3751204013824463, -3.224255084991455, -3.0733895301818848, -2.9225239753723145, -2.7716586589813232, -2.620793342590332, -2.4699277877807617, -2.3190622329711914, -2.1681969165802, -2.017331600189209, -1.8664660453796387, -1.7156004905700684, -1.5647354125976562, -1.413869857788086, -1.2630043029785156, -1.1121387481689453, -0.961273193359375, -0.8104081153869629, -0.6595425605773926, -0.5086770057678223, -0.35781192779541016, -0.20694637298583984, -0.05608081817626953, 0.09478473663330078, 0.2456502914428711, 0.3965153694152832, 0.5473809242248535, 0.6982464790344238, 0.8491115570068359, 0.9999771118164062, 1.1508426666259766, 1.3017082214355469, 1.4525737762451172, 1.6034388542175293, 1.7543044090270996, 1.90516996383667, 2.056035041809082, 2.2069005966186523, 2.3577661514282227, 2.508631706237793, 2.6594972610473633, 2.8103628158569336, 2.9612274169921875, 3.112092971801758, 3.262958526611328, 3.4138240814208984, 3.5646896362304688]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.9870450496673584, -2.8865325450897217, -2.786019802093506, -2.685507297515869, -2.5849947929382324, -2.4844822883605957, -2.38396954536438, -2.283457040786743, -2.1829442977905273, -2.0824317932128906, -1.981919288635254, -1.8814066648483276, -1.7808940410614014, -1.6803815364837646, -1.5798689126968384, -1.4793564081192017, -1.3788437843322754, -1.2783311605453491, -1.1778186559677124, -1.0773060321807861, -0.9767935276031494, -0.8762807846069336, -0.7757682800292969, -0.6752557754516602, -0.5747430324554443, -0.4742305278778076, -0.3737180233001709, -0.2732055187225342, -0.17269277572631836, -0.07218027114868164, 0.028332233428955078, 0.1288449764251709, 0.22935748100280762, 0.32986998558044434, 0.43038272857666016, 0.5308952331542969, 0.6314077377319336, 0.7319204807281494, 0.8324329853057861, 0.9329454898834229, 1.0334579944610596, 1.1339704990386963, 1.2344834804534912, 1.334995985031128, 1.4355084896087646, 1.5360209941864014, 1.636533498764038, 1.7370460033416748, 1.8375589847564697, 1.9380714893341064, 2.038583993911743, 2.13909649848938, 2.2396090030670166, 2.3401215076446533, 2.44063401222229, 2.541146993637085, 2.6416594982147217, 2.7421720027923584, 2.842684507369995, 2.943197011947632, 3.0437095165252686, 3.1442224979400635, 3.2447350025177, 3.345247507095337, 3.4457600116729736]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 4.0, 6.0, 5.0, 3.0, 2.0, 2.0, 7.0, 3.0, 7.0, 7.0, 18.0, 10.0, 24.0, 26.0, 25.0, 29.0, 33.0, 44.0, 43.0, 46.0, 20.0, 17.0, 15.0, 11.0, 9.0, 15.0, 10.0, 11.0, 9.0, 6.0, 6.0, 6.0, 6.0, 6.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-2.5393569469451904, -2.453908920288086, -2.3684608936309814, -2.283012866973877, -2.1975646018981934, -2.112116575241089, -2.0266685485839844, -1.9412205219268799, -1.8557723760604858, -1.7703242301940918, -1.6848762035369873, -1.5994281768798828, -1.5139801502227783, -1.4285320043563843, -1.3430839776992798, -1.2576358318328857, -1.1721878051757812, -1.0867397785186768, -1.0012916326522827, -0.9158436059951782, -0.8303954601287842, -0.7449474334716797, -0.6594994068145752, -0.5740512609481812, -0.4886033535003662, -0.4031550884246826, -0.3177070617675781, -0.23225903511047363, -0.14681100845336914, -0.06136298179626465, 0.024085283279418945, 0.10953330993652344, 0.19498133659362793, 0.2804293632507324, 0.3658773899078369, 0.4513256549835205, 0.536773681640625, 0.6222217082977295, 0.707669734954834, 0.7931177616119385, 0.8785660266876221, 0.9640140533447266, 1.049462080001831, 1.1349101066589355, 1.22035813331604, 1.3058061599731445, 1.3912544250488281, 1.4767024517059326, 1.562150239944458, 1.6475985050201416, 1.7330467700958252, 1.8184945583343506, 1.9039428234100342, 1.9893906116485596, 2.074838876724243, 2.1602871417999268, 2.245734930038452, 2.3311831951141357, 2.416630983352661, 2.5020792484283447, 2.5875275135040283, 2.6729753017425537, 2.7584235668182373, 2.8438713550567627, 2.9293196201324463]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-2.4251949787139893, -2.3654839992523193, -2.3057727813720703, -2.2460618019104004, -2.1863505840301514, -2.1266396045684814, -2.0669283866882324, -2.0072174072265625, -1.947506308555603, -1.8877952098846436, -1.828084111213684, -1.7683730125427246, -1.7086620330810547, -1.6489508152008057, -1.5892398357391357, -1.5295287370681763, -1.4698176383972168, -1.4101065397262573, -1.3503954410552979, -1.2906843423843384, -1.230973243713379, -1.171262264251709, -1.1115511655807495, -1.05184006690979, -0.9921289682388306, -0.9324178695678711, -0.8727067708969116, -0.8129956722259521, -0.7532846927642822, -0.6935735940933228, -0.6338624954223633, -0.5741513967514038, -0.5144402980804443, -0.45472919940948486, -0.3950181007385254, -0.33530712127685547, -0.27559590339660645, -0.21588492393493652, -0.1561737060546875, -0.09646272659301758, -0.036751508712768555, 0.022959470748901367, 0.08267045021057129, 0.1423816680908203, 0.20209264755249023, 0.26180386543273926, 0.3215148448944092, 0.3812260627746582, 0.4409370422363281, 0.500648021697998, 0.5603592395782471, 0.620070219039917, 0.679781436920166, 0.7394924163818359, 0.799203634262085, 0.8589146137237549, 0.9186255931854248, 0.9783368110656738, 1.0380477905273438, 1.0977590084075928, 1.1574699878692627, 1.2171812057495117, 1.2768921852111816, 1.3366034030914307, 1.3963143825531006]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 8.0, 24.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.768195629119873, -0.7349412441253662, -0.7016868591308594, -0.6684325337409973, -0.6351781487464905, -0.6019237637519836, -0.5686694383621216, -0.5354150533676147, -0.5021606683731079, -0.4689062833786011, -0.4356519281864166, -0.4023975729942322, -0.36914318799972534, -0.3358888030052185, -0.30263444781303406, -0.2693800926208496, -0.23612570762634277, -0.20287132263183594, -0.1696169376373291, -0.13636261224746704, -0.1031082272529602, -0.06985384225845337, -0.03659951686859131, -0.0033451318740844727, 0.029909253120422363, 0.0631636381149292, 0.09641802310943604, 0.1296723484992981, 0.16292673349380493, 0.19618111848831177, 0.22943544387817383, 0.26268982887268066, 0.2959442138671875, 0.32919859886169434, 0.36245298385620117, 0.395707368850708, 0.42896175384521484, 0.46221601963043213, 0.49547040462493896, 0.5287247896194458, 0.5619791746139526, 0.5952335596084595, 0.6284879446029663, 0.6617423295974731, 0.6949965953826904, 0.7282509803771973, 0.7615053653717041, 0.7947597503662109, 0.8280141353607178, 0.8612685203552246, 0.8945229053497314, 0.9277772903442383, 0.9610316753387451, 0.9942859411239624, 1.0275403261184692, 1.060794711112976, 1.094049096107483, 1.1273034811019897, 1.1605578660964966, 1.1938122510910034, 1.2270665168762207, 1.2603209018707275, 1.2935752868652344, 1.3268296718597412, 1.360084056854248]}, "_runtime": 353.0076138973236, "_timestamp": 1585136188.4646475, "_step": 298}
{"Episode reward": -97.92774911248917, "Episode length": 999, "Policy Loss": -0.5454389452934265, "Value Loss": 0.030037764459848404, "_runtime": 354.1317296028137, "_timestamp": 1585136189.5887632, "_step": 299}
{"Episode reward": -96.23786648984687, "Episode length": 999, "Policy Loss": -0.5408306121826172, "Value Loss": 0.0249628983438015, "_runtime": 355.2948052883148, "_timestamp": 1585136190.751839, "_step": 300}
{"Episode reward": -108.14547566179155, "Episode length": 999, "Policy Loss": -0.5857728719711304, "Value Loss": 0.032528817653656006, "_runtime": 356.411625623703, "_timestamp": 1585136191.8686593, "_step": 301}
{"Episode reward": -102.91379868861384, "Episode length": 999, "Policy Loss": -0.5710205435752869, "Value Loss": 0.030991945415735245, "_runtime": 357.60892128944397, "_timestamp": 1585136193.065955, "_step": 302}
{"Episode reward": -105.44604422768182, "Episode length": 999, "Policy Loss": -0.5680450201034546, "Value Loss": 0.032661646604537964, "_runtime": 358.77871346473694, "_timestamp": 1585136194.235747, "_step": 303}
{"Episode reward": -107.64846770349683, "Episode length": 999, "Policy Loss": -0.5740517973899841, "Value Loss": 0.03457154706120491, "_runtime": 359.8805375099182, "_timestamp": 1585136195.3375711, "_step": 304}
{"Episode reward": -98.20841673689002, "Episode length": 999, "Policy Loss": -0.5556265115737915, "Value Loss": 0.029789596796035767, "_runtime": 361.0325872898102, "_timestamp": 1585136196.489621, "_step": 305}
{"Episode reward": -104.69226849825466, "Episode length": 999, "Policy Loss": -0.560835063457489, "Value Loss": 0.037346240133047104, "_runtime": 362.18057465553284, "_timestamp": 1585136197.6376083, "_step": 306}
{"Episode reward": -105.6823246894553, "Episode length": 999, "Policy Loss": -0.568251371383667, "Value Loss": 0.03287686035037041, "_runtime": 363.360867023468, "_timestamp": 1585136198.8179007, "_step": 307}
{"Episode reward": -103.54889336600289, "Episode length": 999, "Policy Loss": -0.5687651038169861, "Value Loss": 0.035359397530555725, "_runtime": 364.52689003944397, "_timestamp": 1585136199.9839237, "_step": 308}
{"Episode reward": -107.12954706385219, "Episode length": 999, "Policy Loss": -0.5732588768005371, "Value Loss": 0.03590277209877968, "_runtime": 365.6413502693176, "_timestamp": 1585136201.098384, "_step": 309}
{"Episode reward": -100.74717175403885, "Episode length": 999, "Policy Loss": -0.5608356595039368, "Value Loss": 0.03034489043056965, "_runtime": 366.77799677848816, "_timestamp": 1585136202.2350304, "_step": 310}
{"Episode reward": -108.48734868270553, "Episode length": 999, "Policy Loss": -0.5850434303283691, "Value Loss": 0.03536258637905121, "_runtime": 367.92776918411255, "_timestamp": 1585136203.3848028, "_step": 311}
{"Episode reward": -101.41259522266101, "Episode length": 999, "Policy Loss": -0.5606449842453003, "Value Loss": 0.03125238046050072, "_runtime": 369.0872452259064, "_timestamp": 1585136204.5442789, "_step": 312}
{"Episode reward": -98.4859771516855, "Episode length": 999, "Policy Loss": -0.550681471824646, "Value Loss": 0.02538050152361393, "_runtime": 370.2606177330017, "_timestamp": 1585136205.7176514, "_step": 313}
{"Episode reward": -97.1865657217402, "Episode length": 999, "Policy Loss": -0.538032054901123, "Value Loss": 0.026789193972945213, "_runtime": 371.39957785606384, "_timestamp": 1585136206.8566115, "_step": 314}
{"Episode reward": -94.99312836828241, "Episode length": 999, "Policy Loss": -0.5370585322380066, "Value Loss": 0.027988499030470848, "_runtime": 372.5608596801758, "_timestamp": 1585136208.0178933, "_step": 315}
{"Episode reward": -93.9222386077131, "Episode length": 999, "Policy Loss": -0.5328183174133301, "Value Loss": 0.028932461515069008, "_runtime": 373.6978886127472, "_timestamp": 1585136209.1549222, "_step": 316}
{"Episode reward": -98.0919864308105, "Episode length": 999, "Policy Loss": -0.5418763756752014, "Value Loss": 0.029648402705788612, "_runtime": 374.8139154911041, "_timestamp": 1585136210.2709491, "_step": 317}
{"Episode reward": -104.90973685689919, "Episode length": 999, "Policy Loss": -0.5718828439712524, "Value Loss": 0.03169812262058258, "_runtime": 375.9506986141205, "_timestamp": 1585136211.4077322, "_step": 318}
{"Episode reward": -95.81948141441667, "Episode length": 999, "Policy Loss": -0.5401524305343628, "Value Loss": 0.02677072584629059, "_runtime": 377.1237998008728, "_timestamp": 1585136212.5808334, "_step": 319}
{"Episode reward": -98.0171633882072, "Episode length": 999, "Policy Loss": -0.5493646860122681, "Value Loss": 0.028494929894804955, "_runtime": 378.2291340827942, "_timestamp": 1585136213.6861677, "_step": 320}
{"Episode reward": -100.81415592952713, "Episode length": 999, "Policy Loss": -0.569078266620636, "Value Loss": 0.03146771341562271, "_runtime": 379.38624382019043, "_timestamp": 1585136214.8432775, "_step": 321}
{"Episode reward": -99.60848346811125, "Episode length": 999, "Policy Loss": -0.5477102398872375, "Value Loss": 0.03038339875638485, "_runtime": 380.5146908760071, "_timestamp": 1585136215.9717245, "_step": 322}
{"Episode reward": -101.6216189094028, "Episode length": 999, "Policy Loss": -0.5549368262290955, "Value Loss": 0.03073655627667904, "_runtime": 381.70915389060974, "_timestamp": 1585136217.1661875, "_step": 323}
{"Episode reward": -109.86307022382914, "Episode length": 999, "Policy Loss": -0.5830216407775879, "Value Loss": 0.03650958836078644, "_runtime": 382.8999900817871, "_timestamp": 1585136218.3570237, "_step": 324}
{"Episode reward": -101.12509593011453, "Episode length": 999, "Policy Loss": -0.5506241917610168, "Value Loss": 0.029561635106801987, "_runtime": 384.08386516571045, "_timestamp": 1585136219.5408988, "_step": 325}
{"Episode reward": -104.11781597245765, "Episode length": 999, "Policy Loss": -0.5712882876396179, "Value Loss": 0.03114740364253521, "_runtime": 385.21938467025757, "_timestamp": 1585136220.6764183, "_step": 326}
{"Episode reward": -105.56510939215367, "Episode length": 999, "Policy Loss": -0.577269434928894, "Value Loss": 0.03267553448677063, "_runtime": 386.37112379074097, "_timestamp": 1585136221.8281574, "_step": 327}
{"Episode reward": -97.98229119003736, "Episode length": 999, "Policy Loss": -0.5517610907554626, "Value Loss": 0.028322335332632065, "_runtime": 387.51853370666504, "_timestamp": 1585136222.9755673, "_step": 328}
{"Episode reward": -111.00811672999457, "Episode length": 999, "Policy Loss": -0.5899674296379089, "Value Loss": 0.038738951086997986, "_runtime": 388.66783332824707, "_timestamp": 1585136224.124867, "_step": 329}
{"Episode reward": -101.14521642376882, "Episode length": 999, "Policy Loss": -0.5606053471565247, "Value Loss": 0.03224581480026245, "_runtime": 389.7818913459778, "_timestamp": 1585136225.238925, "_step": 330}
{"Episode reward": -98.04345996512268, "Episode length": 999, "Policy Loss": -0.5597440004348755, "Value Loss": 0.02921045385301113, "_runtime": 390.98847699165344, "_timestamp": 1585136226.4455106, "_step": 331}
{"Episode reward": -97.95786897929817, "Episode length": 999, "Policy Loss": -0.5426343083381653, "Value Loss": 0.028770621865987778, "_runtime": 392.14800214767456, "_timestamp": 1585136227.6050358, "_step": 332}
{"Episode reward": -104.94485945699721, "Episode length": 999, "Policy Loss": -0.5647317171096802, "Value Loss": 0.032525740563869476, "_runtime": 393.32676696777344, "_timestamp": 1585136228.7838006, "_step": 333}
{"Episode reward": -98.1226244158265, "Episode length": 999, "Policy Loss": -0.5489466190338135, "Value Loss": 0.028286738321185112, "_runtime": 394.5012993812561, "_timestamp": 1585136229.958333, "_step": 334}
{"Episode reward": -105.55922275756039, "Episode length": 999, "Policy Loss": -0.5709173679351807, "Value Loss": 0.03332092612981796, "_runtime": 395.6500794887543, "_timestamp": 1585136231.1071131, "_step": 335}
{"Episode reward": -107.15288627366543, "Episode length": 999, "Policy Loss": -0.5804349780082703, "Value Loss": 0.03512081503868103, "_runtime": 396.78394651412964, "_timestamp": 1585136232.2409801, "_step": 336}
{"Episode reward": -112.42664632207976, "Episode length": 999, "Policy Loss": -0.593856155872345, "Value Loss": 0.03763485699892044, "_runtime": 397.91569209098816, "_timestamp": 1585136233.3727257, "_step": 337}
{"Episode reward": -105.09406336635864, "Episode length": 999, "Policy Loss": -0.5749178528785706, "Value Loss": 0.032219089567661285, "_runtime": 399.0481786727905, "_timestamp": 1585136234.5052123, "_step": 338}
{"Episode reward": -101.2009518829967, "Episode length": 999, "Policy Loss": -0.5631705522537231, "Value Loss": 0.02806933782994747, "_runtime": 400.2164213657379, "_timestamp": 1585136235.673455, "_step": 339}
{"Episode reward": -99.85388923565776, "Episode length": 999, "Policy Loss": -0.5551884770393372, "Value Loss": 0.03139473497867584, "_runtime": 401.35856199264526, "_timestamp": 1585136236.8155956, "_step": 340}
{"Episode reward": -108.85125802063445, "Episode length": 999, "Policy Loss": -0.5813641548156738, "Value Loss": 0.03539007529616356, "_runtime": 402.50796580314636, "_timestamp": 1585136237.9649994, "_step": 341}
{"Episode reward": -101.33535027817352, "Episode length": 999, "Policy Loss": -0.5637223124504089, "Value Loss": 0.028285831212997437, "_runtime": 403.6460647583008, "_timestamp": 1585136239.1030984, "_step": 342}
{"Episode reward": -95.21698537602161, "Episode length": 999, "Policy Loss": -0.5499095320701599, "Value Loss": 0.028131790459156036, "_runtime": 404.77115631103516, "_timestamp": 1585136240.22819, "_step": 343}
{"Episode reward": -102.91960602443908, "Episode length": 999, "Policy Loss": -0.5730689764022827, "Value Loss": 0.032880522310733795, "_runtime": 405.9252350330353, "_timestamp": 1585136241.3822687, "_step": 344}
{"Episode reward": -103.83852537540781, "Episode length": 999, "Policy Loss": -0.5658144950866699, "Value Loss": 0.03420218080282211, "_runtime": 407.0794882774353, "_timestamp": 1585136242.536522, "_step": 345}
{"Episode reward": -106.45470088086385, "Episode length": 999, "Policy Loss": -0.5824646353721619, "Value Loss": 0.032892707735300064, "_runtime": 408.18418312072754, "_timestamp": 1585136243.6412168, "_step": 346}
{"Episode reward": -106.94454523549543, "Episode length": 999, "Policy Loss": -0.5735531449317932, "Value Loss": 0.03448263555765152, "_runtime": 409.29875111579895, "_timestamp": 1585136244.7557847, "_step": 347}
{"Episode reward": -104.54709493441867, "Episode length": 999, "Policy Loss": -0.565244197845459, "Value Loss": 0.03424656391143799, "_runtime": 410.4378864765167, "_timestamp": 1585136245.89492, "_step": 348}
{"Episode reward": -108.4663908287782, "Episode length": 999, "Policy Loss": -0.5788242220878601, "Value Loss": 0.03794041648507118, "_runtime": 411.5906870365143, "_timestamp": 1585136247.0477207, "_step": 349}
{"Episode reward": -105.57348783472423, "Episode length": 999, "Policy Loss": -0.572811484336853, "Value Loss": 0.03174745291471481, "_runtime": 412.72379660606384, "_timestamp": 1585136248.1808302, "_step": 350}
{"Episode reward": -108.69066868705752, "Episode length": 999, "Policy Loss": -0.5815943479537964, "Value Loss": 0.0340765155851841, "_runtime": 413.87486481666565, "_timestamp": 1585136249.3318985, "_step": 351}
{"Episode reward": -112.54655556449822, "Episode length": 999, "Policy Loss": -0.5948725938796997, "Value Loss": 0.04083516076207161, "_runtime": 414.9944145679474, "_timestamp": 1585136250.4514482, "_step": 352}
{"Episode reward": -107.51464041359637, "Episode length": 999, "Policy Loss": -0.5766132473945618, "Value Loss": 0.03600037097930908, "_runtime": 416.14760851860046, "_timestamp": 1585136251.6046422, "_step": 353}
{"Episode reward": -103.97894511278064, "Episode length": 999, "Policy Loss": -0.5774698257446289, "Value Loss": 0.03177127614617348, "_runtime": 417.2670843601227, "_timestamp": 1585136252.724118, "_step": 354}
{"Episode reward": -107.23434042729971, "Episode length": 999, "Policy Loss": -0.5736727714538574, "Value Loss": 0.03342746943235397, "_runtime": 418.425017118454, "_timestamp": 1585136253.8820508, "_step": 355}
{"Episode reward": -104.24225673308709, "Episode length": 999, "Policy Loss": -0.5719581842422485, "Value Loss": 0.03262897953391075, "_runtime": 419.58476400375366, "_timestamp": 1585136255.0417976, "_step": 356}
{"Episode reward": -100.27130389815386, "Episode length": 999, "Policy Loss": -0.5655701160430908, "Value Loss": 0.0294144656509161, "_runtime": 420.75105333328247, "_timestamp": 1585136256.208087, "_step": 357}
{"Episode reward": -99.90013202865876, "Episode length": 999, "Policy Loss": -0.5606663823127747, "Value Loss": 0.03161640837788582, "_runtime": 421.90467643737793, "_timestamp": 1585136257.36171, "_step": 358}
{"Episode reward": -103.37380075760477, "Episode length": 999, "Policy Loss": -0.5647403597831726, "Value Loss": 0.03137889876961708, "_runtime": 423.0233826637268, "_timestamp": 1585136258.4804163, "_step": 359}
{"Episode reward": -103.34944680848405, "Episode length": 999, "Policy Loss": -0.5607438683509827, "Value Loss": 0.03414265066385269, "_runtime": 424.14895272254944, "_timestamp": 1585136259.6059864, "_step": 360}
{"Episode reward": -101.28424533106043, "Episode length": 999, "Policy Loss": -0.5600214600563049, "Value Loss": 0.029738985002040863, "_runtime": 425.29657101631165, "_timestamp": 1585136260.7536047, "_step": 361}
{"Episode reward": -100.6772536833288, "Episode length": 999, "Policy Loss": -0.567704439163208, "Value Loss": 0.030784958973526955, "_runtime": 426.4259991645813, "_timestamp": 1585136261.8830328, "_step": 362}
{"Episode reward": -103.33982951867677, "Episode length": 999, "Policy Loss": -0.5754347443580627, "Value Loss": 0.032811831682920456, "_runtime": 427.55484676361084, "_timestamp": 1585136263.0118804, "_step": 363}
{"Episode reward": -101.84782827583042, "Episode length": 999, "Policy Loss": -0.5735269784927368, "Value Loss": 0.033261027187108994, "_runtime": 428.706307888031, "_timestamp": 1585136264.1633415, "_step": 364}
{"Episode reward": -102.45603681170344, "Episode length": 999, "Policy Loss": -0.5746737718582153, "Value Loss": 0.032127998769283295, "_runtime": 429.81449723243713, "_timestamp": 1585136265.2715309, "_step": 365}
{"Episode reward": -103.88023428748949, "Episode length": 999, "Policy Loss": -0.569412350654602, "Value Loss": 0.03210802748799324, "_runtime": 430.9923298358917, "_timestamp": 1585136266.4493635, "_step": 366}
{"Episode reward": -102.87378148831756, "Episode length": 999, "Policy Loss": -0.5708169937133789, "Value Loss": 0.03231680393218994, "_runtime": 432.1516742706299, "_timestamp": 1585136267.608708, "_step": 367}
{"Episode reward": -101.29587597148597, "Episode length": 999, "Policy Loss": -0.5717241764068604, "Value Loss": 0.03260263055562973, "_runtime": 433.298442363739, "_timestamp": 1585136268.755476, "_step": 368}
{"Episode reward": -108.99473196244934, "Episode length": 999, "Policy Loss": -0.5829616189002991, "Value Loss": 0.03452475741505623, "_runtime": 434.46129512786865, "_timestamp": 1585136269.9183288, "_step": 369}
{"Episode reward": -103.57847607443641, "Episode length": 999, "Policy Loss": -0.5674091577529907, "Value Loss": 0.031100058928132057, "_runtime": 435.5937535762787, "_timestamp": 1585136271.0507872, "_step": 370}
{"Episode reward": -107.1663195713335, "Episode length": 999, "Policy Loss": -0.5763953328132629, "Value Loss": 0.031657326966524124, "_runtime": 436.7477207183838, "_timestamp": 1585136272.2047544, "_step": 371}
{"Episode reward": -101.9916621404854, "Episode length": 999, "Policy Loss": -0.5698407888412476, "Value Loss": 0.031344328075647354, "_runtime": 437.90413093566895, "_timestamp": 1585136273.3611646, "_step": 372}
{"Episode reward": -111.96754168125993, "Episode length": 999, "Policy Loss": -0.5885834693908691, "Value Loss": 0.0366315022110939, "_runtime": 439.01814889907837, "_timestamp": 1585136274.4751825, "_step": 373}
{"Episode reward": -93.40049597513179, "Episode length": 999, "Policy Loss": -0.5364335775375366, "Value Loss": 0.026676246896386147, "_runtime": 440.1361343860626, "_timestamp": 1585136275.593168, "_step": 374}
{"Episode reward": -104.95452405664747, "Episode length": 999, "Policy Loss": -0.5767375826835632, "Value Loss": 0.03366488963365555, "_runtime": 441.259624004364, "_timestamp": 1585136276.7166576, "_step": 375}
{"Episode reward": -105.54396374885306, "Episode length": 999, "Policy Loss": -0.5830061435699463, "Value Loss": 0.0344160720705986, "_runtime": 442.38402009010315, "_timestamp": 1585136277.8410537, "_step": 376}
{"Episode reward": -109.43933388713737, "Episode length": 999, "Policy Loss": -0.59131920337677, "Value Loss": 0.04579024761915207, "_runtime": 443.54750299453735, "_timestamp": 1585136279.0045366, "_step": 377}
{"Episode reward": -104.11500399258628, "Episode length": 999, "Policy Loss": -0.5775613784790039, "Value Loss": 0.0322699174284935, "_runtime": 444.6640682220459, "_timestamp": 1585136280.1211019, "_step": 378}
{"Episode reward": -99.82805568423645, "Episode length": 999, "Policy Loss": -0.5560379028320312, "Value Loss": 0.029124191030859947, "_runtime": 445.817227602005, "_timestamp": 1585136281.2742612, "_step": 379}
{"Episode reward": -98.41318016487465, "Episode length": 999, "Policy Loss": -0.5508516430854797, "Value Loss": 0.031293340027332306, "_runtime": 446.9690372943878, "_timestamp": 1585136282.426071, "_step": 380}
{"Episode reward": -100.39432770555644, "Episode length": 999, "Policy Loss": -0.5636293888092041, "Value Loss": 0.029888855293393135, "_runtime": 448.0814619064331, "_timestamp": 1585136283.5384955, "_step": 381}
{"Episode reward": -102.88821361491311, "Episode length": 999, "Policy Loss": -0.5745602250099182, "Value Loss": 0.03383312374353409, "_runtime": 449.26066422462463, "_timestamp": 1585136284.7176979, "_step": 382}
{"Episode reward": -102.04456774529396, "Episode length": 999, "Policy Loss": -0.5666743516921997, "Value Loss": 0.029649486765265465, "_runtime": 450.43619751930237, "_timestamp": 1585136285.8932312, "_step": 383}
{"Episode reward": -107.13395922983716, "Episode length": 999, "Policy Loss": -0.5879808664321899, "Value Loss": 0.03503575176000595, "_runtime": 451.57053804397583, "_timestamp": 1585136287.0275717, "_step": 384}
{"Episode reward": -99.74072316406105, "Episode length": 999, "Policy Loss": -0.5555820465087891, "Value Loss": 0.029029110446572304, "_runtime": 452.7595100402832, "_timestamp": 1585136288.2165437, "_step": 385}
{"Episode reward": -100.0419746516441, "Episode length": 999, "Policy Loss": -0.5594293475151062, "Value Loss": 0.02790840156376362, "_runtime": 453.86560440063477, "_timestamp": 1585136289.322638, "_step": 386}
{"Episode reward": -104.64443342780338, "Episode length": 999, "Policy Loss": -0.5721322298049927, "Value Loss": 0.03606001287698746, "_runtime": 454.9963490962982, "_timestamp": 1585136290.4533827, "_step": 387}
{"Episode reward": -101.88402648235875, "Episode length": 999, "Policy Loss": -0.5641123056411743, "Value Loss": 0.03357595577836037, "_runtime": 456.12007427215576, "_timestamp": 1585136291.577108, "_step": 388}
{"Episode reward": -107.50207348787632, "Episode length": 999, "Policy Loss": -0.5941827893257141, "Value Loss": 0.034894123673439026, "_runtime": 457.29813742637634, "_timestamp": 1585136292.755171, "_step": 389}
{"Episode reward": -99.1564503287248, "Episode length": 999, "Policy Loss": -0.5576295256614685, "Value Loss": 0.026375042274594307, "_runtime": 458.4421374797821, "_timestamp": 1585136293.899171, "_step": 390}
{"Episode reward": -100.19847900881348, "Episode length": 999, "Policy Loss": -0.5557880997657776, "Value Loss": 0.034181542694568634, "_runtime": 459.54658365249634, "_timestamp": 1585136295.0036173, "_step": 391}
{"Episode reward": -98.48242620088634, "Episode length": 999, "Policy Loss": -0.5538108348846436, "Value Loss": 0.02768375538289547, "_runtime": 460.70193791389465, "_timestamp": 1585136296.1589715, "_step": 392}
{"Episode reward": -108.22450259106128, "Episode length": 999, "Policy Loss": -0.5795392394065857, "Value Loss": 0.03148647025227547, "_runtime": 461.85577607154846, "_timestamp": 1585136297.3128097, "_step": 393}
{"Episode reward": -102.76615368530713, "Episode length": 999, "Policy Loss": -0.563001811504364, "Value Loss": 0.03413631021976471, "_runtime": 463.01634550094604, "_timestamp": 1585136298.4733791, "_step": 394}
{"Episode reward": -104.00700296592588, "Episode length": 999, "Policy Loss": -0.5751795768737793, "Value Loss": 0.030632492154836655, "_runtime": 464.1364345550537, "_timestamp": 1585136299.5934682, "_step": 395}
{"Episode reward": -102.11171534969374, "Episode length": 999, "Policy Loss": -0.5623509287834167, "Value Loss": 0.030185852199792862, "_runtime": 465.2495348453522, "_timestamp": 1585136300.7065685, "_step": 396}
{"Episode reward": -102.50299181847494, "Episode length": 999, "Policy Loss": -0.5635009407997131, "Value Loss": 0.0315898172557354, "_runtime": 466.37107610702515, "_timestamp": 1585136301.8281097, "_step": 397}
{"Episode reward": -96.8861413879152, "Episode length": 999, "Policy Loss": -0.5544947385787964, "Value Loss": 0.02836095727980137, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945, -9.297929763793945]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.988480567932129, -8.765507698059082, -8.542533874511719, -8.319561004638672, -8.096588134765625, -7.873614311218262, -7.650641441345215, -7.42766809463501, -7.204694747924805, -6.9817214012146, -6.7587480545043945, -6.535775184631348, -6.312801837921143, -6.0898284912109375, -5.866855621337891, -5.6438822746276855, -5.4209089279174805, -5.197935581207275, -4.97496223449707, -4.751989364624023, -4.529016017913818, -4.306042671203613, -4.083069801330566, -3.8600964546203613, -3.6371231079101562, -3.414149761199951, -3.191176414489746, -2.968203544616699, -2.745230197906494, -2.522256851196289, -2.299283981323242, -2.076310634613037, -1.853337287902832, -1.630363941192627, -1.4073905944824219, -1.184417724609375, -0.9614439010620117, -0.7384710311889648, -0.515498161315918, -0.2925243377685547, -0.06955146789550781, 0.15342140197753906, 0.37639522552490234, 0.5993680953979492, 0.8223409652709961, 1.0453147888183594, 1.2682876586914062, 1.4912614822387695, 1.7142343521118164, 1.9372072219848633, 2.1601810455322266, 2.3831539154052734, 2.6061277389526367, 2.8291006088256836, 3.0520734786987305, 3.2750473022460938, 3.4980201721191406, 3.7209930419921875, 3.943966865539551, 4.166939735412598, 4.3899126052856445, 4.612886428833008, 4.835859298706055, 5.058833122253418, 5.281805992126465]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.438015937805176, -4.288654327392578, -4.1392927169799805, -3.9899308681488037, -3.840569257736206, -3.6912076473236084, -3.5418457984924316, -3.392484188079834, -3.2431225776672363, -3.0937609672546387, -2.944399356842041, -2.7950375080108643, -2.6456758975982666, -2.496314287185669, -2.346952438354492, -2.1975908279418945, -2.048229217529297, -1.8988676071166992, -1.7495059967041016, -1.6001441478729248, -1.4507825374603271, -1.3014209270477295, -1.1520590782165527, -1.002697467803955, -0.8533358573913574, -0.7039742469787598, -0.5546126365661621, -0.40525102615356445, -0.2558889389038086, -0.10652732849121094, 0.04283428192138672, 0.19219589233398438, 0.34155750274658203, 0.4909191131591797, 0.6402807235717773, 0.789642333984375, 0.9390039443969727, 1.0883660316467285, 1.2377276420593262, 1.3870892524719238, 1.5364508628845215, 1.6858124732971191, 1.8351740837097168, 1.9845356941223145, 2.1338977813720703, 2.283259391784668, 2.4326210021972656, 2.5819826126098633, 2.731344223022461, 2.8807058334350586, 3.0300674438476562, 3.179429054260254, 3.3287906646728516, 3.4781527519226074, 3.627513885498047, 3.7768754959106445, 3.9262380599975586, 4.075599670410156, 4.224961280822754, 4.374322891235352, 4.523684501647949, 4.673046112060547, 4.8224077224731445, 4.971769332885742, 5.12113094329834]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 4.0, 6.0, 4.0, 5.0, 1.0, 4.0, 5.0, 3.0, 7.0, 7.0, 17.0, 11.0, 26.0, 24.0, 26.0, 28.0, 35.0, 43.0, 42.0, 46.0, 20.0, 17.0, 16.0, 9.0, 9.0, 16.0, 10.0, 12.0, 8.0, 6.0, 6.0, 4.0, 10.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-3.724886178970337, -3.599524974822998, -3.474163770675659, -3.3488025665283203, -3.2234416007995605, -3.0980801582336426, -2.972719192504883, -2.847357988357544, -2.721996784210205, -2.596635580062866, -2.4712743759155273, -2.3459134101867676, -2.2205519676208496, -2.09519100189209, -1.969829797744751, -1.844468593597412, -1.7191073894500732, -1.5937461853027344, -1.4683849811553955, -1.3430237770080566, -1.2176625728607178, -1.092301607131958, -0.9669404029846191, -0.8415791988372803, -0.7162179946899414, -0.5908567905426025, -0.46549558639526367, -0.3401343822479248, -0.21477341651916504, -0.08941221237182617, 0.035948991775512695, 0.16131019592285156, 0.28667140007019043, 0.4120323657989502, 0.5373938083648682, 0.6627547740936279, 0.7881162166595459, 0.9134771823883057, 1.0388386249542236, 1.1641995906829834, 1.2895610332489014, 1.4149219989776611, 1.540282964706421, 1.6656444072723389, 1.7910053730010986, 1.9163668155670166, 2.0417277812957764, 2.1670892238616943, 2.292450189590454, 2.417811155319214, 2.543172597885132, 2.6685335636138916, 2.7938950061798096, 2.9192559719085693, 3.0446174144744873, 3.169978380203247, 3.295339345932007, 3.420700788497925, 3.5460617542266846, 3.6714231967926025, 3.7967841625213623, 3.9221456050872803, 4.047506332397461, 4.172867774963379, 4.298229217529297]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-3.4948244094848633, -3.4083142280578613, -3.3218038082122803, -3.2352936267852783, -3.1487832069396973, -3.0622730255126953, -2.9757628440856934, -2.8892524242401123, -2.8027420043945312, -2.7162318229675293, -2.6297216415405273, -2.5432112216949463, -2.4567010402679443, -2.3701906204223633, -2.2836804389953613, -2.1971702575683594, -2.1106598377227783, -2.0241494178771973, -1.9376392364501953, -1.8511289358139038, -1.7646186351776123, -1.6781084537506104, -1.5915981531143188, -1.5050878524780273, -1.4185776710510254, -1.3320672512054443, -1.2455570697784424, -1.1590466499328613, -1.0725364685058594, -0.9860260486602783, -0.8995158672332764, -0.8130054473876953, -0.7264952659606934, -0.6399850845336914, -0.5534746646881104, -0.4669644832611084, -0.38045406341552734, -0.2939438819885254, -0.20743346214294434, -0.12092328071594238, -0.03441286087036133, 0.052097320556640625, 0.13860750198364258, 0.22511792182922363, 0.3116281032562256, 0.39813852310180664, 0.4846487045288086, 0.5711588859558105, 0.6576690673828125, 0.7441797256469727, 0.8306899070739746, 0.9172000885009766, 1.0037102699279785, 1.0902209281921387, 1.1767311096191406, 1.2632412910461426, 1.3497514724731445, 1.4362616539001465, 1.5227723121643066, 1.6092824935913086, 1.6957926750183105, 1.7823028564453125, 1.8688135147094727, 1.9553236961364746, 2.0418338775634766]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 17.0, 15.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1.0107933282852173, -0.9647046327590942, -0.918615996837616, -0.8725273013114929, -0.8264386653900146, -0.7803499698638916, -0.7342612743377686, -0.6881725788116455, -0.6420839428901672, -0.595995306968689, -0.5499066114425659, -0.5038179159164429, -0.4577292203903198, -0.41164058446884155, -0.3655518889427185, -0.31946325302124023, -0.2733745574951172, -0.22728586196899414, -0.18119722604751587, -0.13510853052139282, -0.08901989459991455, -0.042931199073791504, 0.003157496452331543, 0.04924619197845459, 0.09533488750457764, 0.14142346382141113, 0.18751215934753418, 0.23360085487365723, 0.2796895503997803, 0.3257782459259033, 0.3718668222427368, 0.41795551776885986, 0.4640442132949829, 0.510132908821106, 0.556221604347229, 0.6023101806640625, 0.6483988761901855, 0.6944875717163086, 0.7405762672424316, 0.7866649627685547, 0.8327535390853882, 0.8788422346115112, 0.9249309301376343, 0.9710196256637573, 1.0171083211898804, 1.0631970167160034, 1.1092857122421265, 1.1553744077682495, 1.2014631032943726, 1.2475515604019165, 1.2936402559280396, 1.3397289514541626, 1.3858176469802856, 1.4319063425064087, 1.4779950380325317, 1.5240837335586548, 1.5701724290847778, 1.6162611246109009, 1.662349820137024, 1.7084382772445679, 1.754526972770691, 1.800615668296814, 1.846704363822937, 1.89279305934906, 1.938881754875183]}, "_runtime": 467.48525047302246, "_timestamp": 1585136302.942284, "_step": 398}
{"Episode reward": -102.75076001894246, "Episode length": 999, "Policy Loss": -0.5667529702186584, "Value Loss": 0.033236682415008545, "_runtime": 468.63417387008667, "_timestamp": 1585136304.0912075, "_step": 399}
{"Episode reward": -102.92340481313941, "Episode length": 999, "Policy Loss": -0.5611032247543335, "Value Loss": 0.03150244057178497, "_runtime": 468.63417387008667, "_timestamp": 1585136304.0912075, "_step": 400}
