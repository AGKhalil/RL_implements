{"Episode reward": -99.01405111811683, "Episode length": 999, "Policy Loss": -0.1331227570772171, "Value Loss": 0.02857985347509384, "_runtime": 7.429180860519409, "_timestamp": 1585418584.575687, "_step": 0}
{"Episode reward": -91.54164222696289, "Episode length": 999, "Policy Loss": -0.12935185432434082, "Value Loss": 0.02464715950191021, "_runtime": 8.826509952545166, "_timestamp": 1585418585.973016, "_step": 1}
{"Episode reward": -105.26833848455763, "Episode length": 999, "Policy Loss": -0.15501292049884796, "Value Loss": 0.03200015425682068, "_runtime": 10.470131874084473, "_timestamp": 1585418587.616638, "_step": 2}
{"Episode reward": -100.6703853583127, "Episode length": 999, "Policy Loss": -0.13837037980556488, "Value Loss": 0.03455961123108864, "_runtime": 12.302520990371704, "_timestamp": 1585418589.449027, "_step": 3}
{"Episode reward": -102.32264190311011, "Episode length": 999, "Policy Loss": -0.1432797759771347, "Value Loss": 0.02993667684495449, "_runtime": 13.527452945709229, "_timestamp": 1585418590.673959, "_step": 4}
{"Episode reward": -105.69004795819289, "Episode length": 999, "Policy Loss": -0.14078830182552338, "Value Loss": 0.03524043411016464, "_runtime": 14.794240951538086, "_timestamp": 1585418591.940747, "_step": 5}
{"Episode reward": -103.67611379805093, "Episode length": 999, "Policy Loss": -0.141045942902565, "Value Loss": 0.0314357653260231, "_runtime": 16.261303901672363, "_timestamp": 1585418593.40781, "_step": 6}
{"Episode reward": -99.20757160997078, "Episode length": 999, "Policy Loss": -0.14372213184833527, "Value Loss": 0.028113454580307007, "_runtime": 19.19032597541809, "_timestamp": 1585418596.336832, "_step": 7}
{"Episode reward": -106.88470087808396, "Episode length": 999, "Policy Loss": -0.14580975472927094, "Value Loss": 0.03295231983065605, "_runtime": 20.544278860092163, "_timestamp": 1585418597.690785, "_step": 8}
{"Episode reward": -104.92793039501186, "Episode length": 999, "Policy Loss": -0.1523948758840561, "Value Loss": 0.034692443907260895, "_runtime": 21.998448848724365, "_timestamp": 1585418599.144955, "_step": 9}
{"Episode reward": -104.1316352515355, "Episode length": 999, "Policy Loss": -0.14468838274478912, "Value Loss": 0.0351426899433136, "_runtime": 23.350104093551636, "_timestamp": 1585418600.4966102, "_step": 10}
{"Episode reward": -107.84659246017074, "Episode length": 999, "Policy Loss": -0.1616365611553192, "Value Loss": 0.038168955594301224, "_runtime": 24.594542980194092, "_timestamp": 1585418601.741049, "_step": 11}
{"Episode reward": -101.66887164145719, "Episode length": 999, "Policy Loss": -0.14158806204795837, "Value Loss": 0.028809605166316032, "_runtime": 25.808772087097168, "_timestamp": 1585418602.9552782, "_step": 12}
{"Episode reward": -92.95708931673984, "Episode length": 999, "Policy Loss": -0.1268702894449234, "Value Loss": 0.026107043027877808, "_runtime": 27.000087022781372, "_timestamp": 1585418604.146593, "_step": 13}
{"Episode reward": -108.99018970620051, "Episode length": 999, "Policy Loss": -0.15309195220470428, "Value Loss": 0.034088682383298874, "_runtime": 28.20276975631714, "_timestamp": 1585418605.3492758, "_step": 14}
{"Episode reward": -97.05477620728529, "Episode length": 999, "Policy Loss": -0.12689726054668427, "Value Loss": 0.027818871662020683, "_runtime": 29.490856885910034, "_timestamp": 1585418606.637363, "_step": 15}
{"Episode reward": -98.60571709624877, "Episode length": 999, "Policy Loss": -0.13818518817424774, "Value Loss": 0.02824244275689125, "_runtime": 31.077879905700684, "_timestamp": 1585418608.224386, "_step": 16}
{"Episode reward": -99.79378663660117, "Episode length": 999, "Policy Loss": -0.13840578496456146, "Value Loss": 0.033259857445955276, "_runtime": 33.07824993133545, "_timestamp": 1585418610.224756, "_step": 17}
{"Episode reward": -102.32966202007697, "Episode length": 999, "Policy Loss": -0.14882653951644897, "Value Loss": 0.029559342190623283, "_runtime": 34.43005895614624, "_timestamp": 1585418611.576565, "_step": 18}
{"Episode reward": -98.41302230076431, "Episode length": 999, "Policy Loss": -0.1319296658039093, "Value Loss": 0.03201485425233841, "_runtime": 35.63910913467407, "_timestamp": 1585418612.7856152, "_step": 19}
{"Episode reward": -96.31881405215846, "Episode length": 999, "Policy Loss": -0.13008728623390198, "Value Loss": 0.026376113295555115, "_runtime": 36.88146996498108, "_timestamp": 1585418614.027976, "_step": 20}
{"Episode reward": -102.35518078457125, "Episode length": 999, "Policy Loss": -0.13750025629997253, "Value Loss": 0.03839433565735817, "_runtime": 38.17933368682861, "_timestamp": 1585418615.3258398, "_step": 21}
{"Episode reward": -105.61336045424405, "Episode length": 999, "Policy Loss": -0.1484319269657135, "Value Loss": 0.029576359316706657, "_runtime": 39.38510489463806, "_timestamp": 1585418616.531611, "_step": 22}
{"Episode reward": -101.80840221109993, "Episode length": 999, "Policy Loss": -0.14893393218517303, "Value Loss": 0.029392408207058907, "_runtime": 40.790114879608154, "_timestamp": 1585418617.936621, "_step": 23}
{"Episode reward": -109.25355110514317, "Episode length": 999, "Policy Loss": -0.14853382110595703, "Value Loss": 0.036563578993082047, "_runtime": 42.19186782836914, "_timestamp": 1585418619.338374, "_step": 24}
{"Episode reward": -104.44389204031765, "Episode length": 999, "Policy Loss": -0.14485958218574524, "Value Loss": 0.03446502238512039, "_runtime": 43.50132489204407, "_timestamp": 1585418620.647831, "_step": 25}
{"Episode reward": -111.39280949256273, "Episode length": 999, "Policy Loss": -0.16546206176280975, "Value Loss": 0.036762550473213196, "_runtime": 44.84092903137207, "_timestamp": 1585418621.987435, "_step": 26}
{"Episode reward": -106.19072200482283, "Episode length": 999, "Policy Loss": -0.1503802239894867, "Value Loss": 0.03419090807437897, "_runtime": 46.072521924972534, "_timestamp": 1585418623.219028, "_step": 27}
{"Episode reward": -103.55777141769934, "Episode length": 999, "Policy Loss": -0.15287460386753082, "Value Loss": 0.03197336941957474, "_runtime": 47.89522099494934, "_timestamp": 1585418625.041727, "_step": 28}
{"Episode reward": -109.3929103865931, "Episode length": 999, "Policy Loss": -0.1571640819311142, "Value Loss": 0.03934084624052048, "_runtime": 50.952922105789185, "_timestamp": 1585418628.0994282, "_step": 29}
{"Episode reward": -102.41098684485759, "Episode length": 999, "Policy Loss": -0.14154528081417084, "Value Loss": 0.030799394473433495, "_runtime": 52.404123067855835, "_timestamp": 1585418629.5506291, "_step": 30}
{"Episode reward": -100.93812054703852, "Episode length": 999, "Policy Loss": -0.1312822848558426, "Value Loss": 0.03487551212310791, "_runtime": 53.36395788192749, "_timestamp": 1585418630.510464, "_step": 31}
{"Episode reward": 23.079511797631454, "Episode length": 713, "Policy Loss": -0.019387461245059967, "Value Loss": 13.992457389831543, "_runtime": 54.939894914627075, "_timestamp": 1585418632.086401, "_step": 32}
{"Episode reward": -106.460392130486, "Episode length": 999, "Policy Loss": -0.15422949194908142, "Value Loss": 0.03582662343978882, "_runtime": 56.2466197013855, "_timestamp": 1585418633.3931258, "_step": 33}
{"Episode reward": -103.74650686595713, "Episode length": 999, "Policy Loss": -0.13185617327690125, "Value Loss": 0.03305232152342796, "_runtime": 57.5538969039917, "_timestamp": 1585418634.700403, "_step": 34}
{"Episode reward": -105.41564161032333, "Episode length": 999, "Policy Loss": -0.14703796803951263, "Value Loss": 0.03197382763028145, "_runtime": 59.17804574966431, "_timestamp": 1585418636.3245518, "_step": 35}
{"Episode reward": -102.84168964672001, "Episode length": 999, "Policy Loss": -0.14018602669239044, "Value Loss": 0.03349309787154198, "_runtime": 63.65613293647766, "_timestamp": 1585418640.802639, "_step": 36}
{"Episode reward": -107.90425672185354, "Episode length": 999, "Policy Loss": -0.15953677892684937, "Value Loss": 0.034361790865659714, "_runtime": 67.48894309997559, "_timestamp": 1585418644.6354492, "_step": 37}
{"Episode reward": -101.13914268912892, "Episode length": 999, "Policy Loss": -0.1388665735721588, "Value Loss": 0.03141177445650101, "_runtime": 70.36811685562134, "_timestamp": 1585418647.514623, "_step": 38}
{"Episode reward": -98.59211416534606, "Episode length": 999, "Policy Loss": -0.13102219998836517, "Value Loss": 0.028691308572888374, "_runtime": 72.29679298400879, "_timestamp": 1585418649.443299, "_step": 39}
{"Episode reward": -99.77506238204786, "Episode length": 999, "Policy Loss": -0.1398596465587616, "Value Loss": 0.029456814751029015, "_runtime": 74.20441484451294, "_timestamp": 1585418651.350921, "_step": 40}
{"Episode reward": -100.41195404019766, "Episode length": 999, "Policy Loss": -0.1388978362083435, "Value Loss": 0.0296022929251194, "_runtime": 75.55990386009216, "_timestamp": 1585418652.70641, "_step": 41}
{"Episode reward": -100.39292628036009, "Episode length": 999, "Policy Loss": -0.14442607760429382, "Value Loss": 0.03005501627922058, "_runtime": 76.95747494697571, "_timestamp": 1585418654.103981, "_step": 42}
{"Episode reward": -101.09181885029231, "Episode length": 999, "Policy Loss": -0.13150948286056519, "Value Loss": 0.03599133342504501, "_runtime": 78.28366470336914, "_timestamp": 1585418655.4301708, "_step": 43}
{"Episode reward": -100.27780214045707, "Episode length": 999, "Policy Loss": -0.13556106388568878, "Value Loss": 0.030593015253543854, "_runtime": 79.64520788192749, "_timestamp": 1585418656.791714, "_step": 44}
{"Episode reward": -111.99551770483276, "Episode length": 999, "Policy Loss": -0.15999092161655426, "Value Loss": 0.03594677150249481, "_runtime": 80.97042298316956, "_timestamp": 1585418658.116929, "_step": 45}
{"Episode reward": -102.44871276835323, "Episode length": 999, "Policy Loss": -0.14786209166049957, "Value Loss": 0.03438084200024605, "_runtime": 82.20630288124084, "_timestamp": 1585418659.352809, "_step": 46}
{"Episode reward": -101.57852436503174, "Episode length": 999, "Policy Loss": -0.1352757215499878, "Value Loss": 0.033862996846437454, "_runtime": 83.52898788452148, "_timestamp": 1585418660.675494, "_step": 47}
{"Episode reward": -95.46517620841642, "Episode length": 999, "Policy Loss": -0.12847775220870972, "Value Loss": 0.02996988035738468, "_runtime": 84.83379077911377, "_timestamp": 1585418661.9802969, "_step": 48}
{"Episode reward": -101.65456902534318, "Episode length": 999, "Policy Loss": -0.13587398827075958, "Value Loss": 0.03100958652794361, "_runtime": 86.0536277294159, "_timestamp": 1585418663.2001338, "_step": 49}
{"Episode reward": -104.47944768130196, "Episode length": 999, "Policy Loss": -0.14416582882404327, "Value Loss": 0.03418048098683357, "_runtime": 87.18228387832642, "_timestamp": 1585418664.32879, "_step": 50}
{"Episode reward": -99.73538610280042, "Episode length": 999, "Policy Loss": -0.13316816091537476, "Value Loss": 0.03064177744090557, "_runtime": 88.39981985092163, "_timestamp": 1585418665.546326, "_step": 51}
{"Episode reward": -98.77956257110155, "Episode length": 999, "Policy Loss": -0.13537690043449402, "Value Loss": 0.032806262373924255, "_runtime": 89.70265793800354, "_timestamp": 1585418666.849164, "_step": 52}
{"Episode reward": -96.28242993749762, "Episode length": 999, "Policy Loss": -0.13011711835861206, "Value Loss": 0.029487164691090584, "_runtime": 91.05229902267456, "_timestamp": 1585418668.198805, "_step": 53}
{"Episode reward": -102.30259590777716, "Episode length": 999, "Policy Loss": -0.14145119488239288, "Value Loss": 0.030264290049672127, "_runtime": 92.26061296463013, "_timestamp": 1585418669.407119, "_step": 54}
{"Episode reward": -102.00871222054745, "Episode length": 999, "Policy Loss": -0.14584793150424957, "Value Loss": 0.030414029955863953, "_runtime": 93.57777094841003, "_timestamp": 1585418670.724277, "_step": 55}
{"Episode reward": -2.77091368708345, "Episode length": 958, "Policy Loss": -0.0457395575940609, "Value Loss": 10.48421573638916, "_runtime": 94.80071806907654, "_timestamp": 1585418671.9472241, "_step": 56}
{"Episode reward": -8.667869791745773, "Episode length": 988, "Policy Loss": -0.05714746564626694, "Value Loss": 10.05064868927002, "_runtime": 96.06466603279114, "_timestamp": 1585418673.211172, "_step": 57}
{"Episode reward": -104.41613107520668, "Episode length": 999, "Policy Loss": -0.1411120444536209, "Value Loss": 0.031048031523823738, "_runtime": 97.30561304092407, "_timestamp": 1585418674.452119, "_step": 58}
{"Episode reward": -104.95513667284948, "Episode length": 999, "Policy Loss": -0.14692650735378265, "Value Loss": 0.03137043118476868, "_runtime": 98.46352100372314, "_timestamp": 1585418675.610027, "_step": 59}
{"Episode reward": -107.3770693723253, "Episode length": 999, "Policy Loss": -0.14390778541564941, "Value Loss": 0.036451589316129684, "_runtime": 99.66165804862976, "_timestamp": 1585418676.8081641, "_step": 60}
{"Episode reward": -104.49380370249416, "Episode length": 999, "Policy Loss": -0.14655019342899323, "Value Loss": 0.03371531516313553, "_runtime": 100.87320399284363, "_timestamp": 1585418678.01971, "_step": 61}
{"Episode reward": -103.87925085502692, "Episode length": 999, "Policy Loss": -0.1475619673728943, "Value Loss": 0.031201649457216263, "_runtime": 102.18928670883179, "_timestamp": 1585418679.3357928, "_step": 62}
{"Episode reward": -97.4435147713593, "Episode length": 999, "Policy Loss": -0.12887544929981232, "Value Loss": 0.02758433297276497, "_runtime": 103.53737688064575, "_timestamp": 1585418680.683883, "_step": 63}
{"Episode reward": -97.07695356437779, "Episode length": 999, "Policy Loss": -0.1319415271282196, "Value Loss": 0.025922222062945366, "_runtime": 104.8185760974884, "_timestamp": 1585418681.9650822, "_step": 64}
{"Episode reward": -101.76729036384008, "Episode length": 999, "Policy Loss": -0.14202821254730225, "Value Loss": 0.03166228160262108, "_runtime": 106.04766488075256, "_timestamp": 1585418683.194171, "_step": 65}
{"Episode reward": -95.15283041229533, "Episode length": 999, "Policy Loss": -0.1231694221496582, "Value Loss": 0.024646129459142685, "_runtime": 107.30972695350647, "_timestamp": 1585418684.456233, "_step": 66}
{"Episode reward": -104.7013697439537, "Episode length": 999, "Policy Loss": -0.14343379437923431, "Value Loss": 0.02975931391119957, "_runtime": 108.61254811286926, "_timestamp": 1585418685.7590542, "_step": 67}
{"Episode reward": -96.29997750728126, "Episode length": 999, "Policy Loss": -0.12875232100486755, "Value Loss": 0.029079169034957886, "_runtime": 109.98273205757141, "_timestamp": 1585418687.1292381, "_step": 68}
{"Episode reward": -103.74927811667479, "Episode length": 999, "Policy Loss": -0.1464681327342987, "Value Loss": 0.03220987692475319, "_runtime": 111.20729112625122, "_timestamp": 1585418688.3537972, "_step": 69}
{"Episode reward": -110.56743769322487, "Episode length": 999, "Policy Loss": -0.1560390740633011, "Value Loss": 0.033191245049238205, "_runtime": 112.45927596092224, "_timestamp": 1585418689.605782, "_step": 70}
{"Episode reward": -98.07016051945193, "Episode length": 999, "Policy Loss": -0.13035911321640015, "Value Loss": 0.028580648824572563, "_runtime": 113.70181798934937, "_timestamp": 1585418690.848324, "_step": 71}
{"Episode reward": -105.39497255947252, "Episode length": 999, "Policy Loss": -0.1403363049030304, "Value Loss": 0.03199484199285507, "_runtime": 114.91160297393799, "_timestamp": 1585418692.058109, "_step": 72}
{"Episode reward": -98.22506418363048, "Episode length": 999, "Policy Loss": -0.12871314585208893, "Value Loss": 0.030046647414565086, "_runtime": 116.1024968624115, "_timestamp": 1585418693.249003, "_step": 73}
{"Episode reward": -102.85743129858922, "Episode length": 999, "Policy Loss": -0.14768393337726593, "Value Loss": 0.03319370746612549, "_runtime": 117.33706784248352, "_timestamp": 1585418694.483574, "_step": 74}
{"Episode reward": -105.90040461656766, "Episode length": 999, "Policy Loss": -0.14770810306072235, "Value Loss": 0.03243730217218399, "_runtime": 118.50034189224243, "_timestamp": 1585418695.646848, "_step": 75}
{"Episode reward": -104.85418593077607, "Episode length": 999, "Policy Loss": -0.14661891758441925, "Value Loss": 0.03461864963173866, "_runtime": 119.74464392662048, "_timestamp": 1585418696.89115, "_step": 76}
{"Episode reward": -104.27672780908313, "Episode length": 999, "Policy Loss": -0.1416780948638916, "Value Loss": 0.03099876269698143, "_runtime": 120.61760783195496, "_timestamp": 1585418697.764114, "_step": 77}
{"Episode reward": 32.06750262553935, "Episode length": 711, "Policy Loss": 0.17600886523723602, "Value Loss": 14.072361946105957, "_runtime": 121.98306894302368, "_timestamp": 1585418699.129575, "_step": 78}
{"Episode reward": -102.63462772455993, "Episode length": 999, "Policy Loss": -0.14144520461559296, "Value Loss": 0.035481225699186325, "_runtime": 123.26538681983948, "_timestamp": 1585418700.411893, "_step": 79}
{"Episode reward": -107.88490635029075, "Episode length": 999, "Policy Loss": -0.15064124763011932, "Value Loss": 0.03274565562605858, "_runtime": 125.1498749256134, "_timestamp": 1585418702.296381, "_step": 80}
{"Episode reward": -103.70080011201563, "Episode length": 999, "Policy Loss": -0.13882550597190857, "Value Loss": 0.0349438339471817, "_runtime": 126.76970481872559, "_timestamp": 1585418703.916211, "_step": 81}
{"Episode reward": -100.35367821596917, "Episode length": 999, "Policy Loss": -0.13452012836933136, "Value Loss": 0.031085001304745674, "_runtime": 128.50634598731995, "_timestamp": 1585418705.652852, "_step": 82}
{"Episode reward": -99.12034655838109, "Episode length": 999, "Policy Loss": -0.13233661651611328, "Value Loss": 0.02902960032224655, "_runtime": 129.9429759979248, "_timestamp": 1585418707.089482, "_step": 83}
{"Episode reward": -99.26302349005161, "Episode length": 999, "Policy Loss": -0.12959066033363342, "Value Loss": 0.028520667925477028, "_runtime": 131.1720449924469, "_timestamp": 1585418708.318551, "_step": 84}
{"Episode reward": -100.2185830726117, "Episode length": 999, "Policy Loss": -0.1381876915693283, "Value Loss": 0.029075929895043373, "_runtime": 132.3801839351654, "_timestamp": 1585418709.52669, "_step": 85}
{"Episode reward": -103.29152745017124, "Episode length": 999, "Policy Loss": -0.14883540570735931, "Value Loss": 0.031230613589286804, "_runtime": 133.66582489013672, "_timestamp": 1585418710.812331, "_step": 86}
{"Episode reward": -107.66939739451061, "Episode length": 999, "Policy Loss": -0.15206070244312286, "Value Loss": 0.03762741759419441, "_runtime": 134.93305110931396, "_timestamp": 1585418712.0795572, "_step": 87}
{"Episode reward": -106.42075853789088, "Episode length": 999, "Policy Loss": -0.14952333271503448, "Value Loss": 0.03380807489156723, "_runtime": 136.11658382415771, "_timestamp": 1585418713.26309, "_step": 88}
{"Episode reward": -103.54497362545592, "Episode length": 999, "Policy Loss": -0.13900622725486755, "Value Loss": 0.033075783401727676, "_runtime": 137.31583189964294, "_timestamp": 1585418714.462338, "_step": 89}
{"Episode reward": -105.9574586593323, "Episode length": 999, "Policy Loss": -0.141399085521698, "Value Loss": 0.03384442627429962, "_runtime": 138.54327487945557, "_timestamp": 1585418715.689781, "_step": 90}
{"Episode reward": -98.95209734930704, "Episode length": 999, "Policy Loss": -0.12961030006408691, "Value Loss": 0.032197095453739166, "_runtime": 139.93892097473145, "_timestamp": 1585418717.085427, "_step": 91}
{"Episode reward": -112.61817840049216, "Episode length": 999, "Policy Loss": -0.16236191987991333, "Value Loss": 0.03382490575313568, "_runtime": 141.29213309288025, "_timestamp": 1585418718.4386392, "_step": 92}
{"Episode reward": -94.89288902324807, "Episode length": 999, "Policy Loss": -0.1313275545835495, "Value Loss": 0.030615482479333878, "_runtime": 142.53891801834106, "_timestamp": 1585418719.685424, "_step": 93}
{"Episode reward": -110.71005396129424, "Episode length": 999, "Policy Loss": -0.15865063667297363, "Value Loss": 0.03513086587190628, "_runtime": 143.75321793556213, "_timestamp": 1585418720.899724, "_step": 94}
{"Episode reward": -109.12410773513066, "Episode length": 999, "Policy Loss": -0.1581178456544876, "Value Loss": 0.033593304455280304, "_runtime": 145.11476588249207, "_timestamp": 1585418722.261272, "_step": 95}
{"Episode reward": -91.95261936069979, "Episode length": 999, "Policy Loss": -0.12211482971906662, "Value Loss": 0.02562066726386547, "_runtime": 146.36028695106506, "_timestamp": 1585418723.506793, "_step": 96}
{"Episode reward": -100.03223454043332, "Episode length": 999, "Policy Loss": -0.13862638175487518, "Value Loss": 0.027945125475525856, "_runtime": 147.55528497695923, "_timestamp": 1585418724.701791, "_step": 97}
{"Episode reward": -105.14488969269917, "Episode length": 999, "Policy Loss": -0.139690563082695, "Value Loss": 0.03397597372531891, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416, 9.03572940826416]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.16032600402832, -4.94413423538208, -4.727941989898682, -4.511750221252441, -4.295558452606201, -4.079366207122803, -3.8631744384765625, -3.646982431411743, -3.430790424346924, -3.2145986557006836, -2.9984066486358643, -2.782214641571045, -2.5660228729248047, -2.3498308658599854, -2.133638858795166, -1.9174470901489258, -1.7012550830841064, -1.485063076019287, -1.2688713073730469, -1.0526790618896484, -0.8364872932434082, -0.620295524597168, -0.40410327911376953, -0.1879115104675293, 0.028280258178710938, 0.24447250366210938, 0.4606642723083496, 0.6768560409545898, 0.8930482864379883, 1.1092400550842285, 1.3254318237304688, 1.5416240692138672, 1.7578158378601074, 1.9740076065063477, 2.190199851989746, 2.4063916206359863, 2.6225833892822266, 2.838775634765625, 3.0549678802490234, 3.2711591720581055, 3.487351417541504, 3.7035436630249023, 3.9197349548339844, 4.135927200317383, 4.352119445800781, 4.568310737609863, 4.784502983093262, 5.00069522857666, 5.216886520385742, 5.433078765869141, 5.649271011352539, 5.865462303161621, 6.0816545486450195, 6.297846794128418, 6.5140380859375, 6.730230331420898, 6.946422576904297, 7.162613868713379, 7.378806114196777, 7.594998359680176, 7.811189651489258, 8.027381896972656, 8.243574142456055, 8.459765434265137, 8.675957679748535]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.824377059936523, -4.682012557983398, -4.539648056030273, -4.397283554077148, -4.254919052124023, -4.112555027008057, -3.9701905250549316, -3.8278260231018066, -3.6854615211486816, -3.5430970191955566, -3.4007325172424316, -3.2583682537078857, -3.1160037517547607, -2.9736392498016357, -2.83127498626709, -2.688910484313965, -2.54654598236084, -2.404181480407715, -2.26181697845459, -2.119452714920044, -1.977088212966919, -1.834723711013794, -1.692359447479248, -1.549994945526123, -1.407630443572998, -1.265265941619873, -1.122901439666748, -0.9805371761322021, -0.8381726741790771, -0.6958084106445312, -0.5534439086914062, -0.41107940673828125, -0.26871490478515625, -0.12635040283203125, 0.01601409912109375, 0.15837860107421875, 0.30074310302734375, 0.44310712814331055, 0.5854716300964355, 0.7278361320495605, 0.8702006340026855, 1.0125651359558105, 1.1549296379089355, 1.2972941398620605, 1.4396581649780273, 1.5820226669311523, 1.7243871688842773, 1.8667516708374023, 2.0091161727905273, 2.1514806747436523, 2.2938451766967773, 2.4362096786499023, 2.5785741806030273, 2.720938205718994, 2.863302707672119, 3.005667209625244, 3.148031711578369, 3.290395736694336, 3.432760238647461, 3.575124740600586, 3.717489242553711, 3.859853744506836, 4.002218246459961, 4.144582748413086, 4.286947250366211]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 5.0, 7.0, 6.0, 6.0, 7.0, 5.0, 11.0, 9.0, 14.0, 10.0, 10.0, 11.0, 19.0, 16.0, 24.0, 53.0, 44.0, 39.0, 35.0, 17.0, 25.0, 32.0, 16.0, 8.0, 19.0, 8.0, 4.0, 5.0, 2.0, 5.0, 1.0, 7.0, 4.0, 6.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0], "bins": [-3.981339693069458, -3.8638527393341064, -3.746365785598755, -3.6288788318634033, -3.5113918781280518, -3.3939049243927, -3.2764182090759277, -3.158931255340576, -3.0414443016052246, -2.923957347869873, -2.8064703941345215, -2.68898344039917, -2.5714964866638184, -2.454009532928467, -2.3365225791931152, -2.2190356254577637, -2.101548671722412, -1.9840617179870605, -1.866574764251709, -1.7490878105163574, -1.6316008567810059, -1.5141139030456543, -1.3966269493103027, -1.2791399955749512, -1.1616532802581787, -1.0441663265228271, -0.9266793727874756, -0.809192419052124, -0.6917054653167725, -0.5742185115814209, -0.45673155784606934, -0.3392446041107178, -0.2217576503753662, -0.10427069664001465, 0.013216257095336914, 0.13070321083068848, 0.24819016456604004, 0.3656771183013916, 0.48316407203674316, 0.6006510257720947, 0.7181379795074463, 0.8356249332427979, 0.9531118869781494, 1.070598840713501, 1.1880857944488525, 1.305572748184204, 1.4230597019195557, 1.5405466556549072, 1.6580331325531006, 1.7755200862884521, 1.8930070400238037, 2.0104939937591553, 2.127980947494507, 2.2454679012298584, 2.36295485496521, 2.4804418087005615, 2.597928762435913, 2.7154157161712646, 2.832902669906616, 2.9503896236419678, 3.0678765773773193, 3.185363531112671, 3.3028504848480225, 3.420337438583374, 3.5378243923187256]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-2.1967780590057373, -2.1073720455169678, -2.0179660320281982, -1.9285600185394287, -1.8391540050506592, -1.7497479915618896, -1.6603419780731201, -1.5709359645843506, -1.481529951095581, -1.3921239376068115, -1.302717924118042, -1.2133119106292725, -1.123905897140503, -1.0344998836517334, -0.9450938701629639, -0.8556878566741943, -0.7662818431854248, -0.6768758296966553, -0.5874698162078857, -0.4980638027191162, -0.4086577892303467, -0.31925177574157715, -0.22984576225280762, -0.14043974876403809, -0.051033735275268555, 0.03837227821350098, 0.1277782917022705, 0.21718430519104004, 0.30659031867980957, 0.3959963321685791, 0.48540234565734863, 0.5748083591461182, 0.6642143726348877, 0.7536203861236572, 0.8430263996124268, 0.9324324131011963, 1.0218384265899658, 1.1112444400787354, 1.2006504535675049, 1.2900564670562744, 1.379462480545044, 1.4688684940338135, 1.558274507522583, 1.6476805210113525, 1.737086534500122, 1.8264925479888916, 1.9158985614776611, 2.0053045749664307, 2.0947105884552, 2.1841166019439697, 2.2735226154327393, 2.362928628921509, 2.4523346424102783, 2.541740655899048, 2.6311466693878174, 2.720552682876587, 2.8099586963653564, 2.899364709854126, 2.9887707233428955, 3.078176736831665, 3.1675827503204346, 3.256988763809204, 3.3463947772979736, 3.435800790786743, 3.5252068042755127]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1.7404555082321167, -1.6964001655578613, -1.6523447036743164, -1.608289361000061, -1.5642340183258057, -1.5201785564422607, -1.4761232137680054, -1.43206787109375, -1.388012409210205, -1.3439569473266602, -1.2999016046524048, -1.2558462619781494, -1.2117908000946045, -1.1677354574203491, -1.1236801147460938, -1.0796246528625488, -1.0355693101882935, -0.9915139079093933, -0.9474585056304932, -0.9034031629562378, -0.8593477606773376, -0.8152923583984375, -0.7712370157241821, -0.7271815538406372, -0.6831262111663818, -0.6390708684921265, -0.5950154066085815, -0.5509600639343262, -0.5069047212600708, -0.4628492593765259, -0.4187939167022705, -0.3747384548187256, -0.3306831121444702, -0.28662776947021484, -0.24257230758666992, -0.19851696491241455, -0.15446150302886963, -0.11040616035461426, -0.06635081768035889, -0.022295355796813965, 0.021759986877441406, 0.06581532955169678, 0.1098707914352417, 0.15392613410949707, 0.19798147678375244, 0.24203693866729736, 0.2860924005508423, 0.3301476240158081, 0.374203085899353, 0.41825854778289795, 0.46231377124786377, 0.5063692331314087, 0.5504246950149536, 0.5944799184799194, 0.6385353803634644, 0.6825908422470093, 0.7266460657119751, 0.77070152759552, 0.8147569894790649, 0.8588124513626099, 0.9028676748275757, 0.9469231367111206, 0.9909785985946655, 1.0350338220596313, 1.0790892839431763]}, "_runtime": 148.72287893295288, "_timestamp": 1585418725.869385, "_step": 98}
{"Episode reward": -98.2807073969239, "Episode length": 999, "Policy Loss": -0.13563868403434753, "Value Loss": 0.02856694906949997, "_runtime": 149.98242092132568, "_timestamp": 1585418727.128927, "_step": 99}
{"Episode reward": -101.85026548140111, "Episode length": 999, "Policy Loss": -0.13963064551353455, "Value Loss": 0.030364159494638443, "_runtime": 151.23741006851196, "_timestamp": 1585418728.3839161, "_step": 100}
{"Episode reward": -106.86341654438104, "Episode length": 999, "Policy Loss": -0.14937619864940643, "Value Loss": 0.03576674312353134, "_runtime": 152.4823317527771, "_timestamp": 1585418729.6288378, "_step": 101}
{"Episode reward": -96.59757637411309, "Episode length": 999, "Policy Loss": -0.12853875756263733, "Value Loss": 0.030028676614165306, "_runtime": 153.74108386039734, "_timestamp": 1585418730.88759, "_step": 102}
{"Episode reward": -96.10690003246613, "Episode length": 999, "Policy Loss": -0.12721700966358185, "Value Loss": 0.02726377174258232, "_runtime": 154.99529385566711, "_timestamp": 1585418732.1418, "_step": 103}
{"Episode reward": -106.11543864396594, "Episode length": 999, "Policy Loss": -0.14868007600307465, "Value Loss": 0.03223757445812225, "_runtime": 157.44075393676758, "_timestamp": 1585418734.58726, "_step": 104}
{"Episode reward": -111.64959712636254, "Episode length": 999, "Policy Loss": -0.16538894176483154, "Value Loss": 0.03557920828461647, "_runtime": 159.62613797187805, "_timestamp": 1585418736.772644, "_step": 105}
{"Episode reward": -100.61275889689456, "Episode length": 999, "Policy Loss": -0.14502717554569244, "Value Loss": 0.030296344310045242, "_runtime": 162.64572596549988, "_timestamp": 1585418739.792232, "_step": 106}
{"Episode reward": -110.07363996621976, "Episode length": 999, "Policy Loss": -0.1464037001132965, "Value Loss": 0.036061886698007584, "_runtime": 164.66648697853088, "_timestamp": 1585418741.812993, "_step": 107}
{"Episode reward": -110.30423330669568, "Episode length": 999, "Policy Loss": -0.1631990373134613, "Value Loss": 0.03220348432660103, "_runtime": 166.01755475997925, "_timestamp": 1585418743.1640608, "_step": 108}
{"Episode reward": -107.30044602209529, "Episode length": 999, "Policy Loss": -0.14542566239833832, "Value Loss": 0.03734822943806648, "_runtime": 167.54078102111816, "_timestamp": 1585418744.687287, "_step": 109}
{"Episode reward": -102.49772511356124, "Episode length": 999, "Policy Loss": -0.13956786692142487, "Value Loss": 0.030906617641448975, "_runtime": 169.32646584510803, "_timestamp": 1585418746.472972, "_step": 110}
{"Episode reward": -106.31917890823333, "Episode length": 999, "Policy Loss": -0.15260004997253418, "Value Loss": 0.032961342483758926, "_runtime": 171.10608983039856, "_timestamp": 1585418748.252596, "_step": 111}
{"Episode reward": -98.15295727160473, "Episode length": 999, "Policy Loss": -0.1328093558549881, "Value Loss": 0.02821059711277485, "_runtime": 172.41215205192566, "_timestamp": 1585418749.5586581, "_step": 112}
{"Episode reward": -109.6657139648519, "Episode length": 999, "Policy Loss": -0.1639023721218109, "Value Loss": 0.037234652787446976, "_runtime": 173.71630692481995, "_timestamp": 1585418750.862813, "_step": 113}
{"Episode reward": -110.76990657151815, "Episode length": 999, "Policy Loss": -0.16042150557041168, "Value Loss": 0.03910334035754204, "_runtime": 174.94552278518677, "_timestamp": 1585418752.0920289, "_step": 114}
{"Episode reward": -103.96372622049265, "Episode length": 999, "Policy Loss": -0.13635338842868805, "Value Loss": 0.03397892415523529, "_runtime": 176.16991877555847, "_timestamp": 1585418753.3164248, "_step": 115}
{"Episode reward": -104.95310381066203, "Episode length": 999, "Policy Loss": -0.14148512482643127, "Value Loss": 0.03097834251821041, "_runtime": 177.38314008712769, "_timestamp": 1585418754.5296462, "_step": 116}
{"Episode reward": -102.2986664710473, "Episode length": 999, "Policy Loss": -0.1418493241071701, "Value Loss": 0.030610976740717888, "_runtime": 178.6452977657318, "_timestamp": 1585418755.7918038, "_step": 117}
{"Episode reward": -104.69655621378104, "Episode length": 999, "Policy Loss": -0.13875165581703186, "Value Loss": 0.032613348215818405, "_runtime": 179.97242093086243, "_timestamp": 1585418757.118927, "_step": 118}
{"Episode reward": -113.97377549251021, "Episode length": 999, "Policy Loss": -0.15809473395347595, "Value Loss": 0.03934408351778984, "_runtime": 181.1882448196411, "_timestamp": 1585418758.334751, "_step": 119}
{"Episode reward": -109.75568815209444, "Episode length": 999, "Policy Loss": -0.14011238515377045, "Value Loss": 0.03907995671033859, "_runtime": 182.43057894706726, "_timestamp": 1585418759.577085, "_step": 120}
{"Episode reward": -106.10831176069381, "Episode length": 999, "Policy Loss": -0.15465839207172394, "Value Loss": 0.03308107703924179, "_runtime": 183.75089502334595, "_timestamp": 1585418760.897401, "_step": 121}
{"Episode reward": -107.57316372114825, "Episode length": 999, "Policy Loss": -0.13696496188640594, "Value Loss": 0.03767682984471321, "_runtime": 184.96335196495056, "_timestamp": 1585418762.109858, "_step": 122}
{"Episode reward": -110.9144481871668, "Episode length": 999, "Policy Loss": -0.15269552171230316, "Value Loss": 0.03585842251777649, "_runtime": 186.17685198783875, "_timestamp": 1585418763.323358, "_step": 123}
{"Episode reward": -111.19831626405856, "Episode length": 999, "Policy Loss": -0.15157003700733185, "Value Loss": 0.03577565774321556, "_runtime": 187.3497178554535, "_timestamp": 1585418764.496224, "_step": 124}
{"Episode reward": -107.60038183109371, "Episode length": 999, "Policy Loss": -0.1484977751970291, "Value Loss": 0.0350458063185215, "_runtime": 188.51730298995972, "_timestamp": 1585418765.663809, "_step": 125}
{"Episode reward": -113.78770619444572, "Episode length": 999, "Policy Loss": -0.16274985671043396, "Value Loss": 0.038291700184345245, "_runtime": 190.0487449169159, "_timestamp": 1585418767.195251, "_step": 126}
{"Episode reward": -104.08674199777668, "Episode length": 999, "Policy Loss": -0.1430646777153015, "Value Loss": 0.03173929825425148, "_runtime": 191.34243893623352, "_timestamp": 1585418768.488945, "_step": 127}
{"Episode reward": -114.72225089376911, "Episode length": 999, "Policy Loss": -0.16299515962600708, "Value Loss": 0.03679964691400528, "_runtime": 193.05675387382507, "_timestamp": 1585418770.20326, "_step": 128}
{"Episode reward": -122.80537379218718, "Episode length": 999, "Policy Loss": -0.1761522889137268, "Value Loss": 0.0468762181699276, "_runtime": 194.5664188861847, "_timestamp": 1585418771.712925, "_step": 129}
{"Episode reward": -118.98193718094369, "Episode length": 999, "Policy Loss": -0.16819725930690765, "Value Loss": 0.04360007122159004, "_runtime": 196.00032997131348, "_timestamp": 1585418773.146836, "_step": 130}
{"Episode reward": -105.90614863745917, "Episode length": 999, "Policy Loss": -0.14172442257404327, "Value Loss": 0.03559614717960358, "_runtime": 197.52779006958008, "_timestamp": 1585418774.6742961, "_step": 131}
{"Episode reward": -118.1380629382999, "Episode length": 999, "Policy Loss": -0.16612809896469116, "Value Loss": 0.0423344261944294, "_runtime": 199.07213473320007, "_timestamp": 1585418776.2186408, "_step": 132}
{"Episode reward": -115.40020579226162, "Episode length": 999, "Policy Loss": -0.15903636813163757, "Value Loss": 0.04139215499162674, "_runtime": 201.56851077079773, "_timestamp": 1585418778.7150168, "_step": 133}
{"Episode reward": -111.82994621049994, "Episode length": 999, "Policy Loss": -0.14551082253456116, "Value Loss": 0.03950732573866844, "_runtime": 203.70226883888245, "_timestamp": 1585418780.848775, "_step": 134}
{"Episode reward": -110.7346270775614, "Episode length": 999, "Policy Loss": -0.14948204159736633, "Value Loss": 0.03707335889339447, "_runtime": 205.6806309223175, "_timestamp": 1585418782.827137, "_step": 135}
{"Episode reward": -119.0034475017585, "Episode length": 999, "Policy Loss": -0.16727495193481445, "Value Loss": 0.04008578509092331, "_runtime": 207.21584391593933, "_timestamp": 1585418784.36235, "_step": 136}
{"Episode reward": -119.57558105721311, "Episode length": 999, "Policy Loss": -0.17348849773406982, "Value Loss": 0.04018232598900795, "_runtime": 208.6934938430786, "_timestamp": 1585418785.84, "_step": 137}
{"Episode reward": -121.0929547996262, "Episode length": 999, "Policy Loss": -0.17616429924964905, "Value Loss": 0.0426800474524498, "_runtime": 210.40393495559692, "_timestamp": 1585418787.550441, "_step": 138}
{"Episode reward": -111.32571857735465, "Episode length": 999, "Policy Loss": -0.15329770743846893, "Value Loss": 0.03616289421916008, "_runtime": 211.9663758277893, "_timestamp": 1585418789.112882, "_step": 139}
{"Episode reward": -112.04430639865272, "Episode length": 999, "Policy Loss": -0.1497332751750946, "Value Loss": 0.03747574985027313, "_runtime": 213.89900088310242, "_timestamp": 1585418791.045507, "_step": 140}
{"Episode reward": -110.33505220891428, "Episode length": 999, "Policy Loss": -0.16232354938983917, "Value Loss": 0.035391665995121, "_runtime": 215.41011714935303, "_timestamp": 1585418792.5566232, "_step": 141}
{"Episode reward": -116.88128115416252, "Episode length": 999, "Policy Loss": -0.16225828230381012, "Value Loss": 0.039546869695186615, "_runtime": 216.7560420036316, "_timestamp": 1585418793.902548, "_step": 142}
{"Episode reward": -113.4102490932992, "Episode length": 999, "Policy Loss": -0.15821444988250732, "Value Loss": 0.03668275102972984, "_runtime": 218.17275094985962, "_timestamp": 1585418795.319257, "_step": 143}
{"Episode reward": -118.22393608735683, "Episode length": 999, "Policy Loss": -0.16023516654968262, "Value Loss": 0.041255105286836624, "_runtime": 219.38682579994202, "_timestamp": 1585418796.5333319, "_step": 144}
{"Episode reward": -107.18495593376134, "Episode length": 999, "Policy Loss": -0.1472138613462448, "Value Loss": 0.03397379443049431, "_runtime": 220.79526281356812, "_timestamp": 1585418797.941769, "_step": 145}
{"Episode reward": -110.75603364243554, "Episode length": 999, "Policy Loss": -0.1505732387304306, "Value Loss": 0.03948819637298584, "_runtime": 222.14366102218628, "_timestamp": 1585418799.290167, "_step": 146}
{"Episode reward": -120.72413738286977, "Episode length": 999, "Policy Loss": -0.16570264101028442, "Value Loss": 0.04494753107428551, "_runtime": 223.771164894104, "_timestamp": 1585418800.917671, "_step": 147}
{"Episode reward": -109.90136252046364, "Episode length": 999, "Policy Loss": -0.14537633955478668, "Value Loss": 0.03328491747379303, "_runtime": 225.1074299812317, "_timestamp": 1585418802.253936, "_step": 148}
{"Episode reward": -122.18120428012215, "Episode length": 999, "Policy Loss": -0.16824983060359955, "Value Loss": 0.04249069467186928, "_runtime": 226.4482159614563, "_timestamp": 1585418803.594722, "_step": 149}
{"Episode reward": -132.8251677116126, "Episode length": 999, "Policy Loss": -0.2003955990076065, "Value Loss": 0.05484773963689804, "_runtime": 227.7191379070282, "_timestamp": 1585418804.865644, "_step": 150}
{"Episode reward": -119.11746181650652, "Episode length": 999, "Policy Loss": -0.17136800289154053, "Value Loss": 0.0401383638381958, "_runtime": 228.94699001312256, "_timestamp": 1585418806.093496, "_step": 151}
{"Episode reward": -117.76035850126637, "Episode length": 999, "Policy Loss": -0.1639297902584076, "Value Loss": 0.040801048278808594, "_runtime": 230.22714185714722, "_timestamp": 1585418807.373648, "_step": 152}
{"Episode reward": -119.64765573146191, "Episode length": 999, "Policy Loss": -0.1590069681406021, "Value Loss": 0.040539246052503586, "_runtime": 231.52408003807068, "_timestamp": 1585418808.670586, "_step": 153}
{"Episode reward": -117.76212045066542, "Episode length": 999, "Policy Loss": -0.16761533915996552, "Value Loss": 0.03834493085741997, "_runtime": 232.87830996513367, "_timestamp": 1585418810.024816, "_step": 154}
{"Episode reward": -119.86328720520888, "Episode length": 999, "Policy Loss": -0.1657060980796814, "Value Loss": 0.04111213982105255, "_runtime": 234.21288394927979, "_timestamp": 1585418811.35939, "_step": 155}
{"Episode reward": -123.81205106507447, "Episode length": 999, "Policy Loss": -0.1787482053041458, "Value Loss": 0.04423737898468971, "_runtime": 235.48021602630615, "_timestamp": 1585418812.626722, "_step": 156}
{"Episode reward": -117.02238694224246, "Episode length": 999, "Policy Loss": -0.1643023043870926, "Value Loss": 0.03932899981737137, "_runtime": 236.8448350429535, "_timestamp": 1585418813.991341, "_step": 157}
{"Episode reward": -109.22224635225375, "Episode length": 999, "Policy Loss": -0.15293776988983154, "Value Loss": 0.03366527333855629, "_runtime": 238.13426780700684, "_timestamp": 1585418815.2807739, "_step": 158}
{"Episode reward": -115.31170464824066, "Episode length": 999, "Policy Loss": -0.16151553392410278, "Value Loss": 0.03628450259566307, "_runtime": 239.9386088848114, "_timestamp": 1585418817.085115, "_step": 159}
{"Episode reward": -112.94518492409723, "Episode length": 999, "Policy Loss": -0.1535588651895523, "Value Loss": 0.03677795082330704, "_runtime": 241.37104392051697, "_timestamp": 1585418818.51755, "_step": 160}
{"Episode reward": -112.78219266414297, "Episode length": 999, "Policy Loss": -0.15650682151317596, "Value Loss": 0.0339251346886158, "_runtime": 242.78882503509521, "_timestamp": 1585418819.935331, "_step": 161}
{"Episode reward": -97.52500050938484, "Episode length": 999, "Policy Loss": -0.12476576864719391, "Value Loss": 0.029828926548361778, "_runtime": 244.0387670993805, "_timestamp": 1585418821.1852732, "_step": 162}
{"Episode reward": -112.50325642939653, "Episode length": 999, "Policy Loss": -0.1616974025964737, "Value Loss": 0.03931546211242676, "_runtime": 245.41542196273804, "_timestamp": 1585418822.561928, "_step": 163}
{"Episode reward": -115.69064903146968, "Episode length": 999, "Policy Loss": -0.16210761666297913, "Value Loss": 0.03940843045711517, "_runtime": 246.77351188659668, "_timestamp": 1585418823.920018, "_step": 164}
{"Episode reward": -110.40697635542199, "Episode length": 999, "Policy Loss": -0.15861183404922485, "Value Loss": 0.037382349371910095, "_runtime": 248.02687001228333, "_timestamp": 1585418825.173376, "_step": 165}
{"Episode reward": -113.20922446602255, "Episode length": 999, "Policy Loss": -0.14683376252651215, "Value Loss": 0.03574975207448006, "_runtime": 249.3977189064026, "_timestamp": 1585418826.544225, "_step": 166}
{"Episode reward": -120.88054204919453, "Episode length": 999, "Policy Loss": -0.16565774381160736, "Value Loss": 0.04009357467293739, "_runtime": 250.85103583335876, "_timestamp": 1585418827.997542, "_step": 167}
{"Episode reward": -111.852793537271, "Episode length": 999, "Policy Loss": -0.15532605350017548, "Value Loss": 0.03889952600002289, "_runtime": 252.23172283172607, "_timestamp": 1585418829.378229, "_step": 168}
{"Episode reward": -115.76081605412104, "Episode length": 999, "Policy Loss": -0.1649380326271057, "Value Loss": 0.04106288030743599, "_runtime": 253.44834399223328, "_timestamp": 1585418830.59485, "_step": 169}
{"Episode reward": -117.09501828949028, "Episode length": 999, "Policy Loss": -0.1579766422510147, "Value Loss": 0.043914247304201126, "_runtime": 254.8440387248993, "_timestamp": 1585418831.9905448, "_step": 170}
{"Episode reward": -113.54742767419256, "Episode length": 999, "Policy Loss": -0.15625514090061188, "Value Loss": 0.035233814269304276, "_runtime": 256.2379288673401, "_timestamp": 1585418833.384435, "_step": 171}
{"Episode reward": -108.90617841142922, "Episode length": 999, "Policy Loss": -0.14221927523612976, "Value Loss": 0.03673107922077179, "_runtime": 257.7933700084686, "_timestamp": 1585418834.939876, "_step": 172}
{"Episode reward": -108.96219043068744, "Episode length": 999, "Policy Loss": -0.14156176149845123, "Value Loss": 0.0384039580821991, "_runtime": 259.1577169895172, "_timestamp": 1585418836.304223, "_step": 173}
{"Episode reward": -115.09351256988482, "Episode length": 999, "Policy Loss": -0.1569875329732895, "Value Loss": 0.043509215116500854, "_runtime": 260.665727853775, "_timestamp": 1585418837.812234, "_step": 174}
{"Episode reward": -121.90609075912313, "Episode length": 999, "Policy Loss": -0.16699321568012238, "Value Loss": 0.042814623564481735, "_runtime": 261.9716808795929, "_timestamp": 1585418839.118187, "_step": 175}
{"Episode reward": -118.35314869870712, "Episode length": 999, "Policy Loss": -0.15886814892292023, "Value Loss": 0.04379868134856224, "_runtime": 263.55421471595764, "_timestamp": 1585418840.7007208, "_step": 176}
{"Episode reward": -110.59779348234278, "Episode length": 999, "Policy Loss": -0.15368755161762238, "Value Loss": 0.035872023552656174, "_runtime": 265.0112178325653, "_timestamp": 1585418842.157724, "_step": 177}
{"Episode reward": -109.69901687852152, "Episode length": 999, "Policy Loss": -0.1465354561805725, "Value Loss": 0.03566513583064079, "_runtime": 266.3823878765106, "_timestamp": 1585418843.528894, "_step": 178}
{"Episode reward": -103.79178467238705, "Episode length": 999, "Policy Loss": -0.1413220316171646, "Value Loss": 0.03398310765624046, "_runtime": 267.7589747905731, "_timestamp": 1585418844.9054809, "_step": 179}
{"Episode reward": -114.38671737342058, "Episode length": 999, "Policy Loss": -0.16145068407058716, "Value Loss": 0.0404665470123291, "_runtime": 268.9978449344635, "_timestamp": 1585418846.144351, "_step": 180}
{"Episode reward": -111.56024385315737, "Episode length": 999, "Policy Loss": -0.15090352296829224, "Value Loss": 0.036895863711833954, "_runtime": 270.4739429950714, "_timestamp": 1585418847.620449, "_step": 181}
{"Episode reward": -115.05091200650033, "Episode length": 999, "Policy Loss": -0.15156884491443634, "Value Loss": 0.03834284842014313, "_runtime": 272.00876688957214, "_timestamp": 1585418849.155273, "_step": 182}
{"Episode reward": -115.43934582793949, "Episode length": 999, "Policy Loss": -0.16320529580116272, "Value Loss": 0.0399957112967968, "_runtime": 273.51883697509766, "_timestamp": 1585418850.665343, "_step": 183}
{"Episode reward": -108.04667515014471, "Episode length": 999, "Policy Loss": -0.1517341434955597, "Value Loss": 0.037213899195194244, "_runtime": 274.9681258201599, "_timestamp": 1585418852.114632, "_step": 184}
{"Episode reward": -120.73437751941168, "Episode length": 999, "Policy Loss": -0.16385430097579956, "Value Loss": 0.04613999277353287, "_runtime": 276.3345708847046, "_timestamp": 1585418853.481077, "_step": 185}
{"Episode reward": -119.90618640655913, "Episode length": 999, "Policy Loss": -0.17028486728668213, "Value Loss": 0.04121055826544762, "_runtime": 277.694904088974, "_timestamp": 1585418854.8414102, "_step": 186}
{"Episode reward": -109.83960447864371, "Episode length": 999, "Policy Loss": -0.1588326394557953, "Value Loss": 0.03830249607563019, "_runtime": 278.9827010631561, "_timestamp": 1585418856.1292071, "_step": 187}
{"Episode reward": -122.17629107485831, "Episode length": 999, "Policy Loss": -0.16529397666454315, "Value Loss": 0.04239213094115257, "_runtime": 280.31266498565674, "_timestamp": 1585418857.459171, "_step": 188}
{"Episode reward": -126.13450733435286, "Episode length": 999, "Policy Loss": -0.16894178092479706, "Value Loss": 0.05045587942004204, "_runtime": 281.5861909389496, "_timestamp": 1585418858.732697, "_step": 189}
{"Episode reward": -109.23184197609766, "Episode length": 999, "Policy Loss": -0.15404514968395233, "Value Loss": 0.03250508010387421, "_runtime": 282.94435596466064, "_timestamp": 1585418860.090862, "_step": 190}
{"Episode reward": -122.26885339239226, "Episode length": 999, "Policy Loss": -0.16328270733356476, "Value Loss": 0.043526411056518555, "_runtime": 284.4630320072174, "_timestamp": 1585418861.609538, "_step": 191}
{"Episode reward": -111.26751140416462, "Episode length": 999, "Policy Loss": -0.16056980192661285, "Value Loss": 0.037003278732299805, "_runtime": 286.17416071891785, "_timestamp": 1585418863.3206668, "_step": 192}
{"Episode reward": -117.34107270398232, "Episode length": 999, "Policy Loss": -0.16635264456272125, "Value Loss": 0.0408097580075264, "_runtime": 287.5154070854187, "_timestamp": 1585418864.6619132, "_step": 193}
{"Episode reward": -114.58560445616551, "Episode length": 999, "Policy Loss": -0.14845150709152222, "Value Loss": 0.039027631282806396, "_runtime": 288.90726494789124, "_timestamp": 1585418866.053771, "_step": 194}
{"Episode reward": -121.88428863888153, "Episode length": 999, "Policy Loss": -0.1767144352197647, "Value Loss": 0.04344971105456352, "_runtime": 290.23540711402893, "_timestamp": 1585418867.3819132, "_step": 195}
{"Episode reward": -128.78652539214187, "Episode length": 999, "Policy Loss": -0.18536972999572754, "Value Loss": 0.046701397746801376, "_runtime": 291.53208899497986, "_timestamp": 1585418868.678595, "_step": 196}
{"Episode reward": -118.87600721086368, "Episode length": 999, "Policy Loss": -0.16547220945358276, "Value Loss": 0.04368035867810249, "_runtime": 292.9031939506531, "_timestamp": 1585418870.0497, "_step": 197}
{"Episode reward": -121.17666645868334, "Episode length": 999, "Policy Loss": -0.16484017670154572, "Value Loss": 0.045375507324934006, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379, 3.291520118713379]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.9637740850448608, -1.8822691440582275, -1.8007640838623047, -1.7192590236663818, -1.6377540826797485, -1.5562491416931152, -1.4747440814971924, -1.3932390213012695, -1.3117340803146362, -1.230229139328003, -1.14872407913208, -1.0672190189361572, -0.9857140779495239, -0.9042090177536011, -0.8227040767669678, -0.7411991357803345, -0.6596940755844116, -0.5781890153884888, -0.49668407440185547, -0.41517913341522217, -0.3336740732192993, -0.25216901302337646, -0.17066407203674316, -0.08915913105010986, -0.007654070854187012, 0.07385098934173584, 0.1553560495376587, 0.23686087131500244, 0.3183659315109253, 0.39987099170684814, 0.4813758134841919, 0.5628808736801147, 0.6443859338760376, 0.7258909940719604, 0.8073960542678833, 0.888900876045227, 0.9704059362411499, 1.0519109964370728, 1.1334158182144165, 1.2149208784103394, 1.2964259386062622, 1.377930998802185, 1.459436058998108, 1.5409408807754517, 1.6224459409713745, 1.7039510011672974, 1.7854558229446411, 1.866960883140564, 1.9484659433364868, 2.029971122741699, 2.111475944519043, 2.1929807662963867, 2.2744860649108887, 2.3559908866882324, 2.437495708465576, 2.519001007080078, 2.600505828857422, 2.6820106506347656, 2.7635159492492676, 2.8450207710266113, 2.926525592803955, 3.008030891418457, 3.089535713195801, 3.1710410118103027, 3.2525458335876465]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.816563606262207, -1.7640399932861328, -1.7115164995193481, -1.658992886543274, -1.6064692735671997, -1.553945779800415, -1.5014221668243408, -1.4488985538482666, -1.3963749408721924, -1.3438514471054077, -1.2913278341293335, -1.2388043403625488, -1.1862807273864746, -1.1337571144104004, -1.0812335014343262, -1.028709888458252, -0.9761863946914673, -0.9236628413200378, -0.8711392283439636, -0.8186156749725342, -0.76609206199646, -0.7135685682296753, -0.6610449552536011, -0.6085213422775269, -0.5559978485107422, -0.503474235534668, -0.45095062255859375, -0.39842700958251953, -0.34590351581573486, -0.29337990283966064, -0.24085628986358643, -0.18833279609680176, -0.13580918312072754, -0.08328557014465332, -0.030762076377868652, 0.021761536598205566, 0.07428514957427979, 0.12680864334106445, 0.17933225631713867, 0.2318558692932129, 0.2843794822692871, 0.33690309524536133, 0.38942646980285645, 0.44195008277893066, 0.4944736957550049, 0.5469973087310791, 0.5995209217071533, 0.6520445346832275, 0.7045679092407227, 0.7570915222167969, 0.8096151351928711, 0.8621387481689453, 0.9146623611450195, 0.9671859741210938, 1.019709587097168, 1.072232961654663, 1.1247565746307373, 1.1772801876068115, 1.2298038005828857, 1.28232741355896, 1.3348510265350342, 1.3873744010925293, 1.4398980140686035, 1.4924216270446777, 1.544945240020752]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 5.0, 5.0, 9.0, 6.0, 5.0, 4.0, 13.0, 8.0, 11.0, 14.0, 11.0, 6.0, 17.0, 18.0, 12.0, 48.0, 47.0, 13.0, 44.0, 38.0, 18.0, 21.0, 27.0, 15.0, 11.0, 13.0, 11.0, 10.0, 4.0, 5.0, 1.0, 3.0, 4.0, 5.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "bins": [-1.3904445171356201, -1.350236177444458, -1.3100277185440063, -1.2698193788528442, -1.2296109199523926, -1.1894025802612305, -1.1491941213607788, -1.1089857816696167, -1.068777322769165, -1.028568983078003, -0.9883605241775513, -0.9481521844863892, -0.9079437851905823, -0.8677353858947754, -0.8275269865989685, -0.7873185873031616, -0.7471101880073547, -0.7069017887115479, -0.666693389415741, -0.6264849901199341, -0.5862765908241272, -0.5460681915283203, -0.5058597922325134, -0.46565139293670654, -0.42544305324554443, -0.3852345943450928, -0.34502625465393066, -0.304817795753479, -0.2646094560623169, -0.22440099716186523, -0.18419265747070312, -0.14398419857025146, -0.10377585887908936, -0.06356751918792725, -0.023359060287475586, 0.016849279403686523, 0.057057738304138184, 0.09726607799530029, 0.13747453689575195, 0.17768287658691406, 0.21789133548736572, 0.25809967517852783, 0.2983081340789795, 0.3385164737701416, 0.37872493267059326, 0.41893327236175537, 0.45914173126220703, 0.49935007095336914, 0.5395584106445312, 0.5797668695449829, 0.6199753284454346, 0.6601836681365967, 0.7003920078277588, 0.7406003475189209, 0.7808089256286621, 0.8210172653198242, 0.8612256050109863, 0.9014339447021484, 0.9416425228118896, 0.9818508625030518, 1.0220592021942139, 1.062267541885376, 1.1024761199951172, 1.1426844596862793, 1.1828927993774414]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9231448769569397, -0.8882870674133301, -0.8534292578697205, -0.8185714483261108, -0.7837135791778564, -0.7488557696342468, -0.7139979600906372, -0.6791401505470276, -0.644282341003418, -0.6094244718551636, -0.574566662311554, -0.5397088527679443, -0.5048510432243347, -0.4699932038784027, -0.4351353943347931, -0.4002775549888611, -0.36541974544525146, -0.33056193590164185, -0.2957041263580322, -0.26084625720977783, -0.2259884476661682, -0.1911306381225586, -0.15627282857894897, -0.12141501903533936, -0.08655720949172974, -0.05169934034347534, -0.016841530799865723, 0.018016278743743896, 0.052874088287353516, 0.08773189783096313, 0.12258976697921753, 0.15744751691818237, 0.19230538606643677, 0.22716325521469116, 0.262021005153656, 0.2968788743019104, 0.33173662424087524, 0.36659449338912964, 0.40145236253738403, 0.4363101124763489, 0.47116798162460327, 0.5060257315635681, 0.5408836007118225, 0.5757414698600769, 0.6105992197990417, 0.6454570889472961, 0.680314838886261, 0.7151727080345154, 0.7500304579734802, 0.7848883271217346, 0.819746196269989, 0.8546039462089539, 0.8894618153572083, 0.9243195652961731, 0.9591774344444275, 0.9940353035926819, 1.028892993927002, 1.063750982284546, 1.0986087322235107, 1.1334667205810547, 1.1683244705200195, 1.2031822204589844, 1.2380399703979492, 1.2728979587554932, 1.307755708694458]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 32.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.41183650493621826, -0.4005866050720215, -0.3893367350101471, -0.3780868351459503, -0.36683693528175354, -0.35558706521987915, -0.3443371653556824, -0.3330872654914856, -0.3218373656272888, -0.31058749556541443, -0.29933759570121765, -0.28808772563934326, -0.2768378257751465, -0.2655879259109497, -0.25433802604675293, -0.24308814108371735, -0.23183825612068176, -0.22058837115764618, -0.2093384712934494, -0.19808858633041382, -0.18683868646621704, -0.17558880150318146, -0.16433891654014587, -0.1530890166759491, -0.1418391466140747, -0.13058924674987793, -0.11933934688568115, -0.10808944702148438, -0.09683957695960999, -0.08558967709541321, -0.07433977723121643, -0.06308990716934204, -0.051840007305145264, -0.040590107440948486, -0.029340237379074097, -0.01809033751487732, -0.006840437650680542, 0.004409432411193848, 0.015659332275390625, 0.026909232139587402, 0.03815913200378418, 0.04940900206565857, 0.06065890192985535, 0.07190880179405212, 0.08315867185592651, 0.09440857172012329, 0.10565847158432007, 0.11690837144851685, 0.12815821170806885, 0.13940811157226562, 0.1506580114364624, 0.16190791130065918, 0.17315781116485596, 0.18440771102905273, 0.1956576108932495, 0.2069074511528015, 0.2181573510169983, 0.22940725088119507, 0.24065715074539185, 0.2519070506095886, 0.2631569504737854, 0.2744067907333374, 0.2856566905975342, 0.29690659046173096, 0.30815649032592773]}, "_runtime": 294.4246418476105, "_timestamp": 1585418871.571148, "_step": 198}
{"Episode reward": -123.11414097696684, "Episode length": 999, "Policy Loss": -0.17490260303020477, "Value Loss": 0.03863132372498512, "_runtime": 295.8022530078888, "_timestamp": 1585418872.948759, "_step": 199}
{"Episode reward": -115.85335505414068, "Episode length": 999, "Policy Loss": -0.1575232744216919, "Value Loss": 0.03783292695879936, "_runtime": 297.1315817832947, "_timestamp": 1585418874.2780879, "_step": 200}
{"Episode reward": -120.64405469347044, "Episode length": 999, "Policy Loss": -0.1844799667596817, "Value Loss": 0.046107832342386246, "_runtime": 298.4569389820099, "_timestamp": 1585418875.603445, "_step": 201}
{"Episode reward": -112.1021789498083, "Episode length": 999, "Policy Loss": -0.1471218764781952, "Value Loss": 0.038697775453329086, "_runtime": 299.79914593696594, "_timestamp": 1585418876.945652, "_step": 202}
{"Episode reward": -122.38829389415244, "Episode length": 999, "Policy Loss": -0.17633530497550964, "Value Loss": 0.04347851499915123, "_runtime": 301.2112407684326, "_timestamp": 1585418878.3577468, "_step": 203}
{"Episode reward": -124.72255396223382, "Episode length": 999, "Policy Loss": -0.17478825151920319, "Value Loss": 0.04645778611302376, "_runtime": 302.4766869544983, "_timestamp": 1585418879.623193, "_step": 204}
{"Episode reward": -123.07894051939117, "Episode length": 999, "Policy Loss": -0.17382177710533142, "Value Loss": 0.042786162346601486, "_runtime": 303.9081058502197, "_timestamp": 1585418881.054612, "_step": 205}
{"Episode reward": -126.16008371268939, "Episode length": 999, "Policy Loss": -0.18294857442378998, "Value Loss": 0.05172210931777954, "_runtime": 305.3555099964142, "_timestamp": 1585418882.502016, "_step": 206}
{"Episode reward": -120.88583950046552, "Episode length": 999, "Policy Loss": -0.16807584464550018, "Value Loss": 0.03965874761343002, "_runtime": 306.6557638645172, "_timestamp": 1585418883.80227, "_step": 207}
{"Episode reward": -117.24970721455557, "Episode length": 999, "Policy Loss": -0.16232448816299438, "Value Loss": 0.04256311431527138, "_runtime": 307.8767189979553, "_timestamp": 1585418885.023225, "_step": 208}
{"Episode reward": -122.52945862934894, "Episode length": 999, "Policy Loss": -0.16489490866661072, "Value Loss": 0.0421140231192112, "_runtime": 309.104376077652, "_timestamp": 1585418886.2508821, "_step": 209}
{"Episode reward": -116.46911267506874, "Episode length": 999, "Policy Loss": -0.1520950198173523, "Value Loss": 0.036601338535547256, "_runtime": 310.5795159339905, "_timestamp": 1585418887.726022, "_step": 210}
{"Episode reward": -120.8520033530159, "Episode length": 999, "Policy Loss": -0.16625282168388367, "Value Loss": 0.04222676157951355, "_runtime": 311.86080980300903, "_timestamp": 1585418889.0073159, "_step": 211}
{"Episode reward": -123.47251481850631, "Episode length": 999, "Policy Loss": -0.1736753284931183, "Value Loss": 0.04469529166817665, "_runtime": 313.1570107936859, "_timestamp": 1585418890.3035169, "_step": 212}
{"Episode reward": -124.8732785003297, "Episode length": 999, "Policy Loss": -0.17062856256961823, "Value Loss": 0.046146828681230545, "_runtime": 314.59084391593933, "_timestamp": 1585418891.73735, "_step": 213}
{"Episode reward": -127.45940926203583, "Episode length": 999, "Policy Loss": -0.1841147392988205, "Value Loss": 0.046562306582927704, "_runtime": 316.05869793891907, "_timestamp": 1585418893.205204, "_step": 214}
{"Episode reward": -116.85671163057303, "Episode length": 999, "Policy Loss": -0.1680748164653778, "Value Loss": 0.042409900575876236, "_runtime": 317.5220420360565, "_timestamp": 1585418894.668548, "_step": 215}
{"Episode reward": -129.24072296976195, "Episode length": 999, "Policy Loss": -0.19182468950748444, "Value Loss": 0.0482955127954483, "_runtime": 318.8253319263458, "_timestamp": 1585418895.971838, "_step": 216}
{"Episode reward": -123.93216813184337, "Episode length": 999, "Policy Loss": -0.17506331205368042, "Value Loss": 0.04327228292822838, "_runtime": 320.2355818748474, "_timestamp": 1585418897.382088, "_step": 217}
{"Episode reward": -126.88323662001186, "Episode length": 999, "Policy Loss": -0.1754421442747116, "Value Loss": 0.04664013162255287, "_runtime": 321.66402983665466, "_timestamp": 1585418898.810536, "_step": 218}
{"Episode reward": -122.58135137246629, "Episode length": 999, "Policy Loss": -0.17295107245445251, "Value Loss": 0.042291972786188126, "_runtime": 323.0881760120392, "_timestamp": 1585418900.234682, "_step": 219}
{"Episode reward": -126.60675354524636, "Episode length": 999, "Policy Loss": -0.1761007159948349, "Value Loss": 0.04486352205276489, "_runtime": 324.5360679626465, "_timestamp": 1585418901.682574, "_step": 220}
{"Episode reward": -112.69568893451094, "Episode length": 999, "Policy Loss": -0.1624632179737091, "Value Loss": 0.03809533640742302, "_runtime": 325.88797092437744, "_timestamp": 1585418903.034477, "_step": 221}
{"Episode reward": -121.41326179372344, "Episode length": 999, "Policy Loss": -0.1726444810628891, "Value Loss": 0.041969139128923416, "_runtime": 327.1817750930786, "_timestamp": 1585418904.3282812, "_step": 222}
{"Episode reward": -125.33993087254237, "Episode length": 999, "Policy Loss": -0.17413212358951569, "Value Loss": 0.04707396402955055, "_runtime": 328.4604489803314, "_timestamp": 1585418905.606955, "_step": 223}
{"Episode reward": -112.65768449254035, "Episode length": 999, "Policy Loss": -0.1591896414756775, "Value Loss": 0.03620436042547226, "_runtime": 329.8212788105011, "_timestamp": 1585418906.967785, "_step": 224}
{"Episode reward": -116.85177440169402, "Episode length": 999, "Policy Loss": -0.16267359256744385, "Value Loss": 0.03985761106014252, "_runtime": 331.28446793556213, "_timestamp": 1585418908.430974, "_step": 225}
{"Episode reward": -119.85565139244552, "Episode length": 999, "Policy Loss": -0.163247212767601, "Value Loss": 0.03894178569316864, "_runtime": 332.62913608551025, "_timestamp": 1585418909.7756422, "_step": 226}
{"Episode reward": -113.87068409823952, "Episode length": 999, "Policy Loss": -0.16135689616203308, "Value Loss": 0.0372934527695179, "_runtime": 334.0703799724579, "_timestamp": 1585418911.216886, "_step": 227}
{"Episode reward": -110.78364063802255, "Episode length": 999, "Policy Loss": -0.14790748059749603, "Value Loss": 0.035623323172330856, "_runtime": 335.4703538417816, "_timestamp": 1585418912.61686, "_step": 228}
{"Episode reward": -103.85882234717657, "Episode length": 999, "Policy Loss": -0.13601964712142944, "Value Loss": 0.03242230415344238, "_runtime": 336.82589197158813, "_timestamp": 1585418913.972398, "_step": 229}
{"Episode reward": -113.16860355973117, "Episode length": 999, "Policy Loss": -0.15520967543125153, "Value Loss": 0.03663916140794754, "_runtime": 338.0954339504242, "_timestamp": 1585418915.24194, "_step": 230}
{"Episode reward": -116.973186249402, "Episode length": 999, "Policy Loss": -0.16264082491397858, "Value Loss": 0.04288683831691742, "_runtime": 339.27159905433655, "_timestamp": 1585418916.4181051, "_step": 231}
{"Episode reward": -106.0029615411539, "Episode length": 999, "Policy Loss": -0.14687050879001617, "Value Loss": 0.03596983477473259, "_runtime": 340.69495391845703, "_timestamp": 1585418917.84146, "_step": 232}
{"Episode reward": -111.44527996917832, "Episode length": 999, "Policy Loss": -0.14854469895362854, "Value Loss": 0.039648618549108505, "_runtime": 342.0223317146301, "_timestamp": 1585418919.1688378, "_step": 233}
{"Episode reward": -112.47332866653329, "Episode length": 999, "Policy Loss": -0.15642543137073517, "Value Loss": 0.03297371417284012, "_runtime": 343.19172978401184, "_timestamp": 1585418920.3382359, "_step": 234}
{"Episode reward": -116.46534508865432, "Episode length": 999, "Policy Loss": -0.17726804316043854, "Value Loss": 0.039149973541498184, "_runtime": 344.38021183013916, "_timestamp": 1585418921.526718, "_step": 235}
{"Episode reward": -115.42069587821241, "Episode length": 999, "Policy Loss": -0.15695004165172577, "Value Loss": 0.03808050975203514, "_runtime": 345.63971996307373, "_timestamp": 1585418922.786226, "_step": 236}
{"Episode reward": -113.37134156961778, "Episode length": 999, "Policy Loss": -0.16648706793785095, "Value Loss": 0.03711758926510811, "_runtime": 347.6594338417053, "_timestamp": 1585418924.80594, "_step": 237}
{"Episode reward": -111.53269314396707, "Episode length": 999, "Policy Loss": -0.1528509557247162, "Value Loss": 0.03876541182398796, "_runtime": 349.80817198753357, "_timestamp": 1585418926.954678, "_step": 238}
{"Episode reward": -111.0639036885846, "Episode length": 999, "Policy Loss": -0.15409569442272186, "Value Loss": 0.033419422805309296, "_runtime": 351.3581130504608, "_timestamp": 1585418928.5046191, "_step": 239}
{"Episode reward": -117.64315008479059, "Episode length": 999, "Policy Loss": -0.16691958904266357, "Value Loss": 0.039029017090797424, "_runtime": 352.95618081092834, "_timestamp": 1585418930.102687, "_step": 240}
{"Episode reward": -110.75364457724105, "Episode length": 999, "Policy Loss": -0.14485907554626465, "Value Loss": 0.036673933267593384, "_runtime": 354.2829689979553, "_timestamp": 1585418931.429475, "_step": 241}
{"Episode reward": -113.55991322249884, "Episode length": 999, "Policy Loss": -0.155704066157341, "Value Loss": 0.03677595406770706, "_runtime": 355.495001077652, "_timestamp": 1585418932.6415071, "_step": 242}
{"Episode reward": -110.59846929439725, "Episode length": 999, "Policy Loss": -0.14939478039741516, "Value Loss": 0.0388215146958828, "_runtime": 356.6724007129669, "_timestamp": 1585418933.8189068, "_step": 243}
{"Episode reward": -123.38603854011384, "Episode length": 999, "Policy Loss": -0.1818229854106903, "Value Loss": 0.04702546074986458, "_runtime": 357.8444867134094, "_timestamp": 1585418934.9909928, "_step": 244}
{"Episode reward": -118.65465153774696, "Episode length": 999, "Policy Loss": -0.15979965031147003, "Value Loss": 0.04054078832268715, "_runtime": 359.0226979255676, "_timestamp": 1585418936.169204, "_step": 245}
{"Episode reward": -118.61513456219441, "Episode length": 999, "Policy Loss": -0.17234185338020325, "Value Loss": 0.04233354702591896, "_runtime": 360.30701994895935, "_timestamp": 1585418937.453526, "_step": 246}
{"Episode reward": -104.69702184204, "Episode length": 999, "Policy Loss": -0.14277999103069305, "Value Loss": 0.03650863096117973, "_runtime": 361.5184590816498, "_timestamp": 1585418938.6649652, "_step": 247}
{"Episode reward": -102.04444329758826, "Episode length": 999, "Policy Loss": -0.13270796835422516, "Value Loss": 0.03340772166848183, "_runtime": 362.7049238681793, "_timestamp": 1585418939.85143, "_step": 248}
{"Episode reward": -109.59501072727963, "Episode length": 999, "Policy Loss": -0.15263886749744415, "Value Loss": 0.0383894145488739, "_runtime": 363.8730309009552, "_timestamp": 1585418941.019537, "_step": 249}
{"Episode reward": -111.3808436030355, "Episode length": 999, "Policy Loss": -0.14924561977386475, "Value Loss": 0.039862051606178284, "_runtime": 365.0510540008545, "_timestamp": 1585418942.19756, "_step": 250}
{"Episode reward": -105.66708945176428, "Episode length": 999, "Policy Loss": -0.146002396941185, "Value Loss": 0.030228134244680405, "_runtime": 366.22312903404236, "_timestamp": 1585418943.369635, "_step": 251}
{"Episode reward": -105.91854751094935, "Episode length": 999, "Policy Loss": -0.1469477415084839, "Value Loss": 0.0322926826775074, "_runtime": 367.478679895401, "_timestamp": 1585418944.625186, "_step": 252}
{"Episode reward": -101.16521292843144, "Episode length": 999, "Policy Loss": -0.13654030859470367, "Value Loss": 0.030002737417817116, "_runtime": 368.6685848236084, "_timestamp": 1585418945.815091, "_step": 253}
{"Episode reward": -97.66389540200605, "Episode length": 999, "Policy Loss": -0.13083712756633759, "Value Loss": 0.03003511391580105, "_runtime": 369.94154691696167, "_timestamp": 1585418947.088053, "_step": 254}
{"Episode reward": -107.33373889190132, "Episode length": 999, "Policy Loss": -0.1549413502216339, "Value Loss": 0.03260660171508789, "_runtime": 371.1631329059601, "_timestamp": 1585418948.309639, "_step": 255}
{"Episode reward": -106.28339651882149, "Episode length": 999, "Policy Loss": -0.14613217115402222, "Value Loss": 0.034030646085739136, "_runtime": 372.4058060646057, "_timestamp": 1585418949.5523121, "_step": 256}
{"Episode reward": -100.96419354483704, "Episode length": 999, "Policy Loss": -0.12884971499443054, "Value Loss": 0.03038666769862175, "_runtime": 373.5863847732544, "_timestamp": 1585418950.7328908, "_step": 257}
{"Episode reward": -107.59958424510589, "Episode length": 999, "Policy Loss": -0.15318912267684937, "Value Loss": 0.035886090248823166, "_runtime": 374.7566268444061, "_timestamp": 1585418951.903133, "_step": 258}
{"Episode reward": -104.94610860053342, "Episode length": 999, "Policy Loss": -0.1433318704366684, "Value Loss": 0.033783283084630966, "_runtime": 375.9862949848175, "_timestamp": 1585418953.132801, "_step": 259}
{"Episode reward": -109.71820204811036, "Episode length": 999, "Policy Loss": -0.14826062321662903, "Value Loss": 0.03519042581319809, "_runtime": 377.2516369819641, "_timestamp": 1585418954.398143, "_step": 260}
{"Episode reward": -109.64732044641232, "Episode length": 999, "Policy Loss": -0.16256946325302124, "Value Loss": 0.03788293898105621, "_runtime": 378.4768078327179, "_timestamp": 1585418955.623314, "_step": 261}
{"Episode reward": -110.89562327308226, "Episode length": 999, "Policy Loss": -0.1658693104982376, "Value Loss": 0.03600754588842392, "_runtime": 379.68136072158813, "_timestamp": 1585418956.8278668, "_step": 262}
{"Episode reward": -107.97116278079172, "Episode length": 999, "Policy Loss": -0.1483076810836792, "Value Loss": 0.03278956562280655, "_runtime": 380.94877576828003, "_timestamp": 1585418958.0952818, "_step": 263}
{"Episode reward": -106.87472812654278, "Episode length": 999, "Policy Loss": -0.14473825693130493, "Value Loss": 0.033370863646268845, "_runtime": 382.21468782424927, "_timestamp": 1585418959.361194, "_step": 264}
{"Episode reward": -106.61347540776578, "Episode length": 999, "Policy Loss": -0.14313896000385284, "Value Loss": 0.037222009152173996, "_runtime": 383.53153681755066, "_timestamp": 1585418960.678043, "_step": 265}
{"Episode reward": -97.85241575592663, "Episode length": 999, "Policy Loss": -0.129344642162323, "Value Loss": 0.028482098132371902, "_runtime": 384.7740867137909, "_timestamp": 1585418961.9205928, "_step": 266}
{"Episode reward": -99.18594563676326, "Episode length": 999, "Policy Loss": -0.13250605762004852, "Value Loss": 0.027623767033219337, "_runtime": 385.96106004714966, "_timestamp": 1585418963.107566, "_step": 267}
{"Episode reward": -104.9973077679719, "Episode length": 999, "Policy Loss": -0.14741915464401245, "Value Loss": 0.030523767694830894, "_runtime": 387.20059990882874, "_timestamp": 1585418964.347106, "_step": 268}
{"Episode reward": -114.2892470640013, "Episode length": 999, "Policy Loss": -0.1578167825937271, "Value Loss": 0.03730235621333122, "_runtime": 388.365131855011, "_timestamp": 1585418965.511638, "_step": 269}
{"Episode reward": -106.96077690591004, "Episode length": 999, "Policy Loss": -0.14255857467651367, "Value Loss": 0.03353310003876686, "_runtime": 389.67406582832336, "_timestamp": 1585418966.820572, "_step": 270}
{"Episode reward": -108.72435603083393, "Episode length": 999, "Policy Loss": -0.14626525342464447, "Value Loss": 0.035970546305179596, "_runtime": 390.877632856369, "_timestamp": 1585418968.024139, "_step": 271}
{"Episode reward": -114.18358304841, "Episode length": 999, "Policy Loss": -0.16055403649806976, "Value Loss": 0.039786022156476974, "_runtime": 392.0708861351013, "_timestamp": 1585418969.2173922, "_step": 272}
{"Episode reward": -112.315270237563, "Episode length": 999, "Policy Loss": -0.1600671410560608, "Value Loss": 0.037447016686201096, "_runtime": 393.254353761673, "_timestamp": 1585418970.4008598, "_step": 273}
{"Episode reward": -108.99720105795409, "Episode length": 999, "Policy Loss": -0.15206459164619446, "Value Loss": 0.03732986003160477, "_runtime": 394.44009280204773, "_timestamp": 1585418971.5865989, "_step": 274}
{"Episode reward": -100.76360703388166, "Episode length": 999, "Policy Loss": -0.13645878434181213, "Value Loss": 0.02804076485335827, "_runtime": 395.6095349788666, "_timestamp": 1585418972.756041, "_step": 275}
{"Episode reward": -113.36244294218018, "Episode length": 999, "Policy Loss": -0.15834540128707886, "Value Loss": 0.037415217608213425, "_runtime": 396.79615092277527, "_timestamp": 1585418973.942657, "_step": 276}
{"Episode reward": -110.34221922560678, "Episode length": 999, "Policy Loss": -0.14985007047653198, "Value Loss": 0.038338057696819305, "_runtime": 398.00543785095215, "_timestamp": 1585418975.151944, "_step": 277}
{"Episode reward": -111.17948875492921, "Episode length": 999, "Policy Loss": -0.16220097243785858, "Value Loss": 0.03641432151198387, "_runtime": 399.25225377082825, "_timestamp": 1585418976.3987598, "_step": 278}
{"Episode reward": -105.13635622797563, "Episode length": 999, "Policy Loss": -0.13678660988807678, "Value Loss": 0.03143986314535141, "_runtime": 400.49972891807556, "_timestamp": 1585418977.646235, "_step": 279}
{"Episode reward": -116.61774421479632, "Episode length": 999, "Policy Loss": -0.16087675094604492, "Value Loss": 0.037877872586250305, "_runtime": 401.6687841415405, "_timestamp": 1585418978.8152902, "_step": 280}
{"Episode reward": -109.8765381635048, "Episode length": 999, "Policy Loss": -0.14978043735027313, "Value Loss": 0.03807555139064789, "_runtime": 402.90771985054016, "_timestamp": 1585418980.054226, "_step": 281}
{"Episode reward": -109.60141670411265, "Episode length": 999, "Policy Loss": -0.14737991988658905, "Value Loss": 0.03807033970952034, "_runtime": 404.1095509529114, "_timestamp": 1585418981.256057, "_step": 282}
{"Episode reward": -103.02050875687009, "Episode length": 999, "Policy Loss": -0.1430041491985321, "Value Loss": 0.03176715970039368, "_runtime": 405.3107750415802, "_timestamp": 1585418982.457281, "_step": 283}
{"Episode reward": -111.59518251046751, "Episode length": 999, "Policy Loss": -0.16518813371658325, "Value Loss": 0.033999085426330566, "_runtime": 406.4917140007019, "_timestamp": 1585418983.63822, "_step": 284}
{"Episode reward": -101.76978849068634, "Episode length": 999, "Policy Loss": -0.13901084661483765, "Value Loss": 0.02773331291973591, "_runtime": 407.68005084991455, "_timestamp": 1585418984.826557, "_step": 285}
{"Episode reward": -111.7186871311354, "Episode length": 999, "Policy Loss": -0.1479107290506363, "Value Loss": 0.03444306179881096, "_runtime": 408.85829401016235, "_timestamp": 1585418986.0048, "_step": 286}
{"Episode reward": -105.82145028943208, "Episode length": 999, "Policy Loss": -0.14159426093101501, "Value Loss": 0.0308759156614542, "_runtime": 410.1050980091095, "_timestamp": 1585418987.251604, "_step": 287}
{"Episode reward": -103.36039118816443, "Episode length": 999, "Policy Loss": -0.14246848225593567, "Value Loss": 0.033745016902685165, "_runtime": 411.26202178001404, "_timestamp": 1585418988.4085279, "_step": 288}
{"Episode reward": -100.6977388167904, "Episode length": 999, "Policy Loss": -0.13526389002799988, "Value Loss": 0.02785220555961132, "_runtime": 412.448796749115, "_timestamp": 1585418989.5953028, "_step": 289}
{"Episode reward": -105.16429377140149, "Episode length": 999, "Policy Loss": -0.14748112857341766, "Value Loss": 0.030120985582470894, "_runtime": 413.66156005859375, "_timestamp": 1585418990.8080661, "_step": 290}
{"Episode reward": -104.39015976539257, "Episode length": 999, "Policy Loss": -0.1456870585680008, "Value Loss": 0.034190502017736435, "_runtime": 415.0078389644623, "_timestamp": 1585418992.154345, "_step": 291}
{"Episode reward": -107.88912050407382, "Episode length": 999, "Policy Loss": -0.14972196519374847, "Value Loss": 0.035030800849199295, "_runtime": 416.2670907974243, "_timestamp": 1585418993.4135969, "_step": 292}
{"Episode reward": -107.22335069434651, "Episode length": 999, "Policy Loss": -0.14818793535232544, "Value Loss": 0.030179090797901154, "_runtime": 417.4571249485016, "_timestamp": 1585418994.603631, "_step": 293}
{"Episode reward": -110.96995389863832, "Episode length": 999, "Policy Loss": -0.15886448323726654, "Value Loss": 0.04045092314481735, "_runtime": 418.59486198425293, "_timestamp": 1585418995.741368, "_step": 294}
{"Episode reward": -103.12478654600439, "Episode length": 999, "Policy Loss": -0.14196094870567322, "Value Loss": 0.03238483518362045, "_runtime": 419.83069682121277, "_timestamp": 1585418996.977203, "_step": 295}
{"Episode reward": -110.44381444351772, "Episode length": 999, "Policy Loss": -0.15764720737934113, "Value Loss": 0.037652142345905304, "_runtime": 421.0717399120331, "_timestamp": 1585418998.218246, "_step": 296}
{"Episode reward": -96.22645903904737, "Episode length": 999, "Policy Loss": -0.1274060755968094, "Value Loss": 0.028898168355226517, "_runtime": 422.3036639690399, "_timestamp": 1585418999.45017, "_step": 297}
{"Episode reward": -99.89031971221186, "Episode length": 999, "Policy Loss": -0.13135457038879395, "Value Loss": 0.027418697252869606, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812, 2.1233596801757812]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.190733790397644, -1.141998052597046, -1.0932623147964478, -1.0445265769958496, -0.9957908391952515, -0.9470551013946533, -0.8983193039894104, -0.8495835661888123, -0.8008478283882141, -0.752112090587616, -0.7033763527870178, -0.6546406149864197, -0.6059048175811768, -0.5571690797805786, -0.5084333419799805, -0.4596976041793823, -0.4109618663787842, -0.36222612857818604, -0.3134903907775879, -0.26475465297698975, -0.2160189151763916, -0.16728317737579346, -0.11854743957519531, -0.06981170177459717, -0.021075844764709473, 0.027659893035888672, 0.07639563083648682, 0.12513136863708496, 0.1738671064376831, 0.22260284423828125, 0.2713385820388794, 0.32007431983947754, 0.3688100576400757, 0.41754579544067383, 0.466281533241272, 0.5150172710418701, 0.5637530088424683, 0.6124887466430664, 0.6612244844436646, 0.7099602222442627, 0.7586959600448608, 0.8074318170547485, 0.8561674356460571, 0.9049032926559448, 0.9536389112472534, 1.0023747682571411, 1.0511103868484497, 1.0998462438583374, 1.148582100868225, 1.1973177194595337, 1.2460535764694214, 1.29478919506073, 1.3435250520706177, 1.3922606706619263, 1.440996527671814, 1.4897321462631226, 1.5384680032730103, 1.5872036218643188, 1.6359394788742065, 1.6846750974655151, 1.7334109544754028, 1.7821465730667114, 1.8308824300765991, 1.8796180486679077, 1.9283539056777954]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1513923406600952, -1.117662787437439, -1.0839332342147827, -1.0502036809921265, -1.0164742469787598, -0.9827446341514587, -0.9490151405334473, -0.915285587310791, -0.8815560340881348, -0.8478264808654785, -0.8140969276428223, -0.7803674340248108, -0.7466378808021545, -0.7129083275794983, -0.6791788339614868, -0.6454492807388306, -0.6117197275161743, -0.5779901742935181, -0.5442606210708618, -0.5105311274528503, -0.4768015742301941, -0.44307202100753784, -0.40934252738952637, -0.3756129741668701, -0.34188342094421387, -0.3081538677215576, -0.27442431449890137, -0.2406948208808899, -0.20696526765823364, -0.1732357144355774, -0.13950622081756592, -0.10577666759490967, -0.07204711437225342, -0.03831756114959717, -0.004588007926940918, 0.029141545295715332, 0.06287109851837158, 0.09660053253173828, 0.13033008575439453, 0.16405963897705078, 0.19778919219970703, 0.23151874542236328, 0.26524829864501953, 0.2989778518676758, 0.3327072858810425, 0.36643683910369873, 0.400166392326355, 0.43389594554901123, 0.4676254987716675, 0.5013550519943237, 0.53508460521698, 0.5688141584396362, 0.6025437116622925, 0.6362731456756592, 0.6700026988983154, 0.7037322521209717, 0.7374618053436279, 0.7711913585662842, 0.8049209117889404, 0.8386504650115967, 0.8723798990249634, 0.9061094522476196, 0.9398390054702759, 0.9735685586929321, 1.0072981119155884]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 5.0, 10.0, 5.0, 9.0, 4.0, 10.0, 14.0, 9.0, 9.0, 12.0, 10.0, 19.0, 15.0, 20.0, 55.0, 38.0, 30.0, 46.0, 17.0, 25.0, 31.0, 18.0, 11.0, 13.0, 13.0, 9.0, 2.0, 4.0, 4.0, 3.0, 5.0, 1.0, 7.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.8921823501586914, -0.8660466074943542, -0.8399108052253723, -0.8137750625610352, -0.7876392602920532, -0.7615035176277161, -0.7353677749633789, -0.709231972694397, -0.6830962300300598, -0.6569604873657227, -0.6308246850967407, -0.6046889424324036, -0.5785531997680664, -0.5524173974990845, -0.5262816548347473, -0.5001459121704102, -0.4740101099014282, -0.4478743374347687, -0.42173856496810913, -0.395602822303772, -0.36946702003479004, -0.3433312773704529, -0.3171955347061157, -0.2910597324371338, -0.26492398977279663, -0.23878824710845947, -0.21265244483947754, -0.18651670217514038, -0.16038095951080322, -0.1342451572418213, -0.10810941457748413, -0.0819736123085022, -0.05583786964416504, -0.02970212697982788, -0.0035663247108459473, 0.02256941795349121, 0.048705220222473145, 0.0748409628868103, 0.10097670555114746, 0.1271125078201294, 0.15324831008911133, 0.1793839931488037, 0.20551979541778564, 0.23165559768676758, 0.25779128074645996, 0.2839270830154419, 0.31006288528442383, 0.3361985683441162, 0.36233437061309814, 0.3884701728820801, 0.41460585594177246, 0.4407416582107544, 0.46687746047973633, 0.4930131435394287, 0.5191489458084106, 0.5452847480773926, 0.571420431137085, 0.5975562334060669, 0.6236920356750488, 0.6498278379440308, 0.6759635210037231, 0.7020993232727051, 0.728235125541687, 0.7543708086013794, 0.7805066108703613]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.580032467842102, -0.5577992796897888, -0.5355660915374756, -0.5133329033851624, -0.49109968543052673, -0.4688664972782135, -0.44663330912590027, -0.42440009117126465, -0.4021669030189514, -0.3799337148666382, -0.35770052671432495, -0.3354673385620117, -0.3132341504096985, -0.29100096225738525, -0.26876774430274963, -0.2465345561504364, -0.22430136799812317, -0.20206817984580994, -0.1798349916934967, -0.15760177373886108, -0.13536858558654785, -0.11313539743423462, -0.09090220928192139, -0.06866902112960815, -0.04643583297729492, -0.02420264482498169, -0.001969456672668457, 0.02026379108428955, 0.04249697923660278, 0.06473016738891602, 0.08696335554122925, 0.10919654369354248, 0.1314297318458557, 0.15366291999816895, 0.17589610815048218, 0.1981292963027954, 0.22036248445510864, 0.24259567260742188, 0.2648289203643799, 0.2870621085166931, 0.30929529666900635, 0.3315284848213196, 0.3537616729736328, 0.37599486112594604, 0.3982280492782593, 0.4204612970352173, 0.44269442558288574, 0.46492767333984375, 0.4871608018875122, 0.5093940496444702, 0.5316271781921387, 0.5538604259490967, 0.5760935544967651, 0.5983268022537231, 0.6205600500106812, 0.6427931785583496, 0.6650264263153076, 0.6872595548629761, 0.7094928026199341, 0.7317259311676025, 0.7539591789245605, 0.776192307472229, 0.798425555229187, 0.8206586837768555, 0.8428919315338135]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 31.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.2447899430990219, -0.23873335123062134, -0.23267674446105957, -0.226620152592659, -0.22056356072425842, -0.21450695395469666, -0.20845036208629608, -0.2023937702178955, -0.19633716344833374, -0.19028057157993317, -0.1842239797115326, -0.17816737294197083, -0.17211078107357025, -0.16605418920516968, -0.1599975824356079, -0.15394100546836853, -0.14788439869880676, -0.141827791929245, -0.13577121496200562, -0.12971460819244385, -0.12365801632404327, -0.1176014095544815, -0.11154481768608093, -0.10548822581768036, -0.09943161904811859, -0.09337502717971802, -0.08731843531131744, -0.08126184344291687, -0.0752052366733551, -0.06914864480495453, -0.06309205293655396, -0.05703544616699219, -0.050978854298591614, -0.04492226243019104, -0.03886565566062927, -0.0328090637922287, -0.026752471923828125, -0.020695865154266357, -0.014639273285865784, -0.00858268141746521, -0.0025260895490646362, 0.0035305172204971313, 0.009587123990058899, 0.01564370095729828, 0.021700307726860046, 0.027756914496421814, 0.033813491463661194, 0.03987009823322296, 0.04592670500278473, 0.05198328197002411, 0.058039888739585876, 0.06409646570682526, 0.07015307247638702, 0.07620967924594879, 0.08226625621318817, 0.08832286298274994, 0.0943794697523117, 0.10043604671955109, 0.10649265348911285, 0.11254926025867462, 0.118605837225914, 0.12466244399547577, 0.13071905076503754, 0.13677562773227692, 0.14283223450183868]}, "_runtime": 423.54922699928284, "_timestamp": 1585419000.695733, "_step": 298}
{"Episode reward": -99.74307001116316, "Episode length": 999, "Policy Loss": -0.13677182793617249, "Value Loss": 0.03244124352931976, "_runtime": 424.7243640422821, "_timestamp": 1585419001.87087, "_step": 299}
{"Episode reward": -94.55520230932466, "Episode length": 999, "Policy Loss": -0.125227153301239, "Value Loss": 0.025047343224287033, "_runtime": 425.93254590034485, "_timestamp": 1585419003.079052, "_step": 300}
{"Episode reward": -110.22802610083468, "Episode length": 999, "Policy Loss": -0.16657699644565582, "Value Loss": 0.03399164229631424, "_runtime": 427.1105818748474, "_timestamp": 1585419004.257088, "_step": 301}
{"Episode reward": -101.62176913695086, "Episode length": 999, "Policy Loss": -0.14020462334156036, "Value Loss": 0.030323633924126625, "_runtime": 428.2921209335327, "_timestamp": 1585419005.438627, "_step": 302}
{"Episode reward": -101.78696862367306, "Episode length": 999, "Policy Loss": -0.13483187556266785, "Value Loss": 0.03072662279009819, "_runtime": 429.63507771492004, "_timestamp": 1585419006.7815838, "_step": 303}
{"Episode reward": -111.42195977207007, "Episode length": 999, "Policy Loss": -0.16475148499011993, "Value Loss": 0.03683345392346382, "_runtime": 430.9158549308777, "_timestamp": 1585419008.062361, "_step": 304}
{"Episode reward": -102.15047843660382, "Episode length": 999, "Policy Loss": -0.14093323051929474, "Value Loss": 0.03062133863568306, "_runtime": 432.1071379184723, "_timestamp": 1585419009.253644, "_step": 305}
{"Episode reward": -106.6867727172382, "Episode length": 999, "Policy Loss": -0.15887832641601562, "Value Loss": 0.03732830286026001, "_runtime": 433.29523181915283, "_timestamp": 1585419010.441738, "_step": 306}
{"Episode reward": -107.92253870406934, "Episode length": 999, "Policy Loss": -0.15337076783180237, "Value Loss": 0.03365837782621384, "_runtime": 434.5283079147339, "_timestamp": 1585419011.674814, "_step": 307}
{"Episode reward": -106.23838486497053, "Episode length": 999, "Policy Loss": -0.15435194969177246, "Value Loss": 0.036792926490306854, "_runtime": 435.7714989185333, "_timestamp": 1585419012.918005, "_step": 308}
{"Episode reward": -107.44528554005727, "Episode length": 999, "Policy Loss": -0.1502021700143814, "Value Loss": 0.03559134155511856, "_runtime": 436.9521028995514, "_timestamp": 1585419014.098609, "_step": 309}
{"Episode reward": -104.10670774693119, "Episode length": 999, "Policy Loss": -0.15848615765571594, "Value Loss": 0.03333140164613724, "_runtime": 438.1298978328705, "_timestamp": 1585419015.276404, "_step": 310}
{"Episode reward": -110.80108906045923, "Episode length": 999, "Policy Loss": -0.15712158381938934, "Value Loss": 0.03555117920041084, "_runtime": 439.29096388816833, "_timestamp": 1585419016.43747, "_step": 311}
{"Episode reward": -107.56651276868303, "Episode length": 999, "Policy Loss": -0.14983992278575897, "Value Loss": 0.03391410410404205, "_runtime": 440.5546019077301, "_timestamp": 1585419017.701108, "_step": 312}
{"Episode reward": -99.31465995905235, "Episode length": 999, "Policy Loss": -0.13430321216583252, "Value Loss": 0.028803791850805283, "_runtime": 441.82961988449097, "_timestamp": 1585419018.976126, "_step": 313}
{"Episode reward": -103.53896177290267, "Episode length": 999, "Policy Loss": -0.1396946907043457, "Value Loss": 0.030741600319743156, "_runtime": 442.9953110218048, "_timestamp": 1585419020.141817, "_step": 314}
{"Episode reward": -100.37978960978943, "Episode length": 999, "Policy Loss": -0.1447865515947342, "Value Loss": 0.030420582741498947, "_runtime": 444.2601249217987, "_timestamp": 1585419021.406631, "_step": 315}
{"Episode reward": -92.23154810023915, "Episode length": 999, "Policy Loss": -0.12759096920490265, "Value Loss": 0.028783703222870827, "_runtime": 445.4975337982178, "_timestamp": 1585419022.6440399, "_step": 316}
{"Episode reward": -102.60918415360636, "Episode length": 999, "Policy Loss": -0.13526922464370728, "Value Loss": 0.031419236212968826, "_runtime": 446.7238059043884, "_timestamp": 1585419023.870312, "_step": 317}
{"Episode reward": -107.81470390329193, "Episode length": 999, "Policy Loss": -0.15037967264652252, "Value Loss": 0.03601033613085747, "_runtime": 447.8917028903961, "_timestamp": 1585419025.038209, "_step": 318}
{"Episode reward": -100.25032970155056, "Episode length": 999, "Policy Loss": -0.14148429036140442, "Value Loss": 0.029412316158413887, "_runtime": 449.0348858833313, "_timestamp": 1585419026.181392, "_step": 319}
{"Episode reward": -98.28593395891399, "Episode length": 999, "Policy Loss": -0.12601885199546814, "Value Loss": 0.02851102128624916, "_runtime": 450.32241773605347, "_timestamp": 1585419027.4689238, "_step": 320}
{"Episode reward": -100.02383563723903, "Episode length": 999, "Policy Loss": -0.13472801446914673, "Value Loss": 0.030457060784101486, "_runtime": 451.54771399497986, "_timestamp": 1585419028.69422, "_step": 321}
{"Episode reward": -106.65228686473115, "Episode length": 999, "Policy Loss": -0.14528951048851013, "Value Loss": 0.03476054593920708, "_runtime": 452.7748529911041, "_timestamp": 1585419029.921359, "_step": 322}
{"Episode reward": -103.47731768647641, "Episode length": 999, "Policy Loss": -0.1395328938961029, "Value Loss": 0.03131936490535736, "_runtime": 453.9515850543976, "_timestamp": 1585419031.0980911, "_step": 323}
{"Episode reward": -108.08785028857642, "Episode length": 999, "Policy Loss": -0.14307710528373718, "Value Loss": 0.03571977838873863, "_runtime": 455.1568958759308, "_timestamp": 1585419032.303402, "_step": 324}
{"Episode reward": -105.1832269735694, "Episode length": 999, "Policy Loss": -0.13792046904563904, "Value Loss": 0.03086220845580101, "_runtime": 456.3369929790497, "_timestamp": 1585419033.483499, "_step": 325}
{"Episode reward": -106.21611413484088, "Episode length": 999, "Policy Loss": -0.1423632800579071, "Value Loss": 0.033867087215185165, "_runtime": 457.50956678390503, "_timestamp": 1585419034.6560729, "_step": 326}
{"Episode reward": -106.88794819014423, "Episode length": 999, "Policy Loss": -0.1451042890548706, "Value Loss": 0.03487725555896759, "_runtime": 458.6637668609619, "_timestamp": 1585419035.810273, "_step": 327}
{"Episode reward": -96.40457527751386, "Episode length": 999, "Policy Loss": -0.13748696446418762, "Value Loss": 0.02777748927474022, "_runtime": 459.913382768631, "_timestamp": 1585419037.0598888, "_step": 328}
{"Episode reward": -115.85328577426294, "Episode length": 999, "Policy Loss": -0.1603383868932724, "Value Loss": 0.04074753448367119, "_runtime": 461.064013004303, "_timestamp": 1585419038.210519, "_step": 329}
{"Episode reward": -101.18052099430831, "Episode length": 999, "Policy Loss": -0.13765482604503632, "Value Loss": 0.03371618315577507, "_runtime": 462.27261781692505, "_timestamp": 1585419039.419124, "_step": 330}
{"Episode reward": -102.03967495376114, "Episode length": 999, "Policy Loss": -0.15183709561824799, "Value Loss": 0.030927425250411034, "_runtime": 463.5566771030426, "_timestamp": 1585419040.7031832, "_step": 331}
{"Episode reward": -98.96183152365445, "Episode length": 999, "Policy Loss": -0.13115304708480835, "Value Loss": 0.02910035103559494, "_runtime": 464.78272104263306, "_timestamp": 1585419041.929227, "_step": 332}
{"Episode reward": -104.23788861204116, "Episode length": 999, "Policy Loss": -0.14724063873291016, "Value Loss": 0.03274041414260864, "_runtime": 466.00095677375793, "_timestamp": 1585419043.1474628, "_step": 333}
{"Episode reward": -103.32942991788931, "Episode length": 999, "Policy Loss": -0.14469335973262787, "Value Loss": 0.030424732714891434, "_runtime": 467.1704800128937, "_timestamp": 1585419044.316986, "_step": 334}
{"Episode reward": -105.9257972942938, "Episode length": 999, "Policy Loss": -0.13611209392547607, "Value Loss": 0.03376389667391777, "_runtime": 468.37850689888, "_timestamp": 1585419045.525013, "_step": 335}
{"Episode reward": -116.47599598411377, "Episode length": 999, "Policy Loss": -0.15718698501586914, "Value Loss": 0.039918407797813416, "_runtime": 469.5988519191742, "_timestamp": 1585419046.745358, "_step": 336}
{"Episode reward": -109.15940619160835, "Episode length": 999, "Policy Loss": -0.15754330158233643, "Value Loss": 0.03617985174059868, "_runtime": 470.7864339351654, "_timestamp": 1585419047.93294, "_step": 337}
{"Episode reward": -112.85118223451329, "Episode length": 999, "Policy Loss": -0.16394178569316864, "Value Loss": 0.036766417324543, "_runtime": 472.015429019928, "_timestamp": 1585419049.161935, "_step": 338}
{"Episode reward": -106.36574204392447, "Episode length": 999, "Policy Loss": -0.14882761240005493, "Value Loss": 0.03230072185397148, "_runtime": 473.24852299690247, "_timestamp": 1585419050.395029, "_step": 339}
{"Episode reward": -101.50726942257299, "Episode length": 999, "Policy Loss": -0.1398138552904129, "Value Loss": 0.031389523297548294, "_runtime": 474.56420493125916, "_timestamp": 1585419051.710711, "_step": 340}
{"Episode reward": -111.01531335914521, "Episode length": 999, "Policy Loss": -0.15785260498523712, "Value Loss": 0.03645450249314308, "_runtime": 475.9206049442291, "_timestamp": 1585419053.067111, "_step": 341}
{"Episode reward": -100.55278102723653, "Episode length": 999, "Policy Loss": -0.13616178929805756, "Value Loss": 0.027776995673775673, "_runtime": 477.16551184654236, "_timestamp": 1585419054.312018, "_step": 342}
{"Episode reward": -104.35518469410884, "Episode length": 999, "Policy Loss": -0.13904494047164917, "Value Loss": 0.032292891293764114, "_runtime": 478.37641191482544, "_timestamp": 1585419055.522918, "_step": 343}
{"Episode reward": -108.18217900301438, "Episode length": 999, "Policy Loss": -0.1550816297531128, "Value Loss": 0.03616369515657425, "_runtime": 479.63245582580566, "_timestamp": 1585419056.778962, "_step": 344}
{"Episode reward": -104.73964562776047, "Episode length": 999, "Policy Loss": -0.1353798657655716, "Value Loss": 0.03356313705444336, "_runtime": 480.8751678466797, "_timestamp": 1585419058.021674, "_step": 345}
{"Episode reward": -112.35335427407308, "Episode length": 999, "Policy Loss": -0.16271139681339264, "Value Loss": 0.03717808797955513, "_runtime": 482.12404799461365, "_timestamp": 1585419059.270554, "_step": 346}
{"Episode reward": -112.54176319990715, "Episode length": 999, "Policy Loss": -0.15760795772075653, "Value Loss": 0.03651634603738785, "_runtime": 483.33896493911743, "_timestamp": 1585419060.485471, "_step": 347}
{"Episode reward": -107.27931375595097, "Episode length": 999, "Policy Loss": -0.15394645929336548, "Value Loss": 0.03639143705368042, "_runtime": 484.5007710456848, "_timestamp": 1585419061.647277, "_step": 348}
{"Episode reward": -112.22742445283106, "Episode length": 999, "Policy Loss": -0.164637953042984, "Value Loss": 0.04173344001173973, "_runtime": 485.74489188194275, "_timestamp": 1585419062.891398, "_step": 349}
{"Episode reward": -115.3714213976283, "Episode length": 999, "Policy Loss": -0.16300509870052338, "Value Loss": 0.03943159058690071, "_runtime": 487.00148487091064, "_timestamp": 1585419064.147991, "_step": 350}
{"Episode reward": -113.11795276163971, "Episode length": 999, "Policy Loss": -0.1487148106098175, "Value Loss": 0.038177553564310074, "_runtime": 488.2342109680176, "_timestamp": 1585419065.380717, "_step": 351}
{"Episode reward": -113.97998609522229, "Episode length": 999, "Policy Loss": -0.1550740748643875, "Value Loss": 0.038862474262714386, "_runtime": 489.45343494415283, "_timestamp": 1585419066.599941, "_step": 352}
{"Episode reward": -116.64071972137899, "Episode length": 999, "Policy Loss": -0.16408440470695496, "Value Loss": 0.043062835931777954, "_runtime": 490.7125780582428, "_timestamp": 1585419067.8590841, "_step": 353}
{"Episode reward": -110.7537007102858, "Episode length": 999, "Policy Loss": -0.15963968634605408, "Value Loss": 0.035985544323921204, "_runtime": 491.89749908447266, "_timestamp": 1585419069.0440052, "_step": 354}
{"Episode reward": -113.88282659361269, "Episode length": 999, "Policy Loss": -0.15070375800132751, "Value Loss": 0.0373433418571949, "_runtime": 493.1017987728119, "_timestamp": 1585419070.2483048, "_step": 355}
{"Episode reward": -107.87754782408571, "Episode length": 999, "Policy Loss": -0.15079787373542786, "Value Loss": 0.03413674980401993, "_runtime": 494.2891299724579, "_timestamp": 1585419071.435636, "_step": 356}
{"Episode reward": -106.92163044772441, "Episode length": 999, "Policy Loss": -0.14778535068035126, "Value Loss": 0.03391677513718605, "_runtime": 495.4777708053589, "_timestamp": 1585419072.6242769, "_step": 357}
{"Episode reward": -103.47124578012668, "Episode length": 999, "Policy Loss": -0.14180833101272583, "Value Loss": 0.03160971403121948, "_runtime": 496.6303217411041, "_timestamp": 1585419073.7768278, "_step": 358}
{"Episode reward": -109.763888657637, "Episode length": 999, "Policy Loss": -0.1549302339553833, "Value Loss": 0.03440367802977562, "_runtime": 497.8939120769501, "_timestamp": 1585419075.0404181, "_step": 359}
{"Episode reward": -108.58637265694126, "Episode length": 999, "Policy Loss": -0.1478273570537567, "Value Loss": 0.0363076776266098, "_runtime": 499.04407691955566, "_timestamp": 1585419076.190583, "_step": 360}
{"Episode reward": -103.69990536177598, "Episode length": 999, "Policy Loss": -0.13763383030891418, "Value Loss": 0.03107789345085621, "_runtime": 500.3254249095917, "_timestamp": 1585419077.471931, "_step": 361}
{"Episode reward": -106.59926612509715, "Episode length": 999, "Policy Loss": -0.14804035425186157, "Value Loss": 0.03483829274773598, "_runtime": 501.5596978664398, "_timestamp": 1585419078.706204, "_step": 362}
{"Episode reward": -109.02791820936699, "Episode length": 999, "Policy Loss": -0.1641417294740677, "Value Loss": 0.03630301356315613, "_runtime": 502.81642389297485, "_timestamp": 1585419079.96293, "_step": 363}
{"Episode reward": -109.64574734289796, "Episode length": 999, "Policy Loss": -0.16045449674129486, "Value Loss": 0.037991203367710114, "_runtime": 504.0506589412689, "_timestamp": 1585419081.197165, "_step": 364}
{"Episode reward": -104.24660438919801, "Episode length": 999, "Policy Loss": -0.14085090160369873, "Value Loss": 0.032883018255233765, "_runtime": 505.48778200149536, "_timestamp": 1585419082.634288, "_step": 365}
{"Episode reward": -109.14511901721296, "Episode length": 999, "Policy Loss": -0.14633630216121674, "Value Loss": 0.03515426069498062, "_runtime": 507.2609441280365, "_timestamp": 1585419084.4074502, "_step": 366}
{"Episode reward": -111.35855283682943, "Episode length": 999, "Policy Loss": -0.1532670557498932, "Value Loss": 0.03731498494744301, "_runtime": 508.9854247570038, "_timestamp": 1585419086.1319308, "_step": 367}
{"Episode reward": -105.78233693099313, "Episode length": 999, "Policy Loss": -0.14202186465263367, "Value Loss": 0.032871063798666, "_runtime": 510.6010317802429, "_timestamp": 1585419087.7475379, "_step": 368}
{"Episode reward": -121.54914368996384, "Episode length": 999, "Policy Loss": -0.16979791224002838, "Value Loss": 0.042979512363672256, "_runtime": 512.3056230545044, "_timestamp": 1585419089.4521291, "_step": 369}
{"Episode reward": -111.44166867873624, "Episode length": 999, "Policy Loss": -0.15610966086387634, "Value Loss": 0.03760021924972534, "_runtime": 514.2034759521484, "_timestamp": 1585419091.349982, "_step": 370}
{"Episode reward": -117.84242545759162, "Episode length": 999, "Policy Loss": -0.16306591033935547, "Value Loss": 0.037787485867738724, "_runtime": 516.0683829784393, "_timestamp": 1585419093.214889, "_step": 371}
{"Episode reward": -113.44179617417926, "Episode length": 999, "Policy Loss": -0.16286545991897583, "Value Loss": 0.03783159330487251, "_runtime": 517.5233209133148, "_timestamp": 1585419094.669827, "_step": 372}
{"Episode reward": -123.30555934237168, "Episode length": 999, "Policy Loss": -0.17947694659233093, "Value Loss": 0.04424111545085907, "_runtime": 518.7386438846588, "_timestamp": 1585419095.88515, "_step": 373}
{"Episode reward": -106.1412016036868, "Episode length": 999, "Policy Loss": -0.1489618867635727, "Value Loss": 0.03293241187930107, "_runtime": 519.9769897460938, "_timestamp": 1585419097.1234958, "_step": 374}
{"Episode reward": -112.74122451479904, "Episode length": 999, "Policy Loss": -0.14834769070148468, "Value Loss": 0.037263114005327225, "_runtime": 521.2072041034698, "_timestamp": 1585419098.3537102, "_step": 375}
{"Episode reward": -114.59112859382311, "Episode length": 999, "Policy Loss": -0.16308186948299408, "Value Loss": 0.03895372897386551, "_runtime": 522.3604860305786, "_timestamp": 1585419099.506992, "_step": 376}
{"Episode reward": -123.41448298785872, "Episode length": 999, "Policy Loss": -0.17279008030891418, "Value Loss": 0.055784840136766434, "_runtime": 523.5353348255157, "_timestamp": 1585419100.681841, "_step": 377}
{"Episode reward": -115.21318035635475, "Episode length": 999, "Policy Loss": -0.15083827078342438, "Value Loss": 0.04386027157306671, "_runtime": 524.7760219573975, "_timestamp": 1585419101.922528, "_step": 378}
{"Episode reward": -111.59328633995703, "Episode length": 999, "Policy Loss": -0.15397727489471436, "Value Loss": 0.03392529487609863, "_runtime": 526.0782771110535, "_timestamp": 1585419103.2247832, "_step": 379}
{"Episode reward": -106.77199700583168, "Episode length": 999, "Policy Loss": -0.1383252888917923, "Value Loss": 0.03585677593946457, "_runtime": 527.309253692627, "_timestamp": 1585419104.4557598, "_step": 380}
{"Episode reward": -123.69147936380736, "Episode length": 999, "Policy Loss": -0.1679801195859909, "Value Loss": 0.04250277578830719, "_runtime": 528.5006897449493, "_timestamp": 1585419105.6471958, "_step": 381}
{"Episode reward": -111.77459623868697, "Episode length": 999, "Policy Loss": -0.1470106989145279, "Value Loss": 0.04010898992419243, "_runtime": 529.7191779613495, "_timestamp": 1585419106.865684, "_step": 382}
{"Episode reward": -119.27576483641386, "Episode length": 999, "Policy Loss": -0.15692080557346344, "Value Loss": 0.04154803603887558, "_runtime": 530.9038579463959, "_timestamp": 1585419108.050364, "_step": 383}
{"Episode reward": -119.97132556282934, "Episode length": 999, "Policy Loss": -0.16235855221748352, "Value Loss": 0.041006091982126236, "_runtime": 532.1467697620392, "_timestamp": 1585419109.2932758, "_step": 384}
{"Episode reward": -123.86866655890911, "Episode length": 999, "Policy Loss": -0.17733027040958405, "Value Loss": 0.04622960463166237, "_runtime": 533.3537929058075, "_timestamp": 1585419110.500299, "_step": 385}
{"Episode reward": -113.38524823046949, "Episode length": 999, "Policy Loss": -0.15104834735393524, "Value Loss": 0.03568107262253761, "_runtime": 534.6410601139069, "_timestamp": 1585419111.7875662, "_step": 386}
{"Episode reward": -123.63882819649186, "Episode length": 999, "Policy Loss": -0.17093856632709503, "Value Loss": 0.0462452732026577, "_runtime": 535.8765029907227, "_timestamp": 1585419113.023009, "_step": 387}
{"Episode reward": -127.67732385835612, "Episode length": 999, "Policy Loss": -0.16731257736682892, "Value Loss": 0.051777433604002, "_runtime": 537.0753667354584, "_timestamp": 1585419114.2218728, "_step": 388}
{"Episode reward": -126.9650508927383, "Episode length": 999, "Policy Loss": -0.1673056185245514, "Value Loss": 0.04743359610438347, "_runtime": 538.2409918308258, "_timestamp": 1585419115.387498, "_step": 389}
{"Episode reward": -127.81764084640251, "Episode length": 999, "Policy Loss": -0.16841630637645721, "Value Loss": 0.045260243117809296, "_runtime": 539.721531867981, "_timestamp": 1585419116.868038, "_step": 390}
{"Episode reward": -121.69401832441822, "Episode length": 999, "Policy Loss": -0.1597520411014557, "Value Loss": 0.047025829553604126, "_runtime": 540.9639959335327, "_timestamp": 1585419118.110502, "_step": 391}
{"Episode reward": -128.00157291853478, "Episode length": 999, "Policy Loss": -0.17684406042099, "Value Loss": 0.04515640065073967, "_runtime": 542.2267079353333, "_timestamp": 1585419119.373214, "_step": 392}
{"Episode reward": -132.01302420897605, "Episode length": 999, "Policy Loss": -0.17957818508148193, "Value Loss": 0.04602606222033501, "_runtime": 543.4080519676208, "_timestamp": 1585419120.554558, "_step": 393}
{"Episode reward": -126.7778317935412, "Episode length": 999, "Policy Loss": -0.18022364377975464, "Value Loss": 0.046312883496284485, "_runtime": 544.5963158607483, "_timestamp": 1585419121.742822, "_step": 394}
{"Episode reward": -125.60412959407452, "Episode length": 999, "Policy Loss": -0.18199624121189117, "Value Loss": 0.045913442969322205, "_runtime": 545.8282918930054, "_timestamp": 1585419122.974798, "_step": 395}
{"Episode reward": -131.72730503799446, "Episode length": 999, "Policy Loss": -0.18021950125694275, "Value Loss": 0.047377604991197586, "_runtime": 547.026752948761, "_timestamp": 1585419124.173259, "_step": 396}
{"Episode reward": -134.20705030525951, "Episode length": 999, "Policy Loss": -0.18747881054878235, "Value Loss": 0.05038287118077278, "_runtime": 548.2121238708496, "_timestamp": 1585419125.35863, "_step": 397}
{"Episode reward": -125.82314142105693, "Episode length": 999, "Policy Loss": -0.17769962549209595, "Value Loss": 0.04544707015156746, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897, 1.6608728170394897]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3283360004425049, -1.2707386016845703, -1.2131412029266357, -1.1555436849594116, -1.097946286201477, -1.0403488874435425, -0.9827514886856079, -0.9251540303230286, -0.8675565719604492, -0.8099591732025146, -0.7523617744445801, -0.6947643160820007, -0.6371669173240662, -0.5795694589614868, -0.5219720602035522, -0.4643746018409729, -0.40677720308303833, -0.34917980432510376, -0.2915823459625244, -0.23398494720458984, -0.17638754844665527, -0.11879003047943115, -0.06119263172149658, -0.0035952329635620117, 0.05400216579437256, 0.11159956455230713, 0.16919708251953125, 0.22679448127746582, 0.2843918800354004, 0.34198927879333496, 0.3995867967605591, 0.45718419551849365, 0.5147815942764282, 0.5723789930343628, 0.6299763917922974, 0.6875739097595215, 0.745171308517456, 0.8027687072753906, 0.8603661060333252, 0.9179635047912598, 0.9755609035491943, 1.033158302307129, 1.0907559394836426, 1.1483533382415771, 1.2059507369995117, 1.2635481357574463, 1.3211455345153809, 1.3787429332733154, 1.43634033203125, 1.4939377307891846, 1.5515351295471191, 1.6091327667236328, 1.6667301654815674, 1.724327564239502, 1.7819249629974365, 1.839522361755371, 1.8971197605133057, 1.9547171592712402, 2.012314558029175, 2.0699119567871094, 2.127509593963623, 2.1851069927215576, 2.242704391479492, 2.3003017902374268, 2.3578991889953613]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.917810320854187, -0.8907139301300049, -0.8636175394058228, -0.8365211486816406, -0.8094247579574585, -0.7823283672332764, -0.7552319765090942, -0.7281356453895569, -0.7010392546653748, -0.6739428639411926, -0.6468464732170105, -0.6197500824928284, -0.5926536917686462, -0.5655573010444641, -0.5384609699249268, -0.5113645792007446, -0.4842681586742401, -0.457171767950058, -0.43007537722587585, -0.4029790163040161, -0.375882625579834, -0.34878623485565186, -0.3216898441314697, -0.2945934534072876, -0.26749706268310547, -0.24040067195892334, -0.2133042812347412, -0.18620795011520386, -0.15911155939102173, -0.1320151686668396, -0.10491877794265747, -0.07782238721847534, -0.05072599649429321, -0.023629605770111084, 0.003466784954071045, 0.030563175678253174, 0.0576595664024353, 0.08475589752197266, 0.11185228824615479, 0.13894867897033691, 0.16604506969451904, 0.19314146041870117, 0.2202378511428833, 0.24733424186706543, 0.27443063259124756, 0.3015270233154297, 0.3286234140396118, 0.35571980476379395, 0.3828161954879761, 0.4099125862121582, 0.43700897693634033, 0.46410536766052246, 0.4912017583847046, 0.5182981491088867, 0.5453944206237793, 0.5724908113479614, 0.5995872020721436, 0.6266835927963257, 0.6537799835205078, 0.6808763742446899, 0.7079727649688721, 0.7350691556930542, 0.7621655464172363, 0.7892619371414185, 0.8163583278656006]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 6.0, 13.0, 11.0, 10.0, 5.0, 6.0, 13.0, 12.0, 23.0, 22.0, 43.0, 62.0, 56.0, 48.0, 24.0, 36.0, 21.0, 17.0, 17.0, 10.0, 3.0, 5.0, 2.0, 3.0, 3.0, 5.0, 2.0, 1.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-1.2931172847747803, -1.2553107738494873, -1.2175042629241943, -1.1796977519989014, -1.1418912410736084, -1.1040847301483154, -1.0662782192230225, -1.0284717082977295, -0.9906651973724365, -0.9528586864471436, -0.9150521755218506, -0.8772456645965576, -0.8394391536712646, -0.8016326427459717, -0.7638261318206787, -0.7260196208953857, -0.6882131099700928, -0.6504065990447998, -0.6126000881195068, -0.5747935771942139, -0.5369870662689209, -0.49918055534362793, -0.46137404441833496, -0.423567533493042, -0.385761022567749, -0.34795451164245605, -0.3101480007171631, -0.2723414897918701, -0.23453497886657715, -0.19672846794128418, -0.1589219570159912, -0.12111544609069824, -0.08330893516540527, -0.045502424240112305, -0.007695913314819336, 0.030110597610473633, 0.0679171085357666, 0.10572361946105957, 0.14353013038635254, 0.1813366413116455, 0.21914315223693848, 0.25694966316223145, 0.2947561740875244, 0.3325626850128174, 0.37036919593811035, 0.4081757068634033, 0.4459822177886963, 0.48378872871398926, 0.5215952396392822, 0.5594017505645752, 0.5972082614898682, 0.6350147724151611, 0.6728212833404541, 0.7106277942657471, 0.74843430519104, 0.786240816116333, 0.824047327041626, 0.861853837966919, 0.8996603488922119, 0.9374668598175049, 0.9752733707427979, 1.0130798816680908, 1.0508863925933838, 1.0886929035186768, 1.1264994144439697]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4387767016887665, -0.42051592469215393, -0.4022551476955414, -0.38399437069892883, -0.3657335638999939, -0.34747278690338135, -0.3292120099067688, -0.31095123291015625, -0.2926904559135437, -0.27442967891693115, -0.2561689019203186, -0.23790811002254486, -0.2196473330259323, -0.20138655602931976, -0.18312576413154602, -0.16486498713493347, -0.14660421013832092, -0.12834343314170837, -0.11008265614509583, -0.09182187914848328, -0.07356110215187073, -0.05530029535293579, -0.03703951835632324, -0.018778741359710693, -0.0005179643630981445, 0.017742812633514404, 0.03600358963012695, 0.0542643666267395, 0.07252517342567444, 0.09078595042228699, 0.10904672741889954, 0.12730750441551208, 0.14556828141212463, 0.16382905840873718, 0.18208983540534973, 0.20035061240196228, 0.21861138939857483, 0.23687216639518738, 0.2551329433917999, 0.2733937203884125, 0.291654497385025, 0.30991533398628235, 0.3281761109828949, 0.34643688797950745, 0.36469766497612, 0.38295844197273254, 0.4012192189693451, 0.41947999596595764, 0.4377407729625702, 0.45600154995918274, 0.4742623269557953, 0.49252310395240784, 0.5107839107513428, 0.5290446281433105, 0.5473054647445679, 0.5655661821365356, 0.583827018737793, 0.6020877361297607, 0.6203485727310181, 0.6386092901229858, 0.6568701267242432, 0.6751308441162109, 0.6933916807174683, 0.711652398109436, 0.7299132347106934]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 33.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-1.3822942972183228, -1.3480980396270752, -1.313901662826538, -1.2797054052352905, -1.245509147644043, -1.2113127708435059, -1.1771165132522583, -1.1429201364517212, -1.1087238788604736, -1.0745275020599365, -1.040331244468689, -1.0061349868774414, -0.9719386696815491, -0.9377423524856567, -0.9035460948944092, -0.8693497776985168, -0.8351534605026245, -0.8009571433067322, -0.7667608261108398, -0.7325645685195923, -0.6983682513237, -0.6641719341278076, -0.6299756765365601, -0.5957793593406677, -0.5615830421447754, -0.5273867249488831, -0.4931904077529907, -0.45899415016174316, -0.42479783296585083, -0.3906015157699585, -0.35640525817871094, -0.32220888137817383, -0.28801262378692627, -0.2538163661956787, -0.2196199893951416, -0.18542373180389404, -0.15122735500335693, -0.11703109741210938, -0.08283483982086182, -0.04863846302032471, -0.014442205429077148, 0.01975405216217041, 0.05395042896270752, 0.08814668655395508, 0.12234294414520264, 0.15653932094573975, 0.1907355785369873, 0.22493195533752441, 0.259128212928772, 0.29332447052001953, 0.32752084732055664, 0.3617171049118042, 0.3959134817123413, 0.43010973930358887, 0.4643059968948364, 0.49850237369537354, 0.5326986312866211, 0.5668948888778687, 0.6010912656784058, 0.6352876424789429, 0.6694837808609009, 0.703680157661438, 0.7378765344619751, 0.7720726728439331, 0.8062690496444702]}, "_runtime": 549.5046389102936, "_timestamp": 1585419126.651145, "_step": 398}
{"Episode reward": -127.7011344501483, "Episode length": 999, "Policy Loss": -0.1727534830570221, "Value Loss": 0.04685194045305252, "_runtime": 550.7687730789185, "_timestamp": 1585419127.9152792, "_step": 399}
{"Episode reward": -128.1356267132495, "Episode length": 999, "Policy Loss": -0.17848682403564453, "Value Loss": 0.04447518289089203, "_runtime": 551.9279289245605, "_timestamp": 1585419129.074435, "_step": 400}
{"Episode reward": -128.74078129732177, "Episode length": 999, "Policy Loss": -0.171791210770607, "Value Loss": 0.04994729906320572, "_runtime": 553.1927809715271, "_timestamp": 1585419130.339287, "_step": 401}
{"Episode reward": -127.22500069202009, "Episode length": 999, "Policy Loss": -0.17565079033374786, "Value Loss": 0.04233565554022789, "_runtime": 554.3835687637329, "_timestamp": 1585419131.5300748, "_step": 402}
{"Episode reward": -128.51861388391043, "Episode length": 999, "Policy Loss": -0.17347250878810883, "Value Loss": 0.0465741902589798, "_runtime": 555.650444984436, "_timestamp": 1585419132.796951, "_step": 403}
{"Episode reward": -120.19648386478428, "Episode length": 999, "Policy Loss": -0.15471352636814117, "Value Loss": 0.044976141303777695, "_runtime": 556.8202419281006, "_timestamp": 1585419133.966748, "_step": 404}
{"Episode reward": -126.07298090147644, "Episode length": 999, "Policy Loss": -0.17182131111621857, "Value Loss": 0.04769992083311081, "_runtime": 558.0146749019623, "_timestamp": 1585419135.161181, "_step": 405}
{"Episode reward": -128.29860574516874, "Episode length": 999, "Policy Loss": -0.1737474650144577, "Value Loss": 0.043830789625644684, "_runtime": 559.2124688625336, "_timestamp": 1585419136.358975, "_step": 406}
{"Episode reward": -126.79635350959094, "Episode length": 999, "Policy Loss": -0.17384319007396698, "Value Loss": 0.04466443508863449, "_runtime": 560.4093608856201, "_timestamp": 1585419137.555867, "_step": 407}
{"Episode reward": -125.86567536035214, "Episode length": 999, "Policy Loss": -0.17273038625717163, "Value Loss": 0.04660961404442787, "_runtime": 561.6808228492737, "_timestamp": 1585419138.827329, "_step": 408}
{"Episode reward": -129.71267007909051, "Episode length": 999, "Policy Loss": -0.18200565874576569, "Value Loss": 0.04704732447862625, "_runtime": 562.9167368412018, "_timestamp": 1585419140.063243, "_step": 409}
{"Episode reward": -123.46720161523473, "Episode length": 999, "Policy Loss": -0.1657947599887848, "Value Loss": 0.04310232028365135, "_runtime": 564.2470848560333, "_timestamp": 1585419141.393591, "_step": 410}
{"Episode reward": -119.93067329588858, "Episode length": 999, "Policy Loss": -0.16495081782341003, "Value Loss": 0.04409271106123924, "_runtime": 565.479348897934, "_timestamp": 1585419142.625855, "_step": 411}
{"Episode reward": -121.06761308230747, "Episode length": 999, "Policy Loss": -0.1662910133600235, "Value Loss": 0.042796727269887924, "_runtime": 566.668163061142, "_timestamp": 1585419143.8146691, "_step": 412}
{"Episode reward": -121.12017971670006, "Episode length": 999, "Policy Loss": -0.16298361122608185, "Value Loss": 0.04179807007312775, "_runtime": 567.8248770236969, "_timestamp": 1585419144.971383, "_step": 413}
{"Episode reward": -130.6988601824152, "Episode length": 999, "Policy Loss": -0.1899380087852478, "Value Loss": 0.0470014363527298, "_runtime": 569.0076608657837, "_timestamp": 1585419146.154167, "_step": 414}
{"Episode reward": -116.9050511494721, "Episode length": 999, "Policy Loss": -0.16148968040943146, "Value Loss": 0.0396440252661705, "_runtime": 570.2082517147064, "_timestamp": 1585419147.3547578, "_step": 415}
{"Episode reward": -131.18712513323982, "Episode length": 999, "Policy Loss": -0.1940436214208603, "Value Loss": 0.04723915830254555, "_runtime": 571.3902409076691, "_timestamp": 1585419148.536747, "_step": 416}
{"Episode reward": -124.87443337372834, "Episode length": 999, "Policy Loss": -0.1698862612247467, "Value Loss": 0.046771034598350525, "_runtime": 572.6130118370056, "_timestamp": 1585419149.759518, "_step": 417}
{"Episode reward": -112.59368675271052, "Episode length": 999, "Policy Loss": -0.15684811770915985, "Value Loss": 0.03612952306866646, "_runtime": 573.8162710666656, "_timestamp": 1585419150.9627771, "_step": 418}
{"Episode reward": -122.57494257888689, "Episode length": 999, "Policy Loss": -0.16856279969215393, "Value Loss": 0.04081131890416145, "_runtime": 574.9768598079681, "_timestamp": 1585419152.1233659, "_step": 419}
{"Episode reward": -122.25618857574193, "Episode length": 999, "Policy Loss": -0.1617904156446457, "Value Loss": 0.04441350698471069, "_runtime": 576.1794610023499, "_timestamp": 1585419153.325967, "_step": 420}
{"Episode reward": -123.04267577227282, "Episode length": 999, "Policy Loss": -0.16585491597652435, "Value Loss": 0.041299931704998016, "_runtime": 577.3364498615265, "_timestamp": 1585419154.482956, "_step": 421}
{"Episode reward": -111.32409488965313, "Episode length": 999, "Policy Loss": -0.15423747897148132, "Value Loss": 0.03774517402052879, "_runtime": 578.4838950634003, "_timestamp": 1585419155.6304011, "_step": 422}
{"Episode reward": -122.71687944222435, "Episode length": 999, "Policy Loss": -0.18475665152072906, "Value Loss": 0.04707179591059685, "_runtime": 579.6870861053467, "_timestamp": 1585419156.8335922, "_step": 423}
{"Episode reward": -115.22757462056353, "Episode length": 999, "Policy Loss": -0.15585099160671234, "Value Loss": 0.03927190601825714, "_runtime": 580.9572877883911, "_timestamp": 1585419158.1037939, "_step": 424}
{"Episode reward": -111.63949441826989, "Episode length": 999, "Policy Loss": -0.15228699147701263, "Value Loss": 0.03776661679148674, "_runtime": 582.1353569030762, "_timestamp": 1585419159.281863, "_step": 425}
{"Episode reward": -118.74939331744746, "Episode length": 999, "Policy Loss": -0.16434386372566223, "Value Loss": 0.04221230000257492, "_runtime": 583.2687668800354, "_timestamp": 1585419160.415273, "_step": 426}
{"Episode reward": -112.69321560680737, "Episode length": 999, "Policy Loss": -0.1460788995027542, "Value Loss": 0.03955690935254097, "_runtime": 584.4344699382782, "_timestamp": 1585419161.580976, "_step": 427}
{"Episode reward": -102.97887985722069, "Episode length": 999, "Policy Loss": -0.12968863546848297, "Value Loss": 0.03192099183797836, "_runtime": 585.6605429649353, "_timestamp": 1585419162.807049, "_step": 428}
{"Episode reward": -116.03912435086683, "Episode length": 999, "Policy Loss": -0.16872352361679077, "Value Loss": 0.03997349739074707, "_runtime": 586.8173060417175, "_timestamp": 1585419163.963812, "_step": 429}
{"Episode reward": -118.31706344916081, "Episode length": 999, "Policy Loss": -0.1605292707681656, "Value Loss": 0.04793284088373184, "_runtime": 588.0659530162811, "_timestamp": 1585419165.212459, "_step": 430}
{"Episode reward": -124.4598282364471, "Episode length": 999, "Policy Loss": -0.18014705181121826, "Value Loss": 0.04912945628166199, "_runtime": 589.3133299350739, "_timestamp": 1585419166.459836, "_step": 431}
{"Episode reward": -120.67483545546352, "Episode length": 999, "Policy Loss": -0.17054425179958344, "Value Loss": 0.04344431683421135, "_runtime": 590.5010709762573, "_timestamp": 1585419167.647577, "_step": 432}
{"Episode reward": -112.75157858960507, "Episode length": 999, "Policy Loss": -0.15463672578334808, "Value Loss": 0.03730449825525284, "_runtime": 591.6595938205719, "_timestamp": 1585419168.8061, "_step": 433}
{"Episode reward": -94.16321935767125, "Episode length": 999, "Policy Loss": -0.12225579470396042, "Value Loss": 0.02616807073354721, "_runtime": 592.8017148971558, "_timestamp": 1585419169.948221, "_step": 434}
{"Episode reward": -115.71419780431948, "Episode length": 999, "Policy Loss": -0.16348308324813843, "Value Loss": 0.040249474346637726, "_runtime": 593.964192867279, "_timestamp": 1585419171.110699, "_step": 435}
{"Episode reward": -113.66849906149481, "Episode length": 999, "Policy Loss": -0.15295593440532684, "Value Loss": 0.03644227609038353, "_runtime": 595.1863939762115, "_timestamp": 1585419172.3329, "_step": 436}
{"Episode reward": -113.96377953453496, "Episode length": 999, "Policy Loss": -0.1666320264339447, "Value Loss": 0.03814730420708656, "_runtime": 596.3642160892487, "_timestamp": 1585419173.5107222, "_step": 437}
{"Episode reward": -112.28878795432487, "Episode length": 999, "Policy Loss": -0.163458913564682, "Value Loss": 0.039315734058618546, "_runtime": 597.5478780269623, "_timestamp": 1585419174.694384, "_step": 438}
{"Episode reward": -117.47726588567221, "Episode length": 999, "Policy Loss": -0.16638489067554474, "Value Loss": 0.03988516330718994, "_runtime": 598.7223238945007, "_timestamp": 1585419175.86883, "_step": 439}
{"Episode reward": -118.86666167982943, "Episode length": 999, "Policy Loss": -0.1629406362771988, "Value Loss": 0.04183785989880562, "_runtime": 599.9683928489685, "_timestamp": 1585419177.114899, "_step": 440}
{"Episode reward": -110.11658688635666, "Episode length": 999, "Policy Loss": -0.15735693275928497, "Value Loss": 0.034137822687625885, "_runtime": 601.1601457595825, "_timestamp": 1585419178.3066518, "_step": 441}
{"Episode reward": -117.84976339752654, "Episode length": 999, "Policy Loss": -0.16760382056236267, "Value Loss": 0.03955945745110512, "_runtime": 602.320965051651, "_timestamp": 1585419179.4674711, "_step": 442}
{"Episode reward": -110.6345742873255, "Episode length": 999, "Policy Loss": -0.15989086031913757, "Value Loss": 0.033676691353321075, "_runtime": 603.5025577545166, "_timestamp": 1585419180.6490638, "_step": 443}
{"Episode reward": -120.9062523042698, "Episode length": 999, "Policy Loss": -0.16980183124542236, "Value Loss": 0.04281088709831238, "_runtime": 604.7150058746338, "_timestamp": 1585419181.861512, "_step": 444}
{"Episode reward": -105.67658570390837, "Episode length": 999, "Policy Loss": -0.14732781052589417, "Value Loss": 0.03769713267683983, "_runtime": 605.9487369060516, "_timestamp": 1585419183.095243, "_step": 445}
{"Episode reward": -109.85278910661322, "Episode length": 999, "Policy Loss": -0.14861205220222473, "Value Loss": 0.03682618588209152, "_runtime": 607.130049943924, "_timestamp": 1585419184.276556, "_step": 446}
{"Episode reward": -105.93295654963315, "Episode length": 999, "Policy Loss": -0.1436549723148346, "Value Loss": 0.03316734731197357, "_runtime": 608.2890198230743, "_timestamp": 1585419185.435526, "_step": 447}
{"Episode reward": -107.66588495538005, "Episode length": 999, "Policy Loss": -0.14647427201271057, "Value Loss": 0.03181638941168785, "_runtime": 609.4860420227051, "_timestamp": 1585419186.632548, "_step": 448}
{"Episode reward": -113.65619410245365, "Episode length": 999, "Policy Loss": -0.1520264744758606, "Value Loss": 0.03766978159546852, "_runtime": 610.7032868862152, "_timestamp": 1585419187.849793, "_step": 449}
{"Episode reward": -111.56954311541381, "Episode length": 999, "Policy Loss": -0.1576457917690277, "Value Loss": 0.036083437502384186, "_runtime": 611.9083330631256, "_timestamp": 1585419189.0548391, "_step": 450}
{"Episode reward": -102.11949059914778, "Episode length": 999, "Policy Loss": -0.1336277723312378, "Value Loss": 0.02964738942682743, "_runtime": 613.1475229263306, "_timestamp": 1585419190.294029, "_step": 451}
{"Episode reward": -102.93792512974179, "Episode length": 999, "Policy Loss": -0.1400042474269867, "Value Loss": 0.034213051199913025, "_runtime": 614.3466658592224, "_timestamp": 1585419191.493172, "_step": 452}
{"Episode reward": -105.75392198093313, "Episode length": 999, "Policy Loss": -0.1453191041946411, "Value Loss": 0.03567327558994293, "_runtime": 615.5348999500275, "_timestamp": 1585419192.681406, "_step": 453}
{"Episode reward": -106.39660167529895, "Episode length": 999, "Policy Loss": -0.142669215798378, "Value Loss": 0.03569189831614494, "_runtime": 616.6715018749237, "_timestamp": 1585419193.818008, "_step": 454}
{"Episode reward": -114.53833536231721, "Episode length": 999, "Policy Loss": -0.16138802468776703, "Value Loss": 0.03967759385704994, "_runtime": 617.8526289463043, "_timestamp": 1585419194.999135, "_step": 455}
{"Episode reward": -110.19583958826456, "Episode length": 999, "Policy Loss": -0.1465482860803604, "Value Loss": 0.034337449818849564, "_runtime": 619.0934979915619, "_timestamp": 1585419196.240004, "_step": 456}
{"Episode reward": -119.55360118962193, "Episode length": 999, "Policy Loss": -0.17179420590400696, "Value Loss": 0.04221762716770172, "_runtime": 620.3365240097046, "_timestamp": 1585419197.48303, "_step": 457}
{"Episode reward": -114.26909446704298, "Episode length": 999, "Policy Loss": -0.16210651397705078, "Value Loss": 0.03754120692610741, "_runtime": 621.5857579708099, "_timestamp": 1585419198.732264, "_step": 458}
{"Episode reward": -105.77902614922615, "Episode length": 999, "Policy Loss": -0.13843387365341187, "Value Loss": 0.03695160895586014, "_runtime": 622.7981629371643, "_timestamp": 1585419199.944669, "_step": 459}
{"Episode reward": -112.68613966609568, "Episode length": 999, "Policy Loss": -0.1498701572418213, "Value Loss": 0.03828034922480583, "_runtime": 624.065150976181, "_timestamp": 1585419201.211657, "_step": 460}
{"Episode reward": -105.1416591342613, "Episode length": 999, "Policy Loss": -0.14635050296783447, "Value Loss": 0.03546702116727829, "_runtime": 625.3125369548798, "_timestamp": 1585419202.459043, "_step": 461}
{"Episode reward": -106.34147075600282, "Episode length": 999, "Policy Loss": -0.1436300128698349, "Value Loss": 0.031950805336236954, "_runtime": 626.566241979599, "_timestamp": 1585419203.712748, "_step": 462}
{"Episode reward": -105.79984015487337, "Episode length": 999, "Policy Loss": -0.13375075161457062, "Value Loss": 0.032820332795381546, "_runtime": 627.7938868999481, "_timestamp": 1585419204.940393, "_step": 463}
{"Episode reward": -104.83810276384482, "Episode length": 999, "Policy Loss": -0.14154641330242157, "Value Loss": 0.03096175380051136, "_runtime": 628.9713878631592, "_timestamp": 1585419206.117894, "_step": 464}
{"Episode reward": -109.03121901757319, "Episode length": 999, "Policy Loss": -0.15192566812038422, "Value Loss": 0.03677788004279137, "_runtime": 630.4173810482025, "_timestamp": 1585419207.5638871, "_step": 465}
{"Episode reward": -118.99260912608403, "Episode length": 999, "Policy Loss": -0.1617407202720642, "Value Loss": 0.04347952827811241, "_runtime": 631.5805020332336, "_timestamp": 1585419208.727008, "_step": 466}
{"Episode reward": -112.89156188779168, "Episode length": 999, "Policy Loss": -0.14886943995952606, "Value Loss": 0.038058802485466, "_runtime": 632.7769100666046, "_timestamp": 1585419209.9234161, "_step": 467}
{"Episode reward": -114.2220533247923, "Episode length": 999, "Policy Loss": -0.17726999521255493, "Value Loss": 0.04018181934952736, "_runtime": 633.9451577663422, "_timestamp": 1585419211.0916638, "_step": 468}
{"Episode reward": -109.50125678536213, "Episode length": 999, "Policy Loss": -0.15492670238018036, "Value Loss": 0.03558835759758949, "_runtime": 635.1564908027649, "_timestamp": 1585419212.3029969, "_step": 469}
{"Episode reward": -106.30330247215768, "Episode length": 999, "Policy Loss": -0.14229616522789001, "Value Loss": 0.03322158008813858, "_runtime": 636.4013628959656, "_timestamp": 1585419213.547869, "_step": 470}
{"Episode reward": -106.16562986657854, "Episode length": 999, "Policy Loss": -0.1518029421567917, "Value Loss": 0.03408656641840935, "_runtime": 637.6938509941101, "_timestamp": 1585419214.840357, "_step": 471}
{"Episode reward": -108.88040992428655, "Episode length": 999, "Policy Loss": -0.14358839392662048, "Value Loss": 0.033867403864860535, "_runtime": 638.9482800960541, "_timestamp": 1585419216.0947862, "_step": 472}
{"Episode reward": -104.67065787330885, "Episode length": 999, "Policy Loss": -0.15019986033439636, "Value Loss": 0.03147200122475624, "_runtime": 640.3253617286682, "_timestamp": 1585419217.4718678, "_step": 473}
{"Episode reward": -93.66239646653804, "Episode length": 999, "Policy Loss": -0.12435462325811386, "Value Loss": 0.02491784654557705, "_runtime": 641.5745918750763, "_timestamp": 1585419218.721098, "_step": 474}
{"Episode reward": -107.71855914514177, "Episode length": 999, "Policy Loss": -0.14458218216896057, "Value Loss": 0.03216995671391487, "_runtime": 642.8428719043732, "_timestamp": 1585419219.989378, "_step": 475}
{"Episode reward": -95.79477770720351, "Episode length": 999, "Policy Loss": -0.12372042238712311, "Value Loss": 0.028172999620437622, "_runtime": 644.157506942749, "_timestamp": 1585419221.304013, "_step": 476}
{"Episode reward": -95.47549778357684, "Episode length": 999, "Policy Loss": -0.12048962712287903, "Value Loss": 0.02871900238096714, "_runtime": 645.3578770160675, "_timestamp": 1585419222.504383, "_step": 477}
{"Episode reward": -93.95209629334313, "Episode length": 999, "Policy Loss": -0.1281682550907135, "Value Loss": 0.024433419108390808, "_runtime": 646.5560169219971, "_timestamp": 1585419223.702523, "_step": 478}
{"Episode reward": -100.41261914257456, "Episode length": 999, "Policy Loss": -0.1381383240222931, "Value Loss": 0.03168570622801781, "_runtime": 647.7987470626831, "_timestamp": 1585419224.9452531, "_step": 479}
{"Episode reward": -103.87379286732462, "Episode length": 999, "Policy Loss": -0.1479649394750595, "Value Loss": 0.031951285898685455, "_runtime": 649.0085868835449, "_timestamp": 1585419226.155093, "_step": 480}
{"Episode reward": -107.03462362850713, "Episode length": 999, "Policy Loss": -0.146064892411232, "Value Loss": 0.034659355878829956, "_runtime": 650.2753200531006, "_timestamp": 1585419227.4218261, "_step": 481}
{"Episode reward": -93.2346771994421, "Episode length": 999, "Policy Loss": -0.12325722724199295, "Value Loss": 0.024951281026005745, "_runtime": 651.4996337890625, "_timestamp": 1585419228.6461399, "_step": 482}
{"Episode reward": -89.72116338986748, "Episode length": 999, "Policy Loss": -0.11562970280647278, "Value Loss": 0.02223420888185501, "_runtime": 652.6985988616943, "_timestamp": 1585419229.845105, "_step": 483}
{"Episode reward": -99.43145577957029, "Episode length": 999, "Policy Loss": -0.13138388097286224, "Value Loss": 0.029462065547704697, "_runtime": 653.8575091362, "_timestamp": 1585419231.0040152, "_step": 484}
{"Episode reward": -105.03087296100365, "Episode length": 999, "Policy Loss": -0.14666323363780975, "Value Loss": 0.031029755249619484, "_runtime": 655.1364457607269, "_timestamp": 1585419232.2829518, "_step": 485}
{"Episode reward": -110.46407709053669, "Episode length": 999, "Policy Loss": -0.16380414366722107, "Value Loss": 0.03918638080358505, "_runtime": 656.3691339492798, "_timestamp": 1585419233.51564, "_step": 486}
{"Episode reward": -103.4828973307555, "Episode length": 999, "Policy Loss": -0.14965659379959106, "Value Loss": 0.03022008202970028, "_runtime": 657.5632169246674, "_timestamp": 1585419234.709723, "_step": 487}
{"Episode reward": -105.70265888486222, "Episode length": 999, "Policy Loss": -0.15697646141052246, "Value Loss": 0.03382005915045738, "_runtime": 658.690908908844, "_timestamp": 1585419235.837415, "_step": 488}
{"Episode reward": -101.49296674628923, "Episode length": 999, "Policy Loss": -0.14066848158836365, "Value Loss": 0.027256352826952934, "_runtime": 659.90292096138, "_timestamp": 1585419237.049427, "_step": 489}
{"Episode reward": -98.72025947753093, "Episode length": 999, "Policy Loss": -0.1336677521467209, "Value Loss": 0.03316085413098335, "_runtime": 661.0832889080048, "_timestamp": 1585419238.229795, "_step": 490}
{"Episode reward": -92.97525414238326, "Episode length": 999, "Policy Loss": -0.11906671524047852, "Value Loss": 0.02437971532344818, "_runtime": 662.2582058906555, "_timestamp": 1585419239.404712, "_step": 491}
{"Episode reward": -99.99667495950493, "Episode length": 999, "Policy Loss": -0.13384093344211578, "Value Loss": 0.028033532202243805, "_runtime": 663.4239609241486, "_timestamp": 1585419240.570467, "_step": 492}
{"Episode reward": -97.21055117000152, "Episode length": 999, "Policy Loss": -0.1341589391231537, "Value Loss": 0.02786773256957531, "_runtime": 664.613627910614, "_timestamp": 1585419241.760134, "_step": 493}
{"Episode reward": -99.6278966251138, "Episode length": 999, "Policy Loss": -0.13245557248592377, "Value Loss": 0.03009789064526558, "_runtime": 665.8136479854584, "_timestamp": 1585419242.960154, "_step": 494}
{"Episode reward": -103.5986090969318, "Episode length": 999, "Policy Loss": -0.14899873733520508, "Value Loss": 0.033225882798433304, "_runtime": 667.1049649715424, "_timestamp": 1585419244.251471, "_step": 495}
{"Episode reward": -103.25042154223115, "Episode length": 999, "Policy Loss": -0.14064253866672516, "Value Loss": 0.032037168741226196, "_runtime": 668.327064037323, "_timestamp": 1585419245.47357, "_step": 496}
{"Episode reward": -102.14430375079164, "Episode length": 999, "Policy Loss": -0.14304323494434357, "Value Loss": 0.030557280406355858, "_runtime": 669.6514999866486, "_timestamp": 1585419246.798006, "_step": 497}
{"Episode reward": -106.01598406733453, "Episode length": 999, "Policy Loss": -0.15020892024040222, "Value Loss": 0.036158472299575806, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908, -4.789490222930908]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-4.3250322341918945, -4.217339038848877, -4.109645366668701, -4.001952171325684, -3.894258975982666, -3.7865655422210693, -3.6788721084594727, -3.571178913116455, -3.4634854793548584, -3.3557920455932617, -3.248098850250244, -3.1404054164886475, -3.032711982727051, -2.925018787384033, -2.8173253536224365, -2.70963191986084, -2.6019387245178223, -2.4942455291748047, -2.386552095413208, -2.2788586616516113, -2.1711654663085938, -2.063472032546997, -1.9557785987854004, -1.8480854034423828, -1.7403919696807861, -1.6326985359191895, -1.5250053405761719, -1.4173119068145752, -1.3096184730529785, -1.201925277709961, -1.0942318439483643, -0.9865386486053467, -0.87884521484375, -0.7711517810821533, -0.6634585857391357, -0.5557651519775391, -0.4480719566345215, -0.3403785228729248, -0.23268508911132812, -0.12499189376831055, -0.01729869842529297, 0.09039497375488281, 0.1980881690979004, 0.30578136444091797, 0.41347503662109375, 0.5211682319641113, 0.6288614273071289, 0.7365550994873047, 0.8442482948303223, 0.9519414901733398, 1.0596351623535156, 1.1673283576965332, 1.2750215530395508, 1.3827152252197266, 1.4904084205627441, 1.5981016159057617, 1.7057952880859375, 1.813488483428955, 1.9211816787719727, 2.0288748741149902, 2.136568546295166, 2.2442617416381836, 2.351954936981201, 2.459648609161377, 2.5673418045043945]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.275973081588745, -2.200845956802368, -2.1257190704345703, -2.0505919456481934, -1.9754648208618164, -1.900337815284729, -1.8252108097076416, -1.7500836849212646, -1.6749566793441772, -1.5998296737670898, -1.524702548980713, -1.4495755434036255, -1.374448537826538, -1.2993214130401611, -1.2241944074630737, -1.1490672826766968, -1.0739402770996094, -0.998813271522522, -0.923686146736145, -0.8485591411590576, -0.7734320163726807, -0.6983050107955933, -0.6231780052185059, -0.5480508804321289, -0.4729238748550415, -0.3977968692779541, -0.32266974449157715, -0.2475426197052002, -0.17241573333740234, -0.09728860855102539, -0.022161483764648438, 0.052965402603149414, 0.12809252738952637, 0.20321965217590332, 0.27834653854370117, 0.3534736633300781, 0.4286007881164551, 0.5037276744842529, 0.5788547992706299, 0.6539819240570068, 0.7291090488433838, 0.8042359352111816, 0.8793630599975586, 0.9544901847839355, 1.0296170711517334, 1.1047441959381104, 1.1798713207244873, 1.2549982070922852, 1.330125331878662, 1.405252456665039, 1.480379343032837, 1.5555064678192139, 1.6306335926055908, 1.7057604789733887, 1.7808878421783447, 1.8560144901275635, 1.9311416149139404, 2.0062687397003174, 2.0813958644866943, 2.1565229892730713, 2.2316501140594482, 2.306776762008667, 2.381903886795044, 2.457031011581421, 2.532158136367798]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 4.0, 3.0, 5.0, 3.0, 7.0, 2.0, 2.0, 6.0, 6.0, 5.0, 10.0, 14.0, 9.0, 31.0, 27.0, 23.0, 28.0, 50.0, 39.0, 56.0, 29.0, 17.0, 17.0, 11.0, 11.0, 10.0, 17.0, 12.0, 8.0, 3.0, 11.0, 3.0, 7.0, 5.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-1.964785099029541, -1.8999354839324951, -1.8350858688354492, -1.7702362537384033, -1.7053866386413574, -1.6405370235443115, -1.5756874084472656, -1.5108377933502197, -1.4459881782531738, -1.381138563156128, -1.316288948059082, -1.2514393329620361, -1.1865897178649902, -1.1217401027679443, -1.0568904876708984, -0.9920408725738525, -0.9271912574768066, -0.8623416423797607, -0.7974920272827148, -0.732642412185669, -0.667792797088623, -0.6029431819915771, -0.5380935668945312, -0.47324395179748535, -0.40839433670043945, -0.34354472160339355, -0.27869510650634766, -0.21384549140930176, -0.14899587631225586, -0.08414626121520996, -0.019296646118164062, 0.045552968978881836, 0.11040258407592773, 0.17525219917297363, 0.24010181427001953, 0.30495142936706543, 0.36980104446411133, 0.4346506595611572, 0.4995002746582031, 0.564349889755249, 0.6291995048522949, 0.6940491199493408, 0.7588987350463867, 0.8237483501434326, 0.8885979652404785, 0.9534475803375244, 1.0182971954345703, 1.0831468105316162, 1.147996425628662, 1.212846040725708, 1.277695655822754, 1.3425452709197998, 1.4073948860168457, 1.4722445011138916, 1.5370941162109375, 1.6019437313079834, 1.6667933464050293, 1.7316429615020752, 1.796492576599121, 1.861342191696167, 1.926191806793213, 1.9910414218902588, 2.0558910369873047, 2.1207404136657715, 2.1855902671813965]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.062176465988159, -2.0106289386749268, -1.9590811729431152, -1.9075335264205933, -1.8559858798980713, -1.8044383525848389, -1.752890706062317, -1.701343059539795, -1.649795413017273, -1.598247766494751, -1.546700119972229, -1.495152473449707, -1.4436049461364746, -1.392057180404663, -1.3405096530914307, -1.2889620065689087, -1.2374143600463867, -1.1858667135238647, -1.1343190670013428, -1.0827715396881104, -1.0312237739562988, -0.9796762466430664, -0.9281286001205444, -0.8765809535980225, -0.8250333070755005, -0.7734856605529785, -0.7219380140304565, -0.6703903675079346, -0.6188428401947021, -0.5672951936721802, -0.5157475471496582, -0.46419990062713623, -0.41265225410461426, -0.3611046075820923, -0.3095569610595703, -0.25800931453704834, -0.20646166801452637, -0.15491414070129395, -0.10336649417877197, -0.05181884765625, -0.00027108192443847656, 0.051276445388793945, 0.10282397270202637, 0.1543717384338379, 0.2059192657470703, 0.25746703147888184, 0.30901455879211426, 0.3605623245239258, 0.4121098518371582, 0.4636573791503906, 0.5152051448822021, 0.5667526721954346, 0.6183004379272461, 0.6698479652404785, 0.72139573097229, 0.7729432582855225, 0.8244907855987549, 0.8760385513305664, 0.9275860786437988, 0.9791338443756104, 1.0306813716888428, 1.0822291374206543, 1.1337766647338867, 1.1853244304656982, 1.2368719577789307]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 32.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.7221312522888184, -0.691823422908783, -0.6615155935287476, -0.6312077641487122, -0.6008999347686768, -0.5705920457839966, -0.5402842164039612, -0.5099763870239258, -0.4796685576438904, -0.449360728263855, -0.4190528988838196, -0.3887450397014618, -0.3584372103214264, -0.328129380941391, -0.2978215217590332, -0.2675136923789978, -0.2372058629989624, -0.206898033618927, -0.1765902042388916, -0.1462823748588562, -0.1159745454788208, -0.08566665649414062, -0.055358827114105225, -0.025050997734069824, 0.005256831645965576, 0.03556466102600098, 0.06587249040603638, 0.09618031978607178, 0.12648820877075195, 0.15679603815078735, 0.18710386753082275, 0.21741169691085815, 0.24771952629089355, 0.27802741527557373, 0.30833518505096436, 0.33864307403564453, 0.36895084381103516, 0.39925873279571533, 0.42956650257110596, 0.45987439155578613, 0.49018216133117676, 0.5204900503158569, 0.5507979393005371, 0.5811057090759277, 0.6114135980606079, 0.6417213678359985, 0.6720292568206787, 0.7023370265960693, 0.7326449155807495, 0.7629528045654297, 0.7932605743408203, 0.8235684633255005, 0.8538762331008911, 0.8841841220855713, 0.9144918918609619, 0.9447997808456421, 0.9751076698303223, 1.005415439605713, 1.035723328590393, 1.0660310983657837, 1.0963389873504639, 1.1266467571258545, 1.1569546461105347, 1.1872624158859253, 1.2175703048706055]}, "_runtime": 670.8785820007324, "_timestamp": 1585419248.025088, "_step": 498}
{"Episode reward": -94.57014272728222, "Episode length": 999, "Policy Loss": -0.12661074101924896, "Value Loss": 0.025671998038887978, "_runtime": 672.0712168216705, "_timestamp": 1585419249.217723, "_step": 499}
