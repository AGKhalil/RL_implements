{"Episode reward": -98.94961598629234, "Episode length": 999, "Policy Loss": -12.497897148132324, "Value Loss": 0.029835058376193047, "_runtime": 12.359278678894043, "_timestamp": 1585079445.4485247, "_step": 0}
{"Episode reward": -92.06211382519305, "Episode length": 999, "Policy Loss": -11.711997985839844, "Value Loss": 0.024859176948666573, "_runtime": 13.449290990829468, "_timestamp": 1585079446.538537, "_step": 1}
{"Episode reward": -106.38533129549512, "Episode length": 999, "Policy Loss": -13.91836929321289, "Value Loss": 0.0331832580268383, "_runtime": 14.55427861213684, "_timestamp": 1585079447.6435246, "_step": 2}
{"Episode reward": -99.90039461567302, "Episode length": 999, "Policy Loss": -12.896820068359375, "Value Loss": 0.032590121030807495, "_runtime": 15.6484694480896, "_timestamp": 1585079448.7377155, "_step": 3}
{"Episode reward": -103.89707212916942, "Episode length": 999, "Policy Loss": -13.301694869995117, "Value Loss": 0.030702047049999237, "_runtime": 16.78061866760254, "_timestamp": 1585079449.8698647, "_step": 4}
{"Episode reward": -104.30806449217162, "Episode length": 999, "Policy Loss": -13.489013671875, "Value Loss": 0.034737978130578995, "_runtime": 17.90450620651245, "_timestamp": 1585079450.9937522, "_step": 5}
{"Episode reward": -104.09192046037268, "Episode length": 999, "Policy Loss": -13.54894733428955, "Value Loss": 0.030830327421426773, "_runtime": 19.055212020874023, "_timestamp": 1585079452.144458, "_step": 6}
{"Episode reward": -99.3898153916103, "Episode length": 999, "Policy Loss": -12.663521766662598, "Value Loss": 0.028169497847557068, "_runtime": 20.17358636856079, "_timestamp": 1585079453.2628324, "_step": 7}
{"Episode reward": -105.44087284849883, "Episode length": 999, "Policy Loss": -13.713029861450195, "Value Loss": 0.032096702605485916, "_runtime": 21.322511196136475, "_timestamp": 1585079454.4117572, "_step": 8}
{"Episode reward": -104.5374795381276, "Episode length": 999, "Policy Loss": -13.514945983886719, "Value Loss": 0.03272375464439392, "_runtime": 22.435145616531372, "_timestamp": 1585079455.5243917, "_step": 9}
{"Episode reward": -102.75494496551009, "Episode length": 999, "Policy Loss": -13.419278144836426, "Value Loss": 0.03207669407129288, "_runtime": 23.557759523391724, "_timestamp": 1585079456.6470056, "_step": 10}
{"Episode reward": -108.29767331392483, "Episode length": 999, "Policy Loss": -14.239513397216797, "Value Loss": 0.040280088782310486, "_runtime": 24.67040777206421, "_timestamp": 1585079457.7596538, "_step": 11}
{"Episode reward": -103.25139469392202, "Episode length": 999, "Policy Loss": -13.546048164367676, "Value Loss": 0.030344057828187943, "_runtime": 25.825772047042847, "_timestamp": 1585079458.915018, "_step": 12}
{"Episode reward": -93.7663285809367, "Episode length": 999, "Policy Loss": -11.66588020324707, "Value Loss": 0.026598133146762848, "_runtime": 26.982434034347534, "_timestamp": 1585079460.07168, "_step": 13}
{"Episode reward": -109.47737318973566, "Episode length": 999, "Policy Loss": -14.608716011047363, "Value Loss": 0.03479740768671036, "_runtime": 28.1094970703125, "_timestamp": 1585079461.198743, "_step": 14}
{"Episode reward": -96.86703290470834, "Episode length": 999, "Policy Loss": -12.589529991149902, "Value Loss": 0.027149435132741928, "_runtime": 29.264824390411377, "_timestamp": 1585079462.3540704, "_step": 15}
{"Episode reward": -97.78617680857522, "Episode length": 999, "Policy Loss": -12.575037002563477, "Value Loss": 0.02843853458762169, "_runtime": 30.429627656936646, "_timestamp": 1585079463.5188737, "_step": 16}
{"Episode reward": -99.56440141785069, "Episode length": 999, "Policy Loss": -12.739391326904297, "Value Loss": 0.03306857496500015, "_runtime": 31.538548707962036, "_timestamp": 1585079464.6277947, "_step": 17}
{"Episode reward": -101.6244094248475, "Episode length": 999, "Policy Loss": -13.021284103393555, "Value Loss": 0.02970946580171585, "_runtime": 32.65998983383179, "_timestamp": 1585079465.7492359, "_step": 18}
{"Episode reward": -96.05701766240038, "Episode length": 999, "Policy Loss": -12.318286895751953, "Value Loss": 0.030543752014636993, "_runtime": 33.79386591911316, "_timestamp": 1585079466.883112, "_step": 19}
{"Episode reward": -95.56070316649924, "Episode length": 999, "Policy Loss": -12.255516052246094, "Value Loss": 0.026696087792515755, "_runtime": 34.99110698699951, "_timestamp": 1585079468.080353, "_step": 20}
{"Episode reward": -100.73841821975775, "Episode length": 999, "Policy Loss": -12.95947551727295, "Value Loss": 0.035342779010534286, "_runtime": 36.13523840904236, "_timestamp": 1585079469.2244844, "_step": 21}
{"Episode reward": -103.80559465189825, "Episode length": 999, "Policy Loss": -13.571073532104492, "Value Loss": 0.029033618047833443, "_runtime": 37.2530517578125, "_timestamp": 1585079470.3422978, "_step": 22}
{"Episode reward": -99.1371898045661, "Episode length": 999, "Policy Loss": -12.673205375671387, "Value Loss": 0.027650462463498116, "_runtime": 38.429229974746704, "_timestamp": 1585079471.518476, "_step": 23}
{"Episode reward": -106.95109968667617, "Episode length": 999, "Policy Loss": -14.055835723876953, "Value Loss": 0.03501109033823013, "_runtime": 39.54281210899353, "_timestamp": 1585079472.6320581, "_step": 24}
{"Episode reward": -102.91251344293899, "Episode length": 999, "Policy Loss": -13.530362129211426, "Value Loss": 0.03267892822623253, "_runtime": 40.647865295410156, "_timestamp": 1585079473.7371113, "_step": 25}
{"Episode reward": -108.77633247726443, "Episode length": 999, "Policy Loss": -14.501163482666016, "Value Loss": 0.03588365390896797, "_runtime": 41.78544044494629, "_timestamp": 1585079474.8746865, "_step": 26}
{"Episode reward": -102.89593296513102, "Episode length": 999, "Policy Loss": -13.302286148071289, "Value Loss": 0.03156081959605217, "_runtime": 42.923677921295166, "_timestamp": 1585079476.012924, "_step": 27}
{"Episode reward": -103.31939276502327, "Episode length": 999, "Policy Loss": -13.4403657913208, "Value Loss": 0.031743865460157394, "_runtime": 44.04755711555481, "_timestamp": 1585079477.1368032, "_step": 28}
{"Episode reward": -108.3873843524033, "Episode length": 999, "Policy Loss": -14.267196655273438, "Value Loss": 0.03968251124024391, "_runtime": 45.21398878097534, "_timestamp": 1585079478.3032348, "_step": 29}
{"Episode reward": -99.52569281327175, "Episode length": 999, "Policy Loss": -12.808357238769531, "Value Loss": 0.028493143618106842, "_runtime": 46.34396290779114, "_timestamp": 1585079479.433209, "_step": 30}
{"Episode reward": -101.38424636853966, "Episode length": 999, "Policy Loss": -12.852798461914062, "Value Loss": 0.03425861522555351, "_runtime": 47.468600273132324, "_timestamp": 1585079480.5578463, "_step": 31}
{"Episode reward": -104.33688089439642, "Episode length": 999, "Policy Loss": -13.495633125305176, "Value Loss": 0.03502729535102844, "_runtime": 48.59765601158142, "_timestamp": 1585079481.686902, "_step": 32}
{"Episode reward": -110.38356871910202, "Episode length": 999, "Policy Loss": -14.704218864440918, "Value Loss": 0.035342395305633545, "_runtime": 49.719117403030396, "_timestamp": 1585079482.8083634, "_step": 33}
{"Episode reward": -101.59371393399316, "Episode length": 999, "Policy Loss": -13.262665748596191, "Value Loss": 0.029985854402184486, "_runtime": 50.85111117362976, "_timestamp": 1585079483.9403572, "_step": 34}
{"Episode reward": -103.09608977186478, "Episode length": 999, "Policy Loss": -13.460866928100586, "Value Loss": 0.03288107365369797, "_runtime": 51.96462798118591, "_timestamp": 1585079485.053874, "_step": 35}
{"Episode reward": -106.95968412940857, "Episode length": 999, "Policy Loss": -14.058088302612305, "Value Loss": 0.033171579241752625, "_runtime": 53.09495830535889, "_timestamp": 1585079486.1842043, "_step": 36}
{"Episode reward": -108.25498643093756, "Episode length": 999, "Policy Loss": -14.373197555541992, "Value Loss": 0.03765758499503136, "_runtime": 54.254533767700195, "_timestamp": 1585079487.3437798, "_step": 37}
{"Episode reward": -98.23354691503728, "Episode length": 999, "Policy Loss": -12.592111587524414, "Value Loss": 0.02861841395497322, "_runtime": 55.36340641975403, "_timestamp": 1585079488.4526525, "_step": 38}
{"Episode reward": -97.82300499719858, "Episode length": 999, "Policy Loss": -12.435441970825195, "Value Loss": 0.02819673717021942, "_runtime": 56.516457319259644, "_timestamp": 1585079489.6057034, "_step": 39}
{"Episode reward": -95.74354751972177, "Episode length": 999, "Policy Loss": -12.017622947692871, "Value Loss": 0.026677913963794708, "_runtime": 57.63625621795654, "_timestamp": 1585079490.7255023, "_step": 40}
{"Episode reward": -105.18312809167102, "Episode length": 999, "Policy Loss": -13.608609199523926, "Value Loss": 0.0323878675699234, "_runtime": 58.74515676498413, "_timestamp": 1585079491.8344028, "_step": 41}
{"Episode reward": -100.0714953372336, "Episode length": 999, "Policy Loss": -12.792108535766602, "Value Loss": 0.03353069722652435, "_runtime": 59.85048460960388, "_timestamp": 1585079492.9397306, "_step": 42}
{"Episode reward": -98.49396375263885, "Episode length": 999, "Policy Loss": -12.538743019104004, "Value Loss": 0.03159130737185478, "_runtime": 60.97480845451355, "_timestamp": 1585079494.0640545, "_step": 43}
{"Episode reward": -103.58368863290764, "Episode length": 999, "Policy Loss": -13.228367805480957, "Value Loss": 0.03076133504509926, "_runtime": 62.06788778305054, "_timestamp": 1585079495.1571338, "_step": 44}
{"Episode reward": -103.79793645786496, "Episode length": 999, "Policy Loss": -13.382163047790527, "Value Loss": 0.031027359887957573, "_runtime": 63.230005741119385, "_timestamp": 1585079496.3192518, "_step": 45}
{"Episode reward": -107.4290562242411, "Episode length": 999, "Policy Loss": -14.313749313354492, "Value Loss": 0.038267455995082855, "_runtime": 64.36240839958191, "_timestamp": 1585079497.4516544, "_step": 46}
{"Episode reward": -98.68755780005678, "Episode length": 999, "Policy Loss": -12.67298412322998, "Value Loss": 0.029021328315138817, "_runtime": 65.47407221794128, "_timestamp": 1585079498.5633183, "_step": 47}
{"Episode reward": -91.35445654202582, "Episode length": 999, "Policy Loss": -11.506871223449707, "Value Loss": 0.025969961658120155, "_runtime": 66.64776825904846, "_timestamp": 1585079499.7370143, "_step": 48}
{"Episode reward": -104.26249516676356, "Episode length": 999, "Policy Loss": -13.794462203979492, "Value Loss": 0.03535488620400429, "_runtime": 67.75145053863525, "_timestamp": 1585079500.8406966, "_step": 49}
{"Episode reward": -102.40294192952942, "Episode length": 999, "Policy Loss": -13.099763870239258, "Value Loss": 0.03428097069263458, "_runtime": 68.87471294403076, "_timestamp": 1585079501.963959, "_step": 50}
{"Episode reward": -94.9733584979544, "Episode length": 999, "Policy Loss": -11.99710750579834, "Value Loss": 0.027319669723510742, "_runtime": 70.01170110702515, "_timestamp": 1585079503.1009471, "_step": 51}
{"Episode reward": -102.031961388769, "Episode length": 999, "Policy Loss": -13.262486457824707, "Value Loss": 0.0344843715429306, "_runtime": 71.1301703453064, "_timestamp": 1585079504.2194164, "_step": 52}
{"Episode reward": -92.39063915056332, "Episode length": 999, "Policy Loss": -11.70467758178711, "Value Loss": 0.024378476664423943, "_runtime": 72.24149823188782, "_timestamp": 1585079505.3307443, "_step": 53}
{"Episode reward": -100.03513044627971, "Episode length": 999, "Policy Loss": -13.13302230834961, "Value Loss": 0.030188772827386856, "_runtime": 73.40450167655945, "_timestamp": 1585079506.4937477, "_step": 54}
{"Episode reward": -99.36742683005636, "Episode length": 999, "Policy Loss": -12.651188850402832, "Value Loss": 0.02848747745156288, "_runtime": 74.52942395210266, "_timestamp": 1585079507.61867, "_step": 55}
{"Episode reward": -112.2378707457526, "Episode length": 999, "Policy Loss": -15.127684593200684, "Value Loss": 0.03566274791955948, "_runtime": 75.67014074325562, "_timestamp": 1585079508.7593868, "_step": 56}
{"Episode reward": -101.42818723776519, "Episode length": 999, "Policy Loss": -13.25500774383545, "Value Loss": 0.03118353709578514, "_runtime": 76.84350180625916, "_timestamp": 1585079509.9327478, "_step": 57}
{"Episode reward": -109.21471971191448, "Episode length": 999, "Policy Loss": -14.601127624511719, "Value Loss": 0.03383099287748337, "_runtime": 77.97047519683838, "_timestamp": 1585079511.0597212, "_step": 58}
{"Episode reward": -98.58164796601753, "Episode length": 999, "Policy Loss": -12.570463180541992, "Value Loss": 0.027781706303358078, "_runtime": 79.12730813026428, "_timestamp": 1585079512.2165542, "_step": 59}
{"Episode reward": -109.57331677925109, "Episode length": 999, "Policy Loss": -14.961518287658691, "Value Loss": 0.037265241146087646, "_runtime": 80.27856278419495, "_timestamp": 1585079513.3678088, "_step": 60}
{"Episode reward": -94.75152867888796, "Episode length": 999, "Policy Loss": -11.995725631713867, "Value Loss": 0.028324026614427567, "_runtime": 81.38019180297852, "_timestamp": 1585079514.4694378, "_step": 61}
{"Episode reward": -104.43435939125987, "Episode length": 999, "Policy Loss": -13.7049560546875, "Value Loss": 0.031076692044734955, "_runtime": 82.49213147163391, "_timestamp": 1585079515.5813775, "_step": 62}
{"Episode reward": -94.19935708897354, "Episode length": 999, "Policy Loss": -11.92544174194336, "Value Loss": 0.025660265237092972, "_runtime": 83.61984634399414, "_timestamp": 1585079516.7090924, "_step": 63}
{"Episode reward": -95.21022421997598, "Episode length": 999, "Policy Loss": -12.236448287963867, "Value Loss": 0.025990663096308708, "_runtime": 84.76660943031311, "_timestamp": 1585079517.8558555, "_step": 64}
{"Episode reward": -100.9062082863368, "Episode length": 999, "Policy Loss": -12.85767650604248, "Value Loss": 0.031313709914684296, "_runtime": 85.94450330734253, "_timestamp": 1585079519.0337493, "_step": 65}
{"Episode reward": -99.3131942188844, "Episode length": 999, "Policy Loss": -12.970069885253906, "Value Loss": 0.02697247639298439, "_runtime": 87.058176279068, "_timestamp": 1585079520.1474223, "_step": 66}
{"Episode reward": -95.32042087976778, "Episode length": 999, "Policy Loss": -11.914325714111328, "Value Loss": 0.02609870210289955, "_runtime": 88.21351170539856, "_timestamp": 1585079521.3027577, "_step": 67}
{"Episode reward": -92.29789436739269, "Episode length": 999, "Policy Loss": -11.42914867401123, "Value Loss": 0.025434980168938637, "_runtime": 89.35659432411194, "_timestamp": 1585079522.4458404, "_step": 68}
{"Episode reward": -103.45911500904701, "Episode length": 999, "Policy Loss": -13.592070579528809, "Value Loss": 0.03212689235806465, "_runtime": 90.45308637619019, "_timestamp": 1585079523.5423324, "_step": 69}
{"Episode reward": -102.5121319420717, "Episode length": 999, "Policy Loss": -13.581345558166504, "Value Loss": 0.0287854615598917, "_runtime": 91.5606336593628, "_timestamp": 1585079524.6498797, "_step": 70}
{"Episode reward": -104.15211237077573, "Episode length": 999, "Policy Loss": -13.653864860534668, "Value Loss": 0.032407719641923904, "_runtime": 92.67241430282593, "_timestamp": 1585079525.7616603, "_step": 71}
{"Episode reward": -98.55537369848437, "Episode length": 999, "Policy Loss": -12.6106595993042, "Value Loss": 0.029112838208675385, "_runtime": 93.84431433677673, "_timestamp": 1585079526.9335604, "_step": 72}
{"Episode reward": -98.63254917475975, "Episode length": 999, "Policy Loss": -12.617431640625, "Value Loss": 0.030639173462986946, "_runtime": 95.05498313903809, "_timestamp": 1585079528.1442292, "_step": 73}
{"Episode reward": -100.92814231632241, "Episode length": 999, "Policy Loss": -12.939217567443848, "Value Loss": 0.030357778072357178, "_runtime": 96.164142370224, "_timestamp": 1585079529.2533884, "_step": 74}
{"Episode reward": -103.82638965376971, "Episode length": 999, "Policy Loss": -13.672857284545898, "Value Loss": 0.0310355331748724, "_runtime": 97.27461504936218, "_timestamp": 1585079530.363861, "_step": 75}
{"Episode reward": -98.23841528999361, "Episode length": 999, "Policy Loss": -12.571915626525879, "Value Loss": 0.031999241560697556, "_runtime": 98.40753436088562, "_timestamp": 1585079531.4967804, "_step": 76}
{"Episode reward": -104.4817170020067, "Episode length": 999, "Policy Loss": -13.616119384765625, "Value Loss": 0.031089989468455315, "_runtime": 99.52463459968567, "_timestamp": 1585079532.6138806, "_step": 77}
{"Episode reward": -95.40101691044008, "Episode length": 999, "Policy Loss": -12.202849388122559, "Value Loss": 0.027618825435638428, "_runtime": 100.61846423149109, "_timestamp": 1585079533.7077103, "_step": 78}
{"Episode reward": -107.38060624780461, "Episode length": 999, "Policy Loss": -14.492079734802246, "Value Loss": 0.035184916108846664, "_runtime": 101.73322463035583, "_timestamp": 1585079534.8224707, "_step": 79}
{"Episode reward": -99.49662972795049, "Episode length": 999, "Policy Loss": -12.724023818969727, "Value Loss": 0.030365999788045883, "_runtime": 102.86439514160156, "_timestamp": 1585079535.9536412, "_step": 80}
{"Episode reward": -102.29186188845502, "Episode length": 999, "Policy Loss": -13.204126358032227, "Value Loss": 0.03083193302154541, "_runtime": 103.99810814857483, "_timestamp": 1585079537.0873542, "_step": 81}
{"Episode reward": -97.73084316587872, "Episode length": 999, "Policy Loss": -12.599894523620605, "Value Loss": 0.0294584222137928, "_runtime": 105.13896822929382, "_timestamp": 1585079538.2282143, "_step": 82}
{"Episode reward": -105.94837278153378, "Episode length": 999, "Policy Loss": -14.089631080627441, "Value Loss": 0.03172019496560097, "_runtime": 106.25315356254578, "_timestamp": 1585079539.3423996, "_step": 83}
{"Episode reward": -92.25691799479485, "Episode length": 999, "Policy Loss": -11.700115203857422, "Value Loss": 0.025141684338450432, "_runtime": 107.39827299118042, "_timestamp": 1585079540.487519, "_step": 84}
{"Episode reward": -105.71895945323031, "Episode length": 999, "Policy Loss": -13.924752235412598, "Value Loss": 0.033168334513902664, "_runtime": 108.52819681167603, "_timestamp": 1585079541.6174428, "_step": 85}
{"Episode reward": -104.68333407407302, "Episode length": 999, "Policy Loss": -13.822701454162598, "Value Loss": 0.03432402014732361, "_runtime": 109.63141679763794, "_timestamp": 1585079542.7206628, "_step": 86}
{"Episode reward": -105.08992956955785, "Episode length": 999, "Policy Loss": -13.790980339050293, "Value Loss": 0.03199760988354683, "_runtime": 110.7361056804657, "_timestamp": 1585079543.8253517, "_step": 87}
{"Episode reward": -97.96227247952655, "Episode length": 999, "Policy Loss": -12.425832748413086, "Value Loss": 0.029666852205991745, "_runtime": 111.87427496910095, "_timestamp": 1585079544.963521, "_step": 88}
{"Episode reward": -108.48103654414518, "Episode length": 999, "Policy Loss": -14.424574851989746, "Value Loss": 0.03466254845261574, "_runtime": 113.06108784675598, "_timestamp": 1585079546.150334, "_step": 89}
{"Episode reward": -97.23743530113487, "Episode length": 999, "Policy Loss": -12.292525291442871, "Value Loss": 0.029896840453147888, "_runtime": 114.19652247428894, "_timestamp": 1585079547.2857685, "_step": 90}
{"Episode reward": -105.60034316271503, "Episode length": 999, "Policy Loss": -13.731118202209473, "Value Loss": 0.03241222724318504, "_runtime": 115.34903335571289, "_timestamp": 1585079548.4382794, "_step": 91}
{"Episode reward": -99.5172553201046, "Episode length": 999, "Policy Loss": -12.749490737915039, "Value Loss": 0.03083229251205921, "_runtime": 116.44974207878113, "_timestamp": 1585079549.538988, "_step": 92}
{"Episode reward": -103.44213304904561, "Episode length": 999, "Policy Loss": -13.70213508605957, "Value Loss": 0.03391275182366371, "_runtime": 117.56775712966919, "_timestamp": 1585079550.6570032, "_step": 93}
{"Episode reward": -105.75824201769612, "Episode length": 999, "Policy Loss": -13.805363655090332, "Value Loss": 0.03135569393634796, "_runtime": 118.66584944725037, "_timestamp": 1585079551.7550955, "_step": 94}
{"Episode reward": -95.92093709615378, "Episode length": 999, "Policy Loss": -11.913931846618652, "Value Loss": 0.026468349620699883, "_runtime": 119.76451683044434, "_timestamp": 1585079552.8537629, "_step": 95}
{"Episode reward": -94.57410720446903, "Episode length": 999, "Policy Loss": -12.041399002075195, "Value Loss": 0.02735186740756035, "_runtime": 120.90130853652954, "_timestamp": 1585079553.9905546, "_step": 96}
{"Episode reward": -103.84170327272624, "Episode length": 999, "Policy Loss": -13.675398826599121, "Value Loss": 0.03150632977485657, "_runtime": 122.03243565559387, "_timestamp": 1585079555.1216817, "_step": 97}
{"Episode reward": -94.69557092914462, "Episode length": 999, "Policy Loss": -12.146007537841797, "Value Loss": 0.028226425871253014, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875, 535.5037841796875]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-299.0596618652344, -286.28839111328125, -273.51715087890625, -260.7458801269531, -247.974609375, -235.20333862304688, -222.4320831298828, -209.66082763671875, -196.88955688476562, -184.1182861328125, -171.34703063964844, -158.57577514648438, -145.80450439453125, -133.03323364257812, -120.26197814941406, -107.49072265625, -94.71945190429688, -81.94818115234375, -69.17692565917969, -56.405670166015625, -43.6343994140625, -30.863128662109375, -18.091888427734375, -5.32061767578125, 7.450653076171875, 20.221923828125, 32.993194580078125, 45.764434814453125, 58.53570556640625, 71.30697631835938, 84.07821655273438, 96.8494873046875, 109.62075805664062, 122.39202880859375, 135.16329956054688, 147.93453979492188, 160.705810546875, 173.47708129882812, 186.24832153320312, 199.01959228515625, 211.79086303710938, 224.56210327148438, 237.33340454101562, 250.10464477539062, 262.8758850097656, 275.6471862792969, 288.4184265136719, 301.1897277832031, 313.9609680175781, 326.7322082519531, 339.5035095214844, 352.2747497558594, 365.0460510253906, 377.8172912597656, 390.5885314941406, 403.3598327636719, 416.1310729980469, 428.9023132324219, 441.6736145019531, 454.4448547363281, 467.2160949707031, 479.9873962402344, 492.7586364746094, 505.5299377441406, 518.3011474609375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-293.43426513671875, -284.8412780761719, -276.2482604980469, -267.6552734375, -259.0622863769531, -250.4692840576172, -241.87628173828125, -233.28329467773438, -224.69029235839844, -216.0972900390625, -207.50430297851562, -198.9113006591797, -190.31829833984375, -181.72531127929688, -173.13230895996094, -164.53932189941406, -155.94631958007812, -147.3533172607422, -138.7603302001953, -130.16732788085938, -121.5743408203125, -112.98133850097656, -104.38833618164062, -95.79534912109375, -87.20234680175781, -78.60934448242188, -70.016357421875, -61.42335510253906, -52.830352783203125, -44.23736572265625, -35.644378662109375, -27.051361083984375, -18.4583740234375, -9.865386962890625, -1.272369384765625, 7.32061767578125, 15.913604736328125, 24.506622314453125, 33.099609375, 41.692596435546875, 50.28558349609375, 58.87860107421875, 67.47158813476562, 76.0645751953125, 84.6575927734375, 93.25057983398438, 101.84356689453125, 110.43658447265625, 119.02957153320312, 127.62255859375, 136.215576171875, 144.80856323242188, 153.40155029296875, 161.99456787109375, 170.58755493164062, 179.1805419921875, 187.7735595703125, 196.36654663085938, 204.95953369140625, 213.55252075195312, 222.1455078125, 230.738525390625, 239.33154296875, 247.92449951171875, 256.51751708984375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 4.0, 7.0, 6.0, 5.0, 8.0, 5.0, 12.0, 12.0, 13.0, 11.0, 13.0, 17.0, 12.0, 25.0, 48.0, 47.0, 40.0, 38.0, 22.0, 30.0, 31.0, 15.0, 15.0, 14.0, 3.0, 7.0, 6.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 5.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0], "bins": [-258.529052734375, -250.95823669433594, -243.3874053955078, -235.81658935546875, -228.24575805664062, -220.67494201660156, -213.10411071777344, -205.53329467773438, -197.96246337890625, -190.3916473388672, -182.82083129882812, -175.25, -167.67916870117188, -160.1083526611328, -152.53753662109375, -144.96670532226562, -137.3958740234375, -129.82505798339844, -122.25424194335938, -114.68341064453125, -107.11259460449219, -99.54176330566406, -91.970947265625, -84.40011596679688, -76.82929992675781, -69.25846862792969, -61.687652587890625, -54.1168212890625, -46.54600524902344, -38.97517395019531, -31.40435791015625, -23.833526611328125, -16.262710571289062, -8.69189453125, -1.121063232421875, 6.44976806640625, 14.02056884765625, 21.591400146484375, 29.1622314453125, 36.733062744140625, 44.303863525390625, 51.87469482421875, 59.445526123046875, 67.016357421875, 74.587158203125, 82.15798950195312, 89.72882080078125, 97.29965209960938, 104.87045288085938, 112.4412841796875, 120.01211547851562, 127.58291625976562, 135.15374755859375, 142.72457885742188, 150.29541015625, 157.8662109375, 165.43704223632812, 173.00787353515625, 180.57870483398438, 188.14950561523438, 195.7203369140625, 203.29116821289062, 210.86199951171875, 218.43280029296875, 226.00363159179688]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-112.85385131835938, -107.87908935546875, -102.90433502197266, -97.92957305908203, -92.95481872558594, -87.98005676269531, -83.00529479980469, -78.03053283691406, -73.05577850341797, -68.08102416992188, -63.10626220703125, -58.131500244140625, -53.156742095947266, -48.181983947753906, -43.20722198486328, -38.23246765136719, -33.25770568847656, -28.282943725585938, -23.308189392089844, -18.33342742919922, -13.358673095703125, -8.3839111328125, -3.409149169921875, 1.5656051635742188, 6.540367126464844, 11.515129089355469, 16.489883422851562, 21.464645385742188, 26.439407348632812, 31.414169311523438, 36.388916015625, 41.363677978515625, 46.33843994140625, 51.313201904296875, 56.2879638671875, 61.26271057128906, 66.23747253417969, 71.21223449707031, 76.18699645996094, 81.16175842285156, 86.13650512695312, 91.11126708984375, 96.08602905273438, 101.060791015625, 106.03555297851562, 111.01031494140625, 115.98506164550781, 120.95982360839844, 125.93458557128906, 130.9093475341797, 135.8841094970703, 140.85885620117188, 145.8336181640625, 150.80838012695312, 155.78314208984375, 160.75790405273438, 165.732666015625, 170.70742797851562, 175.68218994140625, 180.65692138671875, 185.63168334960938, 190.6064453125, 195.58120727539062, 200.55596923828125, 205.53073120117188]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 32.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-136.17198181152344, -132.8865966796875, -129.60121154785156, -126.3158187866211, -123.03042602539062, -119.74504089355469, -116.45965576171875, -113.17426300048828, -109.88887023925781, -106.60348510742188, -103.31809997558594, -100.03270721435547, -96.74732208251953, -93.46192932128906, -90.17654418945312, -86.89115905761719, -83.60576629638672, -80.32037353515625, -77.03498840332031, -73.74960327148438, -70.4642105102539, -67.17882537841797, -63.8934326171875, -60.60804748535156, -57.322662353515625, -54.037269592285156, -50.75188446044922, -47.46649169921875, -44.18110656738281, -40.895713806152344, -37.610328674316406, -34.32493591308594, -31.03955078125, -27.754165649414062, -24.468772888183594, -21.183387756347656, -17.897994995117188, -14.61260986328125, -11.327217102050781, -8.041824340820312, -4.756439208984375, -1.4710540771484375, 1.8143310546875, 5.0997161865234375, 8.385116577148438, 11.670501708984375, 14.955886840820312, 18.24127197265625, 21.526657104492188, 24.812057495117188, 28.097442626953125, 31.382827758789062, 34.668212890625, 37.95361328125, 41.23899841308594, 44.524383544921875, 47.80976867675781, 51.09515380859375, 54.38055419921875, 57.66593933105469, 60.951324462890625, 64.23670959472656, 67.52210998535156, 70.8074951171875, 74.09288024902344]}, "_runtime": 123.23205709457397, "_timestamp": 1585079556.3213031, "_step": 98}
{"Episode reward": -98.03719596244373, "Episode length": 999, "Policy Loss": -12.470027923583984, "Value Loss": 0.025911875069141388, "_runtime": 124.3993833065033, "_timestamp": 1585079557.4886293, "_step": 99}
{"Episode reward": -101.18503113034981, "Episode length": 999, "Policy Loss": -13.201614379882812, "Value Loss": 0.03228079155087471, "_runtime": 125.50593042373657, "_timestamp": 1585079558.5951765, "_step": 100}
{"Episode reward": -94.37119774581596, "Episode length": 999, "Policy Loss": -11.694387435913086, "Value Loss": 0.027322648093104362, "_runtime": 126.6251311302185, "_timestamp": 1585079559.7143772, "_step": 101}
{"Episode reward": -95.47862936631701, "Episode length": 999, "Policy Loss": -12.005599021911621, "Value Loss": 0.026859251782298088, "_runtime": 127.71986937522888, "_timestamp": 1585079560.8091154, "_step": 102}
{"Episode reward": -99.51591998297661, "Episode length": 999, "Policy Loss": -12.694984436035156, "Value Loss": 0.02849830500781536, "_runtime": 128.84491419792175, "_timestamp": 1585079561.9341602, "_step": 103}
{"Episode reward": -104.41254810982774, "Episode length": 999, "Policy Loss": -13.659771919250488, "Value Loss": 0.03151977062225342, "_runtime": 129.97698521614075, "_timestamp": 1585079563.0662313, "_step": 104}
{"Episode reward": -99.81601160796964, "Episode length": 999, "Policy Loss": -12.643756866455078, "Value Loss": 0.02994430623948574, "_runtime": 131.09475803375244, "_timestamp": 1585079564.184004, "_step": 105}
{"Episode reward": -101.43698738176172, "Episode length": 999, "Policy Loss": -13.032979965209961, "Value Loss": 0.03065364621579647, "_runtime": 132.2347502708435, "_timestamp": 1585079565.3239963, "_step": 106}
{"Episode reward": -106.90191077948519, "Episode length": 999, "Policy Loss": -14.12525749206543, "Value Loss": 0.03224329277873039, "_runtime": 133.3963179588318, "_timestamp": 1585079566.485564, "_step": 107}
{"Episode reward": -105.12816397947893, "Episode length": 999, "Policy Loss": -13.878812789916992, "Value Loss": 0.033631227910518646, "_runtime": 134.53507566452026, "_timestamp": 1585079567.6243217, "_step": 108}
{"Episode reward": -100.79902995065402, "Episode length": 999, "Policy Loss": -12.794350624084473, "Value Loss": 0.028501158580183983, "_runtime": 135.70045948028564, "_timestamp": 1585079568.7897055, "_step": 109}
{"Episode reward": -99.19997039925248, "Episode length": 999, "Policy Loss": -12.598901748657227, "Value Loss": 0.03190268203616142, "_runtime": 136.84409499168396, "_timestamp": 1585079569.933341, "_step": 110}
{"Episode reward": -96.68807834242727, "Episode length": 999, "Policy Loss": -12.230140686035156, "Value Loss": 0.029385549947619438, "_runtime": 137.96050381660461, "_timestamp": 1585079571.0497499, "_step": 111}
{"Episode reward": -103.928966744036, "Episode length": 999, "Policy Loss": -13.83175277709961, "Value Loss": 0.03324325755238533, "_runtime": 139.09307312965393, "_timestamp": 1585079572.1823192, "_step": 112}
{"Episode reward": -101.48588369908332, "Episode length": 999, "Policy Loss": -13.345207214355469, "Value Loss": 0.03176131844520569, "_runtime": 140.22571969032288, "_timestamp": 1585079573.3149657, "_step": 113}
{"Episode reward": -97.76977459649024, "Episode length": 999, "Policy Loss": -12.445096015930176, "Value Loss": 0.031036309897899628, "_runtime": 141.31813216209412, "_timestamp": 1585079574.4073782, "_step": 114}
{"Episode reward": -96.6312957702291, "Episode length": 999, "Policy Loss": -12.253446578979492, "Value Loss": 0.026957405731081963, "_runtime": 142.47112584114075, "_timestamp": 1585079575.5603719, "_step": 115}
{"Episode reward": -98.18225326495273, "Episode length": 999, "Policy Loss": -12.587747573852539, "Value Loss": 0.028539715334773064, "_runtime": 143.5972616672516, "_timestamp": 1585079576.6865077, "_step": 116}
{"Episode reward": -92.75524179695066, "Episode length": 999, "Policy Loss": -11.60173225402832, "Value Loss": 0.024603378027677536, "_runtime": 144.69805693626404, "_timestamp": 1585079577.787303, "_step": 117}
{"Episode reward": -108.43048583298555, "Episode length": 999, "Policy Loss": -14.345354080200195, "Value Loss": 0.0370713509619236, "_runtime": 145.85952138900757, "_timestamp": 1585079578.9487674, "_step": 118}
{"Episode reward": -103.2430321519926, "Episode length": 999, "Policy Loss": -13.425020217895508, "Value Loss": 0.03310713171958923, "_runtime": 146.99700903892517, "_timestamp": 1585079580.086255, "_step": 119}
{"Episode reward": -100.0858785910098, "Episode length": 999, "Policy Loss": -12.676868438720703, "Value Loss": 0.03223378583788872, "_runtime": 148.1313488483429, "_timestamp": 1585079581.220595, "_step": 120}
{"Episode reward": -97.00577586311054, "Episode length": 999, "Policy Loss": -12.328283309936523, "Value Loss": 0.031560786068439484, "_runtime": 149.28049230575562, "_timestamp": 1585079582.3697383, "_step": 121}
{"Episode reward": -95.7567598371054, "Episode length": 999, "Policy Loss": -11.90675163269043, "Value Loss": 0.029241010546684265, "_runtime": 150.4470727443695, "_timestamp": 1585079583.5363188, "_step": 122}
{"Episode reward": -109.317784411443, "Episode length": 999, "Policy Loss": -14.517380714416504, "Value Loss": 0.03504837304353714, "_runtime": 151.54730343818665, "_timestamp": 1585079584.6365495, "_step": 123}
{"Episode reward": -94.52460623726769, "Episode length": 999, "Policy Loss": -12.03686809539795, "Value Loss": 0.028909005224704742, "_runtime": 152.6610894203186, "_timestamp": 1585079585.7503355, "_step": 124}
{"Episode reward": -97.77300468462059, "Episode length": 999, "Policy Loss": -12.40417766571045, "Value Loss": 0.02806652896106243, "_runtime": 153.79174375534058, "_timestamp": 1585079586.8809898, "_step": 125}
{"Episode reward": -100.78531790595818, "Episode length": 999, "Policy Loss": -12.940106391906738, "Value Loss": 0.032063502818346024, "_runtime": 154.93197226524353, "_timestamp": 1585079588.0212183, "_step": 126}
{"Episode reward": -98.85302001794341, "Episode length": 999, "Policy Loss": -12.698445320129395, "Value Loss": 0.02800004556775093, "_runtime": 156.05962491035461, "_timestamp": 1585079589.148871, "_step": 127}
{"Episode reward": -104.26244375209127, "Episode length": 999, "Policy Loss": -13.575424194335938, "Value Loss": 0.03382866829633713, "_runtime": 157.18778157234192, "_timestamp": 1585079590.2770276, "_step": 128}
{"Episode reward": -109.42203032502553, "Episode length": 999, "Policy Loss": -14.250913619995117, "Value Loss": 0.03572076931595802, "_runtime": 158.34299540519714, "_timestamp": 1585079591.4322414, "_step": 129}
{"Episode reward": -97.43184910892023, "Episode length": 999, "Policy Loss": -12.478409767150879, "Value Loss": 0.02941906824707985, "_runtime": 159.47286653518677, "_timestamp": 1585079592.5621126, "_step": 130}
{"Episode reward": -104.48371899275594, "Episode length": 999, "Policy Loss": -13.713695526123047, "Value Loss": 0.03460676968097687, "_runtime": 160.59531450271606, "_timestamp": 1585079593.6845605, "_step": 131}
{"Episode reward": -100.37029097724763, "Episode length": 999, "Policy Loss": -13.006983757019043, "Value Loss": 0.03148694336414337, "_runtime": 161.69964480400085, "_timestamp": 1585079594.7888908, "_step": 132}
{"Episode reward": -100.95769946897164, "Episode length": 999, "Policy Loss": -13.218603134155273, "Value Loss": 0.03121032565832138, "_runtime": 162.8339705467224, "_timestamp": 1585079595.9232166, "_step": 133}
{"Episode reward": -94.01691471227731, "Episode length": 999, "Policy Loss": -11.79221248626709, "Value Loss": 0.028749782592058182, "_runtime": 163.96268916130066, "_timestamp": 1585079597.0519352, "_step": 134}
{"Episode reward": -104.13959972906832, "Episode length": 999, "Policy Loss": -13.623395919799805, "Value Loss": 0.033038217574357986, "_runtime": 165.11647009849548, "_timestamp": 1585079598.2057161, "_step": 135}
{"Episode reward": -104.33854697520279, "Episode length": 999, "Policy Loss": -13.410642623901367, "Value Loss": 0.03199506551027298, "_runtime": 166.23071718215942, "_timestamp": 1585079599.3199632, "_step": 136}
{"Episode reward": -109.67863667561701, "Episode length": 999, "Policy Loss": -14.45161247253418, "Value Loss": 0.03504933416843414, "_runtime": 167.37505555152893, "_timestamp": 1585079600.4643016, "_step": 137}
{"Episode reward": -102.02316583843898, "Episode length": 999, "Policy Loss": -13.210511207580566, "Value Loss": 0.028789974749088287, "_runtime": 168.54638051986694, "_timestamp": 1585079601.6356266, "_step": 138}
{"Episode reward": -97.88077527322251, "Episode length": 999, "Policy Loss": -12.231127738952637, "Value Loss": 0.0288655087351799, "_runtime": 169.72626876831055, "_timestamp": 1585079602.8155148, "_step": 139}
{"Episode reward": -102.18557600964166, "Episode length": 999, "Policy Loss": -13.468513488769531, "Value Loss": 0.030450914055109024, "_runtime": 170.87880110740662, "_timestamp": 1585079603.9680471, "_step": 140}
{"Episode reward": -104.66096747964416, "Episode length": 999, "Policy Loss": -14.088541030883789, "Value Loss": 0.030602816492319107, "_runtime": 171.9816164970398, "_timestamp": 1585079605.0708625, "_step": 141}
{"Episode reward": -107.41532471920172, "Episode length": 999, "Policy Loss": -14.209325790405273, "Value Loss": 0.03482875972986221, "_runtime": 173.16818284988403, "_timestamp": 1585079606.257429, "_step": 142}
{"Episode reward": -104.37245832739845, "Episode length": 999, "Policy Loss": -13.604530334472656, "Value Loss": 0.03324326127767563, "_runtime": 174.31675171852112, "_timestamp": 1585079607.4059978, "_step": 143}
{"Episode reward": -96.70679283923427, "Episode length": 999, "Policy Loss": -12.249944686889648, "Value Loss": 0.026851754635572433, "_runtime": 175.44027853012085, "_timestamp": 1585079608.5295246, "_step": 144}
{"Episode reward": -101.00618814825053, "Episode length": 999, "Policy Loss": -12.922774314880371, "Value Loss": 0.030531316995620728, "_runtime": 176.5645673274994, "_timestamp": 1585079609.6538134, "_step": 145}
{"Episode reward": -98.36683379300031, "Episode length": 999, "Policy Loss": -12.555659294128418, "Value Loss": 0.03119603544473648, "_runtime": 177.66006231307983, "_timestamp": 1585079610.7493083, "_step": 146}
{"Episode reward": -98.8750657024438, "Episode length": 999, "Policy Loss": -12.406354904174805, "Value Loss": 0.029836608096957207, "_runtime": 178.76601219177246, "_timestamp": 1585079611.8552582, "_step": 147}
{"Episode reward": -99.37101177274033, "Episode length": 999, "Policy Loss": -12.671316146850586, "Value Loss": 0.028675071895122528, "_runtime": 179.76166248321533, "_timestamp": 1585079612.8509085, "_step": 148}
{"Episode reward": -1.361028433947709, "Episode length": 905, "Policy Loss": 1.5124765634536743, "Value Loss": 11.105450630187988, "_runtime": 180.88611841201782, "_timestamp": 1585079613.9753644, "_step": 149}
{"Episode reward": -108.80213065219993, "Episode length": 999, "Policy Loss": -14.158698081970215, "Value Loss": 0.036483410745859146, "_runtime": 181.98583269119263, "_timestamp": 1585079615.0750787, "_step": 150}
{"Episode reward": -98.6917919123906, "Episode length": 999, "Policy Loss": -12.349024772644043, "Value Loss": 0.02802429161965847, "_runtime": 183.11681056022644, "_timestamp": 1585079616.2060566, "_step": 151}
{"Episode reward": -102.6882156420522, "Episode length": 999, "Policy Loss": -13.158011436462402, "Value Loss": 0.029041167348623276, "_runtime": 184.24803757667542, "_timestamp": 1585079617.3372836, "_step": 152}
{"Episode reward": -102.79235803832908, "Episode length": 999, "Policy Loss": -13.51891040802002, "Value Loss": 0.03142779693007469, "_runtime": 185.36063504219055, "_timestamp": 1585079618.449881, "_step": 153}
{"Episode reward": -102.66377533409938, "Episode length": 999, "Policy Loss": -13.177497863769531, "Value Loss": 0.028469612821936607, "_runtime": 186.48303985595703, "_timestamp": 1585079619.572286, "_step": 154}
{"Episode reward": -103.11824856980027, "Episode length": 999, "Policy Loss": -13.233453750610352, "Value Loss": 0.03175048530101776, "_runtime": 187.59905123710632, "_timestamp": 1585079620.6882973, "_step": 155}
{"Episode reward": -102.8232632851528, "Episode length": 999, "Policy Loss": -13.452373504638672, "Value Loss": 0.03181793913245201, "_runtime": 188.74384236335754, "_timestamp": 1585079621.8330884, "_step": 156}
{"Episode reward": -99.78059093623469, "Episode length": 999, "Policy Loss": -12.855002403259277, "Value Loss": 0.029296115040779114, "_runtime": 189.8530468940735, "_timestamp": 1585079622.942293, "_step": 157}
{"Episode reward": -93.30278039833092, "Episode length": 999, "Policy Loss": -11.684270858764648, "Value Loss": 0.025016823783516884, "_runtime": 190.98907256126404, "_timestamp": 1585079624.0783186, "_step": 158}
{"Episode reward": -101.54870558498453, "Episode length": 999, "Policy Loss": -13.07787036895752, "Value Loss": 0.030461221933364868, "_runtime": 192.08904886245728, "_timestamp": 1585079625.178295, "_step": 159}
{"Episode reward": -106.93525207328247, "Episode length": 999, "Policy Loss": -14.294243812561035, "Value Loss": 0.03285004571080208, "_runtime": 193.2541344165802, "_timestamp": 1585079626.3433805, "_step": 160}
{"Episode reward": -89.9723618118174, "Episode length": 999, "Policy Loss": -11.111854553222656, "Value Loss": 0.02553432248532772, "_runtime": 194.386216878891, "_timestamp": 1585079627.475463, "_step": 161}
{"Episode reward": -98.67043149771436, "Episode length": 999, "Policy Loss": -12.735962867736816, "Value Loss": 0.030963828787207603, "_runtime": 195.48882961273193, "_timestamp": 1585079628.5780756, "_step": 162}
{"Episode reward": -98.30917932411884, "Episode length": 999, "Policy Loss": -12.367039680480957, "Value Loss": 0.029631825163960457, "_runtime": 196.641352891922, "_timestamp": 1585079629.730599, "_step": 163}
{"Episode reward": -103.71081075826787, "Episode length": 999, "Policy Loss": -13.17590618133545, "Value Loss": 0.034157708287239075, "_runtime": 197.74406957626343, "_timestamp": 1585079630.8333156, "_step": 164}
{"Episode reward": -94.87120954087494, "Episode length": 999, "Policy Loss": -11.80306339263916, "Value Loss": 0.027748972177505493, "_runtime": 198.86724424362183, "_timestamp": 1585079631.9564903, "_step": 165}
{"Episode reward": -107.15546817228413, "Episode length": 999, "Policy Loss": -14.11104679107666, "Value Loss": 0.03343554586172104, "_runtime": 199.97682738304138, "_timestamp": 1585079633.0660734, "_step": 166}
{"Episode reward": -96.42409007469738, "Episode length": 999, "Policy Loss": -12.091381072998047, "Value Loss": 0.026505121961236, "_runtime": 201.12208080291748, "_timestamp": 1585079634.2113268, "_step": 167}
{"Episode reward": -102.99440824055894, "Episode length": 999, "Policy Loss": -13.4500732421875, "Value Loss": 0.029399901628494263, "_runtime": 202.25205087661743, "_timestamp": 1585079635.341297, "_step": 168}
{"Episode reward": -102.08068573379151, "Episode length": 999, "Policy Loss": -13.404726028442383, "Value Loss": 0.030827710404992104, "_runtime": 203.42005372047424, "_timestamp": 1585079636.5092998, "_step": 169}
{"Episode reward": -104.50625538304651, "Episode length": 999, "Policy Loss": -13.536759376525879, "Value Loss": 0.03211148828268051, "_runtime": 204.5722200870514, "_timestamp": 1585079637.6614661, "_step": 170}
{"Episode reward": -96.03584686177368, "Episode length": 999, "Policy Loss": -12.383230209350586, "Value Loss": 0.03001232258975506, "_runtime": 205.68659043312073, "_timestamp": 1585079638.7758365, "_step": 171}
{"Episode reward": -92.67121924793922, "Episode length": 999, "Policy Loss": -11.617239952087402, "Value Loss": 0.02803884632885456, "_runtime": 206.92768502235413, "_timestamp": 1585079640.016931, "_step": 172}
{"Episode reward": -100.02366361990944, "Episode length": 999, "Policy Loss": -12.700969696044922, "Value Loss": 0.03154332563281059, "_runtime": 208.0738010406494, "_timestamp": 1585079641.163047, "_step": 173}
{"Episode reward": -94.85091441596248, "Episode length": 999, "Policy Loss": -12.017583847045898, "Value Loss": 0.026391567662358284, "_runtime": 209.2293357849121, "_timestamp": 1585079642.3185818, "_step": 174}
{"Episode reward": -110.77811445595479, "Episode length": 999, "Policy Loss": -14.704437255859375, "Value Loss": 0.03596638888120651, "_runtime": 210.35565280914307, "_timestamp": 1585079643.4448988, "_step": 175}
{"Episode reward": -104.26703949133062, "Episode length": 999, "Policy Loss": -13.391368865966797, "Value Loss": 0.03285754472017288, "_runtime": 211.46613788604736, "_timestamp": 1585079644.555384, "_step": 176}
{"Episode reward": -93.71353740007405, "Episode length": 999, "Policy Loss": -11.743390083312988, "Value Loss": 0.025791695341467857, "_runtime": 212.62913584709167, "_timestamp": 1585079645.718382, "_step": 177}
{"Episode reward": -93.80849347234614, "Episode length": 999, "Policy Loss": -11.741472244262695, "Value Loss": 0.02787059359252453, "_runtime": 213.75091552734375, "_timestamp": 1585079646.8401616, "_step": 178}
{"Episode reward": -95.8190391318536, "Episode length": 999, "Policy Loss": -12.093877792358398, "Value Loss": 0.029965443536639214, "_runtime": 214.88754606246948, "_timestamp": 1585079647.976792, "_step": 179}
{"Episode reward": -100.26219520224228, "Episode length": 999, "Policy Loss": -12.753490447998047, "Value Loss": 0.03372271731495857, "_runtime": 216.07318258285522, "_timestamp": 1585079649.1624286, "_step": 180}
{"Episode reward": -98.34297865469507, "Episode length": 999, "Policy Loss": -12.742258071899414, "Value Loss": 0.03133946284651756, "_runtime": 217.29168033599854, "_timestamp": 1585079650.3809264, "_step": 181}
{"Episode reward": -101.19619109787023, "Episode length": 999, "Policy Loss": -12.945516586303711, "Value Loss": 0.030508752912282944, "_runtime": 218.47647404670715, "_timestamp": 1585079651.56572, "_step": 182}
{"Episode reward": -98.15276622708059, "Episode length": 999, "Policy Loss": -12.52631664276123, "Value Loss": 0.03188302367925644, "_runtime": 219.69635653495789, "_timestamp": 1585079652.7856026, "_step": 183}
{"Episode reward": -101.09267235167485, "Episode length": 999, "Policy Loss": -13.2061185836792, "Value Loss": 0.02947375178337097, "_runtime": 220.8833692073822, "_timestamp": 1585079653.9726152, "_step": 184}
{"Episode reward": -103.91335523660793, "Episode length": 999, "Policy Loss": -13.34196662902832, "Value Loss": 0.033281102776527405, "_runtime": 222.03082823753357, "_timestamp": 1585079655.1200743, "_step": 185}
{"Episode reward": -100.63444268210102, "Episode length": 999, "Policy Loss": -12.865429878234863, "Value Loss": 0.02942710369825363, "_runtime": 223.21436429023743, "_timestamp": 1585079656.3036103, "_step": 186}
{"Episode reward": -99.12485067273471, "Episode length": 999, "Policy Loss": -12.654356956481934, "Value Loss": 0.03145691752433777, "_runtime": 224.38389229774475, "_timestamp": 1585079657.4731383, "_step": 187}
{"Episode reward": -110.47340446239538, "Episode length": 999, "Policy Loss": -14.705711364746094, "Value Loss": 0.03537080064415932, "_runtime": 225.5298137664795, "_timestamp": 1585079658.6190598, "_step": 188}
{"Episode reward": -100.44729471602682, "Episode length": 999, "Policy Loss": -12.72515869140625, "Value Loss": 0.03154245391488075, "_runtime": 226.73155784606934, "_timestamp": 1585079659.8208039, "_step": 189}
{"Episode reward": -98.98505529078092, "Episode length": 999, "Policy Loss": -12.726688385009766, "Value Loss": 0.02876308001577854, "_runtime": 227.84311294555664, "_timestamp": 1585079660.932359, "_step": 190}
{"Episode reward": -96.21602463251446, "Episode length": 999, "Policy Loss": -12.208176612854004, "Value Loss": 0.02795388735830784, "_runtime": 228.9520800113678, "_timestamp": 1585079662.041326, "_step": 191}
{"Episode reward": -100.43380340336311, "Episode length": 999, "Policy Loss": -13.072978019714355, "Value Loss": 0.03135530650615692, "_runtime": 230.07374334335327, "_timestamp": 1585079663.1629894, "_step": 192}
{"Episode reward": -97.02176098108119, "Episode length": 999, "Policy Loss": -12.295546531677246, "Value Loss": 0.028929295018315315, "_runtime": 231.16861987113953, "_timestamp": 1585079664.257866, "_step": 193}
{"Episode reward": -101.99730380257161, "Episode length": 999, "Policy Loss": -13.287727355957031, "Value Loss": 0.030585462227463722, "_runtime": 232.28220987319946, "_timestamp": 1585079665.371456, "_step": 194}
{"Episode reward": -111.76636273465475, "Episode length": 999, "Policy Loss": -15.021471977233887, "Value Loss": 0.039071641862392426, "_runtime": 233.45707893371582, "_timestamp": 1585079666.546325, "_step": 195}
{"Episode reward": -109.60024895765538, "Episode length": 999, "Policy Loss": -14.60464096069336, "Value Loss": 0.03521694988012314, "_runtime": 234.5869174003601, "_timestamp": 1585079667.6761634, "_step": 196}
{"Episode reward": -97.54668563642161, "Episode length": 999, "Policy Loss": -12.545684814453125, "Value Loss": 0.02791057899594307, "_runtime": 235.72281312942505, "_timestamp": 1585079668.8120592, "_step": 197}
{"Episode reward": -101.29945091557452, "Episode length": 999, "Policy Loss": -13.014373779296875, "Value Loss": 0.030641455203294754, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125, 153.8017578125]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-89.28959655761719, -85.35696411132812, -81.4243392944336, -77.49170684814453, -73.55907440185547, -69.62644958496094, -65.69381713867188, -61.76118469238281, -57.82855224609375, -53.89592361450195, -49.963294982910156, -46.030662536621094, -42.0980339050293, -38.165401458740234, -34.23277282714844, -30.300140380859375, -26.367511749267578, -22.43488311767578, -18.50225067138672, -14.569618225097656, -10.636993408203125, -6.7043609619140625, -2.771728515625, 1.1609039306640625, 5.093528747558594, 9.026161193847656, 12.958793640136719, 16.89141845703125, 20.824050903320312, 24.756683349609375, 28.689315795898438, 32.62194061279297, 36.55457305908203, 40.48719787597656, 44.419830322265625, 48.35246276855469, 52.28509521484375, 56.21772766113281, 60.150360107421875, 64.08299255371094, 68.01560974121094, 71.9482421875, 75.88087463378906, 79.81350708007812, 83.74613952636719, 87.67877197265625, 91.61140441894531, 95.54402160644531, 99.47665405273438, 103.40928649902344, 107.3419189453125, 111.27455139160156, 115.20718383789062, 119.13981628417969, 123.07243347167969, 127.00506591796875, 130.9376983642578, 134.87033081054688, 138.80296325683594, 142.735595703125, 146.66822814941406, 150.60084533691406, 154.53347778320312, 158.4661102294922, 162.39874267578125]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-84.38580322265625, -81.91649627685547, -79.44718933105469, -76.97789001464844, -74.50858306884766, -72.03927612304688, -69.56997680664062, -67.10066986083984, -64.63136291503906, -62.16205596923828, -59.692752838134766, -57.22344970703125, -54.75414276123047, -52.28483581542969, -49.81553268432617, -47.346229553222656, -44.876922607421875, -42.407615661621094, -39.93831253051758, -37.46900939941406, -34.99970245361328, -32.5303955078125, -30.061092376708984, -27.59178924560547, -25.122482299804688, -22.653175354003906, -20.183868408203125, -17.714569091796875, -15.245262145996094, -12.775955200195312, -10.306655883789062, -7.837348937988281, -5.3680419921875, -2.8987350463867188, -0.4294281005859375, 2.0398712158203125, 4.509178161621094, 6.978485107421875, 9.447784423828125, 11.917091369628906, 14.386398315429688, 16.85570526123047, 19.32501220703125, 21.7943115234375, 24.26361846923828, 26.732925415039062, 29.202224731445312, 31.671531677246094, 34.140838623046875, 36.610145568847656, 39.07945251464844, 41.54875183105469, 44.01806640625, 46.48736572265625, 48.9566650390625, 51.42597961425781, 53.89527893066406, 56.36457824707031, 58.833892822265625, 61.303192138671875, 63.772491455078125, 66.24180603027344, 68.71110534667969, 71.180419921875, 73.64971923828125]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 8.0, 15.0, 8.0, 7.0, 11.0, 18.0, 18.0, 15.0, 28.0, 45.0, 51.0, 37.0, 39.0, 27.0, 38.0, 27.0, 16.0, 12.0, 12.0, 3.0, 7.0, 6.0, 1.0, 2.0, 3.0, 4.0, 7.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0], "bins": [-84.91510772705078, -82.4303207397461, -79.9455337524414, -77.46075439453125, -74.97596740722656, -72.49118041992188, -70.00639343261719, -67.5216064453125, -65.03681945800781, -62.55203628540039, -60.0672492980957, -57.58246612548828, -55.097679138183594, -52.612892150878906, -50.12810516357422, -47.6433219909668, -45.15853500366211, -42.67374801635742, -40.18896484375, -37.70417785644531, -35.219390869140625, -32.7346076965332, -30.249820709228516, -27.765033721923828, -25.280250549316406, -22.79546356201172, -20.31067657470703, -17.825889587402344, -15.341102600097656, -12.8563232421875, -10.371536254882812, -7.886749267578125, -5.4019622802734375, -2.91717529296875, -0.4323883056640625, 2.052398681640625, 4.537178039550781, 7.021965026855469, 9.506752014160156, 11.991539001464844, 14.476325988769531, 16.96111297607422, 19.445892333984375, 21.930679321289062, 24.41546630859375, 26.900253295898438, 29.385040283203125, 31.869827270507812, 34.35460662841797, 36.839393615722656, 39.324180603027344, 41.80896759033203, 44.29375457763672, 46.778541564941406, 49.263328552246094, 51.74811553955078, 54.23290252685547, 56.717689514160156, 59.20246124267578, 61.68724822998047, 64.17203521728516, 66.65682220458984, 69.14160919189453, 71.62639617919922, 74.1111831665039]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-29.334781646728516, -27.929445266723633, -26.52410888671875, -25.1187744140625, -23.713436126708984, -22.308101654052734, -20.90276527404785, -19.49742889404297, -18.092092514038086, -16.686756134033203, -15.28141975402832, -13.876084327697754, -12.470748901367188, -11.065412521362305, -9.660076141357422, -8.254739761352539, -6.849403381347656, -5.444067001342773, -4.038730621337891, -2.633394241333008, -1.228057861328125, 0.177276611328125, 1.5826129913330078, 2.9879493713378906, 4.393283843994141, 5.798622131347656, 7.203956604003906, 8.609294891357422, 10.014629364013672, 11.419967651367188, 12.825302124023438, 14.230640411376953, 15.635974884033203, 17.041309356689453, 18.44664764404297, 19.85198211669922, 21.257320404052734, 22.662654876708984, 24.0679931640625, 25.47332763671875, 26.878665924072266, 28.284000396728516, 29.689334869384766, 31.09467315673828, 32.50000762939453, 33.90534591674805, 35.3106803894043, 36.71601486206055, 38.1213493347168, 39.52669143676758, 40.93202590942383, 42.33736038208008, 43.74269485473633, 45.14803695678711, 46.55337142944336, 47.95870590209961, 49.36404037475586, 50.76937484741211, 52.17471694946289, 53.58005142211914, 54.98538589477539, 56.39072036743164, 57.79606246948242, 59.20139694213867, 60.60673141479492]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 14.0, 9.0, 7.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0], "bins": [-58.625160217285156, -57.22721481323242, -55.82926940917969, -54.43132781982422, -53.033382415771484, -51.63543701171875, -50.237491607666016, -48.83954620361328, -47.44160461425781, -46.04365921020508, -44.645713806152344, -43.24776840209961, -41.849822998046875, -40.451881408691406, -39.053932189941406, -37.65599060058594, -36.2580451965332, -34.86009979248047, -33.462158203125, -32.064208984375, -30.66626739501953, -29.268321990966797, -27.870376586914062, -26.472431182861328, -25.074485778808594, -23.676544189453125, -22.27859878540039, -20.880653381347656, -19.482707977294922, -18.084762573242188, -16.68682098388672, -15.288875579833984, -13.89093017578125, -12.492984771728516, -11.095039367675781, -9.697097778320312, -8.299152374267578, -6.901206970214844, -5.503261566162109, -4.105316162109375, -2.7073745727539062, -1.3094291687011719, 0.0885162353515625, 1.4864616394042969, 2.8844070434570312, 4.282352447509766, 5.6802978515625, 7.078239440917969, 8.476188659667969, 9.874130249023438, 11.272071838378906, 12.670021057128906, 14.067962646484375, 15.465911865234375, 16.863853454589844, 18.261795043945312, 19.659744262695312, 21.05768585205078, 22.45563507080078, 23.85357666015625, 25.25151824951172, 26.64946746826172, 28.047409057617188, 29.445358276367188, 30.843299865722656]}, "_runtime": 236.85961031913757, "_timestamp": 1585079669.9488564, "_step": 198}
{"Episode reward": -103.65610054256587, "Episode length": 999, "Policy Loss": -13.366333961486816, "Value Loss": 0.029175125062465668, "_runtime": 237.96684861183167, "_timestamp": 1585079671.0560946, "_step": 199}
{"Episode reward": -101.29964689151302, "Episode length": 999, "Policy Loss": -13.218469619750977, "Value Loss": 0.031742583960294724, "_runtime": 239.08771467208862, "_timestamp": 1585079672.1769607, "_step": 200}
{"Episode reward": -105.39896041132505, "Episode length": 999, "Policy Loss": -13.939383506774902, "Value Loss": 0.03326902538537979, "_runtime": 240.20505380630493, "_timestamp": 1585079673.2942998, "_step": 201}
{"Episode reward": -94.76403175298917, "Episode length": 999, "Policy Loss": -12.150155067443848, "Value Loss": 0.0258207805454731, "_runtime": 241.29300951957703, "_timestamp": 1585079674.3822556, "_step": 202}
{"Episode reward": -111.18656958972821, "Episode length": 999, "Policy Loss": -14.831334114074707, "Value Loss": 0.03670017048716545, "_runtime": 242.38358211517334, "_timestamp": 1585079675.4728281, "_step": 203}
{"Episode reward": -103.36391886816203, "Episode length": 999, "Policy Loss": -13.587522506713867, "Value Loss": 0.03371954709291458, "_runtime": 243.54576683044434, "_timestamp": 1585079676.6350129, "_step": 204}
{"Episode reward": -107.7008444419843, "Episode length": 999, "Policy Loss": -14.284374237060547, "Value Loss": 0.033163074404001236, "_runtime": 244.69440245628357, "_timestamp": 1585079677.7836485, "_step": 205}
{"Episode reward": -105.69323799322589, "Episode length": 999, "Policy Loss": -13.89733600616455, "Value Loss": 0.0344008170068264, "_runtime": 245.8800482749939, "_timestamp": 1585079678.9692943, "_step": 206}
{"Episode reward": -92.5974713408618, "Episode length": 999, "Policy Loss": -11.684006690979004, "Value Loss": 0.02464170940220356, "_runtime": 246.9951469898224, "_timestamp": 1585079680.084393, "_step": 207}
{"Episode reward": -90.60183824572567, "Episode length": 999, "Policy Loss": -11.195462226867676, "Value Loss": 0.026163510978221893, "_runtime": 248.105477809906, "_timestamp": 1585079681.1947238, "_step": 208}
{"Episode reward": -100.70091932372748, "Episode length": 999, "Policy Loss": -12.626276969909668, "Value Loss": 0.028569474816322327, "_runtime": 249.26141667366028, "_timestamp": 1585079682.3506627, "_step": 209}
{"Episode reward": -94.1695700974827, "Episode length": 999, "Policy Loss": -11.922977447509766, "Value Loss": 0.02802583947777748, "_runtime": 250.3724467754364, "_timestamp": 1585079683.4616928, "_step": 210}
{"Episode reward": -96.8143624594221, "Episode length": 999, "Policy Loss": -12.191705703735352, "Value Loss": 0.027758024632930756, "_runtime": 251.47167658805847, "_timestamp": 1585079684.5609226, "_step": 211}
{"Episode reward": -102.34142319127128, "Episode length": 999, "Policy Loss": -12.990984916687012, "Value Loss": 0.031705647706985474, "_runtime": 252.61166858673096, "_timestamp": 1585079685.7009146, "_step": 212}
{"Episode reward": -99.62944681809216, "Episode length": 999, "Policy Loss": -12.717740058898926, "Value Loss": 0.028704047203063965, "_runtime": 253.7311520576477, "_timestamp": 1585079686.820398, "_step": 213}
{"Episode reward": -102.0198268494308, "Episode length": 999, "Policy Loss": -13.334616661071777, "Value Loss": 0.03307909518480301, "_runtime": 254.8488483428955, "_timestamp": 1585079687.9380944, "_step": 214}
{"Episode reward": -107.40603900905802, "Episode length": 999, "Policy Loss": -14.175127029418945, "Value Loss": 0.034104835242033005, "_runtime": 255.98697590827942, "_timestamp": 1585079689.076222, "_step": 215}
{"Episode reward": -105.16854214975514, "Episode length": 999, "Policy Loss": -13.636473655700684, "Value Loss": 0.03225289657711983, "_runtime": 256.7305679321289, "_timestamp": 1585079689.819814, "_step": 216}
{"Episode reward": 32.9120468063485, "Episode length": 646, "Policy Loss": 9.925273895263672, "Value Loss": 15.426833152770996, "_runtime": 257.8079149723053, "_timestamp": 1585079690.897161, "_step": 217}
{"Episode reward": -106.37026393605368, "Episode length": 999, "Policy Loss": -13.936431884765625, "Value Loss": 0.033826109021902084, "_runtime": 258.94965863227844, "_timestamp": 1585079692.0389047, "_step": 218}
{"Episode reward": -101.05177022344964, "Episode length": 999, "Policy Loss": -13.020523071289062, "Value Loss": 0.03239201754331589, "_runtime": 260.0681138038635, "_timestamp": 1585079693.1573598, "_step": 219}
{"Episode reward": -98.45106762625934, "Episode length": 999, "Policy Loss": -12.636693000793457, "Value Loss": 0.02793370746076107, "_runtime": 261.1585502624512, "_timestamp": 1585079694.2477963, "_step": 220}
{"Episode reward": -99.68714775077027, "Episode length": 999, "Policy Loss": -12.716104507446289, "Value Loss": 0.029988564550876617, "_runtime": 262.25466990470886, "_timestamp": 1585079695.343916, "_step": 221}
{"Episode reward": -104.54895421186492, "Episode length": 999, "Policy Loss": -13.548303604125977, "Value Loss": 0.032194994390010834, "_runtime": 263.38027000427246, "_timestamp": 1585079696.469516, "_step": 222}
{"Episode reward": -107.19796756481256, "Episode length": 999, "Policy Loss": -13.951597213745117, "Value Loss": 0.03589694947004318, "_runtime": 264.5347480773926, "_timestamp": 1585079697.623994, "_step": 223}
{"Episode reward": -101.51523317256198, "Episode length": 999, "Policy Loss": -13.306382179260254, "Value Loss": 0.030841605737805367, "_runtime": 265.64261174201965, "_timestamp": 1585079698.7318578, "_step": 224}
{"Episode reward": -100.96674519209287, "Episode length": 999, "Policy Loss": -12.89492130279541, "Value Loss": 0.031485624611377716, "_runtime": 266.78059434890747, "_timestamp": 1585079699.8698404, "_step": 225}
{"Episode reward": -100.90820979710546, "Episode length": 999, "Policy Loss": -12.9584321975708, "Value Loss": 0.03194759413599968, "_runtime": 267.87510919570923, "_timestamp": 1585079700.9643552, "_step": 226}
{"Episode reward": -104.75590000016246, "Episode length": 999, "Policy Loss": -13.820505142211914, "Value Loss": 0.03223665431141853, "_runtime": 268.98618721961975, "_timestamp": 1585079702.0754333, "_step": 227}
{"Episode reward": -96.16501124256766, "Episode length": 999, "Policy Loss": -12.308182716369629, "Value Loss": 0.028033405542373657, "_runtime": 270.10136890411377, "_timestamp": 1585079703.190615, "_step": 228}
{"Episode reward": -92.74851181828845, "Episode length": 999, "Policy Loss": -11.76838493347168, "Value Loss": 0.024158991873264313, "_runtime": 271.1848621368408, "_timestamp": 1585079704.2741082, "_step": 229}
{"Episode reward": -101.8119377851518, "Episode length": 999, "Policy Loss": -13.10556697845459, "Value Loss": 0.03162112832069397, "_runtime": 272.28053855895996, "_timestamp": 1585079705.3697846, "_step": 230}
{"Episode reward": -100.10402665588487, "Episode length": 999, "Policy Loss": -12.887280464172363, "Value Loss": 0.033831167966127396, "_runtime": 273.40590834617615, "_timestamp": 1585079706.4951544, "_step": 231}
{"Episode reward": -90.89879491823118, "Episode length": 999, "Policy Loss": -11.436056137084961, "Value Loss": 0.026684682816267014, "_runtime": 274.5319175720215, "_timestamp": 1585079707.6211636, "_step": 232}
{"Episode reward": -107.27550591820636, "Episode length": 999, "Policy Loss": -14.160460472106934, "Value Loss": 0.03379150107502937, "_runtime": 275.6294364929199, "_timestamp": 1585079708.7186825, "_step": 233}
{"Episode reward": -100.08990467014011, "Episode length": 999, "Policy Loss": -12.981118202209473, "Value Loss": 0.02483433485031128, "_runtime": 276.792031288147, "_timestamp": 1585079709.8812773, "_step": 234}
{"Episode reward": -104.6347899463976, "Episode length": 999, "Policy Loss": -13.732378959655762, "Value Loss": 0.03396720066666603, "_runtime": 277.9040582180023, "_timestamp": 1585079710.9933043, "_step": 235}
{"Episode reward": -101.70332431648237, "Episode length": 999, "Policy Loss": -13.117438316345215, "Value Loss": 0.03022056445479393, "_runtime": 279.0104422569275, "_timestamp": 1585079712.0996883, "_step": 236}
{"Episode reward": -100.62818165984402, "Episode length": 999, "Policy Loss": -13.005298614501953, "Value Loss": 0.029212376102805138, "_runtime": 280.12774777412415, "_timestamp": 1585079713.2169938, "_step": 237}
{"Episode reward": -95.5782987237206, "Episode length": 999, "Policy Loss": -12.118623733520508, "Value Loss": 0.029248658567667007, "_runtime": 281.2447974681854, "_timestamp": 1585079714.3340435, "_step": 238}
{"Episode reward": -103.7915478968298, "Episode length": 999, "Policy Loss": -13.859175682067871, "Value Loss": 0.02917501889169216, "_runtime": 282.3929371833801, "_timestamp": 1585079715.4821832, "_step": 239}
{"Episode reward": -105.39141741343417, "Episode length": 999, "Policy Loss": -13.865580558776855, "Value Loss": 0.03467363864183426, "_runtime": 283.5518078804016, "_timestamp": 1585079716.641054, "_step": 240}
{"Episode reward": -99.3739540793547, "Episode length": 999, "Policy Loss": -12.608919143676758, "Value Loss": 0.029032228514552116, "_runtime": 284.6982362270355, "_timestamp": 1585079717.7874823, "_step": 241}
{"Episode reward": -104.8779479154527, "Episode length": 999, "Policy Loss": -14.119214057922363, "Value Loss": 0.03236275166273117, "_runtime": 285.84510564804077, "_timestamp": 1585079718.9343517, "_step": 242}
{"Episode reward": -104.46170043275944, "Episode length": 999, "Policy Loss": -13.556872367858887, "Value Loss": 0.035494815558195114, "_runtime": 286.95248460769653, "_timestamp": 1585079720.0417306, "_step": 243}
{"Episode reward": -105.21489399975125, "Episode length": 999, "Policy Loss": -13.756336212158203, "Value Loss": 0.03319260850548744, "_runtime": 288.0601758956909, "_timestamp": 1585079721.149422, "_step": 244}
{"Episode reward": -109.06742229090283, "Episode length": 999, "Policy Loss": -14.508129119873047, "Value Loss": 0.03493660315871239, "_runtime": 289.16831731796265, "_timestamp": 1585079722.2575634, "_step": 245}
{"Episode reward": -107.37338636119328, "Episode length": 999, "Policy Loss": -14.012534141540527, "Value Loss": 0.0351523831486702, "_runtime": 290.27805185317993, "_timestamp": 1585079723.367298, "_step": 246}
{"Episode reward": -98.4780492036609, "Episode length": 999, "Policy Loss": -12.635054588317871, "Value Loss": 0.031149376183748245, "_runtime": 291.3810033798218, "_timestamp": 1585079724.4702494, "_step": 247}
{"Episode reward": -93.27522989638796, "Episode length": 999, "Policy Loss": -11.812653541564941, "Value Loss": 0.027935482561588287, "_runtime": 292.5083055496216, "_timestamp": 1585079725.5975516, "_step": 248}
{"Episode reward": -102.8097601739627, "Episode length": 999, "Policy Loss": -13.550893783569336, "Value Loss": 0.033062249422073364, "_runtime": 293.6091904640198, "_timestamp": 1585079726.6984365, "_step": 249}
{"Episode reward": -105.3231497141793, "Episode length": 999, "Policy Loss": -13.84067153930664, "Value Loss": 0.0371682308614254, "_runtime": 294.7259895801544, "_timestamp": 1585079727.8152356, "_step": 250}
{"Episode reward": -99.02812006968094, "Episode length": 999, "Policy Loss": -12.882813453674316, "Value Loss": 0.026339584961533546, "_runtime": 295.87938165664673, "_timestamp": 1585079728.9686277, "_step": 251}
{"Episode reward": -98.21564694768396, "Episode length": 999, "Policy Loss": -12.556156158447266, "Value Loss": 0.03023480251431465, "_runtime": 297.00885105133057, "_timestamp": 1585079730.098097, "_step": 252}
{"Episode reward": -91.49796416063481, "Episode length": 999, "Policy Loss": -11.217910766601562, "Value Loss": 0.02524654194712639, "_runtime": 298.1392526626587, "_timestamp": 1585079731.2284987, "_step": 253}
{"Episode reward": -96.09425270456978, "Episode length": 999, "Policy Loss": -12.400681495666504, "Value Loss": 0.028553394600749016, "_runtime": 299.2663311958313, "_timestamp": 1585079732.3555772, "_step": 254}
{"Episode reward": -98.76516005389985, "Episode length": 999, "Policy Loss": -12.673977851867676, "Value Loss": 0.028398659080266953, "_runtime": 300.3647344112396, "_timestamp": 1585079733.4539804, "_step": 255}
{"Episode reward": -98.62840379337737, "Episode length": 999, "Policy Loss": -12.444681167602539, "Value Loss": 0.03157908841967583, "_runtime": 301.4972858428955, "_timestamp": 1585079734.5865319, "_step": 256}
{"Episode reward": -94.36654074261075, "Episode length": 999, "Policy Loss": -12.114697456359863, "Value Loss": 0.027121298015117645, "_runtime": 302.6373908519745, "_timestamp": 1585079735.726637, "_step": 257}
{"Episode reward": -99.54223849997452, "Episode length": 999, "Policy Loss": -12.85193920135498, "Value Loss": 0.028402455151081085, "_runtime": 303.8000581264496, "_timestamp": 1585079736.8893042, "_step": 258}
{"Episode reward": -99.74384203905934, "Episode length": 999, "Policy Loss": -12.681036949157715, "Value Loss": 0.029877187684178352, "_runtime": 304.9401090145111, "_timestamp": 1585079738.029355, "_step": 259}
{"Episode reward": -99.50892433065243, "Episode length": 999, "Policy Loss": -12.916630744934082, "Value Loss": 0.028948334977030754, "_runtime": 306.0544173717499, "_timestamp": 1585079739.1436634, "_step": 260}
{"Episode reward": -105.04592108546322, "Episode length": 999, "Policy Loss": -13.718435287475586, "Value Loss": 0.034909188747406006, "_runtime": 307.15957617759705, "_timestamp": 1585079740.2488222, "_step": 261}
{"Episode reward": -97.78383543494706, "Episode length": 999, "Policy Loss": -12.131577491760254, "Value Loss": 0.02987520582973957, "_runtime": 308.2892208099365, "_timestamp": 1585079741.3784668, "_step": 262}
{"Episode reward": -105.50651330591404, "Episode length": 999, "Policy Loss": -13.90397834777832, "Value Loss": 0.03217647224664688, "_runtime": 309.4185848236084, "_timestamp": 1585079742.5078309, "_step": 263}
{"Episode reward": -93.63145596391837, "Episode length": 999, "Policy Loss": -11.870196342468262, "Value Loss": 0.026159455999732018, "_runtime": 310.5562834739685, "_timestamp": 1585079743.6455295, "_step": 264}
{"Episode reward": -95.80639922668426, "Episode length": 999, "Policy Loss": -12.079751968383789, "Value Loss": 0.031131746247410774, "_runtime": 311.6925868988037, "_timestamp": 1585079744.781833, "_step": 265}
{"Episode reward": -91.98895967484539, "Episode length": 999, "Policy Loss": -11.539375305175781, "Value Loss": 0.023788658902049065, "_runtime": 312.8107931613922, "_timestamp": 1585079745.9000392, "_step": 266}
{"Episode reward": -93.15924485958301, "Episode length": 999, "Policy Loss": -11.542825698852539, "Value Loss": 0.025462443009018898, "_runtime": 313.9335880279541, "_timestamp": 1585079747.022834, "_step": 267}
{"Episode reward": -98.77743842744316, "Episode length": 999, "Policy Loss": -12.784177780151367, "Value Loss": 0.028667990118265152, "_runtime": 315.07782649993896, "_timestamp": 1585079748.1670725, "_step": 268}
{"Episode reward": -105.78492197240327, "Episode length": 999, "Policy Loss": -14.063112258911133, "Value Loss": 0.033128876239061356, "_runtime": 316.1760334968567, "_timestamp": 1585079749.2652795, "_step": 269}
{"Episode reward": -99.24866724258678, "Episode length": 999, "Policy Loss": -12.927136421203613, "Value Loss": 0.029994044452905655, "_runtime": 317.29420256614685, "_timestamp": 1585079750.3834486, "_step": 270}
{"Episode reward": -101.06085745112685, "Episode length": 999, "Policy Loss": -12.822308540344238, "Value Loss": 0.03141893446445465, "_runtime": 318.4525411128998, "_timestamp": 1585079751.5417871, "_step": 271}
{"Episode reward": -106.24008368174898, "Episode length": 999, "Policy Loss": -14.11398696899414, "Value Loss": 0.03416991978883743, "_runtime": 319.58393025398254, "_timestamp": 1585079752.6731763, "_step": 272}
{"Episode reward": -107.70915984715602, "Episode length": 999, "Policy Loss": -14.140510559082031, "Value Loss": 0.03768467903137207, "_runtime": 320.75700068473816, "_timestamp": 1585079753.8462467, "_step": 273}
{"Episode reward": -97.71417226104111, "Episode length": 999, "Policy Loss": -12.183083534240723, "Value Loss": 0.027056409046053886, "_runtime": 321.86797046661377, "_timestamp": 1585079754.9572165, "_step": 274}
{"Episode reward": -94.75814445798603, "Episode length": 999, "Policy Loss": -11.794966697692871, "Value Loss": 0.02630314603447914, "_runtime": 323.0003447532654, "_timestamp": 1585079756.0895908, "_step": 275}
{"Episode reward": -98.39197735003103, "Episode length": 999, "Policy Loss": -12.622389793395996, "Value Loss": 0.026511255651712418, "_runtime": 324.17453932762146, "_timestamp": 1585079757.2637854, "_step": 276}
{"Episode reward": -109.544970458959, "Episode length": 999, "Policy Loss": -14.554622650146484, "Value Loss": 0.03822697326540947, "_runtime": 325.2841114997864, "_timestamp": 1585079758.3733575, "_step": 277}
{"Episode reward": -99.1111514388032, "Episode length": 999, "Policy Loss": -12.61848258972168, "Value Loss": 0.030653614550828934, "_runtime": 326.38877630233765, "_timestamp": 1585079759.4780223, "_step": 278}
{"Episode reward": -95.98012362936602, "Episode length": 999, "Policy Loss": -12.258621215820312, "Value Loss": 0.025545742362737656, "_runtime": 327.5022795200348, "_timestamp": 1585079760.5915256, "_step": 279}
{"Episode reward": -112.93247960500709, "Episode length": 999, "Policy Loss": -15.337889671325684, "Value Loss": 0.03800104930996895, "_runtime": 328.6109690666199, "_timestamp": 1585079761.700215, "_step": 280}
{"Episode reward": -94.16147458717697, "Episode length": 999, "Policy Loss": -11.72286319732666, "Value Loss": 0.027955349534749985, "_runtime": 329.70374369621277, "_timestamp": 1585079762.7929897, "_step": 281}
{"Episode reward": -95.3035453343417, "Episode length": 999, "Policy Loss": -12.199728012084961, "Value Loss": 0.029932890087366104, "_runtime": 330.8334665298462, "_timestamp": 1585079763.9227126, "_step": 282}
{"Episode reward": -95.47918351249443, "Episode length": 999, "Policy Loss": -12.267594337463379, "Value Loss": 0.027286911383271217, "_runtime": 331.9204857349396, "_timestamp": 1585079765.0097318, "_step": 283}
{"Episode reward": -105.22115146826533, "Episode length": 999, "Policy Loss": -13.644519805908203, "Value Loss": 0.031719356775283813, "_runtime": 333.05277919769287, "_timestamp": 1585079766.1420252, "_step": 284}
{"Episode reward": -96.21341654141581, "Episode length": 999, "Policy Loss": -12.256535530090332, "Value Loss": 0.02430042065680027, "_runtime": 334.17391419410706, "_timestamp": 1585079767.2631602, "_step": 285}
{"Episode reward": -103.62030061469255, "Episode length": 999, "Policy Loss": -13.491869926452637, "Value Loss": 0.03044091910123825, "_runtime": 335.2785716056824, "_timestamp": 1585079768.3678176, "_step": 286}
{"Episode reward": -93.00866054806966, "Episode length": 999, "Policy Loss": -11.697047233581543, "Value Loss": 0.02306017279624939, "_runtime": 336.37935853004456, "_timestamp": 1585079769.4686046, "_step": 287}
{"Episode reward": -97.4577299702498, "Episode length": 999, "Policy Loss": -12.488638877868652, "Value Loss": 0.03009454347193241, "_runtime": 337.4918177127838, "_timestamp": 1585079770.5810637, "_step": 288}
{"Episode reward": -94.78251395560424, "Episode length": 999, "Policy Loss": -12.021095275878906, "Value Loss": 0.02595105767250061, "_runtime": 338.63028931617737, "_timestamp": 1585079771.7195354, "_step": 289}
{"Episode reward": -98.56724116584046, "Episode length": 999, "Policy Loss": -12.603963851928711, "Value Loss": 0.026343513280153275, "_runtime": 339.73373794555664, "_timestamp": 1585079772.822984, "_step": 290}
{"Episode reward": -99.82973540464029, "Episode length": 999, "Policy Loss": -12.726838111877441, "Value Loss": 0.03303099051117897, "_runtime": 340.8562262058258, "_timestamp": 1585079773.9454722, "_step": 291}
{"Episode reward": -99.38865455062255, "Episode length": 999, "Policy Loss": -12.823395729064941, "Value Loss": 0.029559671878814697, "_runtime": 341.9425902366638, "_timestamp": 1585079775.0318363, "_step": 292}
{"Episode reward": -100.42815915266868, "Episode length": 999, "Policy Loss": -12.910489082336426, "Value Loss": 0.028086557984352112, "_runtime": 343.08530926704407, "_timestamp": 1585079776.1745553, "_step": 293}
{"Episode reward": -104.78999569998459, "Episode length": 999, "Policy Loss": -13.796192169189453, "Value Loss": 0.038981035351753235, "_runtime": 344.2236487865448, "_timestamp": 1585079777.3128948, "_step": 294}
{"Episode reward": -99.4617678382288, "Episode length": 999, "Policy Loss": -12.61329174041748, "Value Loss": 0.031757548451423645, "_runtime": 345.3337366580963, "_timestamp": 1585079778.4229827, "_step": 295}
{"Episode reward": -100.16318233351996, "Episode length": 999, "Policy Loss": -12.85998249053955, "Value Loss": 0.030863098800182343, "_runtime": 346.44369769096375, "_timestamp": 1585079779.5329437, "_step": 296}
{"Episode reward": -93.53327741526857, "Episode length": 999, "Policy Loss": -11.813129425048828, "Value Loss": 0.024695299565792084, "_runtime": 347.5473403930664, "_timestamp": 1585079780.6365864, "_step": 297}
{"Episode reward": -97.21983357102164, "Episode length": 999, "Policy Loss": -12.570013999938965, "Value Loss": 0.027270261198282242, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375, -102.1634521484375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-99.3899154663086, -96.95257568359375, -94.51522827148438, -92.077880859375, -89.64054107666016, -87.20320129394531, -84.76585388183594, -82.32850646972656, -79.89116668701172, -77.45382690429688, -75.0164794921875, -72.57913208007812, -70.14179229736328, -67.70445251464844, -65.26710510253906, -62.82976150512695, -60.392417907714844, -57.955074310302734, -55.517730712890625, -53.080387115478516, -50.643043518066406, -48.2056999206543, -45.76835632324219, -43.33101272583008, -40.89366912841797, -38.45632553100586, -36.01898193359375, -33.581642150878906, -31.14429473876953, -28.706947326660156, -26.269607543945312, -23.83226776123047, -21.394920349121094, -18.95757293701172, -16.520233154296875, -14.082893371582031, -11.645545959472656, -9.208198547363281, -6.7708587646484375, -4.333518981933594, -1.8961715698242188, 0.5411758422851562, 2.978515625, 5.415855407714844, 7.853202819824219, 10.290550231933594, 12.727890014648438, 15.165229797363281, 17.602577209472656, 20.03992462158203, 22.477264404296875, 24.91460418701172, 27.351951599121094, 29.78929901123047, 32.22663116455078, 34.663978576660156, 37.10132598876953, 39.538673400878906, 41.97602081298828, 44.413352966308594, 46.85070037841797, 49.288047790527344, 51.725379943847656, 54.16272735595703, 56.600074768066406]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-49.053157806396484, -47.413291931152344, -45.77342224121094, -44.1335563659668, -42.493690490722656, -40.853824615478516, -39.213958740234375, -37.57408905029297, -35.93422317504883, -34.29435729980469, -32.65448760986328, -31.01462173461914, -29.374755859375, -27.73488998413086, -26.095022201538086, -24.455154418945312, -22.815288543701172, -21.17542266845703, -19.535554885864258, -17.895687103271484, -16.255821228027344, -14.615955352783203, -12.976085662841797, -11.336219787597656, -9.696353912353516, -8.056488037109375, -6.416622161865234, -4.776752471923828, -3.1368865966796875, -1.4970207214355469, 0.14284896850585938, 1.78271484375, 3.4225807189941406, 5.062446594238281, 6.702312469482422, 8.342182159423828, 9.982048034667969, 11.62191390991211, 13.261783599853516, 14.901649475097656, 16.541515350341797, 18.181385040283203, 19.821247100830078, 21.461116790771484, 23.10098648071289, 24.740848541259766, 26.380718231201172, 28.020580291748047, 29.660449981689453, 31.30031967163086, 32.940181732177734, 34.58005142211914, 36.219913482666016, 37.85978317260742, 39.49965286254883, 41.1395149230957, 42.77938461303711, 44.419254302978516, 46.05911636352539, 47.6989860534668, 49.3388557434082, 50.97871780395508, 52.618587493896484, 54.25844955444336, 55.898319244384766]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 4.0, 4.0, 6.0, 2.0, 2.0, 4.0, 4.0, 4.0, 8.0, 4.0, 10.0, 12.0, 19.0, 27.0, 33.0, 27.0, 39.0, 36.0, 43.0, 52.0, 25.0, 15.0, 19.0, 14.0, 10.0, 11.0, 11.0, 13.0, 6.0, 8.0, 4.0, 8.0, 4.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0], "bins": [-44.82616424560547, -43.327606201171875, -41.82905197143555, -40.33049774169922, -38.831939697265625, -37.33338165283203, -35.8348274230957, -34.336273193359375, -32.83771514892578, -31.33915901184082, -29.84060287475586, -28.3420467376709, -26.843490600585938, -25.344934463500977, -23.846378326416016, -22.347822189331055, -20.849266052246094, -19.350709915161133, -17.852153778076172, -16.35359764099121, -14.85504150390625, -13.356485366821289, -11.857929229736328, -10.359375, -8.860816955566406, -7.3622589111328125, -5.863704681396484, -4.365150451660156, -2.8665924072265625, -1.3680343627929688, 0.13051986694335938, 1.6290740966796875, 3.1276321411132812, 4.626190185546875, 6.124744415283203, 7.623298645019531, 9.121856689453125, 10.620414733886719, 12.118968963623047, 13.617523193359375, 15.116081237792969, 16.614639282226562, 18.11319351196289, 19.61174774169922, 21.110305786132812, 22.608863830566406, 24.10741424560547, 25.605972290039062, 27.104530334472656, 28.60308837890625, 30.101646423339844, 31.600196838378906, 33.0987548828125, 34.597312927246094, 36.095863342285156, 37.59442138671875, 39.092979431152344, 40.59153747558594, 42.09009552001953, 43.588645935058594, 45.08720397949219, 46.58576202392578, 48.084312438964844, 49.58287048339844, 51.08142852783203]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-39.383514404296875, -38.44865417480469, -37.5137939453125, -36.57892990112305, -35.64406967163086, -34.70920944213867, -33.774349212646484, -32.8394889831543, -31.904626846313477, -30.969764709472656, -30.03490447998047, -29.10004425048828, -28.16518211364746, -27.23031997680664, -26.295459747314453, -25.360599517822266, -24.425739288330078, -23.490877151489258, -22.55601692199707, -21.62115478515625, -20.686294555664062, -19.751432418823242, -18.816572189331055, -17.881711959838867, -16.946849822998047, -16.01198959350586, -15.077127456665039, -14.142267227172852, -13.207406997680664, -12.272544860839844, -11.337684631347656, -10.402822494506836, -9.467962265014648, -8.533102035522461, -7.598239898681641, -6.663379669189453, -5.728519439697266, -4.7936553955078125, -3.858795166015625, -2.9239349365234375, -1.98907470703125, -1.0542144775390625, -0.11935043334960938, 0.8155097961425781, 1.7503700256347656, 2.685230255126953, 3.6200904846191406, 4.554954528808594, 5.489814758300781, 6.424674987792969, 7.359535217285156, 8.294395446777344, 9.229259490966797, 10.164119720458984, 11.098979949951172, 12.03384017944336, 12.968700408935547, 13.903564453125, 14.838424682617188, 15.773284912109375, 16.708145141601562, 17.64300537109375, 18.577869415283203, 19.51272964477539, 20.447589874267578]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 32.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-15.18580436706543, -14.487561225891113, -13.789319038391113, -13.091075897216797, -12.392833709716797, -11.69459056854248, -10.996347427368164, -10.298105239868164, -9.599862098693848, -8.901618957519531, -8.203376770019531, -7.505133628845215, -6.806890487670898, -6.108648300170898, -5.410405158996582, -4.712162971496582, -4.013919830322266, -3.315676689147949, -2.617434501647949, -1.9191913604736328, -1.2209491729736328, -0.5227060317993164, 0.175537109375, 0.873779296875, 1.5720233917236328, 2.270265579223633, 2.968507766723633, 3.666749954223633, 4.364994049072266, 5.063236236572266, 5.761478424072266, 6.459722518920898, 7.157964706420898, 7.856206893920898, 8.554450988769531, 9.252693176269531, 9.950935363769531, 10.649179458618164, 11.347421646118164, 12.045663833618164, 12.743906021118164, 13.442150115966797, 14.140392303466797, 14.838634490966797, 15.53687858581543, 16.23512077331543, 16.93336296081543, 17.63160514831543, 18.329851150512695, 19.028093338012695, 19.726335525512695, 20.424577713012695, 21.122819900512695, 21.821062088012695, 22.519304275512695, 23.21755027770996, 23.91579246520996, 24.61403465270996, 25.31227684020996, 26.01051902770996, 26.70876121520996, 27.407007217407227, 28.105249404907227, 28.803491592407227, 29.501733779907227]}, "_runtime": 348.66147923469543, "_timestamp": 1585079781.7507253, "_step": 298}
{"Episode reward": -94.76174660201215, "Episode length": 999, "Policy Loss": -11.932279586791992, "Value Loss": 0.02805039845407009, "_runtime": 349.75642585754395, "_timestamp": 1585079782.845672, "_step": 299}
{"Episode reward": -94.20937701458911, "Episode length": 999, "Policy Loss": -11.91347885131836, "Value Loss": 0.024737855419516563, "_runtime": 350.8851206302643, "_timestamp": 1585079783.9743667, "_step": 300}
{"Episode reward": -106.13276581699542, "Episode length": 999, "Policy Loss": -14.071064949035645, "Value Loss": 0.0320756733417511, "_runtime": 351.99319076538086, "_timestamp": 1585079785.0824368, "_step": 301}
{"Episode reward": -100.91622065770817, "Episode length": 999, "Policy Loss": -12.982563972473145, "Value Loss": 0.028612859547138214, "_runtime": 353.1396174430847, "_timestamp": 1585079786.2288635, "_step": 302}
{"Episode reward": -104.26670191227335, "Episode length": 999, "Policy Loss": -13.513921737670898, "Value Loss": 0.032188862562179565, "_runtime": 354.283611536026, "_timestamp": 1585079787.3728576, "_step": 303}
{"Episode reward": -103.12723982759915, "Episode length": 999, "Policy Loss": -13.52052116394043, "Value Loss": 0.032327111810445786, "_runtime": 355.386004447937, "_timestamp": 1585079788.4752505, "_step": 304}
{"Episode reward": -97.0170702228426, "Episode length": 999, "Policy Loss": -12.445077896118164, "Value Loss": 0.029120096936821938, "_runtime": 356.51025557518005, "_timestamp": 1585079789.5995016, "_step": 305}
{"Episode reward": -102.30535350286132, "Episode length": 999, "Policy Loss": -13.488876342773438, "Value Loss": 0.033258773386478424, "_runtime": 357.6518859863281, "_timestamp": 1585079790.741132, "_step": 306}
{"Episode reward": -103.36914077724349, "Episode length": 999, "Policy Loss": -13.451356887817383, "Value Loss": 0.031076889485120773, "_runtime": 358.7948338985443, "_timestamp": 1585079791.88408, "_step": 307}
{"Episode reward": -101.33584557037699, "Episode length": 999, "Policy Loss": -13.163440704345703, "Value Loss": 0.034177329391241074, "_runtime": 359.9229655265808, "_timestamp": 1585079793.0122116, "_step": 308}
{"Episode reward": -103.92852739767986, "Episode length": 999, "Policy Loss": -13.563100814819336, "Value Loss": 0.03406761959195137, "_runtime": 361.0448305606842, "_timestamp": 1585079794.1340766, "_step": 309}
{"Episode reward": -97.87191143941907, "Episode length": 999, "Policy Loss": -12.67606258392334, "Value Loss": 0.028722872957587242, "_runtime": 362.1328766345978, "_timestamp": 1585079795.2221227, "_step": 310}
{"Episode reward": -105.08774614971644, "Episode length": 999, "Policy Loss": -13.773513793945312, "Value Loss": 0.03298065438866615, "_runtime": 363.3044412136078, "_timestamp": 1585079796.3936872, "_step": 311}
{"Episode reward": -98.85367952483462, "Episode length": 999, "Policy Loss": -12.504133224487305, "Value Loss": 0.02979520708322525, "_runtime": 364.43843603134155, "_timestamp": 1585079797.527682, "_step": 312}
{"Episode reward": -96.10008080381839, "Episode length": 999, "Policy Loss": -12.239217758178711, "Value Loss": 0.024210259318351746, "_runtime": 365.5999274253845, "_timestamp": 1585079798.6891735, "_step": 313}
{"Episode reward": -93.50365804669593, "Episode length": 999, "Policy Loss": -11.920625686645508, "Value Loss": 0.025456324219703674, "_runtime": 366.76275515556335, "_timestamp": 1585079799.8520012, "_step": 314}
{"Episode reward": -91.98139272853628, "Episode length": 999, "Policy Loss": -11.664642333984375, "Value Loss": 0.02617577277123928, "_runtime": 367.8529920578003, "_timestamp": 1585079800.942238, "_step": 315}
{"Episode reward": -89.43214737272639, "Episode length": 999, "Policy Loss": -11.02110767364502, "Value Loss": 0.02593231201171875, "_runtime": 368.9635498523712, "_timestamp": 1585079802.052796, "_step": 316}
{"Episode reward": -94.8692968879376, "Episode length": 999, "Policy Loss": -11.985086441040039, "Value Loss": 0.02690264768898487, "_runtime": 370.0854558944702, "_timestamp": 1585079803.174702, "_step": 317}
{"Episode reward": -101.58439048254924, "Episode length": 999, "Policy Loss": -13.316399574279785, "Value Loss": 0.030059801414608955, "_runtime": 371.17937564849854, "_timestamp": 1585079804.2686217, "_step": 318}
{"Episode reward": -92.67478733429859, "Episode length": 999, "Policy Loss": -11.64365291595459, "Value Loss": 0.025344479829072952, "_runtime": 372.25957345962524, "_timestamp": 1585079805.3488195, "_step": 319}
{"Episode reward": -94.28957646542439, "Episode length": 999, "Policy Loss": -12.022832870483398, "Value Loss": 0.025603000074625015, "_runtime": 373.4258360862732, "_timestamp": 1585079806.5150821, "_step": 320}
{"Episode reward": -98.25124970481897, "Episode length": 999, "Policy Loss": -12.575087547302246, "Value Loss": 0.030663488432765007, "_runtime": 374.5365767478943, "_timestamp": 1585079807.6258228, "_step": 321}
{"Episode reward": -96.39055749054845, "Episode length": 999, "Policy Loss": -12.30394172668457, "Value Loss": 0.02830429933965206, "_runtime": 375.6434209346771, "_timestamp": 1585079808.732667, "_step": 322}
{"Episode reward": -96.34491798839868, "Episode length": 999, "Policy Loss": -12.500630378723145, "Value Loss": 0.027867140248417854, "_runtime": 376.85181069374084, "_timestamp": 1585079809.9410567, "_step": 323}
{"Episode reward": -106.92447901201953, "Episode length": 999, "Policy Loss": -14.110489845275879, "Value Loss": 0.0333072729408741, "_runtime": 377.9582657814026, "_timestamp": 1585079811.0475118, "_step": 324}
{"Episode reward": -97.265786127167, "Episode length": 999, "Policy Loss": -12.412203788757324, "Value Loss": 0.028121037408709526, "_runtime": 379.0619144439697, "_timestamp": 1585079812.1511605, "_step": 325}
{"Episode reward": -100.88003661519508, "Episode length": 999, "Policy Loss": -13.070086479187012, "Value Loss": 0.02873740717768669, "_runtime": 380.1869282722473, "_timestamp": 1585079813.2761743, "_step": 326}
{"Episode reward": -102.40883134480251, "Episode length": 999, "Policy Loss": -13.23758602142334, "Value Loss": 0.03151470795273781, "_runtime": 381.2923457622528, "_timestamp": 1585079814.3815918, "_step": 327}
{"Episode reward": -95.45321379835734, "Episode length": 999, "Policy Loss": -12.269804000854492, "Value Loss": 0.027520067989826202, "_runtime": 382.4083561897278, "_timestamp": 1585079815.4976022, "_step": 328}
{"Episode reward": -107.07027115449708, "Episode length": 999, "Policy Loss": -14.099248886108398, "Value Loss": 0.035237375646829605, "_runtime": 383.5422794818878, "_timestamp": 1585079816.6315255, "_step": 329}
{"Episode reward": -98.23994331267643, "Episode length": 999, "Policy Loss": -12.501940727233887, "Value Loss": 0.031074432656168938, "_runtime": 384.66240429878235, "_timestamp": 1585079817.7516503, "_step": 330}
{"Episode reward": -97.80549246622381, "Episode length": 999, "Policy Loss": -12.472228050231934, "Value Loss": 0.02882787585258484, "_runtime": 385.79761266708374, "_timestamp": 1585079818.8868587, "_step": 331}
{"Episode reward": -93.67060788449909, "Episode length": 999, "Policy Loss": -11.925887107849121, "Value Loss": 0.025523772463202477, "_runtime": 386.929181098938, "_timestamp": 1585079820.0184271, "_step": 332}
{"Episode reward": -101.4422784268922, "Episode length": 999, "Policy Loss": -13.117592811584473, "Value Loss": 0.030154814943671227, "_runtime": 388.06926012039185, "_timestamp": 1585079821.1585062, "_step": 333}
{"Episode reward": -94.8909902802364, "Episode length": 999, "Policy Loss": -12.038546562194824, "Value Loss": 0.02619757317006588, "_runtime": 389.19718050956726, "_timestamp": 1585079822.2864265, "_step": 334}
{"Episode reward": -100.36878989936208, "Episode length": 999, "Policy Loss": -12.867996215820312, "Value Loss": 0.0311825443059206, "_runtime": 390.2987504005432, "_timestamp": 1585079823.3879964, "_step": 335}
{"Episode reward": -104.29704982142839, "Episode length": 999, "Policy Loss": -13.592772483825684, "Value Loss": 0.034252431243658066, "_runtime": 391.3985826969147, "_timestamp": 1585079824.4878287, "_step": 336}
{"Episode reward": -107.5262064005824, "Episode length": 999, "Policy Loss": -14.32923412322998, "Value Loss": 0.034373894333839417, "_runtime": 392.5378084182739, "_timestamp": 1585079825.6270545, "_step": 337}
{"Episode reward": -102.14720828562486, "Episode length": 999, "Policy Loss": -13.337003707885742, "Value Loss": 0.03147279843688011, "_runtime": 393.6502230167389, "_timestamp": 1585079826.739469, "_step": 338}
{"Episode reward": -99.0158045991693, "Episode length": 999, "Policy Loss": -12.818816184997559, "Value Loss": 0.02682454325258732, "_runtime": 394.82587337493896, "_timestamp": 1585079827.9151194, "_step": 339}
{"Episode reward": -96.98735603810147, "Episode length": 999, "Policy Loss": -12.263360023498535, "Value Loss": 0.029157590121030807, "_runtime": 395.97374510765076, "_timestamp": 1585079829.0629911, "_step": 340}
{"Episode reward": -106.78920252270613, "Episode length": 999, "Policy Loss": -14.34149169921875, "Value Loss": 0.03284912928938866, "_runtime": 397.07213020324707, "_timestamp": 1585079830.1613762, "_step": 341}
{"Episode reward": -97.18500682780832, "Episode length": 999, "Policy Loss": -12.477998733520508, "Value Loss": 0.026152856647968292, "_runtime": 398.1908447742462, "_timestamp": 1585079831.2800908, "_step": 342}
{"Episode reward": -93.92695276239266, "Episode length": 999, "Policy Loss": -11.782118797302246, "Value Loss": 0.02681277133524418, "_runtime": 399.3372747898102, "_timestamp": 1585079832.4265208, "_step": 343}
{"Episode reward": -99.84582470191732, "Episode length": 999, "Policy Loss": -13.028553009033203, "Value Loss": 0.03140724450349808, "_runtime": 400.4232304096222, "_timestamp": 1585079833.5124764, "_step": 344}
{"Episode reward": -100.13171991267086, "Episode length": 999, "Policy Loss": -12.86220932006836, "Value Loss": 0.03335602208971977, "_runtime": 401.5143172740936, "_timestamp": 1585079834.6035633, "_step": 345}
{"Episode reward": -103.63252123868693, "Episode length": 999, "Policy Loss": -13.79523754119873, "Value Loss": 0.03153422847390175, "_runtime": 402.6232397556305, "_timestamp": 1585079835.7124858, "_step": 346}
{"Episode reward": -102.21211564304265, "Episode length": 999, "Policy Loss": -13.332934379577637, "Value Loss": 0.03218093141913414, "_runtime": 403.7593822479248, "_timestamp": 1585079836.8486283, "_step": 347}
{"Episode reward": -101.6408299902696, "Episode length": 999, "Policy Loss": -13.182147979736328, "Value Loss": 0.0320136696100235, "_runtime": 404.87795662879944, "_timestamp": 1585079837.9672027, "_step": 348}
{"Episode reward": -104.21853809892579, "Episode length": 999, "Policy Loss": -13.837319374084473, "Value Loss": 0.03567909821867943, "_runtime": 406.0070593357086, "_timestamp": 1585079839.0963054, "_step": 349}
{"Episode reward": -101.65494984392396, "Episode length": 999, "Policy Loss": -13.070507049560547, "Value Loss": 0.030299846082925797, "_runtime": 407.1253490447998, "_timestamp": 1585079840.214595, "_step": 350}
{"Episode reward": -103.93963980400217, "Episode length": 999, "Policy Loss": -13.54539680480957, "Value Loss": 0.03168053179979324, "_runtime": 408.2740831375122, "_timestamp": 1585079841.3633292, "_step": 351}
{"Episode reward": -106.82744149748244, "Episode length": 999, "Policy Loss": -13.788948059082031, "Value Loss": 0.03730177506804466, "_runtime": 409.42410111427307, "_timestamp": 1585079842.5133471, "_step": 352}
{"Episode reward": -103.43693485473989, "Episode length": 999, "Policy Loss": -13.675848960876465, "Value Loss": 0.03340272977948189, "_runtime": 410.5236918926239, "_timestamp": 1585079843.612938, "_step": 353}
{"Episode reward": -102.00179845118305, "Episode length": 999, "Policy Loss": -13.223587036132812, "Value Loss": 0.03005341812968254, "_runtime": 411.63115644454956, "_timestamp": 1585079844.7204025, "_step": 354}
{"Episode reward": -102.24301974251135, "Episode length": 999, "Policy Loss": -13.406451225280762, "Value Loss": 0.03129096329212189, "_runtime": 412.734956741333, "_timestamp": 1585079845.8242028, "_step": 355}
{"Episode reward": -101.75705786072434, "Episode length": 999, "Policy Loss": -13.228865623474121, "Value Loss": 0.030387308448553085, "_runtime": 413.8712637424469, "_timestamp": 1585079846.9605098, "_step": 356}
{"Episode reward": -96.75675624143753, "Episode length": 999, "Policy Loss": -12.164384841918945, "Value Loss": 0.02681097574532032, "_runtime": 415.00869965553284, "_timestamp": 1585079848.0979457, "_step": 357}
{"Episode reward": -97.36343256596884, "Episode length": 999, "Policy Loss": -12.21696662902832, "Value Loss": 0.029356399551033974, "_runtime": 416.1592011451721, "_timestamp": 1585079849.2484472, "_step": 358}
{"Episode reward": -99.4807298028441, "Episode length": 999, "Policy Loss": -12.91108226776123, "Value Loss": 0.028651446104049683, "_runtime": 417.27224135398865, "_timestamp": 1585079850.3614874, "_step": 359}
{"Episode reward": -99.44277333440391, "Episode length": 999, "Policy Loss": -13.035544395446777, "Value Loss": 0.031913306564092636, "_runtime": 418.4139196872711, "_timestamp": 1585079851.5031657, "_step": 360}
{"Episode reward": -98.46489937785894, "Episode length": 999, "Policy Loss": -12.81181526184082, "Value Loss": 0.02879893220961094, "_runtime": 419.55627393722534, "_timestamp": 1585079852.64552, "_step": 361}
{"Episode reward": -96.9641602335231, "Episode length": 999, "Policy Loss": -12.427833557128906, "Value Loss": 0.029223045334219933, "_runtime": 420.6778585910797, "_timestamp": 1585079853.7671046, "_step": 362}
{"Episode reward": -99.83917064455449, "Episode length": 999, "Policy Loss": -12.821525573730469, "Value Loss": 0.030563484877347946, "_runtime": 421.7719099521637, "_timestamp": 1585079854.861156, "_step": 363}
{"Episode reward": -99.4509158311713, "Episode length": 999, "Policy Loss": -12.830245971679688, "Value Loss": 0.0315161757171154, "_runtime": 422.87930035591125, "_timestamp": 1585079855.9685464, "_step": 364}
{"Episode reward": -100.97056421664479, "Episode length": 999, "Policy Loss": -13.051867485046387, "Value Loss": 0.03112887777388096, "_runtime": 423.9990072250366, "_timestamp": 1585079857.0882533, "_step": 365}
{"Episode reward": -99.22369554560045, "Episode length": 999, "Policy Loss": -12.723889350891113, "Value Loss": 0.028654346242547035, "_runtime": 425.1655287742615, "_timestamp": 1585079858.2547748, "_step": 366}
{"Episode reward": -100.15071501162845, "Episode length": 999, "Policy Loss": -12.745593070983887, "Value Loss": 0.030871940776705742, "_runtime": 426.2598309516907, "_timestamp": 1585079859.349077, "_step": 367}
{"Episode reward": -97.68372751400506, "Episode length": 999, "Policy Loss": -12.448689460754395, "Value Loss": 0.0315888486802578, "_runtime": 427.3740165233612, "_timestamp": 1585079860.4632626, "_step": 368}
{"Episode reward": -107.61678978078004, "Episode length": 999, "Policy Loss": -13.960018157958984, "Value Loss": 0.033057380467653275, "_runtime": 428.47718262672424, "_timestamp": 1585079861.5664287, "_step": 369}
{"Episode reward": -98.40076404332733, "Episode length": 999, "Policy Loss": -12.791365623474121, "Value Loss": 0.0275474414229393, "_runtime": 429.586222410202, "_timestamp": 1585079862.6754684, "_step": 370}
{"Episode reward": -103.34303856805535, "Episode length": 999, "Policy Loss": -13.493498802185059, "Value Loss": 0.030167201533913612, "_runtime": 430.71278381347656, "_timestamp": 1585079863.8020298, "_step": 371}
{"Episode reward": -98.39768457021898, "Episode length": 999, "Policy Loss": -12.465802192687988, "Value Loss": 0.02864653617143631, "_runtime": 431.83526945114136, "_timestamp": 1585079864.9245155, "_step": 372}
{"Episode reward": -104.91180646076845, "Episode length": 999, "Policy Loss": -13.731171607971191, "Value Loss": 0.031188955530524254, "_runtime": 432.9574730396271, "_timestamp": 1585079866.046719, "_step": 373}
{"Episode reward": -91.58019067531662, "Episode length": 999, "Policy Loss": -11.225123405456543, "Value Loss": 0.0242895670235157, "_runtime": 434.06325006484985, "_timestamp": 1585079867.152496, "_step": 374}
{"Episode reward": -99.7057609556536, "Episode length": 999, "Policy Loss": -12.742490768432617, "Value Loss": 0.029935529455542564, "_runtime": 435.1906805038452, "_timestamp": 1585079868.2799265, "_step": 375}
{"Episode reward": -103.38533361423539, "Episode length": 999, "Policy Loss": -13.275664329528809, "Value Loss": 0.03257371112704277, "_runtime": 436.2855348587036, "_timestamp": 1585079869.374781, "_step": 376}
{"Episode reward": -106.3838843455699, "Episode length": 999, "Policy Loss": -13.932604789733887, "Value Loss": 0.04194406047463417, "_runtime": 437.39311122894287, "_timestamp": 1585079870.4823573, "_step": 377}
{"Episode reward": -100.81944977675664, "Episode length": 999, "Policy Loss": -13.088851928710938, "Value Loss": 0.030193187296390533, "_runtime": 438.49848198890686, "_timestamp": 1585079871.587728, "_step": 378}
{"Episode reward": -95.80072323504261, "Episode length": 999, "Policy Loss": -12.269847869873047, "Value Loss": 0.027728315442800522, "_runtime": 439.5949196815491, "_timestamp": 1585079872.6841657, "_step": 379}
{"Episode reward": -94.86092152550319, "Episode length": 999, "Policy Loss": -12.189927101135254, "Value Loss": 0.02927221544086933, "_runtime": 440.6973979473114, "_timestamp": 1585079873.786644, "_step": 380}
{"Episode reward": -96.75276925977681, "Episode length": 999, "Policy Loss": -12.087395668029785, "Value Loss": 0.02774275466799736, "_runtime": 441.79368591308594, "_timestamp": 1585079874.882932, "_step": 381}
{"Episode reward": -100.1361064210705, "Episode length": 999, "Policy Loss": -12.915153503417969, "Value Loss": 0.032037679105997086, "_runtime": 442.899849653244, "_timestamp": 1585079875.9890957, "_step": 382}
{"Episode reward": -98.34563579254618, "Episode length": 999, "Policy Loss": -12.588713645935059, "Value Loss": 0.02687206119298935, "_runtime": 444.013370513916, "_timestamp": 1585079877.1026165, "_step": 383}
{"Episode reward": -103.85477886502764, "Episode length": 999, "Policy Loss": -13.667288780212402, "Value Loss": 0.032483041286468506, "_runtime": 445.1440200805664, "_timestamp": 1585079878.233266, "_step": 384}
{"Episode reward": -96.66958591705834, "Episode length": 999, "Policy Loss": -12.042926788330078, "Value Loss": 0.027804387733340263, "_runtime": 446.2360062599182, "_timestamp": 1585079879.3252523, "_step": 385}
{"Episode reward": -96.49101782342716, "Episode length": 999, "Policy Loss": -12.249320030212402, "Value Loss": 0.026393482461571693, "_runtime": 447.3463339805603, "_timestamp": 1585079880.43558, "_step": 386}
{"Episode reward": -101.62248811750835, "Episode length": 999, "Policy Loss": -13.281785011291504, "Value Loss": 0.03371536359190941, "_runtime": 448.4673578739166, "_timestamp": 1585079881.556604, "_step": 387}
{"Episode reward": -99.09914709600602, "Episode length": 999, "Policy Loss": -12.554912567138672, "Value Loss": 0.03255040571093559, "_runtime": 449.58599066734314, "_timestamp": 1585079882.6752367, "_step": 388}
{"Episode reward": -102.11975646512235, "Episode length": 999, "Policy Loss": -13.139993667602539, "Value Loss": 0.031614284962415695, "_runtime": 450.73504757881165, "_timestamp": 1585079883.8242936, "_step": 389}
{"Episode reward": -95.00504444633881, "Episode length": 999, "Policy Loss": -11.857335090637207, "Value Loss": 0.024257155135273933, "_runtime": 451.84806632995605, "_timestamp": 1585079884.9373124, "_step": 390}
{"Episode reward": -96.16778817035552, "Episode length": 999, "Policy Loss": -12.334623336791992, "Value Loss": 0.03146842122077942, "_runtime": 452.98013639450073, "_timestamp": 1585079886.0693824, "_step": 391}
{"Episode reward": -96.83018974318767, "Episode length": 999, "Policy Loss": -12.43538761138916, "Value Loss": 0.02784864977002144, "_runtime": 454.12358140945435, "_timestamp": 1585079887.2128274, "_step": 392}
{"Episode reward": -103.22295258459316, "Episode length": 999, "Policy Loss": -13.70776653289795, "Value Loss": 0.02791026048362255, "_runtime": 455.2467186450958, "_timestamp": 1585079888.3359647, "_step": 393}
{"Episode reward": -100.00325902938982, "Episode length": 999, "Policy Loss": -12.783838272094727, "Value Loss": 0.03342438116669655, "_runtime": 456.3552598953247, "_timestamp": 1585079889.444506, "_step": 394}
{"Episode reward": -102.47082441371833, "Episode length": 999, "Policy Loss": -13.135622024536133, "Value Loss": 0.029346266761422157, "_runtime": 457.49057483673096, "_timestamp": 1585079890.5798209, "_step": 395}
{"Episode reward": -98.13001140306062, "Episode length": 999, "Policy Loss": -12.790428161621094, "Value Loss": 0.027901113033294678, "_runtime": 458.59797644615173, "_timestamp": 1585079891.6872225, "_step": 396}
{"Episode reward": -98.64438386056055, "Episode length": 999, "Policy Loss": -12.620397567749023, "Value Loss": 0.02864331752061844, "_runtime": 459.7011089324951, "_timestamp": 1585079892.790355, "_step": 397}
{"Episode reward": -93.28079807566435, "Episode length": 999, "Policy Loss": -11.636290550231934, "Value Loss": 0.0265379436314106, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547, -144.9842987060547]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-141.66220092773438, -138.18148803710938, -134.70077514648438, -131.2200469970703, -127.73933410644531, -124.25862121582031, -120.77790069580078, -117.29718780517578, -113.81646728515625, -110.33575439453125, -106.85504150390625, -103.37432098388672, -99.89360046386719, -96.41288757324219, -92.93217468261719, -89.45145416259766, -85.97073364257812, -82.49002075195312, -79.00930786132812, -75.5285873413086, -72.0478744506836, -68.56715393066406, -65.08644104003906, -61.60572052001953, -58.12500762939453, -54.644287109375, -51.16357421875, -47.68285369873047, -44.20214080810547, -40.72142028808594, -37.24070739746094, -33.759986877441406, -30.279273986816406, -26.798561096191406, -23.317840576171875, -19.837127685546875, -16.356407165527344, -12.875686645507812, -9.394973754882812, -5.9142608642578125, -2.4335479736328125, 1.04718017578125, 4.52789306640625, 8.00860595703125, 11.48931884765625, 14.970046997070312, 18.450759887695312, 21.931472778320312, 25.412185668945312, 28.892898559570312, 32.373626708984375, 35.854339599609375, 39.335052490234375, 42.815765380859375, 46.29649353027344, 49.77720642089844, 53.25791931152344, 56.73863220214844, 60.2193603515625, 63.7000732421875, 67.1807861328125, 70.6614990234375, 74.14222717285156, 77.62294006347656, 81.10365295410156]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-69.47290802001953, -67.14778900146484, -64.82267761230469, -62.49755859375, -60.17244338989258, -57.847328186035156, -55.52220916748047, -53.19709396362305, -50.871978759765625, -48.5468635559082, -46.22174835205078, -43.896629333496094, -41.57151412963867, -39.24639892578125, -36.92127990722656, -34.59616470336914, -32.27104949951172, -29.945934295654297, -27.620819091796875, -25.295700073242188, -22.970584869384766, -20.645469665527344, -18.320350646972656, -15.995235443115234, -13.670120239257812, -11.34500503540039, -9.019889831542969, -6.694770812988281, -4.369651794433594, -2.0445404052734375, 0.28057861328125, 2.6056900024414062, 4.930809020996094, 7.255928039550781, 9.581039428710938, 11.906158447265625, 14.231269836425781, 16.55638885498047, 18.881507873535156, 21.206619262695312, 23.53173828125, 25.856857299804688, 28.181968688964844, 30.50708770751953, 32.83220672607422, 35.157318115234375, 37.48243713378906, 39.80754852294922, 42.132667541503906, 44.457786560058594, 46.78289794921875, 49.10801696777344, 51.433128356933594, 53.75824737548828, 56.08336639404297, 58.408477783203125, 60.733604431152344, 63.05870819091797, 65.38382720947266, 67.70894622802734, 70.03406524658203, 72.35918426513672, 74.68428802490234, 77.00940704345703, 79.33452606201172]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 4.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 10.0, 2.0, 11.0, 14.0, 19.0, 28.0, 29.0, 28.0, 37.0, 39.0, 43.0, 52.0, 24.0, 14.0, 18.0, 13.0, 10.0, 12.0, 12.0, 12.0, 7.0, 9.0, 3.0, 7.0, 5.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-62.71714782714844, -60.618133544921875, -58.51911926269531, -56.42010498046875, -54.32109069824219, -52.222076416015625, -50.1230583190918, -48.024044036865234, -45.92502975463867, -43.82601547241211, -41.72700119018555, -39.62798309326172, -37.528968811035156, -35.429954528808594, -33.33094024658203, -31.23192596435547, -29.132911682128906, -27.033897399902344, -24.93488311767578, -22.83586883544922, -20.736854553222656, -18.637836456298828, -16.538822174072266, -14.439807891845703, -12.34079360961914, -10.241779327392578, -8.142765045166016, -6.043750762939453, -3.944732666015625, -1.8457183837890625, 0.2532958984375, 2.3523101806640625, 4.451324462890625, 6.5503387451171875, 8.64935302734375, 10.748367309570312, 12.847381591796875, 14.946395874023438, 17.04541015625, 19.144424438476562, 21.243438720703125, 23.34246063232422, 25.44147491455078, 27.540489196777344, 29.639503479003906, 31.73851776123047, 33.83753204345703, 35.936546325683594, 38.035560607910156, 40.13457489013672, 42.23358917236328, 44.332603454589844, 46.431617736816406, 48.53063201904297, 50.62964630126953, 52.728660583496094, 54.82768249511719, 56.92669677734375, 59.02571105957031, 61.124725341796875, 63.22373962402344, 65.32275390625, 67.42176818847656, 69.52078247070312, 71.61979675292969]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-55.92771530151367, -54.59195327758789, -53.256195068359375, -51.920433044433594, -50.58467102050781, -49.24890899658203, -47.913150787353516, -46.577388763427734, -45.24163055419922, -43.90586853027344, -42.570106506347656, -41.234344482421875, -39.89858627319336, -38.56282424926758, -37.22706604003906, -35.89130401611328, -34.5555419921875, -33.21977996826172, -31.88401985168457, -30.548259735107422, -29.21249771118164, -27.876737594604492, -26.540977478027344, -25.205215454101562, -23.869457244873047, -22.533695220947266, -21.197933197021484, -19.862171173095703, -18.526412963867188, -17.190650939941406, -15.854888916015625, -14.51913070678711, -13.183368682861328, -11.847606658935547, -10.511848449707031, -9.17608642578125, -7.840324401855469, -6.504566192626953, -5.168804168701172, -3.8330421447753906, -2.4972801208496094, -1.1615219116210938, 0.1742401123046875, 1.5100021362304688, 2.8457603454589844, 4.181522369384766, 5.517284393310547, 6.8530426025390625, 8.188800811767578, 9.52456283569336, 10.86032485961914, 12.196086883544922, 13.531848907470703, 14.867610931396484, 16.203372955322266, 17.539127349853516, 18.874889373779297, 20.210651397705078, 21.54641342163086, 22.88217544555664, 24.217937469482422, 25.553691864013672, 26.889453887939453, 28.225215911865234, 29.560977935791016]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 12.0, 20.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-20.978504180908203, -20.030736923217773, -19.08296775817871, -18.13520050048828, -17.18743324279785, -16.23966407775879, -15.29189682006836, -14.344128608703613, -13.396360397338867, -12.448593139648438, -11.500824928283691, -10.553056716918945, -9.605289459228516, -8.65752124786377, -7.709753036499023, -6.761985778808594, -5.814217567443848, -4.866449356079102, -3.918682098388672, -2.9709129333496094, -2.0231456756591797, -1.07537841796875, -0.1276092529296875, 0.8201580047607422, 1.7679252624511719, 2.7156944274902344, 3.663461685180664, 4.611228942871094, 5.558998107910156, 6.506765365600586, 7.454532623291016, 8.402301788330078, 9.350069046020508, 10.297836303710938, 11.24560546875, 12.193374633789062, 13.14113998413086, 14.088909149169922, 15.036678314208984, 15.984443664550781, 16.932212829589844, 17.879981994628906, 18.827747344970703, 19.775516510009766, 20.723285675048828, 21.671051025390625, 22.618820190429688, 23.56658935546875, 24.514354705810547, 25.46212387084961, 26.409893035888672, 27.35765838623047, 28.30542755126953, 29.253196716308594, 30.20096206665039, 31.148731231689453, 32.096500396728516, 33.04426574707031, 33.992034912109375, 34.93980407714844, 35.887569427490234, 36.8353385925293, 37.78310775756836, 38.730873107910156, 39.67864227294922]}, "_runtime": 460.8162055015564, "_timestamp": 1585079893.9054515, "_step": 398}
{"Episode reward": -98.99725286272782, "Episode length": 999, "Policy Loss": -12.83862590789795, "Value Loss": 0.029302211478352547, "_runtime": 461.9028708934784, "_timestamp": 1585079894.992117, "_step": 399}
{"Episode reward": -99.65601455095393, "Episode length": 999, "Policy Loss": -12.656755447387695, "Value Loss": 0.030162138864398003, "_runtime": 463.02768301963806, "_timestamp": 1585079896.116929, "_step": 400}
{"Episode reward": -101.02117016930211, "Episode length": 999, "Policy Loss": -13.309844970703125, "Value Loss": 0.03531814366579056, "_runtime": 464.1578004360199, "_timestamp": 1585079897.2470465, "_step": 401}
{"Episode reward": -95.82515324708793, "Episode length": 999, "Policy Loss": -11.960897445678711, "Value Loss": 0.026047218590974808, "_runtime": 465.2657926082611, "_timestamp": 1585079898.3550386, "_step": 402}
{"Episode reward": -98.37460933263783, "Episode length": 999, "Policy Loss": -12.63514518737793, "Value Loss": 0.028553146868944168, "_runtime": 466.35728693008423, "_timestamp": 1585079899.446533, "_step": 403}
{"Episode reward": -93.55274428565167, "Episode length": 999, "Policy Loss": -11.76173210144043, "Value Loss": 0.02923090197145939, "_runtime": 467.46785020828247, "_timestamp": 1585079900.5570962, "_step": 404}
{"Episode reward": -97.78852166792782, "Episode length": 999, "Policy Loss": -12.451066970825195, "Value Loss": 0.027741866186261177, "_runtime": 468.58161973953247, "_timestamp": 1585079901.6708658, "_step": 405}
{"Episode reward": -100.78364469517238, "Episode length": 999, "Policy Loss": -13.067813873291016, "Value Loss": 0.02880110777914524, "_runtime": 469.7507402896881, "_timestamp": 1585079902.8399863, "_step": 406}
{"Episode reward": -92.78713320027884, "Episode length": 999, "Policy Loss": -11.602652549743652, "Value Loss": 0.025964757427573204, "_runtime": 470.8673686981201, "_timestamp": 1585079903.9566147, "_step": 407}
{"Episode reward": -95.42432025234396, "Episode length": 999, "Policy Loss": -12.210927963256836, "Value Loss": 0.02753678523004055, "_runtime": 471.95184350013733, "_timestamp": 1585079905.0410895, "_step": 408}
{"Episode reward": -99.98298901568758, "Episode length": 999, "Policy Loss": -12.841864585876465, "Value Loss": 0.028871776536107063, "_runtime": 473.0844624042511, "_timestamp": 1585079906.1737084, "_step": 409}
{"Episode reward": -102.66214419008105, "Episode length": 999, "Policy Loss": -13.390360832214355, "Value Loss": 0.030859431251883507, "_runtime": 474.21830439567566, "_timestamp": 1585079907.3075504, "_step": 410}
{"Episode reward": -92.63212769419563, "Episode length": 999, "Policy Loss": -11.820642471313477, "Value Loss": 0.02592439576983452, "_runtime": 475.32066226005554, "_timestamp": 1585079908.4099083, "_step": 411}
{"Episode reward": -99.98830386473276, "Episode length": 999, "Policy Loss": -12.878292083740234, "Value Loss": 0.02964182011783123, "_runtime": 476.4205000400543, "_timestamp": 1585079909.509746, "_step": 412}
{"Episode reward": -99.52375590717327, "Episode length": 999, "Policy Loss": -12.960382461547852, "Value Loss": 0.029963387176394463, "_runtime": 477.52714109420776, "_timestamp": 1585079910.6163871, "_step": 413}
{"Episode reward": -96.99559077224137, "Episode length": 999, "Policy Loss": -12.24698257446289, "Value Loss": 0.02824549563229084, "_runtime": 478.620468378067, "_timestamp": 1585079911.7097144, "_step": 414}
{"Episode reward": -102.26526311646931, "Episode length": 999, "Policy Loss": -13.29561996459961, "Value Loss": 0.029740819707512856, "_runtime": 479.73403668403625, "_timestamp": 1585079912.8232827, "_step": 415}
{"Episode reward": -104.64004104671014, "Episode length": 999, "Policy Loss": -13.62000846862793, "Value Loss": 0.03161869943141937, "_runtime": 480.86714720726013, "_timestamp": 1585079913.9563932, "_step": 416}
{"Episode reward": -100.20174756093994, "Episode length": 999, "Policy Loss": -13.150303840637207, "Value Loss": 0.03118726797401905, "_runtime": 481.953675031662, "_timestamp": 1585079915.042921, "_step": 417}
{"Episode reward": -92.34400846038378, "Episode length": 999, "Policy Loss": -11.408075332641602, "Value Loss": 0.024984052404761314, "_runtime": 483.090616941452, "_timestamp": 1585079916.179863, "_step": 418}
{"Episode reward": -102.11641914178664, "Episode length": 999, "Policy Loss": -13.255208969116211, "Value Loss": 0.030262703076004982, "_runtime": 484.23004388809204, "_timestamp": 1585079917.31929, "_step": 419}
{"Episode reward": -103.6318517396589, "Episode length": 999, "Policy Loss": -13.589521408081055, "Value Loss": 0.035110846161842346, "_runtime": 485.3565661907196, "_timestamp": 1585079918.4458122, "_step": 420}
{"Episode reward": -98.17099319695797, "Episode length": 999, "Policy Loss": -12.817782402038574, "Value Loss": 0.027737347409129143, "_runtime": 486.4567275047302, "_timestamp": 1585079919.5459735, "_step": 421}
{"Episode reward": -97.1071395089569, "Episode length": 999, "Policy Loss": -12.403353691101074, "Value Loss": 0.030242236331105232, "_runtime": 487.60089564323425, "_timestamp": 1585079920.6901417, "_step": 422}
{"Episode reward": -107.11444063106563, "Episode length": 999, "Policy Loss": -14.016735076904297, "Value Loss": 0.038370080292224884, "_runtime": 488.7027213573456, "_timestamp": 1585079921.7919674, "_step": 423}
{"Episode reward": -95.16655482651751, "Episode length": 999, "Policy Loss": -12.070507049560547, "Value Loss": 0.027643129229545593, "_runtime": 489.8119423389435, "_timestamp": 1585079922.9011884, "_step": 424}
{"Episode reward": -98.91724210617974, "Episode length": 999, "Policy Loss": -12.585103034973145, "Value Loss": 0.028982052579522133, "_runtime": 490.961473941803, "_timestamp": 1585079924.05072, "_step": 425}
{"Episode reward": -100.28595848089061, "Episode length": 999, "Policy Loss": -12.818780899047852, "Value Loss": 0.030642341822385788, "_runtime": 492.0384154319763, "_timestamp": 1585079925.1276615, "_step": 426}
{"Episode reward": -94.12201642865718, "Episode length": 999, "Policy Loss": -11.551712036132812, "Value Loss": 0.02821735478937626, "_runtime": 493.2081370353699, "_timestamp": 1585079926.297383, "_step": 427}
{"Episode reward": -89.43304573833818, "Episode length": 999, "Policy Loss": -10.949036598205566, "Value Loss": 0.02449183352291584, "_runtime": 494.32978415489197, "_timestamp": 1585079927.4190302, "_step": 428}
{"Episode reward": -103.14129694150411, "Episode length": 999, "Policy Loss": -13.33260726928711, "Value Loss": 0.03199324011802673, "_runtime": 495.4224224090576, "_timestamp": 1585079928.5116684, "_step": 429}
{"Episode reward": -97.27130566856812, "Episode length": 999, "Policy Loss": -12.198785781860352, "Value Loss": 0.030247727409005165, "_runtime": 496.5347406864166, "_timestamp": 1585079929.6239867, "_step": 430}
{"Episode reward": -109.22419151882515, "Episode length": 999, "Policy Loss": -14.470489501953125, "Value Loss": 0.039762817323207855, "_runtime": 497.6342158317566, "_timestamp": 1585079930.7234619, "_step": 431}
{"Episode reward": -102.46453168261777, "Episode length": 999, "Policy Loss": -13.398900985717773, "Value Loss": 0.03130696341395378, "_runtime": 498.7310335636139, "_timestamp": 1585079931.8202796, "_step": 432}
{"Episode reward": -95.2456741307427, "Episode length": 999, "Policy Loss": -11.981252670288086, "Value Loss": 0.02777859754860401, "_runtime": 499.8286566734314, "_timestamp": 1585079932.9179027, "_step": 433}
{"Episode reward": -93.13582020099722, "Episode length": 999, "Policy Loss": -11.753507614135742, "Value Loss": 0.02398746833205223, "_runtime": 500.95080637931824, "_timestamp": 1585079934.0400524, "_step": 434}
{"Episode reward": -106.09941298932277, "Episode length": 999, "Policy Loss": -14.034819602966309, "Value Loss": 0.03346828371286392, "_runtime": 502.05261993408203, "_timestamp": 1585079935.141866, "_step": 435}
{"Episode reward": -101.15133169936385, "Episode length": 999, "Policy Loss": -12.965264320373535, "Value Loss": 0.029399313032627106, "_runtime": 503.21174669265747, "_timestamp": 1585079936.3009927, "_step": 436}
{"Episode reward": -100.01056615840744, "Episode length": 999, "Policy Loss": -12.782076835632324, "Value Loss": 0.028975345194339752, "_runtime": 504.3348491191864, "_timestamp": 1585079937.4240952, "_step": 437}
{"Episode reward": -106.83954071635944, "Episode length": 999, "Policy Loss": -13.930695533752441, "Value Loss": 0.03603776916861534, "_runtime": 505.42950534820557, "_timestamp": 1585079938.5187514, "_step": 438}
{"Episode reward": -101.15589093769049, "Episode length": 999, "Policy Loss": -12.984099388122559, "Value Loss": 0.029805434867739677, "_runtime": 506.5814731121063, "_timestamp": 1585079939.6707191, "_step": 439}
{"Episode reward": -104.27388073720971, "Episode length": 999, "Policy Loss": -13.624886512756348, "Value Loss": 0.03287546709179878, "_runtime": 507.68475222587585, "_timestamp": 1585079940.7739983, "_step": 440}
{"Episode reward": -103.02595753958438, "Episode length": 999, "Policy Loss": -13.44120979309082, "Value Loss": 0.030139952898025513, "_runtime": 508.7956657409668, "_timestamp": 1585079941.8849118, "_step": 441}
{"Episode reward": -107.8031855892939, "Episode length": 999, "Policy Loss": -14.159991264343262, "Value Loss": 0.034218765795230865, "_runtime": 509.9139485359192, "_timestamp": 1585079943.0031946, "_step": 442}
{"Episode reward": -97.52319630602733, "Episode length": 999, "Policy Loss": -12.539093017578125, "Value Loss": 0.02552226558327675, "_runtime": 511.01879143714905, "_timestamp": 1585079944.1080375, "_step": 443}
{"Episode reward": -105.06537039862305, "Episode length": 999, "Policy Loss": -13.585349082946777, "Value Loss": 0.03557438775897026, "_runtime": 512.1046903133392, "_timestamp": 1585079945.1939363, "_step": 444}
{"Episode reward": -94.23225171186108, "Episode length": 999, "Policy Loss": -11.887332916259766, "Value Loss": 0.029997719451785088, "_runtime": 513.2490015029907, "_timestamp": 1585079946.3382475, "_step": 445}
{"Episode reward": -98.58393022589928, "Episode length": 999, "Policy Loss": -12.569485664367676, "Value Loss": 0.02909865602850914, "_runtime": 514.3934721946716, "_timestamp": 1585079947.4827182, "_step": 446}
{"Episode reward": -93.22360589313455, "Episode length": 999, "Policy Loss": -11.757406234741211, "Value Loss": 0.02561044692993164, "_runtime": 515.4936861991882, "_timestamp": 1585079948.5829322, "_step": 447}
{"Episode reward": -98.6539067768772, "Episode length": 999, "Policy Loss": -12.768656730651855, "Value Loss": 0.027375483885407448, "_runtime": 516.6300313472748, "_timestamp": 1585079949.7192774, "_step": 448}
{"Episode reward": -97.68197845482393, "Episode length": 999, "Policy Loss": -12.57429027557373, "Value Loss": 0.030367907136678696, "_runtime": 517.7323598861694, "_timestamp": 1585079950.821606, "_step": 449}
{"Episode reward": -101.6500932232063, "Episode length": 999, "Policy Loss": -13.16572093963623, "Value Loss": 0.03074549324810505, "_runtime": 518.8634366989136, "_timestamp": 1585079951.9526827, "_step": 450}
{"Episode reward": -90.43681919702726, "Episode length": 999, "Policy Loss": -11.182866096496582, "Value Loss": 0.023391351103782654, "_runtime": 520.0035910606384, "_timestamp": 1585079953.092837, "_step": 451}
{"Episode reward": -90.76477791870035, "Episode length": 999, "Policy Loss": -11.294069290161133, "Value Loss": 0.028814002871513367, "_runtime": 521.1256985664368, "_timestamp": 1585079954.2149446, "_step": 452}
{"Episode reward": -98.9740589651658, "Episode length": 999, "Policy Loss": -12.518622398376465, "Value Loss": 0.03079206682741642, "_runtime": 522.2219970226288, "_timestamp": 1585079955.311243, "_step": 453}
{"Episode reward": -94.2865478637093, "Episode length": 999, "Policy Loss": -11.933799743652344, "Value Loss": 0.026523815467953682, "_runtime": 523.3580856323242, "_timestamp": 1585079956.4473317, "_step": 454}
{"Episode reward": -104.80889424893795, "Episode length": 999, "Policy Loss": -13.960267066955566, "Value Loss": 0.03428194671869278, "_runtime": 524.4836418628693, "_timestamp": 1585079957.572888, "_step": 455}
{"Episode reward": -103.07832895703072, "Episode length": 999, "Policy Loss": -13.623383522033691, "Value Loss": 0.030734151601791382, "_runtime": 525.6207332611084, "_timestamp": 1585079958.7099793, "_step": 456}
{"Episode reward": -109.04422856590851, "Episode length": 999, "Policy Loss": -14.698566436767578, "Value Loss": 0.03496645763516426, "_runtime": 526.7765362262726, "_timestamp": 1585079959.8657823, "_step": 457}
{"Episode reward": -101.38601999896822, "Episode length": 999, "Policy Loss": -13.269227981567383, "Value Loss": 0.03038763254880905, "_runtime": 527.8727717399597, "_timestamp": 1585079960.9620178, "_step": 458}
{"Episode reward": -95.23444959182021, "Episode length": 999, "Policy Loss": -11.989917755126953, "Value Loss": 0.030058685690164566, "_runtime": 528.9672436714172, "_timestamp": 1585079962.0564897, "_step": 459}
{"Episode reward": -104.78061833362094, "Episode length": 999, "Policy Loss": -13.910778999328613, "Value Loss": 0.033110361546278, "_runtime": 530.0920436382294, "_timestamp": 1585079963.1812897, "_step": 460}
{"Episode reward": -98.0056669548175, "Episode length": 999, "Policy Loss": -12.500323295593262, "Value Loss": 0.03163796290755272, "_runtime": 531.182648897171, "_timestamp": 1585079964.271895, "_step": 461}
{"Episode reward": -94.92037798415352, "Episode length": 999, "Policy Loss": -12.017727851867676, "Value Loss": 0.02532438188791275, "_runtime": 532.2724866867065, "_timestamp": 1585079965.3617327, "_step": 462}
{"Episode reward": -98.486560543056, "Episode length": 999, "Policy Loss": -12.50682544708252, "Value Loss": 0.027690783143043518, "_runtime": 533.4245848655701, "_timestamp": 1585079966.513831, "_step": 463}
{"Episode reward": -97.09232388002678, "Episode length": 999, "Policy Loss": -12.11031436920166, "Value Loss": 0.02792341448366642, "_runtime": 534.4016456604004, "_timestamp": 1585079967.4908917, "_step": 464}
{"Episode reward": 13.613791643593046, "Episode length": 887, "Policy Loss": 4.028926372528076, "Value Loss": 11.261590003967285, "_runtime": 535.529744386673, "_timestamp": 1585079968.6189904, "_step": 465}
{"Episode reward": -109.2535906249627, "Episode length": 999, "Policy Loss": -14.50416088104248, "Value Loss": 0.039480842649936676, "_runtime": 536.6561014652252, "_timestamp": 1585079969.7453475, "_step": 466}
{"Episode reward": -102.09501197459274, "Episode length": 999, "Policy Loss": -13.214510917663574, "Value Loss": 0.03180796653032303, "_runtime": 537.7527451515198, "_timestamp": 1585079970.8419912, "_step": 467}
{"Episode reward": -104.08238072510231, "Episode length": 999, "Policy Loss": -13.430154800415039, "Value Loss": 0.030483096837997437, "_runtime": 538.8614361286163, "_timestamp": 1585079971.9506822, "_step": 468}
{"Episode reward": -97.2129014122182, "Episode length": 999, "Policy Loss": -12.2476167678833, "Value Loss": 0.02912081591784954, "_runtime": 539.984183549881, "_timestamp": 1585079973.0734296, "_step": 469}
{"Episode reward": -95.97129092753482, "Episode length": 999, "Policy Loss": -12.338030815124512, "Value Loss": 0.02678767405450344, "_runtime": 541.0847215652466, "_timestamp": 1585079974.1739676, "_step": 470}
{"Episode reward": -96.95710577316287, "Episode length": 999, "Policy Loss": -12.206340789794922, "Value Loss": 0.029252033680677414, "_runtime": 542.17902302742, "_timestamp": 1585079975.268269, "_step": 471}
{"Episode reward": -100.34676746303478, "Episode length": 999, "Policy Loss": -12.678720474243164, "Value Loss": 0.029762985184788704, "_runtime": 543.358208656311, "_timestamp": 1585079976.4474547, "_step": 472}
{"Episode reward": -99.44245400297217, "Episode length": 999, "Policy Loss": -12.693593978881836, "Value Loss": 0.02947649545967579, "_runtime": 544.4793679714203, "_timestamp": 1585079977.568614, "_step": 473}
{"Episode reward": -90.72082089118825, "Episode length": 999, "Policy Loss": -11.381336212158203, "Value Loss": 0.024293838068842888, "_runtime": 545.5775384902954, "_timestamp": 1585079978.6667845, "_step": 474}
{"Episode reward": -100.4363023433106, "Episode length": 999, "Policy Loss": -13.047029495239258, "Value Loss": 0.027590090408921242, "_runtime": 546.7324843406677, "_timestamp": 1585079979.8217304, "_step": 475}
{"Episode reward": -91.36870810413663, "Episode length": 999, "Policy Loss": -11.293478012084961, "Value Loss": 0.025052303448319435, "_runtime": 547.6136560440063, "_timestamp": 1585079980.702902, "_step": 476}
{"Episode reward": 26.072833713779914, "Episode length": 807, "Policy Loss": 6.039170265197754, "Value Loss": 12.426669120788574, "_runtime": 548.7174549102783, "_timestamp": 1585079981.806701, "_step": 477}
{"Episode reward": -92.29881008970429, "Episode length": 999, "Policy Loss": -11.652056694030762, "Value Loss": 0.024634085595607758, "_runtime": 549.8171138763428, "_timestamp": 1585079982.90636, "_step": 478}
{"Episode reward": -97.58068884683995, "Episode length": 999, "Policy Loss": -12.488250732421875, "Value Loss": 0.028631726279854774, "_runtime": 550.9482297897339, "_timestamp": 1585079984.0374758, "_step": 479}
{"Episode reward": -106.36682201037961, "Episode length": 999, "Policy Loss": -13.968441009521484, "Value Loss": 0.034147173166275024, "_runtime": 552.0422174930573, "_timestamp": 1585079985.1314635, "_step": 480}
{"Episode reward": -98.78654559146487, "Episode length": 999, "Policy Loss": -12.88066577911377, "Value Loss": 0.03091459348797798, "_runtime": 553.2221779823303, "_timestamp": 1585079986.311424, "_step": 481}
{"Episode reward": -96.2162683943239, "Episode length": 999, "Policy Loss": -11.916692733764648, "Value Loss": 0.027832338586449623, "_runtime": 554.3333461284637, "_timestamp": 1585079987.4225922, "_step": 482}
{"Episode reward": -86.64653450155431, "Episode length": 999, "Policy Loss": -10.612907409667969, "Value Loss": 0.02038666419684887, "_runtime": 555.4377198219299, "_timestamp": 1585079988.5269659, "_step": 483}
{"Episode reward": -98.295310795625, "Episode length": 999, "Policy Loss": -12.707401275634766, "Value Loss": 0.0284267570823431, "_runtime": 556.5513904094696, "_timestamp": 1585079989.6406364, "_step": 484}
{"Episode reward": -99.27406045381711, "Episode length": 999, "Policy Loss": -12.825785636901855, "Value Loss": 0.027479814365506172, "_runtime": 557.6643688678741, "_timestamp": 1585079990.753615, "_step": 485}
{"Episode reward": -113.31450845649277, "Episode length": 999, "Policy Loss": -14.958242416381836, "Value Loss": 0.040847912430763245, "_runtime": 558.7620990276337, "_timestamp": 1585079991.851345, "_step": 486}
{"Episode reward": -106.96558952194005, "Episode length": 999, "Policy Loss": -14.0073881149292, "Value Loss": 0.032865703105926514, "_runtime": 559.8768291473389, "_timestamp": 1585079992.9660752, "_step": 487}
{"Episode reward": -103.83657433605313, "Episode length": 999, "Policy Loss": -13.61941909790039, "Value Loss": 0.03208522871136665, "_runtime": 561.006560087204, "_timestamp": 1585079994.0958061, "_step": 488}
{"Episode reward": -103.74216069133213, "Episode length": 999, "Policy Loss": -13.273110389709473, "Value Loss": 0.028322912752628326, "_runtime": 562.1254405975342, "_timestamp": 1585079995.2146866, "_step": 489}
{"Episode reward": -99.71052042359392, "Episode length": 999, "Policy Loss": -12.73809814453125, "Value Loss": 0.031763508915901184, "_runtime": 563.2630660533905, "_timestamp": 1585079996.352312, "_step": 490}
{"Episode reward": -94.4729600060521, "Episode length": 999, "Policy Loss": -11.881889343261719, "Value Loss": 0.025150107219815254, "_runtime": 564.4120256900787, "_timestamp": 1585079997.5012717, "_step": 491}
{"Episode reward": -99.90353446522406, "Episode length": 999, "Policy Loss": -12.938608169555664, "Value Loss": 0.02594839036464691, "_runtime": 565.5151307582855, "_timestamp": 1585079998.6043768, "_step": 492}
{"Episode reward": -98.21088196775518, "Episode length": 999, "Policy Loss": -12.448018074035645, "Value Loss": 0.029028907418251038, "_runtime": 566.6411488056183, "_timestamp": 1585079999.7303948, "_step": 493}
{"Episode reward": -101.79547212479035, "Episode length": 999, "Policy Loss": -13.111737251281738, "Value Loss": 0.03055163472890854, "_runtime": 567.7388348579407, "_timestamp": 1585080000.828081, "_step": 494}
{"Episode reward": -102.27596374346052, "Episode length": 999, "Policy Loss": -13.152076721191406, "Value Loss": 0.03184996545314789, "_runtime": 568.8661544322968, "_timestamp": 1585080001.9554005, "_step": 495}
{"Episode reward": -104.87721340601213, "Episode length": 999, "Policy Loss": -13.606197357177734, "Value Loss": 0.03234358876943588, "_runtime": 569.9926137924194, "_timestamp": 1585080003.0818598, "_step": 496}
{"Episode reward": -100.37962008051295, "Episode length": 999, "Policy Loss": -12.886423110961914, "Value Loss": 0.029384255409240723, "_runtime": 571.0934779644012, "_timestamp": 1585080004.182724, "_step": 497}
{"Episode reward": -106.38299871876393, "Episode length": 999, "Policy Loss": -14.002861976623535, "Value Loss": 0.03615919500589371, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844, -302.3179626464844]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-275.3421630859375, -268.53875732421875, -261.7353515625, -254.9319305419922, -248.12852478027344, -241.3251190185547, -234.52169799804688, -227.71829223632812, -220.91488647460938, -214.11148071289062, -207.30807495117188, -200.50465393066406, -193.7012481689453, -186.89784240722656, -180.09442138671875, -173.291015625, -166.48760986328125, -159.6842041015625, -152.88079833984375, -146.07737731933594, -139.2739715576172, -132.47056579589844, -125.66714477539062, -118.86373901367188, -112.06033325195312, -105.25692749023438, -98.45352172851562, -91.65010070800781, -84.84669494628906, -78.04328918457031, -71.2398681640625, -64.43646240234375, -57.633056640625, -50.82965087890625, -44.0262451171875, -37.22282409667969, -30.419418334960938, -23.616012573242188, -16.812591552734375, -10.009185791015625, -3.205780029296875, 3.597625732421875, 10.401031494140625, 17.204437255859375, 24.00787353515625, 30.811279296875, 37.61468505859375, 44.4180908203125, 51.22149658203125, 58.02490234375, 64.82830810546875, 71.6317138671875, 78.43511962890625, 85.23855590820312, 92.04196166992188, 98.84536743164062, 105.64877319335938, 112.45217895507812, 119.25558471679688, 126.05899047851562, 132.8624267578125, 139.66583251953125, 146.46923828125, 153.27264404296875, 160.0760498046875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-145.72801208496094, -140.88748168945312, -136.04696655273438, -131.20643615722656, -126.36590576171875, -121.52538299560547, -116.68486022949219, -111.84432983398438, -107.00379943847656, -102.16327667236328, -97.32275390625, -92.48222351074219, -87.6417007446289, -82.80117797851562, -77.96064758300781, -73.1201171875, -68.27959442138672, -63.43907165527344, -58.598541259765625, -53.758018493652344, -48.91748809814453, -44.07696533203125, -39.23643493652344, -34.395912170410156, -29.555389404296875, -24.714859008789062, -19.87433624267578, -15.0338134765625, -10.193283081054688, -5.352752685546875, -0.5122222900390625, 4.3282928466796875, 9.1688232421875, 14.009353637695312, 18.849868774414062, 23.690399169921875, 28.530929565429688, 33.3714599609375, 38.21197509765625, 43.05250549316406, 47.893035888671875, 52.733551025390625, 57.57408142089844, 62.41461181640625, 67.25514221191406, 72.09565734863281, 76.93618774414062, 81.77671813964844, 86.61723327636719, 91.457763671875, 96.29829406738281, 101.13882446289062, 105.97933959960938, 110.81986999511719, 115.66038513183594, 120.50093078613281, 125.34144592285156, 130.1819610595703, 135.0225067138672, 139.86302185058594, 144.7035675048828, 149.54408264160156, 154.3845977783203, 159.2251434326172, 164.06565856933594]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 6.0, 3.0, 4.0, 2.0, 7.0, 6.0, 5.0, 9.0, 14.0, 12.0, 32.0, 27.0, 24.0, 37.0, 43.0, 44.0, 45.0, 26.0, 19.0, 19.0, 11.0, 11.0, 11.0, 12.0, 14.0, 6.0, 7.0, 7.0, 6.0, 7.0, 5.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-127.46267700195312, -123.22895050048828, -118.99523162841797, -114.76150512695312, -110.52778625488281, -106.29405975341797, -102.06033325195312, -97.82661437988281, -93.59288787841797, -89.35916137695312, -85.12544250488281, -80.89171600341797, -76.65798950195312, -72.42427062988281, -68.19054412841797, -63.95682144165039, -59.72309875488281, -55.48937225341797, -51.255653381347656, -47.02192687988281, -42.7882080078125, -38.554481506347656, -34.32075500488281, -30.0870361328125, -25.853309631347656, -21.619583129882812, -17.3858642578125, -13.152137756347656, -8.918411254882812, -4.6846923828125, -0.45096588134765625, 3.7827606201171875, 8.0164794921875, 12.250198364257812, 16.483932495117188, 20.7176513671875, 24.951370239257812, 29.185104370117188, 33.4188232421875, 37.65254211425781, 41.886260986328125, 46.1199951171875, 50.35371398925781, 54.587432861328125, 58.8211669921875, 63.05488586425781, 67.28860473632812, 71.5223388671875, 75.75605773925781, 79.98977661132812, 84.2235107421875, 88.45722961425781, 92.69094848632812, 96.9246826171875, 101.15840148925781, 105.39212036132812, 109.6258544921875, 113.85957336425781, 118.09329223632812, 122.32701110839844, 126.56074523925781, 130.79446411132812, 135.0281982421875, 139.26190185546875, 143.49563598632812]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-117.52721405029297, -114.70191192626953, -111.87661743164062, -109.05131530761719, -106.22601318359375, -103.40071105957031, -100.57540893554688, -97.75011444091797, -94.92481231689453, -92.0995101928711, -89.27421569824219, -86.44891357421875, -83.62361145019531, -80.79830932617188, -77.97300720214844, -75.14771270751953, -72.3224105834961, -69.49710845947266, -66.67181396484375, -63.84651184082031, -61.021209716796875, -58.19590759277344, -55.370609283447266, -52.545310974121094, -49.720008850097656, -46.89470672607422, -44.06940460205078, -41.244110107421875, -38.41880798339844, -35.593505859375, -32.768211364746094, -29.942909240722656, -27.11760711669922, -24.29230499267578, -21.467002868652344, -18.641708374023438, -15.81640625, -12.991104125976562, -10.165809631347656, -7.340507507324219, -4.515205383300781, -1.6899032592773438, 1.1353988647460938, 3.960693359375, 6.7859954833984375, 9.611297607421875, 12.436592102050781, 15.261894226074219, 18.087196350097656, 20.912498474121094, 23.73780059814453, 26.56310272216797, 29.388404846191406, 32.21369171142578, 35.03899383544922, 37.864295959472656, 40.689598083496094, 43.51490020751953, 46.34020233154297, 49.165504455566406, 51.99079132080078, 54.81609344482422, 57.641395568847656, 60.466697692871094, 63.29199981689453]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 11.0, 23.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-38.06196212768555, -36.35413360595703, -34.646305084228516, -32.9384765625, -31.230648040771484, -29.52281951904297, -27.81498908996582, -26.107160568237305, -24.39933204650879, -22.691503524780273, -20.983675003051758, -19.275846481323242, -17.568016052246094, -15.860187530517578, -14.152359008789062, -12.444530487060547, -10.736701965332031, -9.028873443603516, -7.321044921875, -5.613216400146484, -3.9053878784179688, -2.197559356689453, -0.4897308349609375, 1.2180976867675781, 2.9259300231933594, 4.633758544921875, 6.341587066650391, 8.049415588378906, 9.757244110107422, 11.465072631835938, 13.172901153564453, 14.880729675292969, 16.588558197021484, 18.29638671875, 20.004215240478516, 21.71204376220703, 23.419872283935547, 25.127700805664062, 26.835529327392578, 28.54336166381836, 30.25118637084961, 31.95901870727539, 33.66684341430664, 35.37467575073242, 37.08250045776367, 38.79033279418945, 40.4981575012207, 42.205989837646484, 43.913822174072266, 45.621646881103516, 47.3294792175293, 49.03730392456055, 50.74513626098633, 52.45296096801758, 54.16079330444336, 55.86861801147461, 57.57645034790039, 59.28427505493164, 60.99210739135742, 62.69993209838867, 64.40776062011719, 66.11558532714844, 67.82342529296875, 69.53125, 71.23907470703125]}, "_runtime": 572.1856915950775, "_timestamp": 1585080005.2749376, "_step": 498}
{"Episode reward": -97.71865014908168, "Episode length": 999, "Policy Loss": -12.318282127380371, "Value Loss": 0.02781064063310623, "_runtime": 573.3251209259033, "_timestamp": 1585080006.414367, "_step": 499}
