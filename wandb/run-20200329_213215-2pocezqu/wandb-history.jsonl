{"Episode reward": -53.02637399569628, "Episode length": 999, "Policy Loss": -0.06469489634037018, "Value Loss": 0.003977496176958084, "_runtime": 8476.43778514862, "_timestamp": 1585517554.8585148, "_step": 0}
{"Episode reward": -98.17095971501419, "Episode length": 999, "Policy Loss": 0.5824060440063477, "Value Loss": 7.051153182983398, "_runtime": 8477.947304010391, "_timestamp": 1585517556.3680336, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -19.06199073791504, "Value Loss": 336.9894714355469, "_runtime": 8479.466658830643, "_timestamp": 1585517557.8873885, "_step": 2}
{"Episode reward": 8.176191815599893, "Episode length": 956, "Policy Loss": -0.32820436358451843, "Value Loss": 95.69153594970703, "_runtime": 8479.729701519012, "_timestamp": 1585517558.1504312, "_step": 3}
{"Episode reward": 87.52191429375281, "Episode length": 128, "Policy Loss": -3.4185805320739746, "Value Loss": 96.16616821289062, "_runtime": 8481.274938344955, "_timestamp": 1585517559.695668, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.661645770072937, "Value Loss": 0.005775023251771927, "_runtime": 8482.859071969986, "_timestamp": 1585517561.2798016, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.98161244392395, "Value Loss": 3.149259567260742, "_runtime": 8484.34555220604, "_timestamp": 1585517562.7662818, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.362115859985352, "Value Loss": 95.31459045410156, "_runtime": 8485.918534517288, "_timestamp": 1585517564.3392642, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.006559371948242, "Value Loss": 168.4304962158203, "_runtime": 8487.544754981995, "_timestamp": 1585517565.9654846, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.107316970825195, "Value Loss": 6.987043857574463, "_runtime": 8489.087887763977, "_timestamp": 1585517567.5086174, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0954864025115967, "Value Loss": 32.158870697021484, "_runtime": 8490.668808698654, "_timestamp": 1585517569.0895383, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6554924249649048, "Value Loss": 1.6622060537338257, "_runtime": 8492.261374950409, "_timestamp": 1585517570.6821046, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.566658854484558, "Value Loss": 3.519613027572632, "_runtime": 8492.493022918701, "_timestamp": 1585517570.9137526, "_step": 12}
{"Episode reward": 89.3632433994515, "Episode length": 107, "Policy Loss": 6.629010200500488, "Value Loss": 86.38141632080078, "_runtime": 8492.755420446396, "_timestamp": 1585517571.17615, "_step": 13}
{"Episode reward": 86.90000000000003, "Episode length": 131, "Policy Loss": -10.535350799560547, "Value Loss": 78.87181854248047, "_runtime": 8492.979321479797, "_timestamp": 1585517571.400051, "_step": 14}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": 14.5322904586792, "Value Loss": 107.37468719482422, "_runtime": 8493.126930952072, "_timestamp": 1585517571.5476606, "_step": 15}
{"Episode reward": 90.60000000000002, "Episode length": 94, "Policy Loss": 9.015284538269043, "Value Loss": 107.38078308105469, "_runtime": 8493.29240489006, "_timestamp": 1585517571.7131345, "_step": 16}
{"Episode reward": 90.20000000000002, "Episode length": 98, "Policy Loss": -14.879261016845703, "Value Loss": 102.37915802001953, "_runtime": 8493.445813179016, "_timestamp": 1585517571.8665428, "_step": 17}
{"Episode reward": 90.69999564475731, "Episode length": 94, "Policy Loss": -1.858841896057129, "Value Loss": 101.17385864257812, "_runtime": 8493.641951799393, "_timestamp": 1585517572.0626814, "_step": 18}
{"Episode reward": 87.45665111400743, "Episode length": 127, "Policy Loss": 5.70473051071167, "Value Loss": 74.90155029296875, "_runtime": 8493.822757005692, "_timestamp": 1585517572.2434866, "_step": 19}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 5.713011741638184, "Value Loss": 78.78641510009766, "_runtime": 8494.009064435959, "_timestamp": 1585517572.429794, "_step": 20}
{"Episode reward": 87.70350728075483, "Episode length": 123, "Policy Loss": 3.403282880783081, "Value Loss": 71.55296325683594, "_runtime": 8494.177627563477, "_timestamp": 1585517572.5983572, "_step": 21}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 4.734890937805176, "Value Loss": 82.5216064453125, "_runtime": 8494.323782444, "_timestamp": 1585517572.744512, "_step": 22}
{"Episode reward": 90.74213815167761, "Episode length": 94, "Policy Loss": -8.92011547088623, "Value Loss": 102.30391693115234, "_runtime": 8494.556966304779, "_timestamp": 1585517572.977696, "_step": 23}
{"Episode reward": 84.45992404972199, "Episode length": 156, "Policy Loss": -6.972363471984863, "Value Loss": 58.41007995605469, "_runtime": 8494.766202688217, "_timestamp": 1585517573.1869323, "_step": 24}
{"Episode reward": 86.21502027502288, "Episode length": 138, "Policy Loss": 0.5265225172042847, "Value Loss": 63.58499526977539, "_runtime": 8494.92751288414, "_timestamp": 1585517573.3482425, "_step": 25}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 3.1142892837524414, "Value Loss": 86.87779235839844, "_runtime": 8495.091379642487, "_timestamp": 1585517573.5121093, "_step": 26}
{"Episode reward": 89.69333386133106, "Episode length": 104, "Policy Loss": 2.4286882877349854, "Value Loss": 87.84233093261719, "_runtime": 8495.28408741951, "_timestamp": 1585517573.704817, "_step": 27}
{"Episode reward": 87.59305887130542, "Episode length": 125, "Policy Loss": 5.0059099197387695, "Value Loss": 77.10368347167969, "_runtime": 8495.484241008759, "_timestamp": 1585517573.9049706, "_step": 28}
{"Episode reward": 86.98011268817211, "Episode length": 132, "Policy Loss": 1.5674786567687988, "Value Loss": 65.81331634521484, "_runtime": 8495.706939935684, "_timestamp": 1585517574.1276696, "_step": 29}
{"Episode reward": 85.29983166230926, "Episode length": 148, "Policy Loss": -2.381173610687256, "Value Loss": 62.57487106323242, "_runtime": 8495.887702226639, "_timestamp": 1585517574.3084319, "_step": 30}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 0.41627615690231323, "Value Loss": 74.67496490478516, "_runtime": 8496.063411712646, "_timestamp": 1585517574.4841413, "_step": 31}
{"Episode reward": 88.71079990714792, "Episode length": 113, "Policy Loss": 1.371477484703064, "Value Loss": 80.32122802734375, "_runtime": 8496.245970249176, "_timestamp": 1585517574.6667, "_step": 32}
{"Episode reward": 88.39792296381205, "Episode length": 117, "Policy Loss": 2.359185218811035, "Value Loss": 71.75684356689453, "_runtime": 8496.434276342392, "_timestamp": 1585517574.855006, "_step": 33}
{"Episode reward": 87.79755143595398, "Episode length": 123, "Policy Loss": 2.612133026123047, "Value Loss": 68.3031234741211, "_runtime": 8496.668233394623, "_timestamp": 1585517575.088963, "_step": 34}
{"Episode reward": 84.40000000000005, "Episode length": 156, "Policy Loss": 2.339204788208008, "Value Loss": 53.9648551940918, "_runtime": 8496.825702428818, "_timestamp": 1585517575.246432, "_step": 35}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": 3.2798078060150146, "Value Loss": 83.48908233642578, "_runtime": 8497.012769937515, "_timestamp": 1585517575.4334996, "_step": 36}
{"Episode reward": 87.85470243357125, "Episode length": 122, "Policy Loss": -0.5111876130104065, "Value Loss": 63.119441986083984, "_runtime": 8497.230839967728, "_timestamp": 1585517575.6515696, "_step": 37}
{"Episode reward": 85.80064744715932, "Episode length": 142, "Policy Loss": -5.527932643890381, "Value Loss": 57.18571853637695, "_runtime": 8497.391436815262, "_timestamp": 1585517575.8121665, "_step": 38}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": 4.04536771774292, "Value Loss": 82.35562133789062, "_runtime": 8497.550169467926, "_timestamp": 1585517575.970899, "_step": 39}
{"Episode reward": 89.80000000000003, "Episode length": 102, "Policy Loss": 3.6771204471588135, "Value Loss": 74.97879791259766, "_runtime": 8497.723717927933, "_timestamp": 1585517576.1444476, "_step": 40}
{"Episode reward": 89.05512529413684, "Episode length": 111, "Policy Loss": 3.157858371734619, "Value Loss": 72.8514633178711, "_runtime": 8497.90653514862, "_timestamp": 1585517576.3272648, "_step": 41}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": 1.7415060997009277, "Value Loss": 71.2081298828125, "_runtime": 8498.071281909943, "_timestamp": 1585517576.4920115, "_step": 42}
{"Episode reward": 89.38788724009504, "Episode length": 107, "Policy Loss": 2.5004899501800537, "Value Loss": 71.24948120117188, "_runtime": 8498.240005493164, "_timestamp": 1585517576.6607351, "_step": 43}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 3.0362160205841064, "Value Loss": 70.77174377441406, "_runtime": 8498.409816265106, "_timestamp": 1585517576.830546, "_step": 44}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 3.413098096847534, "Value Loss": 65.380615234375, "_runtime": 8498.57189655304, "_timestamp": 1585517576.9926262, "_step": 45}
{"Episode reward": 89.67403482472861, "Episode length": 105, "Policy Loss": 3.368720531463623, "Value Loss": 67.20863342285156, "_runtime": 8498.75957274437, "_timestamp": 1585517577.1803024, "_step": 46}
{"Episode reward": 87.89565699960662, "Episode length": 123, "Policy Loss": 1.2500579357147217, "Value Loss": 55.67813491821289, "_runtime": 8498.927405118942, "_timestamp": 1585517577.3481348, "_step": 47}
{"Episode reward": 89.19273972708964, "Episode length": 109, "Policy Loss": 1.3756520748138428, "Value Loss": 56.87268829345703, "_runtime": 8499.114478826523, "_timestamp": 1585517577.5352085, "_step": 48}
{"Episode reward": 87.78384075409778, "Episode length": 123, "Policy Loss": -0.54297935962677, "Value Loss": 49.74069595336914, "_runtime": 8499.296741247177, "_timestamp": 1585517577.717471, "_step": 49}
{"Episode reward": 88.29877142647736, "Episode length": 118, "Policy Loss": 2.2529990673065186, "Value Loss": 63.86268997192383, "_runtime": 8499.48350906372, "_timestamp": 1585517577.9042387, "_step": 50}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 3.700591564178467, "Value Loss": 81.82262420654297, "_runtime": 8499.649446249008, "_timestamp": 1585517578.070176, "_step": 51}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 2.541938066482544, "Value Loss": 50.18247604370117, "_runtime": 8499.824734210968, "_timestamp": 1585517578.2454638, "_step": 52}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 2.8719429969787598, "Value Loss": 82.66161346435547, "_runtime": 8499.995897054672, "_timestamp": 1585517578.4166267, "_step": 53}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 4.028822422027588, "Value Loss": 85.98670959472656, "_runtime": 8500.172835588455, "_timestamp": 1585517578.5935652, "_step": 54}
{"Episode reward": 88.56827613160803, "Episode length": 115, "Policy Loss": 3.314657688140869, "Value Loss": 80.33840942382812, "_runtime": 8500.34121465683, "_timestamp": 1585517578.7619443, "_step": 55}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 3.5112404823303223, "Value Loss": 77.86642456054688, "_runtime": 8500.626805305481, "_timestamp": 1585517579.047535, "_step": 56}
{"Episode reward": 80.79932758798823, "Episode length": 193, "Policy Loss": -0.14989502727985382, "Value Loss": 41.69730758666992, "_runtime": 8500.807366132736, "_timestamp": 1585517579.2280958, "_step": 57}
{"Episode reward": 88.38745867537321, "Episode length": 117, "Policy Loss": 1.5192155838012695, "Value Loss": 66.41795349121094, "_runtime": 8500.994193077087, "_timestamp": 1585517579.4149227, "_step": 58}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 2.0353779792785645, "Value Loss": 67.19754791259766, "_runtime": 8501.184208631516, "_timestamp": 1585517579.6049383, "_step": 59}
{"Episode reward": 88.00678707557084, "Episode length": 120, "Policy Loss": 2.572509288787842, "Value Loss": 74.63069915771484, "_runtime": 8501.381146907806, "_timestamp": 1585517579.8018765, "_step": 60}
{"Episode reward": 87.10000000000004, "Episode length": 129, "Policy Loss": 0.21840424835681915, "Value Loss": 67.81369018554688, "_runtime": 8501.546681404114, "_timestamp": 1585517579.967411, "_step": 61}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": -0.5391553640365601, "Value Loss": 71.54861450195312, "_runtime": 8501.758889913559, "_timestamp": 1585517580.1796196, "_step": 62}
{"Episode reward": 86.16265763640408, "Episode length": 139, "Policy Loss": -5.130227088928223, "Value Loss": 59.055145263671875, "_runtime": 8501.928858757019, "_timestamp": 1585517580.3495884, "_step": 63}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 3.233250141143799, "Value Loss": 76.5123519897461, "_runtime": 8502.101269960403, "_timestamp": 1585517580.5219996, "_step": 64}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 4.670689582824707, "Value Loss": 73.83985137939453, "_runtime": 8502.277114152908, "_timestamp": 1585517580.6978438, "_step": 65}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 2.800994396209717, "Value Loss": 70.61443328857422, "_runtime": 8502.459782838821, "_timestamp": 1585517580.8805125, "_step": 66}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 9.592214584350586, "Value Loss": 67.8160171508789, "_runtime": 8502.640457868576, "_timestamp": 1585517581.0611875, "_step": 67}
{"Episode reward": 88.19261335504383, "Episode length": 119, "Policy Loss": 5.046782970428467, "Value Loss": 64.14336395263672, "_runtime": 8502.808453083038, "_timestamp": 1585517581.2291827, "_step": 68}
{"Episode reward": 89.0648764356971, "Episode length": 110, "Policy Loss": 2.0523946285247803, "Value Loss": 71.05778503417969, "_runtime": 8502.987531900406, "_timestamp": 1585517581.4082615, "_step": 69}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -5.035095691680908, "Value Loss": 69.32076263427734, "_runtime": 8503.15448641777, "_timestamp": 1585517581.575216, "_step": 70}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": -0.6104152798652649, "Value Loss": 72.80318450927734, "_runtime": 8503.325933218002, "_timestamp": 1585517581.7466629, "_step": 71}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 1.7963521480560303, "Value Loss": 66.66031646728516, "_runtime": 8503.503930091858, "_timestamp": 1585517581.9246597, "_step": 72}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 2.1884920597076416, "Value Loss": 68.97100067138672, "_runtime": 8503.677953481674, "_timestamp": 1585517582.098683, "_step": 73}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 2.4023525714874268, "Value Loss": 69.90892791748047, "_runtime": 8503.867479085922, "_timestamp": 1585517582.2882087, "_step": 74}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": 5.128724098205566, "Value Loss": 62.564300537109375, "_runtime": 8504.041933774948, "_timestamp": 1585517582.4626634, "_step": 75}
{"Episode reward": 88.79793459043226, "Episode length": 114, "Policy Loss": 4.550162315368652, "Value Loss": 68.14476776123047, "_runtime": 8504.215322732925, "_timestamp": 1585517582.6360524, "_step": 76}
{"Episode reward": 88.72971815733148, "Episode length": 113, "Policy Loss": 4.419469356536865, "Value Loss": 65.49186706542969, "_runtime": 8504.38238120079, "_timestamp": 1585517582.8031108, "_step": 77}
{"Episode reward": 89.2870102759451, "Episode length": 108, "Policy Loss": 3.3183178901672363, "Value Loss": 69.93267822265625, "_runtime": 8504.55993270874, "_timestamp": 1585517582.9806623, "_step": 78}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 2.3712668418884277, "Value Loss": 64.28427124023438, "_runtime": 8504.763191223145, "_timestamp": 1585517583.1839209, "_step": 79}
{"Episode reward": 86.50000000000004, "Episode length": 135, "Policy Loss": 1.0169988870620728, "Value Loss": 56.98944091796875, "_runtime": 8504.94695854187, "_timestamp": 1585517583.3676882, "_step": 80}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 0.8050936460494995, "Value Loss": 63.73270797729492, "_runtime": 8505.128548622131, "_timestamp": 1585517583.5492783, "_step": 81}
{"Episode reward": 88.21382628296554, "Episode length": 118, "Policy Loss": 0.36779189109802246, "Value Loss": 63.37873840332031, "_runtime": 8505.294802188873, "_timestamp": 1585517583.7155318, "_step": 82}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 3.0180070400238037, "Value Loss": 62.83110046386719, "_runtime": 8505.480749845505, "_timestamp": 1585517583.9014795, "_step": 83}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": 5.797561168670654, "Value Loss": 57.840091705322266, "_runtime": 8505.622450351715, "_timestamp": 1585517584.04318, "_step": 84}
{"Episode reward": 91.0654170569951, "Episode length": 90, "Policy Loss": 6.7739033699035645, "Value Loss": 74.85015106201172, "_runtime": 8505.79734826088, "_timestamp": 1585517584.218078, "_step": 85}
{"Episode reward": 88.61460058444648, "Episode length": 114, "Policy Loss": 2.2200090885162354, "Value Loss": 68.46659851074219, "_runtime": 8505.992032289505, "_timestamp": 1585517584.412762, "_step": 86}
{"Episode reward": 87.31604400796354, "Episode length": 127, "Policy Loss": 4.9190473556518555, "Value Loss": 55.00810623168945, "_runtime": 8506.158316850662, "_timestamp": 1585517584.5790465, "_step": 87}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 2.30442476272583, "Value Loss": 64.2912368774414, "_runtime": 8506.325006961823, "_timestamp": 1585517584.7457366, "_step": 88}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": -1.6762418746948242, "Value Loss": 68.86006927490234, "_runtime": 8506.488273859024, "_timestamp": 1585517584.9090035, "_step": 89}
{"Episode reward": 89.50000000000003, "Episode length": 105, "Policy Loss": 0.9777048826217651, "Value Loss": 62.2337532043457, "_runtime": 8506.65478682518, "_timestamp": 1585517585.0755165, "_step": 90}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 4.265817642211914, "Value Loss": 63.55155944824219, "_runtime": 8506.827737092972, "_timestamp": 1585517585.2484667, "_step": 91}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 4.6444597244262695, "Value Loss": 68.61219024658203, "_runtime": 8507.022601604462, "_timestamp": 1585517585.4433312, "_step": 92}
{"Episode reward": 87.20000000000003, "Episode length": 128, "Policy Loss": -1.2241766452789307, "Value Loss": 54.48735809326172, "_runtime": 8507.233976125717, "_timestamp": 1585517585.6547058, "_step": 93}
{"Episode reward": 86.00000000000004, "Episode length": 140, "Policy Loss": 1.3733099699020386, "Value Loss": 53.18693923950195, "_runtime": 8507.388171195984, "_timestamp": 1585517585.8089008, "_step": 94}
{"Episode reward": 90.19800590401867, "Episode length": 99, "Policy Loss": 4.0495171546936035, "Value Loss": 69.88628387451172, "_runtime": 8507.548865556717, "_timestamp": 1585517585.9695952, "_step": 95}
{"Episode reward": 89.70000000000003, "Episode length": 103, "Policy Loss": 4.796722888946533, "Value Loss": 66.98477172851562, "_runtime": 8507.724534273148, "_timestamp": 1585517586.145264, "_step": 96}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 10.887594223022461, "Value Loss": 55.0731086730957, "_runtime": 8507.912425756454, "_timestamp": 1585517586.3331554, "_step": 97}
{"Episode reward": 87.70000000000003, "Episode length": 123, "Policy Loss": 0.8899955153465271, "Value Loss": 55.69654083251953, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375, 510138.4375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-510139.78125, -451686.8125, -393233.8125, -334780.8125, -276327.84375, -217874.84375, -159421.875, -100968.90625, -42515.90625, 15937.09375, 74390.09375, 132843.03125, 191296.03125, 249749.03125, 308201.96875, 366654.96875, 425107.96875, 483560.96875, 542014.0, 600467.0, 658920.0, 717372.875, 775825.875, 834278.875, 892731.875, 951184.875, 1009637.875, 1068090.875, 1126543.75, 1184996.75, 1243449.75, 1301902.75, 1360355.75, 1418808.75, 1477261.75, 1535714.75, 1594167.75, 1652620.75, 1711073.75, 1769526.75, 1827979.75, 1886432.5, 1944885.5, 2003338.5, 2061791.5, 2120244.5, 2178697.5, 2237150.5, 2295603.5, 2354056.5, 2412509.5, 2470962.5, 2529415.5, 2587868.5, 2646321.5, 2704774.5, 2763227.25, 2821680.25, 2880133.25, 2938586.25, 2997039.25, 3055492.25, 3113945.25, 3172398.25, 3230851.25]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-935701.9375, -905764.6875, -875827.4375, -845890.1875, -815952.9375, -786015.6875, -756078.4375, -726141.1875, -696203.9375, -666266.6875, -636329.4375, -606392.1875, -576454.9375, -546517.6875, -516580.4375, -486643.1875, -456705.9375, -426768.6875, -396831.4375, -366894.1875, -336956.9375, -307019.6875, -277082.4375, -247145.1875, -217207.9375, -187270.6875, -157333.4375, -127396.1875, -97458.9375, -67521.6875, -37584.4375, -7647.1875, 22290.0625, 52227.3125, 82164.5625, 112101.8125, 142039.0625, 171976.3125, 201913.5625, 231850.8125, 261788.0625, 291725.3125, 321662.5625, 351599.8125, 381537.0625, 411474.3125, 441411.5625, 471348.8125, 501286.0625, 531223.3125, 561160.5625, 591097.8125, 621035.0625, 650972.3125, 680909.5625, 710846.8125, 740784.0625, 770721.3125, 800658.5625, 830595.8125, 860533.0625, 890470.3125, 920407.5625, 950344.8125, 980282.0625]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 2.0, 5.0, 4.0, 5.0, 6.0, 6.0, 6.0, 7.0, 4.0, 4.0, 6.0, 6.0, 11.0, 7.0, 27.0, 293.0, 8.0, 0.0, 5.0, 6.0, 8.0, 2.0, 1.0, 2.0, 5.0, 3.0, 8.0, 3.0, 5.0, 4.0, 5.0, 5.0, 4.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-856733.5625, -829322.875, -801912.25, -774501.5625, -747090.9375, -719680.25, -692269.625, -664858.9375, -637448.25, -610037.625, -582627.0, -555216.3125, -527805.625, -500394.96875, -472984.3125, -445573.65625, -418163.0, -390752.34375, -363341.6875, -335931.03125, -308520.375, -281109.6875, -253699.0625, -226288.375, -198877.6875, -171467.0625, -144056.375, -116645.75, -89235.0625, -61824.4375, -34413.75, -7003.125, 20407.5625, 47818.25, 75228.875, 102639.5625, 130050.1875, 157460.875, 184871.5, 212282.1875, 239692.8125, 267103.5625, 294514.1875, 321924.8125, 349335.4375, 376746.1875, 404156.8125, 431567.4375, 458978.1875, 486388.8125, 513799.4375, 541210.0625, 568620.8125, 596031.4375, 623442.0625, 650852.6875, 678263.4375, 705674.0625, 733084.6875, 760495.4375, 787906.0625, 815316.6875, 842727.3125, 870138.0625, 897548.6875]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0], "bins": [-16902170.0, -16506908.0, -16111646.0, -15716384.0, -15321122.0, -14925860.0, -14530598.0, -14135336.0, -13740074.0, -13344812.0, -12949550.0, -12554288.0, -12159026.0, -11763764.0, -11368502.0, -10973240.0, -10577978.0, -10182716.0, -9787454.0, -9392192.0, -8996930.0, -8601668.0, -8206407.0, -7811145.0, -7415883.0, -7020621.0, -6625359.0, -6230097.0, -5834835.0, -5439573.0, -5044311.0, -4649049.0, -4253787.0, -3858525.0, -3463263.0, -3068001.0, -2672739.0, -2277477.0, -1882215.0, -1486953.0, -1091691.0, -696429.0, -301167.0, 94094.0, 489356.0, 884618.0, 1279880.0, 1675142.0, 2070404.0, 2465666.0, 2860928.0, 3256190.0, 3651452.0, 4046714.0, 4441976.0, 4837238.0, 5232500.0, 5627762.0, 6023024.0, 6418286.0, 6813548.0, 7208810.0, 7604072.0, 7999334.0, 8394596.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 5.0, 8.0, 8.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0], "bins": [-3829242.5, -3739694.75, -3650147.0, -3560599.25, -3471051.5, -3381503.75, -3291956.0, -3202408.25, -3112860.5, -3023312.75, -2933765.0, -2844217.25, -2754669.5, -2665121.5, -2575574.0, -2486026.0, -2396478.5, -2306930.5, -2217383.0, -2127835.0, -2038287.375, -1948739.625, -1859191.875, -1769644.125, -1680096.25, -1590548.5, -1501000.75, -1411453.0, -1321905.25, -1232357.5, -1142809.75, -1053262.0, -963714.25, -874166.5, -784618.75, -695071.0, -605523.25, -515975.5, -426427.75, -336880.0, -247332.25, -157784.5, -68236.75, 21311.0, 110858.75, 200406.5, 289954.25, 379502.0, 469050.0, 558597.5, 648145.5, 737693.0, 827241.0, 916788.5, 1006336.5, 1095884.0, 1185432.0, 1274979.5, 1364527.5, 1454075.0, 1543623.0, 1633170.5, 1722718.5, 1812266.0, 1901814.0]}, "_runtime": 8508.081654548645, "_timestamp": 1585517586.5023842, "_step": 98}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": -0.14101243019104004, "Value Loss": 65.17283630371094, "_runtime": 8508.268585681915, "_timestamp": 1585517586.6893153, "_step": 99}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": -3.0284135341644287, "Value Loss": 57.581722259521484, "_runtime": 8508.448444366455, "_timestamp": 1585517586.869174, "_step": 100}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 3.51667857170105, "Value Loss": 54.334617614746094, "_runtime": 8508.608976364136, "_timestamp": 1585517587.029706, "_step": 101}
{"Episode reward": 89.69173917795963, "Episode length": 104, "Policy Loss": 2.7166476249694824, "Value Loss": 68.89176940917969, "_runtime": 8508.779611110687, "_timestamp": 1585517587.2003407, "_step": 102}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 3.063016414642334, "Value Loss": 63.86912155151367, "_runtime": 8508.93844628334, "_timestamp": 1585517587.359176, "_step": 103}
{"Episode reward": 90.40000000000002, "Episode length": 96, "Policy Loss": 1.4030795097351074, "Value Loss": 68.59874725341797, "_runtime": 8509.124269485474, "_timestamp": 1585517587.5449991, "_step": 104}
{"Episode reward": 88.40917935956787, "Episode length": 116, "Policy Loss": 5.043208122253418, "Value Loss": 56.060394287109375, "_runtime": 8509.28862118721, "_timestamp": 1585517587.7093508, "_step": 105}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": 2.9660696983337402, "Value Loss": 60.26634979248047, "_runtime": 8509.45044016838, "_timestamp": 1585517587.8711698, "_step": 106}
{"Episode reward": 89.54623987731121, "Episode length": 105, "Policy Loss": 1.6229965686798096, "Value Loss": 58.664188385009766, "_runtime": 8509.643060684204, "_timestamp": 1585517588.0637903, "_step": 107}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": 0.4067712128162384, "Value Loss": 71.35047912597656, "_runtime": 8509.819395303726, "_timestamp": 1585517588.240125, "_step": 108}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -2.1351430416107178, "Value Loss": 54.64923858642578, "_runtime": 8509.983368873596, "_timestamp": 1585517588.4040985, "_step": 109}
{"Episode reward": 89.49937646498441, "Episode length": 106, "Policy Loss": 3.821627378463745, "Value Loss": 58.82844924926758, "_runtime": 8510.142179965973, "_timestamp": 1585517588.5629096, "_step": 110}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": 4.418510437011719, "Value Loss": 62.49312973022461, "_runtime": 8510.31717967987, "_timestamp": 1585517588.7379093, "_step": 111}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 4.198571681976318, "Value Loss": 61.647315979003906, "_runtime": 8510.483201742172, "_timestamp": 1585517588.9039314, "_step": 112}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 5.131083011627197, "Value Loss": 54.7142219543457, "_runtime": 8510.670024633408, "_timestamp": 1585517589.0907543, "_step": 113}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": 2.46109676361084, "Value Loss": 55.06330490112305, "_runtime": 8510.828336715698, "_timestamp": 1585517589.2490664, "_step": 114}
{"Episode reward": 89.70000000000003, "Episode length": 103, "Policy Loss": -0.4256175458431244, "Value Loss": 66.44725036621094, "_runtime": 8511.010328769684, "_timestamp": 1585517589.4310584, "_step": 115}
{"Episode reward": 88.098990701139, "Episode length": 120, "Policy Loss": 2.3512442111968994, "Value Loss": 56.338436126708984, "_runtime": 8511.179300785065, "_timestamp": 1585517589.6000304, "_step": 116}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 3.7230594158172607, "Value Loss": 63.048683166503906, "_runtime": 8511.358368396759, "_timestamp": 1585517589.779098, "_step": 117}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 2.231171131134033, "Value Loss": 63.34315490722656, "_runtime": 8511.550718069077, "_timestamp": 1585517589.9714477, "_step": 118}
{"Episode reward": 87.30000000000004, "Episode length": 127, "Policy Loss": 0.26045164465904236, "Value Loss": 66.12757110595703, "_runtime": 8511.720992326736, "_timestamp": 1585517590.141722, "_step": 119}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": -1.3846361637115479, "Value Loss": 80.8134765625, "_runtime": 8511.89994430542, "_timestamp": 1585517590.320674, "_step": 120}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 7.373234748840332, "Value Loss": 62.03703308105469, "_runtime": 8512.073453426361, "_timestamp": 1585517590.494183, "_step": 121}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 9.729473114013672, "Value Loss": 74.58958435058594, "_runtime": 8512.409330129623, "_timestamp": 1585517590.8300598, "_step": 122}
{"Episode reward": 77.28355584668176, "Episode length": 228, "Policy Loss": 7.560129165649414, "Value Loss": 32.771934509277344, "_runtime": 8512.579488992691, "_timestamp": 1585517591.0002186, "_step": 123}
{"Episode reward": 88.98016831872522, "Episode length": 111, "Policy Loss": 3.7093257904052734, "Value Loss": 62.83262252807617, "_runtime": 8512.741962432861, "_timestamp": 1585517591.162692, "_step": 124}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": 4.524302005767822, "Value Loss": 58.685543060302734, "_runtime": 8512.924885988235, "_timestamp": 1585517591.3456156, "_step": 125}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": -1.028376817703247, "Value Loss": 59.090293884277344, "_runtime": 8513.09714269638, "_timestamp": 1585517591.5178723, "_step": 126}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": -0.9952700734138489, "Value Loss": 59.669166564941406, "_runtime": 8513.26823592186, "_timestamp": 1585517591.6889656, "_step": 127}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": -0.8243964314460754, "Value Loss": 54.13405990600586, "_runtime": 8513.444392681122, "_timestamp": 1585517591.8651223, "_step": 128}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 1.9166122674942017, "Value Loss": 60.66583251953125, "_runtime": 8513.843767404556, "_timestamp": 1585517592.264497, "_step": 129}
{"Episode reward": 72.94320148694513, "Episode length": 272, "Policy Loss": -0.19832661747932434, "Value Loss": 26.842376708984375, "_runtime": 8514.007389307022, "_timestamp": 1585517592.428119, "_step": 130}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": 2.7970218658447266, "Value Loss": 57.39775085449219, "_runtime": 8514.179028987885, "_timestamp": 1585517592.5997586, "_step": 131}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 3.4890544414520264, "Value Loss": 57.447689056396484, "_runtime": 8514.358940124512, "_timestamp": 1585517592.7796698, "_step": 132}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": 5.255191326141357, "Value Loss": 59.33252716064453, "_runtime": 8514.559324026108, "_timestamp": 1585517592.9800537, "_step": 133}
{"Episode reward": 86.70000000000003, "Episode length": 133, "Policy Loss": 3.6196277141571045, "Value Loss": 53.015464782714844, "_runtime": 8514.7418384552, "_timestamp": 1585517593.162568, "_step": 134}
{"Episode reward": 88.07276251824509, "Episode length": 120, "Policy Loss": 3.394993305206299, "Value Loss": 53.10245895385742, "_runtime": 8514.930685043335, "_timestamp": 1585517593.3514147, "_step": 135}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": 3.7626495361328125, "Value Loss": 54.04011535644531, "_runtime": 8515.218507528305, "_timestamp": 1585517593.6392372, "_step": 136}
{"Episode reward": 80.69034310458001, "Episode length": 195, "Policy Loss": 0.029970373958349228, "Value Loss": 30.606372833251953, "_runtime": 8515.383515834808, "_timestamp": 1585517593.8042455, "_step": 137}
{"Episode reward": 89.3934692051262, "Episode length": 107, "Policy Loss": 2.3513994216918945, "Value Loss": 53.6851921081543, "_runtime": 8515.56326675415, "_timestamp": 1585517593.9839964, "_step": 138}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": -2.175719738006592, "Value Loss": 47.602474212646484, "_runtime": 8515.732644796371, "_timestamp": 1585517594.1533744, "_step": 139}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 0.8412263989448547, "Value Loss": 52.1390380859375, "_runtime": 8515.910556554794, "_timestamp": 1585517594.3312862, "_step": 140}
{"Episode reward": 88.32304981870114, "Episode length": 117, "Policy Loss": 0.3293982744216919, "Value Loss": 51.78596115112305, "_runtime": 8516.093384504318, "_timestamp": 1585517594.5141141, "_step": 141}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": -1.698129653930664, "Value Loss": 56.456424713134766, "_runtime": 8516.421774148941, "_timestamp": 1585517594.8425038, "_step": 142}
{"Episode reward": 77.75442737934641, "Episode length": 224, "Policy Loss": -1.936220407485962, "Value Loss": 28.135435104370117, "_runtime": 8516.741013288498, "_timestamp": 1585517595.161743, "_step": 143}
{"Episode reward": 78.49999999999997, "Episode length": 215, "Policy Loss": 0.0019130973378196359, "Value Loss": 27.363052368164062, "_runtime": 8517.333853244781, "_timestamp": 1585517595.754583, "_step": 144}
{"Episode reward": 59.49713826733029, "Episode length": 406, "Policy Loss": -1.6809897422790527, "Value Loss": 19.519067764282227, "_runtime": 8517.522575616837, "_timestamp": 1585517595.9433053, "_step": 145}
{"Episode reward": 88.99801809323333, "Episode length": 111, "Policy Loss": 3.806365728378296, "Value Loss": 58.19488525390625, "_runtime": 8517.714303970337, "_timestamp": 1585517596.1350336, "_step": 146}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 2.463777542114258, "Value Loss": 43.61442184448242, "_runtime": 8517.90508723259, "_timestamp": 1585517596.3258169, "_step": 147}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 2.8300349712371826, "Value Loss": 61.021846771240234, "_runtime": 8518.094942569733, "_timestamp": 1585517596.5156722, "_step": 148}
{"Episode reward": 87.50000000000003, "Episode length": 125, "Policy Loss": -1.0400837659835815, "Value Loss": 58.20866394042969, "_runtime": 8518.259257793427, "_timestamp": 1585517596.6799874, "_step": 149}
{"Episode reward": 89.38152801288382, "Episode length": 107, "Policy Loss": 2.0174813270568848, "Value Loss": 52.40097427368164, "_runtime": 8518.49200797081, "_timestamp": 1585517596.9127376, "_step": 150}
{"Episode reward": 84.48667765594442, "Episode length": 156, "Policy Loss": 2.7117812633514404, "Value Loss": 33.237770080566406, "_runtime": 8518.683090686798, "_timestamp": 1585517597.1038203, "_step": 151}
{"Episode reward": 87.50000000000003, "Episode length": 125, "Policy Loss": 6.978172779083252, "Value Loss": 53.42669677734375, "_runtime": 8518.864174365997, "_timestamp": 1585517597.284904, "_step": 152}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": 4.990942001342773, "Value Loss": 49.512638092041016, "_runtime": 8519.048244953156, "_timestamp": 1585517597.4689746, "_step": 153}
{"Episode reward": 88.13169861277568, "Episode length": 119, "Policy Loss": 1.658713936805725, "Value Loss": 58.39555740356445, "_runtime": 8519.21770119667, "_timestamp": 1585517597.6384308, "_step": 154}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 0.4149710237979889, "Value Loss": 76.96365356445312, "_runtime": 8519.386335611343, "_timestamp": 1585517597.8070652, "_step": 155}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 1.0425878763198853, "Value Loss": 88.1941146850586, "_runtime": 8519.551982402802, "_timestamp": 1585517597.972712, "_step": 156}
{"Episode reward": 89.20000000000003, "Episode length": 108, "Policy Loss": 4.366064071655273, "Value Loss": 81.13982391357422, "_runtime": 8519.71166419983, "_timestamp": 1585517598.1323938, "_step": 157}
{"Episode reward": 89.60000000000002, "Episode length": 104, "Policy Loss": 4.833864212036133, "Value Loss": 86.85720825195312, "_runtime": 8519.876606464386, "_timestamp": 1585517598.297336, "_step": 158}
{"Episode reward": 89.29155849961101, "Episode length": 108, "Policy Loss": 5.580851078033447, "Value Loss": 75.65572357177734, "_runtime": 8520.02994132042, "_timestamp": 1585517598.450671, "_step": 159}
{"Episode reward": 89.90000000000002, "Episode length": 101, "Policy Loss": 3.6509006023406982, "Value Loss": 73.033447265625, "_runtime": 8520.308242321014, "_timestamp": 1585517598.728972, "_step": 160}
{"Episode reward": 81.10000000000001, "Episode length": 189, "Policy Loss": 5.093177318572998, "Value Loss": 34.280242919921875, "_runtime": 8520.493994235992, "_timestamp": 1585517598.9147239, "_step": 161}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 9.807500839233398, "Value Loss": 87.17288208007812, "_runtime": 8520.671731233597, "_timestamp": 1585517599.0924609, "_step": 162}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": 5.553349018096924, "Value Loss": 63.29842758178711, "_runtime": 8520.843694925308, "_timestamp": 1585517599.2644246, "_step": 163}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 5.850136756896973, "Value Loss": 66.0373764038086, "_runtime": 8521.016028642654, "_timestamp": 1585517599.4367583, "_step": 164}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 5.356781959533691, "Value Loss": 70.2359619140625, "_runtime": 8521.17889714241, "_timestamp": 1585517599.5996268, "_step": 165}
{"Episode reward": 89.40000000000003, "Episode length": 106, "Policy Loss": 6.388431072235107, "Value Loss": 78.17061614990234, "_runtime": 8521.368510723114, "_timestamp": 1585517599.7892404, "_step": 166}
{"Episode reward": 87.65999927804191, "Episode length": 125, "Policy Loss": 4.529991626739502, "Value Loss": 66.14137268066406, "_runtime": 8521.539289474487, "_timestamp": 1585517599.960019, "_step": 167}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": 4.141398906707764, "Value Loss": 67.99200439453125, "_runtime": 8521.75583600998, "_timestamp": 1585517600.1765656, "_step": 168}
{"Episode reward": 85.60822549521771, "Episode length": 145, "Policy Loss": -0.1540723592042923, "Value Loss": 46.06131362915039, "_runtime": 8521.9315366745, "_timestamp": 1585517600.3522663, "_step": 169}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": -0.9019899964332581, "Value Loss": 53.176204681396484, "_runtime": 8522.099319934845, "_timestamp": 1585517600.5200496, "_step": 170}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": 0.5596747994422913, "Value Loss": 58.85441207885742, "_runtime": 8522.282838582993, "_timestamp": 1585517600.7035682, "_step": 171}
{"Episode reward": 88.10000000000004, "Episode length": 119, "Policy Loss": -2.6322238445281982, "Value Loss": 68.97938537597656, "_runtime": 8522.466634273529, "_timestamp": 1585517600.887364, "_step": 172}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": -4.533674716949463, "Value Loss": 47.57098388671875, "_runtime": 8522.650391817093, "_timestamp": 1585517601.0711215, "_step": 173}
{"Episode reward": 87.95784595375883, "Episode length": 121, "Policy Loss": -0.9740813970565796, "Value Loss": 48.490909576416016, "_runtime": 8522.884783506393, "_timestamp": 1585517601.3055131, "_step": 174}
{"Episode reward": 84.30000000000004, "Episode length": 157, "Policy Loss": -4.372835636138916, "Value Loss": 36.43425750732422, "_runtime": 8523.055747032166, "_timestamp": 1585517601.4764767, "_step": 175}
{"Episode reward": 88.90000000000003, "Episode length": 111, "Policy Loss": -0.056198395788669586, "Value Loss": 47.8837776184082, "_runtime": 8523.232228040695, "_timestamp": 1585517601.6529577, "_step": 176}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 0.8053269386291504, "Value Loss": 47.75203323364258, "_runtime": 8523.40245270729, "_timestamp": 1585517601.8231823, "_step": 177}
{"Episode reward": 89.00000000000003, "Episode length": 110, "Policy Loss": 1.500470519065857, "Value Loss": 50.477989196777344, "_runtime": 8523.577600002289, "_timestamp": 1585517601.9983296, "_step": 178}
{"Episode reward": 88.59995154615663, "Episode length": 115, "Policy Loss": 1.290672779083252, "Value Loss": 54.10442352294922, "_runtime": 8523.750411510468, "_timestamp": 1585517602.1711411, "_step": 179}
{"Episode reward": 88.79817641219127, "Episode length": 113, "Policy Loss": 1.00827157497406, "Value Loss": 45.01641082763672, "_runtime": 8523.92885518074, "_timestamp": 1585517602.3495848, "_step": 180}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -3.3010833263397217, "Value Loss": 49.33470916748047, "_runtime": 8524.333479642868, "_timestamp": 1585517602.7542093, "_step": 181}
{"Episode reward": 72.56251390257373, "Episode length": 275, "Policy Loss": -6.746601581573486, "Value Loss": 22.818729400634766, "_runtime": 8524.512853622437, "_timestamp": 1585517602.9335833, "_step": 182}
{"Episode reward": 88.30000000000003, "Episode length": 117, "Policy Loss": -2.9163198471069336, "Value Loss": 49.44451904296875, "_runtime": 8524.684245824814, "_timestamp": 1585517603.1049755, "_step": 183}
{"Episode reward": 88.86004012300322, "Episode length": 112, "Policy Loss": 0.312420517206192, "Value Loss": 51.899574279785156, "_runtime": 8524.87175822258, "_timestamp": 1585517603.2924879, "_step": 184}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": 2.608335494995117, "Value Loss": 85.98038482666016, "_runtime": 8525.054892539978, "_timestamp": 1585517603.4756222, "_step": 185}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 4.343101501464844, "Value Loss": 54.425559997558594, "_runtime": 8525.215580701828, "_timestamp": 1585517603.6363103, "_step": 186}
{"Episode reward": 89.4394169985317, "Episode length": 106, "Policy Loss": 3.8089206218719482, "Value Loss": 71.42308044433594, "_runtime": 8525.406961202621, "_timestamp": 1585517603.8276908, "_step": 187}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": 3.3256003856658936, "Value Loss": 61.2164192199707, "_runtime": 8525.570835351944, "_timestamp": 1585517603.991565, "_step": 188}
{"Episode reward": 89.39237897656861, "Episode length": 107, "Policy Loss": 3.995795965194702, "Value Loss": 68.23233795166016, "_runtime": 8525.737219333649, "_timestamp": 1585517604.157949, "_step": 189}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 4.470126152038574, "Value Loss": 62.96188735961914, "_runtime": 8525.910916805267, "_timestamp": 1585517604.3316464, "_step": 190}
{"Episode reward": 88.70000000000003, "Episode length": 113, "Policy Loss": 5.6374382972717285, "Value Loss": 50.82871627807617, "_runtime": 8526.13164114952, "_timestamp": 1585517604.5523708, "_step": 191}
{"Episode reward": 85.20000000000005, "Episode length": 148, "Policy Loss": 4.820756435394287, "Value Loss": 43.61746597290039, "_runtime": 8526.311755180359, "_timestamp": 1585517604.7324848, "_step": 192}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 4.2064528465271, "Value Loss": 45.158103942871094, "_runtime": 8526.484162807465, "_timestamp": 1585517604.9048924, "_step": 193}
{"Episode reward": 88.76050525000322, "Episode length": 113, "Policy Loss": 2.112708806991577, "Value Loss": 56.527469635009766, "_runtime": 8526.677402496338, "_timestamp": 1585517605.0981321, "_step": 194}
{"Episode reward": 87.40000000000003, "Episode length": 126, "Policy Loss": -3.2132503986358643, "Value Loss": 39.61594772338867, "_runtime": 8526.841770410538, "_timestamp": 1585517605.2625, "_step": 195}
{"Episode reward": 89.38225875161591, "Episode length": 107, "Policy Loss": 1.26982843875885, "Value Loss": 59.79330825805664, "_runtime": 8527.005227565765, "_timestamp": 1585517605.4259572, "_step": 196}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 2.407787799835205, "Value Loss": 51.37593078613281, "_runtime": 8527.254334926605, "_timestamp": 1585517605.6750646, "_step": 197}
{"Episode reward": 83.30000000000004, "Episode length": 167, "Policy Loss": -1.244145154953003, "Value Loss": 32.27037811279297, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375, 503025.4375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-509893.78125, -247555.78125, 14782.21875, 277120.21875, 539458.25, 801796.25, 1064134.25, 1326472.25, 1588810.25, 1851148.25, 2113486.25, 2375824.25, 2638162.25, 2900500.25, 3162838.25, 3425176.25, 3687514.25, 3949852.25, 4212190.0, 4474528.0, 4736866.0, 4999204.0, 5261542.0, 5523880.0, 5786218.0, 6048556.0, 6310894.0, 6573232.0, 6835570.0, 7097908.0, 7360246.0, 7622584.0, 7884922.0, 8147260.0, 8409598.0, 8671936.0, 8934274.0, 9196612.0, 9458950.0, 9721288.0, 9983626.0, 10245964.0, 10508302.0, 10770640.0, 11032978.0, 11295316.0, 11557654.0, 11819992.0, 12082330.0, 12344668.0, 12607006.0, 12869344.0, 13131682.0, 13394020.0, 13656358.0, 13918696.0, 14181034.0, 14443372.0, 14705710.0, 14968048.0, 15230386.0, 15492724.0, 15755062.0, 16017400.0, 16279738.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0], "bins": [-717431.9375, -706214.3125, -694996.625, -683779.0, -672561.3125, -661343.6875, -650126.0, -638908.375, -627690.6875, -616473.0625, -605255.375, -594037.75, -582820.125, -571602.4375, -560384.75, -549167.125, -537949.5, -526731.8125, -515514.15625, -504296.5, -493078.84375, -481861.1875, -470643.5625, -459425.875, -448208.25, -436990.59375, -425772.9375, -414555.28125, -403337.625, -392119.96875, -380902.3125, -369684.65625, -358467.0, -347249.34375, -336031.6875, -324814.03125, -313596.375, -302378.71875, -291161.0625, -279943.40625, -268725.75, -257508.125, -246290.46875, -235072.8125, -223855.15625, -212637.5, -201419.84375, -190202.1875, -178984.5625, -167766.875, -156549.25, -145331.5625, -134113.9375, -122896.25, -111678.625, -100460.9375, -89243.3125, -78025.625, -66808.0, -55590.3125, -44372.6875, -33155.0, -21937.375, -10719.6875, 497.9375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 3.0, 2.0, 0.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 11.0, 3.0, 328.0, 10.0, 1.0, 4.0, 6.0, 7.0, 9.0, 6.0, 9.0, 1.0, 3.0, 8.0, 8.0, 6.0, 8.0, 3.0, 6.0], "bins": [-1800142.375, -1762021.625, -1723900.75, -1685780.0, -1647659.125, -1609538.375, -1571417.5, -1533296.75, -1495176.0, -1457055.125, -1418934.25, -1380813.5, -1342692.75, -1304571.875, -1266451.125, -1228330.25, -1190209.5, -1152088.75, -1113967.875, -1075847.0, -1037726.25, -999605.5, -961484.6875, -923363.875, -885243.0625, -847122.25, -809001.4375, -770880.625, -732759.875, -694639.0, -656518.25, -618397.375, -580276.625, -542155.875, -504035.0, -465914.25, -427793.375, -389672.625, -351551.75, -313431.0, -275310.125, -237189.375, -199068.625, -160947.75, -122827.0, -84706.125, -46585.375, -8464.5, 29656.25, 67777.0, 105897.875, 144018.625, 182139.5, 220260.25, 258381.125, 296501.875, 334622.625, 372743.375, 410864.375, 448985.125, 487105.875, 525226.625, 563347.625, 601468.375, 639589.125]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-7719239.5, -7561474.5, -7403709.0, -7245944.0, -7088178.5, -6930413.5, -6772648.0, -6614883.0, -6457118.0, -6299352.5, -6141587.0, -5983822.0, -5826057.0, -5668291.5, -5510526.5, -5352761.0, -5194996.0, -5037231.0, -4879465.5, -4721700.0, -4563935.0, -4406170.0, -4248405.0, -4090639.5, -3932874.25, -3775109.0, -3617343.75, -3459578.5, -3301813.5, -3144048.0, -2986283.0, -2828517.5, -2670752.5, -2512987.5, -2355222.0, -2197457.0, -2039691.5, -1881926.5, -1724161.0, -1566396.0, -1408630.5, -1250865.5, -1093100.5, -935335.0, -777570.0, -619804.5, -462039.5, -304274.0, -146509.0, 11256.0, 169021.5, 326786.5, 484552.0, 642317.0, 800082.5, 957847.5, 1115612.5, 1273377.5, 1431143.5, 1588908.5, 1746673.5, 1904438.5, 2062204.5, 2219969.5, 2377734.5]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 5.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 17.0, 4.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1023955.0, -949234.375, -874513.75, -799793.125, -725072.5, -650351.875, -575631.25, -500910.625, -426190.0, -351469.375, -276748.75, -202028.125, -127307.5, -52586.875, 22133.75, 96854.375, 171575.0, 246295.625, 321016.25, 395736.875, 470457.5, 545178.125, 619898.75, 694619.375, 769340.0, 844060.625, 918781.25, 993501.875, 1068222.5, 1142943.0, 1217663.75, 1292384.5, 1367105.0, 1441825.5, 1516546.25, 1591267.0, 1665987.5, 1740708.0, 1815428.75, 1890149.5, 1964870.0, 2039590.5, 2114311.25, 2189032.0, 2263752.5, 2338473.0, 2413193.75, 2487914.5, 2562635.0, 2637355.5, 2712076.25, 2786797.0, 2861517.5, 2936238.0, 3010958.75, 3085679.5, 3160400.0, 3235120.5, 3309841.0, 3384562.0, 3459282.5, 3534003.0, 3608724.0, 3683444.5, 3758165.0]}, "_runtime": 8527.450161457062, "_timestamp": 1585517605.870891, "_step": 198}
{"Episode reward": 87.90000000000003, "Episode length": 121, "Policy Loss": 1.8600504398345947, "Value Loss": 40.760013580322266, "_runtime": 8527.639553785324, "_timestamp": 1585517606.0602834, "_step": 199}
{"Episode reward": 87.80000000000004, "Episode length": 122, "Policy Loss": 2.6869664192199707, "Value Loss": 41.701141357421875, "_runtime": 8527.818350076675, "_timestamp": 1585517606.2390797, "_step": 200}
{"Episode reward": 88.50000000000003, "Episode length": 115, "Policy Loss": 1.228446125984192, "Value Loss": 47.23444366455078, "_runtime": 8528.143469333649, "_timestamp": 1585517606.564199, "_step": 201}
{"Episode reward": 78.03513201230668, "Episode length": 221, "Policy Loss": 0.11703919619321823, "Value Loss": 28.132173538208008, "_runtime": 8528.319096565247, "_timestamp": 1585517606.7398262, "_step": 202}
{"Episode reward": 88.60000000000002, "Episode length": 114, "Policy Loss": 3.097053050994873, "Value Loss": 59.13402557373047, "_runtime": 8528.508991479874, "_timestamp": 1585517606.929721, "_step": 203}
{"Episode reward": 87.50000000000003, "Episode length": 125, "Policy Loss": 3.9199159145355225, "Value Loss": 53.5196418762207, "_runtime": 8529.242188692093, "_timestamp": 1585517607.6629183, "_step": 204}
{"Episode reward": 50.42703501450399, "Episode length": 497, "Policy Loss": -0.6709887981414795, "Value Loss": 12.684032440185547, "_runtime": 8529.561312913895, "_timestamp": 1585517607.9820426, "_step": 205}
{"Episode reward": 79.18729807301968, "Episode length": 209, "Policy Loss": 1.4938316345214844, "Value Loss": 29.52850341796875, "_runtime": 8529.725587129593, "_timestamp": 1585517608.1463168, "_step": 206}
{"Episode reward": 89.3846528685652, "Episode length": 107, "Policy Loss": 2.2214651107788086, "Value Loss": 60.12837600708008, "_runtime": 8530.233218669891, "_timestamp": 1585517608.6539483, "_step": 207}
{"Episode reward": 66.6999999999998, "Episode length": 333, "Policy Loss": -0.047147300094366074, "Value Loss": 17.92036247253418, "_runtime": 8530.422345876694, "_timestamp": 1585517608.8430755, "_step": 208}
{"Episode reward": 88.20000000000003, "Episode length": 118, "Policy Loss": 3.184741497039795, "Value Loss": 45.77516174316406, "_runtime": 8530.75530076027, "_timestamp": 1585517609.1760304, "_step": 209}
{"Episode reward": 77.69278291976076, "Episode length": 224, "Policy Loss": 0.09473950415849686, "Value Loss": 23.87057876586914, "_runtime": 8530.94067811966, "_timestamp": 1585517609.3614078, "_step": 210}
{"Episode reward": 89.05877954882817, "Episode length": 110, "Policy Loss": 2.1941025257110596, "Value Loss": 44.82891845703125, "_runtime": 8531.229378938675, "_timestamp": 1585517609.6501086, "_step": 211}
{"Episode reward": 80.6, "Episode length": 194, "Policy Loss": -0.08643018454313278, "Value Loss": 26.890241622924805, "_runtime": 8531.403552532196, "_timestamp": 1585517609.8242822, "_step": 212}
{"Episode reward": 89.30000000000003, "Episode length": 107, "Policy Loss": 1.2056174278259277, "Value Loss": 41.45808029174805, "_runtime": 8531.58720779419, "_timestamp": 1585517610.0079374, "_step": 213}
{"Episode reward": 88.13058714155306, "Episode length": 120, "Policy Loss": -1.9559235572814941, "Value Loss": 40.10197067260742, "_runtime": 8531.76602768898, "_timestamp": 1585517610.1867573, "_step": 214}
{"Episode reward": 88.80000000000003, "Episode length": 112, "Policy Loss": -0.21666431427001953, "Value Loss": 43.00487518310547, "_runtime": 8532.455531597137, "_timestamp": 1585517610.8762612, "_step": 215}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": -2.4021615982055664, "Value Loss": 10.866920471191406, "_runtime": 8532.769206047058, "_timestamp": 1585517611.1899357, "_step": 216}
{"Episode reward": 79.69999999999999, "Episode length": 203, "Policy Loss": -2.1495184898376465, "Value Loss": 21.751937866210938, "_runtime": 8533.065298318863, "_timestamp": 1585517611.486028, "_step": 217}
{"Episode reward": 80.1, "Episode length": 199, "Policy Loss": -0.776911199092865, "Value Loss": 21.960262298583984, "_runtime": 8533.993441820145, "_timestamp": 1585517612.4141715, "_step": 218}
{"Episode reward": 39.389613652269475, "Episode length": 608, "Policy Loss": -1.7495707273483276, "Value Loss": 8.027442932128906, "_runtime": 8534.189800262451, "_timestamp": 1585517612.61053, "_step": 219}
{"Episode reward": 88.59732584485322, "Episode length": 115, "Policy Loss": 2.4356799125671387, "Value Loss": 39.671714782714844, "_runtime": 8534.364817857742, "_timestamp": 1585517612.7855475, "_step": 220}
{"Episode reward": 89.10000000000002, "Episode length": 109, "Policy Loss": 1.4811185598373413, "Value Loss": 48.542686462402344, "_runtime": 8534.882740020752, "_timestamp": 1585517613.3034697, "_step": 221}
{"Episode reward": 67.19999999999982, "Episode length": 328, "Policy Loss": -0.6846840381622314, "Value Loss": 18.596384048461914, "_runtime": 8535.49602985382, "_timestamp": 1585517613.9167595, "_step": 222}
{"Episode reward": 58.78869682032124, "Episode length": 414, "Policy Loss": -1.0576421022415161, "Value Loss": 17.111635208129883, "_runtime": 8535.845160722733, "_timestamp": 1585517614.2658904, "_step": 223}
{"Episode reward": 76.38104667101095, "Episode length": 237, "Policy Loss": -0.3499257564544678, "Value Loss": 28.14717674255371, "_runtime": 8536.075306892395, "_timestamp": 1585517614.4960365, "_step": 224}
{"Episode reward": 85.70933763874442, "Episode length": 143, "Policy Loss": -0.22105364501476288, "Value Loss": 45.95707702636719, "_runtime": 8536.544778108597, "_timestamp": 1585517614.9655077, "_step": 225}
{"Episode reward": 69.69967869762525, "Episode length": 304, "Policy Loss": 0.3047962486743927, "Value Loss": 21.392370223999023, "_runtime": 8536.966073274612, "_timestamp": 1585517615.386803, "_step": 226}
{"Episode reward": 72.9008047162043, "Episode length": 276, "Policy Loss": 0.7320547699928284, "Value Loss": 18.46242332458496, "_runtime": 8537.152998924255, "_timestamp": 1585517615.5737286, "_step": 227}
{"Episode reward": 88.00000000000003, "Episode length": 120, "Policy Loss": 7.780938625335693, "Value Loss": 43.76958465576172, "_runtime": 8537.455114364624, "_timestamp": 1585517615.875844, "_step": 228}
{"Episode reward": 80.57934521082207, "Episode length": 195, "Policy Loss": 1.4946638345718384, "Value Loss": 27.463964462280273, "_runtime": 8537.76492190361, "_timestamp": 1585517616.1856515, "_step": 229}
{"Episode reward": 80.0, "Episode length": 200, "Policy Loss": 0.3928689658641815, "Value Loss": 22.859302520751953, "_runtime": 8537.944229602814, "_timestamp": 1585517616.3649592, "_step": 230}
{"Episode reward": 88.40000000000003, "Episode length": 116, "Policy Loss": -1.3222534656524658, "Value Loss": 53.3499870300293, "_runtime": 8538.72397184372, "_timestamp": 1585517617.1447015, "_step": 231}
{"Episode reward": 47.76420538511453, "Episode length": 524, "Policy Loss": -1.6990832090377808, "Value Loss": 10.71713638305664, "_runtime": 8538.932762145996, "_timestamp": 1585517617.3534918, "_step": 232}
{"Episode reward": 87.79989618299834, "Episode length": 124, "Policy Loss": -0.3741723299026489, "Value Loss": 49.87670135498047, "_runtime": 8539.226154088974, "_timestamp": 1585517617.6468837, "_step": 233}
{"Episode reward": 80.52860078225811, "Episode length": 197, "Policy Loss": 0.22493073344230652, "Value Loss": 25.5747013092041, "_runtime": 8539.752434253693, "_timestamp": 1585517618.173164, "_step": 234}
{"Episode reward": 65.95028168292606, "Episode length": 345, "Policy Loss": 0.07204554229974747, "Value Loss": 19.805994033813477, "_runtime": 8540.054778575897, "_timestamp": 1585517618.4755082, "_step": 235}
{"Episode reward": 79.72105579221241, "Episode length": 204, "Policy Loss": 1.7453672885894775, "Value Loss": 27.716047286987305, "_runtime": 8541.096313476562, "_timestamp": 1585517619.517043, "_step": 236}
{"Episode reward": 29.682468948206008, "Episode length": 707, "Policy Loss": -1.1284295320510864, "Value Loss": 7.011979579925537, "_runtime": 8542.599484920502, "_timestamp": 1585517621.0202146, "_step": 237}
{"Episode reward": -99.4915773010293, "Episode length": 999, "Policy Loss": -1.9588299989700317, "Value Loss": 0.16059264540672302, "_runtime": 8542.910814523697, "_timestamp": 1585517621.3315442, "_step": 238}
{"Episode reward": 80.42983454132033, "Episode length": 197, "Policy Loss": 1.0120638608932495, "Value Loss": 26.883499145507812, "_runtime": 8544.425705194473, "_timestamp": 1585517622.8464348, "_step": 239}
{"Episode reward": -99.46068883514461, "Episode length": 999, "Policy Loss": -1.7211558818817139, "Value Loss": 0.17734675109386444, "_runtime": 8545.032452106476, "_timestamp": 1585517623.4531817, "_step": 240}
{"Episode reward": 62.98891988971247, "Episode length": 372, "Policy Loss": -0.5000174045562744, "Value Loss": 13.258782386779785, "_runtime": 8545.32464313507, "_timestamp": 1585517623.7453728, "_step": 241}
{"Episode reward": 80.88982472941643, "Episode length": 193, "Policy Loss": 1.5009866952896118, "Value Loss": 31.996505737304688, "_runtime": 8546.167063713074, "_timestamp": 1585517624.5877934, "_step": 242}
{"Episode reward": 47.6240215948603, "Episode length": 529, "Policy Loss": -0.4719228446483612, "Value Loss": 8.435014724731445, "_runtime": 8547.008311033249, "_timestamp": 1585517625.4290407, "_step": 243}
{"Episode reward": 44.49508474191525, "Episode length": 558, "Policy Loss": -0.7502138614654541, "Value Loss": 8.08569622039795, "_runtime": 8547.428575515747, "_timestamp": 1585517625.8493052, "_step": 244}
{"Episode reward": 72.5702437731223, "Episode length": 285, "Policy Loss": 0.11251498758792877, "Value Loss": 16.862201690673828, "_runtime": 8547.862652778625, "_timestamp": 1585517626.2833824, "_step": 245}
{"Episode reward": 72.01389986771292, "Episode length": 282, "Policy Loss": -0.46625810861587524, "Value Loss": 13.69985580444336, "_runtime": 8549.417806625366, "_timestamp": 1585517627.8385363, "_step": 246}
{"Episode reward": -99.17378581962807, "Episode length": 999, "Policy Loss": -1.0347509384155273, "Value Loss": 0.387041836977005, "_runtime": 8550.896825790405, "_timestamp": 1585517629.3175554, "_step": 247}
{"Episode reward": -99.03564353488095, "Episode length": 999, "Policy Loss": -1.4248021841049194, "Value Loss": 0.18513235449790955, "_runtime": 8552.24652171135, "_timestamp": 1585517630.6672513, "_step": 248}
{"Episode reward": 10.743457412872104, "Episode length": 904, "Policy Loss": -1.1526389122009277, "Value Loss": 148.83160400390625, "_runtime": 8553.064227104187, "_timestamp": 1585517631.4849567, "_step": 249}
{"Episode reward": 49.42349986468476, "Episode length": 511, "Policy Loss": 1.9098014831542969, "Value Loss": 19.774248123168945, "_runtime": 8554.61423945427, "_timestamp": 1585517633.034969, "_step": 250}
{"Episode reward": -99.07853516918787, "Episode length": 999, "Policy Loss": 3.114980936050415, "Value Loss": 1.3193072080612183, "_runtime": 8555.81000828743, "_timestamp": 1585517634.230738, "_step": 251}
{"Episode reward": 23.107453032698075, "Episode length": 777, "Policy Loss": 3.582812786102295, "Value Loss": 19.412134170532227, "_runtime": 8556.494830846786, "_timestamp": 1585517634.9155605, "_step": 252}
{"Episode reward": 56.294483033543436, "Episode length": 442, "Policy Loss": 6.110864162445068, "Value Loss": 23.898605346679688, "_runtime": 8556.854101657867, "_timestamp": 1585517635.2748313, "_step": 253}
{"Episode reward": 79.5467978603566, "Episode length": 206, "Policy Loss": 7.602678298950195, "Value Loss": 50.12224578857422, "_runtime": 8558.215349197388, "_timestamp": 1585517636.6360788, "_step": 254}
{"Episode reward": 11.811026356671832, "Episode length": 892, "Policy Loss": 5.7821269035339355, "Value Loss": 12.113372802734375, "_runtime": 8559.001308918, "_timestamp": 1585517637.4220386, "_step": 255}
{"Episode reward": 49.36764368561108, "Episode length": 511, "Policy Loss": 6.075077056884766, "Value Loss": 20.490272521972656, "_runtime": 8559.962801456451, "_timestamp": 1585517638.383531, "_step": 256}
{"Episode reward": 36.096955693908804, "Episode length": 649, "Policy Loss": 5.256592750549316, "Value Loss": 16.171241760253906, "_runtime": 8560.568465471268, "_timestamp": 1585517638.989195, "_step": 257}
{"Episode reward": 62.873795364926266, "Episode length": 374, "Policy Loss": 5.751259803771973, "Value Loss": 27.451082229614258, "_runtime": 8561.228463172913, "_timestamp": 1585517639.6491928, "_step": 258}
{"Episode reward": 56.865730214291496, "Episode length": 435, "Policy Loss": 5.280762672424316, "Value Loss": 23.57453727722168, "_runtime": 8562.75226521492, "_timestamp": 1585517641.1729949, "_step": 259}
{"Episode reward": -99.75455934242206, "Episode length": 999, "Policy Loss": 4.048084735870361, "Value Loss": 0.4088785648345947, "_runtime": 8564.256598234177, "_timestamp": 1585517642.6773279, "_step": 260}
{"Episode reward": -99.60903389915136, "Episode length": 999, "Policy Loss": 3.654745101928711, "Value Loss": 0.34879010915756226, "_runtime": 8565.329359531403, "_timestamp": 1585517643.7500892, "_step": 261}
{"Episode reward": 30.101276834457508, "Episode length": 706, "Policy Loss": 4.062633037567139, "Value Loss": 14.398538589477539, "_runtime": 8566.553719758987, "_timestamp": 1585517644.9744494, "_step": 262}
{"Episode reward": 22.722611464526423, "Episode length": 781, "Policy Loss": 3.677229166030884, "Value Loss": 12.956747055053711, "_runtime": 8567.390792369843, "_timestamp": 1585517645.811522, "_step": 263}
{"Episode reward": 47.96514706606104, "Episode length": 525, "Policy Loss": 3.711082935333252, "Value Loss": 19.05133819580078, "_runtime": 8568.922243118286, "_timestamp": 1585517647.3429728, "_step": 264}
{"Episode reward": -99.18516031829567, "Episode length": 999, "Policy Loss": 2.255960464477539, "Value Loss": 0.19684448838233948, "_runtime": 8569.50193452835, "_timestamp": 1585517647.9226642, "_step": 265}
{"Episode reward": 64.77802863233066, "Episode length": 354, "Policy Loss": 3.8976001739501953, "Value Loss": 27.921367645263672, "_runtime": 8569.8393471241, "_timestamp": 1585517648.2600768, "_step": 266}
{"Episode reward": 79.61820473221078, "Episode length": 208, "Policy Loss": 4.6430134773254395, "Value Loss": 47.446861267089844, "_runtime": 8570.873459815979, "_timestamp": 1585517649.2941895, "_step": 267}
{"Episode reward": 34.266993877451156, "Episode length": 660, "Policy Loss": 2.501845598220825, "Value Loss": 14.959107398986816, "_runtime": 8571.897102355957, "_timestamp": 1585517650.317832, "_step": 268}
{"Episode reward": 33.08958700236356, "Episode length": 674, "Policy Loss": 1.8734925985336304, "Value Loss": 14.548144340515137, "_runtime": 8572.852946996689, "_timestamp": 1585517651.2736766, "_step": 269}
{"Episode reward": 36.51674007047857, "Episode length": 647, "Policy Loss": 1.5739814043045044, "Value Loss": 15.058176040649414, "_runtime": 8573.800099849701, "_timestamp": 1585517652.2208295, "_step": 270}
{"Episode reward": 40.383202681053525, "Episode length": 607, "Policy Loss": 1.0524274110794067, "Value Loss": 16.078834533691406, "_runtime": 8574.447691440582, "_timestamp": 1585517652.868421, "_step": 271}
{"Episode reward": 62.15992647564492, "Episode length": 384, "Policy Loss": 1.5075273513793945, "Value Loss": 25.358001708984375, "_runtime": 8574.79644370079, "_timestamp": 1585517653.2171733, "_step": 272}
{"Episode reward": 79.55044954165668, "Episode length": 209, "Policy Loss": 3.3372139930725098, "Value Loss": 46.25520706176758, "_runtime": 8576.337513446808, "_timestamp": 1585517654.758243, "_step": 273}
{"Episode reward": -99.66543333455927, "Episode length": 999, "Policy Loss": -0.5158525109291077, "Value Loss": 0.05852897837758064, "_runtime": 8577.656183242798, "_timestamp": 1585517656.0769129, "_step": 274}
{"Episode reward": 13.20420325792152, "Episode length": 873, "Policy Loss": 0.25901976227760315, "Value Loss": 11.17660903930664, "_runtime": 8579.16258263588, "_timestamp": 1585517657.5833123, "_step": 275}
{"Episode reward": -98.63892127717581, "Episode length": 999, "Policy Loss": -0.2580605745315552, "Value Loss": 0.3479762375354767, "_runtime": 8579.63576054573, "_timestamp": 1585517658.0564902, "_step": 276}
{"Episode reward": 73.44232880613174, "Episode length": 270, "Policy Loss": 2.6110904216766357, "Value Loss": 36.20347595214844, "_runtime": 8579.988691568375, "_timestamp": 1585517658.4094212, "_step": 277}
{"Episode reward": 79.73970206278173, "Episode length": 206, "Policy Loss": 1.8464558124542236, "Value Loss": 47.326107025146484, "_runtime": 8580.448682785034, "_timestamp": 1585517658.8694124, "_step": 278}
{"Episode reward": 72.70038107150836, "Episode length": 279, "Policy Loss": 2.654353618621826, "Value Loss": 35.21394348144531, "_runtime": 8581.186135053635, "_timestamp": 1585517659.6068647, "_step": 279}
{"Episode reward": 51.69749203230374, "Episode length": 490, "Policy Loss": 0.4141755700111389, "Value Loss": 19.69135284423828, "_runtime": 8581.934627056122, "_timestamp": 1585517660.3553567, "_step": 280}
{"Episode reward": 51.40048112418549, "Episode length": 496, "Policy Loss": 0.5279909372329712, "Value Loss": 19.796733856201172, "_runtime": 8583.450631856918, "_timestamp": 1585517661.8713615, "_step": 281}
{"Episode reward": -99.43801460358323, "Episode length": 999, "Policy Loss": -1.2739367485046387, "Value Loss": 0.11688077449798584, "_runtime": 8584.97383570671, "_timestamp": 1585517663.3945653, "_step": 282}
{"Episode reward": -99.0367566777654, "Episode length": 999, "Policy Loss": -1.3132736682891846, "Value Loss": 0.11273761838674545, "_runtime": 8585.531741380692, "_timestamp": 1585517663.952471, "_step": 283}
{"Episode reward": 64.92037849664464, "Episode length": 353, "Policy Loss": 1.0144462585449219, "Value Loss": 27.570091247558594, "_runtime": 8587.074761629105, "_timestamp": 1585517665.4954913, "_step": 284}
{"Episode reward": -98.50347670331789, "Episode length": 999, "Policy Loss": -1.352674126625061, "Value Loss": 0.08192848414182663, "_runtime": 8588.647956371307, "_timestamp": 1585517667.068686, "_step": 285}
{"Episode reward": -98.5228932383639, "Episode length": 999, "Policy Loss": -1.1434345245361328, "Value Loss": 0.1233724057674408, "_runtime": 8590.045772790909, "_timestamp": 1585517668.4665024, "_step": 286}
{"Episode reward": 8.18343749441587, "Episode length": 928, "Policy Loss": -0.5882334113121033, "Value Loss": 10.663414001464844, "_runtime": 8591.620190143585, "_timestamp": 1585517670.0409198, "_step": 287}
{"Episode reward": -98.62441575320314, "Episode length": 999, "Policy Loss": -1.026539921760559, "Value Loss": 0.1568857729434967, "_runtime": 8593.190249443054, "_timestamp": 1585517671.610979, "_step": 288}
{"Episode reward": -98.90361442686857, "Episode length": 999, "Policy Loss": -1.3275703191757202, "Value Loss": 0.12135349214076996, "_runtime": 8594.278761386871, "_timestamp": 1585517672.699491, "_step": 289}
{"Episode reward": 31.6063676585362, "Episode length": 694, "Policy Loss": -0.2603098154067993, "Value Loss": 14.42370891571045, "_runtime": 8595.2521545887, "_timestamp": 1585517673.6728842, "_step": 290}
{"Episode reward": 39.184270100306925, "Episode length": 614, "Policy Loss": 0.03242617845535278, "Value Loss": 16.356351852416992, "_runtime": 8596.829663276672, "_timestamp": 1585517675.250393, "_step": 291}
{"Episode reward": -98.9004666343108, "Episode length": 999, "Policy Loss": -1.183840036392212, "Value Loss": 0.10404089838266373, "_runtime": 8598.420211791992, "_timestamp": 1585517676.8409414, "_step": 292}
{"Episode reward": -97.90280689169877, "Episode length": 999, "Policy Loss": -0.8312638998031616, "Value Loss": 0.22075404226779938, "_runtime": 8599.958189725876, "_timestamp": 1585517678.3789194, "_step": 293}
{"Episode reward": -99.17299734286831, "Episode length": 999, "Policy Loss": -1.162448525428772, "Value Loss": 0.13025008141994476, "_runtime": 8601.523142814636, "_timestamp": 1585517679.9438725, "_step": 294}
{"Episode reward": -99.25491684135999, "Episode length": 999, "Policy Loss": -1.2330361604690552, "Value Loss": 0.05879783257842064, "_runtime": 8602.149326324463, "_timestamp": 1585517680.570056, "_step": 295}
{"Episode reward": 62.625257340209195, "Episode length": 379, "Policy Loss": 0.7647672891616821, "Value Loss": 26.053579330444336, "_runtime": 8603.70866727829, "_timestamp": 1585517682.129397, "_step": 296}
{"Episode reward": -99.44444226910447, "Episode length": 999, "Policy Loss": -1.125534176826477, "Value Loss": 0.051481761038303375, "_runtime": 8605.293219566345, "_timestamp": 1585517683.7139492, "_step": 297}
{"Episode reward": -99.42367675535796, "Episode length": 999, "Policy Loss": -1.0976438522338867, "Value Loss": 0.0454862006008625, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373, 0.15274645388126373]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.29390382766723633, -0.24861738085746765, -0.20333093404769897, -0.1580445021390915, -0.11275805532932281, -0.06747160851955414, -0.022185176610946655, 0.02310127019882202, 0.0683877170085907, 0.11367416381835938, 0.15896061062812805, 0.20424705743789673, 0.24953347444534302, 0.2948199510574341, 0.34010636806488037, 0.38539284467697144, 0.4306792616844177, 0.475965678691864, 0.5212521553039551, 0.5665385723114014, 0.6118250489234924, 0.6571114659309387, 0.7023979425430298, 0.7476843595504761, 0.7929707765579224, 0.8382571935653687, 0.8835437297821045, 0.9288301467895508, 0.9741165637969971, 1.0194029808044434, 1.0646895170211792, 1.1099759340286255, 1.1552623510360718, 1.200548768043518, 1.2458351850509644, 1.2911217212677002, 1.3364081382751465, 1.3816945552825928, 1.426980972290039, 1.472267508506775, 1.5175539255142212, 1.5628403425216675, 1.6081267595291138, 1.65341317653656, 1.698699712753296, 1.7439861297607422, 1.7892725467681885, 1.8345589637756348, 1.879845380783081, 1.9251317977905273, 1.9704182147979736, 2.015704870223999, 2.0609912872314453, 2.1062777042388916, 2.151564121246338, 2.196850538253784, 2.2421369552612305, 2.2874233722686768, 2.332709789276123, 2.3779962062835693, 2.4232828617095947, 2.468569278717041, 2.5138556957244873, 2.5591421127319336, 2.60442852973938]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.16966654360294342, -0.16611911356449127, -0.16257168352603912, -0.15902426838874817, -0.15547683835029602, -0.15192940831184387, -0.14838197827339172, -0.14483454823493958, -0.14128711819648743, -0.13773970305919647, -0.13419227302074432, -0.13064484298229218, -0.12709741294384003, -0.12354999035596848, -0.12000256031751633, -0.11645513772964478, -0.11290770769119263, -0.10936027765274048, -0.10581285506486893, -0.10226542502641678, -0.09871800243854523, -0.09517057240009308, -0.09162314236164093, -0.08807571977376938, -0.08452828973531723, -0.08098085969686508, -0.07743343710899353, -0.07388600707054138, -0.07033857703208923, -0.06679115444421768, -0.06324372440576553, -0.05969630181789398, -0.056148871779441833, -0.052601441740989685, -0.049054019153118134, -0.045506589114665985, -0.041959166526794434, -0.038411736488342285, -0.03486430644989014, -0.03131687641143799, -0.027769461274147034, -0.024222031235694885, -0.020674601197242737, -0.01712717115879059, -0.01357974112033844, -0.010032311081886292, -0.006484895944595337, -0.0029374659061431885, 0.00060996413230896, 0.004157394170761108, 0.007704824209213257, 0.011252239346504211, 0.01479966938495636, 0.01834709942340851, 0.021894529461860657, 0.025441959500312805, 0.028989389538764954, 0.03253680467605591, 0.03608423471450806, 0.039631664752960205, 0.043179094791412354, 0.0467265248298645, 0.05027393996715546, 0.053821370005607605, 0.05736880004405975]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 9.0, 9.0, 26.0, 78.0, 297.0, 17.0, 9.0, 7.0, 5.0, 11.0, 5.0, 7.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 5.0, 4.0, 2.0], "bins": [-0.5540220737457275, -0.5418221950531006, -0.5296222567558289, -0.5174223780632019, -0.5052224397659302, -0.4930225610733032, -0.4808226525783539, -0.46862274408340454, -0.4564228355884552, -0.44422292709350586, -0.4320230185985565, -0.4198231101036072, -0.4076232314109802, -0.3954232931137085, -0.38322341442108154, -0.3710235059261322, -0.35882359743118286, -0.3466236889362335, -0.3344237804412842, -0.3222239017486572, -0.3100239634513855, -0.29782408475875854, -0.2856241762638092, -0.27342426776885986, -0.2612243592739105, -0.24902445077896118, -0.23682454228401184, -0.2246246337890625, -0.21242475509643555, -0.2002248466014862, -0.18802493810653687, -0.17582502961158752, -0.16362512111663818, -0.15142521262168884, -0.1392253041267395, -0.12702539563179016, -0.11482548713684082, -0.10262560844421387, -0.09042569994926453, -0.07822579145431519, -0.06602588295936584, -0.053825974464416504, -0.04162609577178955, -0.029426157474517822, -0.01722627878189087, -0.005026340484619141, 0.0071735382080078125, 0.01937347650527954, 0.031573355197906494, 0.04377323389053345, 0.055973172187805176, 0.06817305088043213, 0.08037298917770386, 0.09257286787033081, 0.10477280616760254, 0.11697268486022949, 0.12917256355285645, 0.14137250185012817, 0.15357238054275513, 0.16577231884002686, 0.1779721975326538, 0.19017213582992554, 0.2023720145225525, 0.21457195281982422, 0.22677183151245117]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.17572320997714996, -0.15531767904758453, -0.1349121332168579, -0.11450660228729248, -0.09410107135772705, -0.07369554042816162, -0.053290002048015594, -0.03288446366786957, -0.012478932738304138, 0.007926598191261292, 0.02833212912082672, 0.048737674951553345, 0.06914320588111877, 0.0895487517118454, 0.10995428264141083, 0.13035981357097626, 0.1507653445005417, 0.17117087543010712, 0.19157640635967255, 0.21198193728923798, 0.2323874682188034, 0.25279301404953003, 0.27319854497909546, 0.2936040759086609, 0.3140096068382263, 0.3344151973724365, 0.35482072830200195, 0.3752262592315674, 0.3956317901611328, 0.41603732109069824, 0.43644285202026367, 0.4568483829498291, 0.47725391387939453, 0.49765944480895996, 0.5180649757385254, 0.5384705066680908, 0.5588760375976562, 0.5792815685272217, 0.5996870994567871, 0.6200926303863525, 0.640498161315918, 0.6609037518501282, 0.6813092827796936, 0.701714813709259, 0.7221203446388245, 0.7425258755683899, 0.7629314064979553, 0.7833369374275208, 0.8037424683570862, 0.8241479992866516, 0.8445535898208618, 0.8649591207504272, 0.8853646516799927, 0.9057701826095581, 0.9261757135391235, 0.946581244468689, 0.9669867753982544, 0.9873923063278198, 1.0077978372573853, 1.0282033681869507, 1.0486088991165161, 1.0690144300460815, 1.089419960975647, 1.1098254919052124, 1.1302310228347778]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 4.0, 3.0, 4.0, 3.0, 2.0, 0.0, 1.0, 6.0, 2.0, 4.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0], "bins": [-0.6336357593536377, -0.6183841824531555, -0.6031325459480286, -0.5878809690475464, -0.5726293325424194, -0.5573777556419373, -0.5421261191368103, -0.5268745422363281, -0.5116229057312012, -0.496371328830719, -0.48111972212791443, -0.46586811542510986, -0.4506165385246277, -0.43536490201950073, -0.42011332511901855, -0.404861718416214, -0.3896101117134094, -0.37435850501060486, -0.3591068983078003, -0.3438552916049957, -0.32860368490219116, -0.313352108001709, -0.2981005012989044, -0.28284889459609985, -0.2675972878932953, -0.2523456811904907, -0.23709407448768616, -0.2218424677848816, -0.20659089088439941, -0.19133928418159485, -0.17608767747879028, -0.16083607077598572, -0.14558446407318115, -0.13033288717269897, -0.11508125066757202, -0.09982967376708984, -0.08457803726196289, -0.06932646036148071, -0.05407482385635376, -0.03882324695587158, -0.02357161045074463, -0.008320033550262451, 0.0069315433502197266, 0.02218317985534668, 0.03743475675582886, 0.05268639326095581, 0.06793797016143799, 0.08318960666656494, 0.09844118356704712, 0.1136927604675293, 0.12894439697265625, 0.14419597387313843, 0.15944761037826538, 0.17469918727874756, 0.1899508237838745, 0.2052024006843567, 0.22045397758483887, 0.23570561408996582, 0.250957190990448, 0.26620882749557495, 0.28146040439605713, 0.2967120409011841, 0.31196361780166626, 0.3272152543067932, 0.3424668312072754]}, "_runtime": 8606.798856973648, "_timestamp": 1585517685.2195866, "_step": 298}
{"Episode reward": -99.14933877321212, "Episode length": 999, "Policy Loss": -1.0055063962936401, "Value Loss": 0.07248837500810623, "_runtime": 8608.372040987015, "_timestamp": 1585517686.7927706, "_step": 299}
{"Episode reward": -98.01066153033304, "Episode length": 999, "Policy Loss": -0.7511561512947083, "Value Loss": 0.06847407668828964, "_runtime": 8609.950848817825, "_timestamp": 1585517688.3715785, "_step": 300}
{"Episode reward": -97.98557854133846, "Episode length": 999, "Policy Loss": -0.6356807947158813, "Value Loss": 0.12426069378852844, "_runtime": 8611.502052783966, "_timestamp": 1585517689.9227824, "_step": 301}
{"Episode reward": -99.32961676991235, "Episode length": 999, "Policy Loss": -0.8814360499382019, "Value Loss": 0.04053933918476105, "_runtime": 8613.07566332817, "_timestamp": 1585517691.496393, "_step": 302}
{"Episode reward": -98.76820576286441, "Episode length": 999, "Policy Loss": -0.7292709946632385, "Value Loss": 0.0723896473646164, "_runtime": 8614.663036108017, "_timestamp": 1585517693.0837657, "_step": 303}
{"Episode reward": -98.87487064119863, "Episode length": 999, "Policy Loss": -0.7592511773109436, "Value Loss": 0.10628513246774673, "_runtime": 8616.232108831406, "_timestamp": 1585517694.6528385, "_step": 304}
{"Episode reward": -99.50012947405249, "Episode length": 999, "Policy Loss": -0.670777440071106, "Value Loss": 0.029388409107923508, "_runtime": 8617.80555820465, "_timestamp": 1585517696.2262878, "_step": 305}
{"Episode reward": -98.36064523996482, "Episode length": 999, "Policy Loss": -0.5015982985496521, "Value Loss": 0.07225096225738525, "_runtime": 8619.395821809769, "_timestamp": 1585517697.8165514, "_step": 306}
{"Episode reward": -99.5544884375763, "Episode length": 999, "Policy Loss": -0.5225355625152588, "Value Loss": 0.012496110051870346, "_runtime": 8620.96848487854, "_timestamp": 1585517699.3892145, "_step": 307}
{"Episode reward": -99.22533110176182, "Episode length": 999, "Policy Loss": -0.437533974647522, "Value Loss": 0.021802181378006935, "_runtime": 8622.579596996307, "_timestamp": 1585517701.0003266, "_step": 308}
{"Episode reward": -99.13734993157139, "Episode length": 999, "Policy Loss": -0.2492130994796753, "Value Loss": 0.03677397593855858, "_runtime": 8623.852317094803, "_timestamp": 1585517702.2730467, "_step": 309}
{"Episode reward": 21.288771672305643, "Episode length": 798, "Policy Loss": 0.4964868426322937, "Value Loss": 12.329888343811035, "_runtime": 8625.429876089096, "_timestamp": 1585517703.8506057, "_step": 310}
{"Episode reward": -99.37616720693245, "Episode length": 999, "Policy Loss": -0.308409184217453, "Value Loss": 0.05509086325764656, "_runtime": 8627.014842033386, "_timestamp": 1585517705.4355717, "_step": 311}
{"Episode reward": -99.01664472200939, "Episode length": 999, "Policy Loss": -0.1749582290649414, "Value Loss": 0.01673136092722416, "_runtime": 8628.577333211899, "_timestamp": 1585517706.9980628, "_step": 312}
{"Episode reward": -98.21424096108831, "Episode length": 999, "Policy Loss": -0.05879900977015495, "Value Loss": 0.024611767381429672, "_runtime": 8630.157532930374, "_timestamp": 1585517708.5782626, "_step": 313}
{"Episode reward": -98.1449114804785, "Episode length": 999, "Policy Loss": -0.11501707881689072, "Value Loss": 0.036582812666893005, "_runtime": 8631.27625966072, "_timestamp": 1585517709.6969893, "_step": 314}
{"Episode reward": 30.51538141930766, "Episode length": 704, "Policy Loss": 0.7708970904350281, "Value Loss": 14.065112113952637, "_runtime": 8632.860544681549, "_timestamp": 1585517711.2812743, "_step": 315}
{"Episode reward": -99.01061668702215, "Episode length": 999, "Policy Loss": -0.09443627297878265, "Value Loss": 0.02295270934700966, "_runtime": 8633.934759140015, "_timestamp": 1585517712.3554888, "_step": 316}
{"Episode reward": 33.3024259722843, "Episode length": 673, "Policy Loss": 0.8719435334205627, "Value Loss": 14.672822952270508, "_runtime": 8634.808370351791, "_timestamp": 1585517713.2291, "_step": 317}
{"Episode reward": 45.0221225318583, "Episode length": 553, "Policy Loss": 1.127107858657837, "Value Loss": 17.86016082763672, "_runtime": 8635.548674821854, "_timestamp": 1585517713.9694045, "_step": 318}
{"Episode reward": 55.02219150334864, "Episode length": 454, "Policy Loss": 1.388362169265747, "Value Loss": 21.687183380126953, "_runtime": 8637.102167606354, "_timestamp": 1585517715.5228972, "_step": 319}
{"Episode reward": -99.30741513536299, "Episode length": 999, "Policy Loss": -0.09024617820978165, "Value Loss": 0.033665306866168976, "_runtime": 8638.623834609985, "_timestamp": 1585517717.0445642, "_step": 320}
{"Episode reward": -99.50487397097314, "Episode length": 999, "Policy Loss": -0.06235305964946747, "Value Loss": 0.007781005930155516, "_runtime": 8639.766382694244, "_timestamp": 1585517718.1871123, "_step": 321}
{"Episode reward": 26.24587839357217, "Episode length": 752, "Policy Loss": 0.8358166217803955, "Value Loss": 13.131796836853027, "_runtime": 8641.239681005478, "_timestamp": 1585517719.6604106, "_step": 322}
{"Episode reward": 6.5049667394042245, "Episode length": 940, "Policy Loss": 0.6291016936302185, "Value Loss": 10.405728340148926, "_runtime": 8642.513438940048, "_timestamp": 1585517720.9341686, "_step": 323}
{"Episode reward": 19.833084453781666, "Episode length": 812, "Policy Loss": 0.5604365468025208, "Value Loss": 12.199395179748535, "_runtime": 8644.048564195633, "_timestamp": 1585517722.4692938, "_step": 324}
{"Episode reward": -99.37259525681259, "Episode length": 999, "Policy Loss": -0.21833036839962006, "Value Loss": 0.0861906036734581, "_runtime": 8644.911943912506, "_timestamp": 1585517723.3326735, "_step": 325}
{"Episode reward": 46.332856742457146, "Episode length": 543, "Policy Loss": 0.8436630964279175, "Value Loss": 18.12574577331543, "_runtime": 8646.511311531067, "_timestamp": 1585517724.9320412, "_step": 326}
{"Episode reward": -99.28533428660064, "Episode length": 999, "Policy Loss": -0.2815116345882416, "Value Loss": 0.030981557443737984, "_runtime": 8647.51288986206, "_timestamp": 1585517725.9336195, "_step": 327}
{"Episode reward": 37.38255578605126, "Episode length": 631, "Policy Loss": 0.7847746014595032, "Value Loss": 15.514668464660645, "_runtime": 8649.037390470505, "_timestamp": 1585517727.45812, "_step": 328}
{"Episode reward": -99.25473716065474, "Episode length": 999, "Policy Loss": -0.2826017141342163, "Value Loss": 0.014244437217712402, "_runtime": 8649.940338134766, "_timestamp": 1585517728.3610678, "_step": 329}
{"Episode reward": 44.11368731168541, "Episode length": 568, "Policy Loss": 0.7032777667045593, "Value Loss": 17.266956329345703, "_runtime": 8651.181370019913, "_timestamp": 1585517729.6020997, "_step": 330}
{"Episode reward": 20.31013465844117, "Episode length": 807, "Policy Loss": 0.43864646553993225, "Value Loss": 12.196211814880371, "_runtime": 8652.73426580429, "_timestamp": 1585517731.1549954, "_step": 331}
{"Episode reward": -99.5798463624979, "Episode length": 999, "Policy Loss": -0.4169633984565735, "Value Loss": 0.013943895697593689, "_runtime": 8654.25323677063, "_timestamp": 1585517732.6739664, "_step": 332}
{"Episode reward": -99.51705003138176, "Episode length": 999, "Policy Loss": -0.383088618516922, "Value Loss": 0.018100498244166374, "_runtime": 8655.79292178154, "_timestamp": 1585517734.2136514, "_step": 333}
{"Episode reward": -99.5812497976717, "Episode length": 999, "Policy Loss": -0.44065842032432556, "Value Loss": 0.010481997393071651, "_runtime": 8657.352985858917, "_timestamp": 1585517735.7737155, "_step": 334}
{"Episode reward": -99.00971131535296, "Episode length": 999, "Policy Loss": -0.5020803809165955, "Value Loss": 0.056039489805698395, "_runtime": 8658.909156560898, "_timestamp": 1585517737.3298862, "_step": 335}
{"Episode reward": -99.18967852143965, "Episode length": 999, "Policy Loss": -0.4696804881095886, "Value Loss": 0.014328566379845142, "_runtime": 8659.315573453903, "_timestamp": 1585517737.736303, "_step": 336}
{"Episode reward": 77.86340134787943, "Episode length": 225, "Policy Loss": 2.3498337268829346, "Value Loss": 43.27229690551758, "_runtime": 8659.60125041008, "_timestamp": 1585517738.02198, "_step": 337}
{"Episode reward": 85.24615155229367, "Episode length": 151, "Policy Loss": 3.5575528144836426, "Value Loss": 64.75302124023438, "_runtime": 8661.155542850494, "_timestamp": 1585517739.5762725, "_step": 338}
{"Episode reward": -99.53824138725228, "Episode length": 999, "Policy Loss": -0.5417781472206116, "Value Loss": 0.05323311686515808, "_runtime": 8662.646011352539, "_timestamp": 1585517741.066741, "_step": 339}
{"Episode reward": -99.41583158037653, "Episode length": 999, "Policy Loss": -0.6987413763999939, "Value Loss": 0.11626850813627243, "_runtime": 8664.12270951271, "_timestamp": 1585517742.5434391, "_step": 340}
{"Episode reward": -98.9794166527676, "Episode length": 999, "Policy Loss": -0.6239447593688965, "Value Loss": 0.1835058629512787, "_runtime": 8664.949079036713, "_timestamp": 1585517743.3698087, "_step": 341}
{"Episode reward": 49.44125987735919, "Episode length": 512, "Policy Loss": 0.605133056640625, "Value Loss": 18.910930633544922, "_runtime": 8666.502204179764, "_timestamp": 1585517744.9229338, "_step": 342}
{"Episode reward": -98.66739369950226, "Episode length": 999, "Policy Loss": -0.7375364303588867, "Value Loss": 0.21695026755332947, "_runtime": 8667.495241165161, "_timestamp": 1585517745.9159708, "_step": 343}
{"Episode reward": 35.71624446447491, "Episode length": 647, "Policy Loss": 0.13789716362953186, "Value Loss": 15.083824157714844, "_runtime": 8668.109055757523, "_timestamp": 1585517746.5297854, "_step": 344}
{"Episode reward": 60.12166875996143, "Episode length": 402, "Policy Loss": 0.736167848110199, "Value Loss": 24.223047256469727, "_runtime": 8668.889879226685, "_timestamp": 1585517747.3106089, "_step": 345}
{"Episode reward": 51.496138119856816, "Episode length": 491, "Policy Loss": 0.5984579920768738, "Value Loss": 19.890094757080078, "_runtime": 8670.45636510849, "_timestamp": 1585517748.8770947, "_step": 346}
{"Episode reward": -99.58581809560793, "Episode length": 999, "Policy Loss": -0.7403525710105896, "Value Loss": 0.07786060124635696, "_runtime": 8671.95865726471, "_timestamp": 1585517750.379387, "_step": 347}
{"Episode reward": -99.17379703833305, "Episode length": 999, "Policy Loss": -0.6608172059059143, "Value Loss": 0.27828219532966614, "_runtime": 8672.971722364426, "_timestamp": 1585517751.392452, "_step": 348}
{"Episode reward": 33.19802740346863, "Episode length": 671, "Policy Loss": 0.22764453291893005, "Value Loss": 14.513178825378418, "_runtime": 8674.509275436401, "_timestamp": 1585517752.930005, "_step": 349}
{"Episode reward": -99.45997862874837, "Episode length": 999, "Policy Loss": -0.9021631479263306, "Value Loss": 0.03839312866330147, "_runtime": 8676.045581817627, "_timestamp": 1585517754.4663115, "_step": 350}
{"Episode reward": -99.33987149331298, "Episode length": 999, "Policy Loss": -0.779781699180603, "Value Loss": 0.05328470468521118, "_runtime": 8677.570001840591, "_timestamp": 1585517755.9907315, "_step": 351}
{"Episode reward": -99.7156657916488, "Episode length": 999, "Policy Loss": -0.7997664213180542, "Value Loss": 0.037354882806539536, "_runtime": 8678.78216791153, "_timestamp": 1585517757.2028975, "_step": 352}
{"Episode reward": 22.24376315212149, "Episode length": 783, "Policy Loss": -0.09228143095970154, "Value Loss": 12.42597484588623, "_runtime": 8680.170105218887, "_timestamp": 1585517758.5908349, "_step": 353}
{"Episode reward": 11.690281332713226, "Episode length": 890, "Policy Loss": -0.11189206689596176, "Value Loss": 10.942361831665039, "_runtime": 8681.732068300247, "_timestamp": 1585517760.152798, "_step": 354}
{"Episode reward": -99.05831963771521, "Episode length": 999, "Policy Loss": -0.6492478251457214, "Value Loss": 0.043328676372766495, "_runtime": 8683.281978607178, "_timestamp": 1585517761.7027082, "_step": 355}
{"Episode reward": -99.50416760733148, "Episode length": 999, "Policy Loss": -0.7663060426712036, "Value Loss": 0.027901161462068558, "_runtime": 8684.827858924866, "_timestamp": 1585517763.2485886, "_step": 356}
{"Episode reward": -99.08049616529979, "Episode length": 999, "Policy Loss": -0.6937533617019653, "Value Loss": 0.02309800684452057, "_runtime": 8685.35849070549, "_timestamp": 1585517763.7792203, "_step": 357}
{"Episode reward": 68.92181299849847, "Episode length": 312, "Policy Loss": 1.4016019105911255, "Value Loss": 31.061054229736328, "_runtime": 8686.103123188019, "_timestamp": 1585517764.5238528, "_step": 358}
{"Episode reward": 54.0520354894588, "Episode length": 465, "Policy Loss": 0.6391597390174866, "Value Loss": 20.581769943237305, "_runtime": 8686.991594552994, "_timestamp": 1585517765.4123242, "_step": 359}
{"Episode reward": 44.68644282774566, "Episode length": 561, "Policy Loss": 0.5545263886451721, "Value Loss": 17.203161239624023, "_runtime": 8688.504611253738, "_timestamp": 1585517766.925341, "_step": 360}
{"Episode reward": -98.7064282784297, "Episode length": 999, "Policy Loss": -0.6235734820365906, "Value Loss": 0.3478115200996399, "_runtime": 8690.01422548294, "_timestamp": 1585517768.4349551, "_step": 361}
{"Episode reward": -99.38728562010402, "Episode length": 999, "Policy Loss": -0.6068071126937866, "Value Loss": 0.12231557816267014, "_runtime": 8691.08882856369, "_timestamp": 1585517769.5095582, "_step": 362}
{"Episode reward": 30.665327938093256, "Episode length": 704, "Policy Loss": 0.5099190473556519, "Value Loss": 13.795281410217285, "_runtime": 8692.488565206528, "_timestamp": 1585517770.9092948, "_step": 363}
{"Episode reward": 10.950764744346444, "Episode length": 903, "Policy Loss": 0.18908657133579254, "Value Loss": 10.725510597229004, "_runtime": 8694.07513833046, "_timestamp": 1585517772.495868, "_step": 364}
{"Episode reward": -98.63890072149374, "Episode length": 999, "Policy Loss": -0.4838925004005432, "Value Loss": 0.0783270001411438, "_runtime": 8695.603093147278, "_timestamp": 1585517774.0238228, "_step": 365}
{"Episode reward": -98.90853060848754, "Episode length": 999, "Policy Loss": -0.5859470367431641, "Value Loss": 0.20281121134757996, "_runtime": 8697.155004739761, "_timestamp": 1585517775.5757344, "_step": 366}
{"Episode reward": -99.70223048380437, "Episode length": 999, "Policy Loss": -0.5351366400718689, "Value Loss": 0.017887940630316734, "_runtime": 8698.719527721405, "_timestamp": 1585517777.1402574, "_step": 367}
{"Episode reward": -98.41733460773807, "Episode length": 999, "Policy Loss": -0.5027564167976379, "Value Loss": 0.16308680176734924, "_runtime": 8700.281831026077, "_timestamp": 1585517778.7025607, "_step": 368}
{"Episode reward": -99.43560348133535, "Episode length": 999, "Policy Loss": -0.5059089064598083, "Value Loss": 0.025288840755820274, "_runtime": 8701.838303565979, "_timestamp": 1585517780.2590332, "_step": 369}
{"Episode reward": -98.4976726231224, "Episode length": 999, "Policy Loss": -0.4287731647491455, "Value Loss": 0.12948651611804962, "_runtime": 8702.833898305893, "_timestamp": 1585517781.254628, "_step": 370}
{"Episode reward": 38.029013619821924, "Episode length": 627, "Policy Loss": 0.6126195192337036, "Value Loss": 15.598846435546875, "_runtime": 8704.39800620079, "_timestamp": 1585517782.8187358, "_step": 371}
{"Episode reward": -99.6296021901765, "Episode length": 999, "Policy Loss": -0.3911009430885315, "Value Loss": 0.009013543836772442, "_runtime": 8705.966680765152, "_timestamp": 1585517784.3874104, "_step": 372}
{"Episode reward": -99.0962244758686, "Episode length": 999, "Policy Loss": -0.3558097183704376, "Value Loss": 0.03529076278209686, "_runtime": 8707.495361328125, "_timestamp": 1585517785.916091, "_step": 373}
{"Episode reward": -98.88331791615911, "Episode length": 999, "Policy Loss": -0.2414621114730835, "Value Loss": 0.04005017131567001, "_runtime": 8709.054351329803, "_timestamp": 1585517787.475081, "_step": 374}
{"Episode reward": -99.3251451554136, "Episode length": 999, "Policy Loss": -0.307926744222641, "Value Loss": 0.07349850982427597, "_runtime": 8710.620735645294, "_timestamp": 1585517789.0414653, "_step": 375}
{"Episode reward": -98.50763107336076, "Episode length": 999, "Policy Loss": -0.2644727826118469, "Value Loss": 0.031528767198324203, "_runtime": 8712.010811328888, "_timestamp": 1585517790.431541, "_step": 376}
{"Episode reward": 12.09890511683841, "Episode length": 888, "Policy Loss": 0.7639122605323792, "Value Loss": 11.122859954833984, "_runtime": 8713.579372406006, "_timestamp": 1585517792.000102, "_step": 377}
{"Episode reward": -99.07290154434038, "Episode length": 999, "Policy Loss": -0.10826264321804047, "Value Loss": 0.035720936954021454, "_runtime": 8714.243052005768, "_timestamp": 1585517792.6637816, "_step": 378}
{"Episode reward": 60.551982133100374, "Episode length": 405, "Policy Loss": 1.6722091436386108, "Value Loss": 24.246776580810547, "_runtime": 8715.793902873993, "_timestamp": 1585517794.2146325, "_step": 379}
{"Episode reward": -98.84861271251448, "Episode length": 999, "Policy Loss": -0.18675293028354645, "Value Loss": 0.022564386948943138, "_runtime": 8717.397505760193, "_timestamp": 1585517795.8182354, "_step": 380}
{"Episode reward": -98.81936225397128, "Episode length": 999, "Policy Loss": -0.18244482576847076, "Value Loss": 0.013097669929265976, "_runtime": 8717.990904092789, "_timestamp": 1585517796.4116337, "_step": 381}
{"Episode reward": 62.00185647813655, "Episode length": 388, "Policy Loss": 1.4544597864151, "Value Loss": 25.16216468811035, "_runtime": 8719.545228719711, "_timestamp": 1585517797.9659584, "_step": 382}
{"Episode reward": -99.39026176847737, "Episode length": 999, "Policy Loss": -0.24131596088409424, "Value Loss": 0.005853703711181879, "_runtime": 8721.102382183075, "_timestamp": 1585517799.5231118, "_step": 383}
{"Episode reward": -99.35745755574546, "Episode length": 999, "Policy Loss": -0.2380802035331726, "Value Loss": 0.012317268177866936, "_runtime": 8722.600048542023, "_timestamp": 1585517801.0207782, "_step": 384}
{"Episode reward": -99.15153068207499, "Episode length": 999, "Policy Loss": -0.26671791076660156, "Value Loss": 0.032412271946668625, "_runtime": 8724.166046380997, "_timestamp": 1585517802.586776, "_step": 385}
{"Episode reward": -99.2768680581857, "Episode length": 999, "Policy Loss": -0.23196284472942352, "Value Loss": 0.0270824171602726, "_runtime": 8725.736891508102, "_timestamp": 1585517804.1576211, "_step": 386}
{"Episode reward": -98.8910273408144, "Episode length": 999, "Policy Loss": -0.21284939348697662, "Value Loss": 0.02922256663441658, "_runtime": 8727.285096168518, "_timestamp": 1585517805.7058258, "_step": 387}
{"Episode reward": -99.08118655607642, "Episode length": 999, "Policy Loss": -0.2901352047920227, "Value Loss": 0.030550582334399223, "_runtime": 8728.128279685974, "_timestamp": 1585517806.5490093, "_step": 388}
{"Episode reward": 47.80526012687541, "Episode length": 523, "Policy Loss": 0.9309872984886169, "Value Loss": 18.396316528320312, "_runtime": 8729.314250946045, "_timestamp": 1585517807.7349806, "_step": 389}
{"Episode reward": 25.59628959492599, "Episode length": 757, "Policy Loss": 0.4769909679889679, "Value Loss": 12.870291709899902, "_runtime": 8730.870187997818, "_timestamp": 1585517809.2909176, "_step": 390}
{"Episode reward": -98.84142691918298, "Episode length": 999, "Policy Loss": -0.3053346574306488, "Value Loss": 0.07276641577482224, "_runtime": 8731.857051372528, "_timestamp": 1585517810.277781, "_step": 391}
{"Episode reward": 36.746453279360104, "Episode length": 645, "Policy Loss": 0.3483448624610901, "Value Loss": 15.15705394744873, "_runtime": 8733.405864238739, "_timestamp": 1585517811.8265939, "_step": 392}
{"Episode reward": -99.44483129301214, "Episode length": 999, "Policy Loss": -0.305986613035202, "Value Loss": 0.03882425278425217, "_runtime": 8734.956463336945, "_timestamp": 1585517813.377193, "_step": 393}
{"Episode reward": -99.03941201058302, "Episode length": 999, "Policy Loss": -0.26868581771850586, "Value Loss": 0.08768671751022339, "_runtime": 8736.482820034027, "_timestamp": 1585517814.9035497, "_step": 394}
{"Episode reward": -99.16602198185211, "Episode length": 999, "Policy Loss": -0.19420166313648224, "Value Loss": 0.10385826230049133, "_runtime": 8738.046575069427, "_timestamp": 1585517816.4673047, "_step": 395}
{"Episode reward": -99.4572557830351, "Episode length": 999, "Policy Loss": -0.2970040440559387, "Value Loss": 0.034585222601890564, "_runtime": 8739.610521316528, "_timestamp": 1585517818.031251, "_step": 396}
{"Episode reward": -99.83293439518789, "Episode length": 999, "Policy Loss": -0.2597842216491699, "Value Loss": 0.011486299335956573, "_runtime": 8741.209291696548, "_timestamp": 1585517819.6300213, "_step": 397}
{"Episode reward": -99.02813267876603, "Episode length": 999, "Policy Loss": -0.29695335030555725, "Value Loss": 0.07916528731584549, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271, -0.2230023294687271]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0], "bins": [-4.519343852996826, -4.445163726806641, -4.370983600616455, -4.2968034744262695, -4.222622871398926, -4.14844274520874, -4.074262619018555, -4.000082492828369, -3.9259023666381836, -3.851722002029419, -3.7775418758392334, -3.7033615112304688, -3.629181385040283, -3.5550012588500977, -3.480821132659912, -3.4066410064697266, -3.332460641860962, -3.2582802772521973, -3.1841001510620117, -3.109920024871826, -3.0357398986816406, -2.961559772491455, -2.8873794078826904, -2.813199281692505, -2.7390189170837402, -2.6648387908935547, -2.590658664703369, -2.5164785385131836, -2.442298173904419, -2.3681180477142334, -2.293937921524048, -2.219757556915283, -2.1455774307250977, -2.071397304534912, -1.9972169399261475, -1.923036813735962, -1.8488566875457764, -1.7746763229370117, -1.7004961967468262, -1.6263160705566406, -1.552135944366455, -1.4779555797576904, -1.4037754535675049, -1.3295953273773193, -1.2554149627685547, -1.1812348365783691, -1.1070547103881836, -1.032874345779419, -0.9586942195892334, -0.8845140933990479, -0.8103337287902832, -0.7361536026000977, -0.6619734764099121, -0.5877931118011475, -0.513613224029541, -0.43943262100219727, -0.3652524948120117, -0.29107236862182617, -0.21689224243164062, -0.14271211624145508, -0.06853199005126953, 0.005648612976074219, 0.07982873916625977, 0.1540088653564453, 0.22818899154663086]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4149613082408905, -0.4072500765323639, -0.39953887462615967, -0.39182764291763306, -0.38411644101142883, -0.3764052093029022, -0.368694007396698, -0.3609827756881714, -0.3532715439796448, -0.34556034207344055, -0.33784911036491394, -0.3301379084587097, -0.3224266767501831, -0.3147154450416565, -0.30700424313545227, -0.29929301142692566, -0.29158180952072144, -0.2838705778121948, -0.2761593461036682, -0.268448144197464, -0.26073694229125977, -0.25302571058273315, -0.24531449377536774, -0.23760326206684113, -0.2298920452594757, -0.2221808284521103, -0.21446961164474487, -0.20675839483737946, -0.19904717803001404, -0.19133594632148743, -0.183624729514122, -0.1759135127067566, -0.16820229589939117, -0.16049107909202576, -0.15277984738349915, -0.14506864547729492, -0.1373574137687683, -0.1296462118625641, -0.12193498015403748, -0.11422374844551086, -0.10651254653930664, -0.09880131483078003, -0.0910901129245758, -0.0833788812160492, -0.07566767930984497, -0.06795644760131836, -0.06024521589279175, -0.052534013986587524, -0.04482278227806091, -0.03711158037185669, -0.029400348663330078, -0.021689146757125854, -0.013977915048599243, -0.006266683340072632, 0.0014445185661315918, 0.009155750274658203, 0.016866952180862427, 0.024578183889389038, 0.03228941559791565, 0.04000061750411987, 0.047711849212646484, 0.05542305111885071, 0.06313428282737732, 0.07084548473358154, 0.07855671644210815]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 5.0, 2.0, 3.0, 6.0, 3.0, 8.0, 20.0, 26.0, 21.0, 28.0, 18.0, 192.0, 28.0, 73.0, 24.0, 5.0, 15.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.4840797781944275, -0.4718838334083557, -0.45968788862228394, -0.44749194383621216, -0.4352959990501404, -0.4231000542640686, -0.4109041094779968, -0.39870816469192505, -0.38651221990585327, -0.3743162751197815, -0.3621203303337097, -0.34992438554763794, -0.3377284109592438, -0.325532466173172, -0.3133365213871002, -0.30114057660102844, -0.28894463181495667, -0.2767486870288849, -0.2645527422428131, -0.25235679745674133, -0.24016085267066956, -0.22796490788459778, -0.215768963098526, -0.20357301831245422, -0.19137704372406006, -0.17918109893798828, -0.1669851541519165, -0.15478920936584473, -0.14259326457977295, -0.13039731979370117, -0.1182013750076294, -0.10600543022155762, -0.09380948543548584, -0.08161354064941406, -0.06941759586334229, -0.05722165107727051, -0.04502570629119873, -0.03282976150512695, -0.020633816719055176, -0.008437871932983398, 0.003758072853088379, 0.015954017639160156, 0.028149962425231934, 0.04034590721130371, 0.05254185199737549, 0.06473779678344727, 0.07693374156951904, 0.08912968635559082, 0.10132569074630737, 0.11352163553237915, 0.12571758031845093, 0.1379135251045227, 0.15010946989059448, 0.16230541467666626, 0.17450135946273804, 0.18669730424880981, 0.1988932490348816, 0.21108919382095337, 0.22328513860702515, 0.23548108339309692, 0.2476770281791687, 0.2598729729652405, 0.27206891775131226, 0.28426486253738403, 0.2964608073234558]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3923259973526, -1.3404632806777954, -1.2886004447937012, -1.2367377281188965, -1.1848750114440918, -1.133012294769287, -1.0811494588851929, -1.0292867422103882, -0.9774239659309387, -0.9255611896514893, -0.8736984729766846, -0.8218356966972351, -0.7699729204177856, -0.718110203742981, -0.6662474274635315, -0.6143847107887268, -0.5625219345092773, -0.5106591582298279, -0.4587964415550232, -0.40693366527557373, -0.35507094860076904, -0.3032081127166748, -0.2513453960418701, -0.19948267936706543, -0.1476198434829712, -0.0957571268081665, -0.043894410133361816, 0.007968306541442871, 0.05983114242553711, 0.1116938591003418, 0.16355657577514648, 0.21541941165924072, 0.2672821283340454, 0.3191448450088501, 0.37100768089294434, 0.422870397567749, 0.4747331142425537, 0.526595950126648, 0.5784586668014526, 0.6303213834762573, 0.682184100151062, 0.7340468168258667, 0.7859097719192505, 0.8377724885940552, 0.8896352052688599, 0.9414979219436646, 0.9933606386184692, 1.045223355293274, 1.0970863103866577, 1.1489490270614624, 1.200811743736267, 1.2526744604110718, 1.3045371770858765, 1.3563998937606812, 1.4082626104354858, 1.4601255655288696, 1.5119882822036743, 1.563850998878479, 1.6157137155532837, 1.6675764322280884, 1.719439148902893, 1.7713021039962769, 1.8231648206710815, 1.8750275373458862, 1.926890254020691]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 5.0, 4.0, 8.0, 1.0, 4.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5660040378570557, -0.5510571002960205, -0.5361101627349854, -0.5211631655693054, -0.5062162280082703, -0.4912692904472351, -0.47632232308387756, -0.46137535572052, -0.44642841815948486, -0.4314814805984497, -0.41653451323509216, -0.4015875458717346, -0.38664060831069946, -0.3716936707496643, -0.35674670338630676, -0.3417997360229492, -0.32685279846191406, -0.3119058609008789, -0.29695889353752136, -0.2820119261741638, -0.26706498861312866, -0.2521180510520935, -0.23717108368873596, -0.22222411632537842, -0.20727717876434326, -0.1923302412033081, -0.17738327383995056, -0.16243630647659302, -0.14748936891555786, -0.1325424313545227, -0.11759546399116516, -0.10264849662780762, -0.08770155906677246, -0.0727546215057373, -0.05780768394470215, -0.04286068677902222, -0.02791374921798706, -0.012966811656951904, 0.0019801855087280273, 0.016927123069763184, 0.03187406063079834, 0.046820998191833496, 0.06176793575286865, 0.07671493291854858, 0.09166187047958374, 0.1066088080406189, 0.12155580520629883, 0.13650274276733398, 0.15144968032836914, 0.1663966178894043, 0.18134355545043945, 0.19629055261611938, 0.21123749017715454, 0.2261844277381897, 0.24113142490386963, 0.2560783624649048, 0.27102530002593994, 0.2859722375869751, 0.30091917514801025, 0.3158661723136902, 0.33081310987472534, 0.3457600474357605, 0.36070704460144043, 0.3756539821624756, 0.39060091972351074]}, "_runtime": 8742.780666828156, "_timestamp": 1585517821.2013965, "_step": 398}
{"Episode reward": -99.26419606596885, "Episode length": 999, "Policy Loss": -0.2627469003200531, "Value Loss": 0.02778235264122486, "_runtime": 8744.349039077759, "_timestamp": 1585517822.7697687, "_step": 399}
{"Episode reward": -99.74841676968941, "Episode length": 999, "Policy Loss": -0.24877861142158508, "Value Loss": 0.004134112969040871, "_runtime": 8745.906425237656, "_timestamp": 1585517824.3271549, "_step": 400}
{"Episode reward": -99.24892854603125, "Episode length": 999, "Policy Loss": -0.23122136294841766, "Value Loss": 0.008075090125203133, "_runtime": 8747.479083538055, "_timestamp": 1585517825.8998132, "_step": 401}
{"Episode reward": -99.56370414549835, "Episode length": 999, "Policy Loss": -0.19534270465373993, "Value Loss": 0.05221742019057274, "_runtime": 8749.048231601715, "_timestamp": 1585517827.4689612, "_step": 402}
{"Episode reward": -98.49918115108356, "Episode length": 999, "Policy Loss": -0.16859348118305206, "Value Loss": 0.05527334660291672, "_runtime": 8749.972235679626, "_timestamp": 1585517828.3929653, "_step": 403}
{"Episode reward": 43.18750902436293, "Episode length": 581, "Policy Loss": 0.8602668642997742, "Value Loss": 16.753870010375977, "_runtime": 8751.53071975708, "_timestamp": 1585517829.9514494, "_step": 404}
{"Episode reward": -99.37711661326426, "Episode length": 999, "Policy Loss": -0.16885200142860413, "Value Loss": 0.033294398337602615, "_runtime": 8753.016838312149, "_timestamp": 1585517831.437568, "_step": 405}
{"Episode reward": 5.966924710448495, "Episode length": 952, "Policy Loss": 0.6282397508621216, "Value Loss": 10.327631950378418, "_runtime": 8754.535159349442, "_timestamp": 1585517832.955889, "_step": 406}
{"Episode reward": -99.0739222406038, "Episode length": 999, "Policy Loss": -0.12715771794319153, "Value Loss": 0.015011594630777836, "_runtime": 8756.09888100624, "_timestamp": 1585517834.5196106, "_step": 407}
{"Episode reward": -99.59847737152022, "Episode length": 999, "Policy Loss": -0.16063691675662994, "Value Loss": 0.0066664135083556175, "_runtime": 8757.665337562561, "_timestamp": 1585517836.0860672, "_step": 408}
{"Episode reward": -99.09146896853932, "Episode length": 999, "Policy Loss": -0.15681202709674835, "Value Loss": 0.015604191459715366, "_runtime": 8759.211683034897, "_timestamp": 1585517837.6324127, "_step": 409}
{"Episode reward": -99.48216882542103, "Episode length": 999, "Policy Loss": -0.14948225021362305, "Value Loss": 0.007275104988366365, "_runtime": 8760.115972995758, "_timestamp": 1585517838.5367026, "_step": 410}
{"Episode reward": 44.60393428951193, "Episode length": 565, "Policy Loss": 0.9684796929359436, "Value Loss": 17.160947799682617, "_runtime": 8761.423501491547, "_timestamp": 1585517839.8442311, "_step": 411}
{"Episode reward": 16.877235521904723, "Episode length": 842, "Policy Loss": 0.7025273442268372, "Value Loss": 11.603622436523438, "_runtime": 8762.720564842224, "_timestamp": 1585517841.1412945, "_step": 412}
{"Episode reward": 18.53233151599109, "Episode length": 826, "Policy Loss": 0.5369513034820557, "Value Loss": 11.869428634643555, "_runtime": 8763.43504858017, "_timestamp": 1585517841.8557782, "_step": 413}
{"Episode reward": 57.6517763203144, "Episode length": 433, "Policy Loss": 1.131581425666809, "Value Loss": 22.387630462646484, "_runtime": 8764.987871170044, "_timestamp": 1585517843.4086008, "_step": 414}
{"Episode reward": -99.72731300513122, "Episode length": 999, "Policy Loss": -0.2089093029499054, "Value Loss": 0.006941342726349831, "_runtime": 8766.539964437485, "_timestamp": 1585517844.960694, "_step": 415}
{"Episode reward": -99.54651087338262, "Episode length": 999, "Policy Loss": -0.23538702726364136, "Value Loss": 0.030553873628377914, "_runtime": 8768.047300100327, "_timestamp": 1585517846.4680297, "_step": 416}
{"Episode reward": -99.43351139181428, "Episode length": 999, "Policy Loss": -0.2827950716018677, "Value Loss": 0.041801631450653076, "_runtime": 8769.61461520195, "_timestamp": 1585517848.0353448, "_step": 417}
{"Episode reward": -98.07693280731706, "Episode length": 999, "Policy Loss": -0.293768972158432, "Value Loss": 0.24342094361782074, "_runtime": 8771.17915892601, "_timestamp": 1585517849.5998886, "_step": 418}
{"Episode reward": -99.20145947019304, "Episode length": 999, "Policy Loss": -0.25541120767593384, "Value Loss": 0.013093664310872555, "_runtime": 8772.651854991913, "_timestamp": 1585517851.0725846, "_step": 419}
{"Episode reward": 5.8078894012105025, "Episode length": 954, "Policy Loss": 0.7887143492698669, "Value Loss": 10.295100212097168, "_runtime": 8774.221157550812, "_timestamp": 1585517852.6418872, "_step": 420}
{"Episode reward": -99.08516493780346, "Episode length": 999, "Policy Loss": -0.28291982412338257, "Value Loss": 0.013596117496490479, "_runtime": 8775.522139787674, "_timestamp": 1585517853.9428694, "_step": 421}
{"Episode reward": 17.734295116341258, "Episode length": 827, "Policy Loss": 0.45355111360549927, "Value Loss": 11.595053672790527, "_runtime": 8776.762047290802, "_timestamp": 1585517855.182777, "_step": 422}
{"Episode reward": 21.24331910616189, "Episode length": 795, "Policy Loss": 0.4449385404586792, "Value Loss": 12.09568977355957, "_runtime": 8777.600680112839, "_timestamp": 1585517856.0214097, "_step": 423}
{"Episode reward": 47.416925047204366, "Episode length": 529, "Policy Loss": 0.7516076564788818, "Value Loss": 18.17897605895996, "_runtime": 8779.153781414032, "_timestamp": 1585517857.574511, "_step": 424}
{"Episode reward": -99.56686882178178, "Episode length": 999, "Policy Loss": -0.28359851241111755, "Value Loss": 0.017038259655237198, "_runtime": 8780.583448886871, "_timestamp": 1585517859.0041785, "_step": 425}
{"Episode reward": 8.441128341054934, "Episode length": 928, "Policy Loss": 0.21519671380519867, "Value Loss": 10.350052833557129, "_runtime": 8782.096602916718, "_timestamp": 1585517860.5173326, "_step": 426}
{"Episode reward": -99.59928133326038, "Episode length": 999, "Policy Loss": -0.38164806365966797, "Value Loss": 0.0070876493118703365, "_runtime": 8782.724018096924, "_timestamp": 1585517861.1447477, "_step": 427}
{"Episode reward": 61.818900681744424, "Episode length": 386, "Policy Loss": 1.1976258754730225, "Value Loss": 24.778274536132812, "_runtime": 8784.262524604797, "_timestamp": 1585517862.6832542, "_step": 428}
{"Episode reward": -98.40845897140089, "Episode length": 999, "Policy Loss": -0.28685206174850464, "Value Loss": 0.04782310873270035, "_runtime": 8785.512711286545, "_timestamp": 1585517863.933441, "_step": 429}
{"Episode reward": 20.427883152004085, "Episode length": 803, "Policy Loss": 0.2905649244785309, "Value Loss": 11.825363159179688, "_runtime": 8786.903430461884, "_timestamp": 1585517865.32416, "_step": 430}
{"Episode reward": 10.70332918716403, "Episode length": 904, "Policy Loss": 0.2459583580493927, "Value Loss": 10.424537658691406, "_runtime": 8787.564929485321, "_timestamp": 1585517865.9856591, "_step": 431}
{"Episode reward": 59.786857940693835, "Episode length": 405, "Policy Loss": 1.2581688165664673, "Value Loss": 23.90142059326172, "_runtime": 8789.108191728592, "_timestamp": 1585517867.5289214, "_step": 432}
{"Episode reward": -98.78182514897404, "Episode length": 999, "Policy Loss": -0.38419821858406067, "Value Loss": 0.20148296654224396, "_runtime": 8790.656137228012, "_timestamp": 1585517869.0768669, "_step": 433}
{"Episode reward": -99.37518234208045, "Episode length": 999, "Policy Loss": -0.43145808577537537, "Value Loss": 0.01575305312871933, "_runtime": 8792.158661603928, "_timestamp": 1585517870.5793912, "_step": 434}
{"Episode reward": -99.35186775649302, "Episode length": 999, "Policy Loss": -0.4174485504627228, "Value Loss": 0.05588917434215546, "_runtime": 8793.730669021606, "_timestamp": 1585517872.1513987, "_step": 435}
{"Episode reward": -98.1894452724072, "Episode length": 999, "Policy Loss": -0.5772504806518555, "Value Loss": 0.30829983949661255, "_runtime": 8795.12714266777, "_timestamp": 1585517873.5478723, "_step": 436}
{"Episode reward": 10.301588420393628, "Episode length": 903, "Policy Loss": 0.1481303572654724, "Value Loss": 10.530274391174316, "_runtime": 8796.674464702606, "_timestamp": 1585517875.0951943, "_step": 437}
{"Episode reward": -99.30065394237361, "Episode length": 999, "Policy Loss": -0.44827955961227417, "Value Loss": 0.009663031436502934, "_runtime": 8797.988123893738, "_timestamp": 1585517876.4088535, "_step": 438}
{"Episode reward": 17.659063894742843, "Episode length": 833, "Policy Loss": 0.34280791878700256, "Value Loss": 11.421353340148926, "_runtime": 8799.533001184464, "_timestamp": 1585517877.9537308, "_step": 439}
{"Episode reward": -99.59598805644875, "Episode length": 999, "Policy Loss": -0.4334114193916321, "Value Loss": 0.015157170593738556, "_runtime": 8801.089164495468, "_timestamp": 1585517879.5098941, "_step": 440}
{"Episode reward": -98.38911951068758, "Episode length": 999, "Policy Loss": -0.32287654280662537, "Value Loss": 0.2603461444377899, "_runtime": 8802.636535167694, "_timestamp": 1585517881.0572648, "_step": 441}
{"Episode reward": -99.1891926351674, "Episode length": 999, "Policy Loss": -0.33580079674720764, "Value Loss": 0.023035399615764618, "_runtime": 8804.187346935272, "_timestamp": 1585517882.6080766, "_step": 442}
{"Episode reward": -99.3856401038994, "Episode length": 999, "Policy Loss": -0.3740811049938202, "Value Loss": 0.016023965552449226, "_runtime": 8805.444435834885, "_timestamp": 1585517883.8651655, "_step": 443}
{"Episode reward": 20.648936525342975, "Episode length": 802, "Policy Loss": 0.4983818829059601, "Value Loss": 11.866464614868164, "_runtime": 8807.00696849823, "_timestamp": 1585517885.4276981, "_step": 444}
{"Episode reward": -99.13575427957839, "Episode length": 999, "Policy Loss": -0.35618850588798523, "Value Loss": 0.012915574014186859, "_runtime": 8808.572452545166, "_timestamp": 1585517886.9931822, "_step": 445}
{"Episode reward": -98.04785382948381, "Episode length": 999, "Policy Loss": -0.19491396844387054, "Value Loss": 0.5333036780357361, "_runtime": 8809.850398778915, "_timestamp": 1585517888.2711284, "_step": 446}
{"Episode reward": 20.225228334626337, "Episode length": 805, "Policy Loss": 0.3944127857685089, "Value Loss": 11.824625968933105, "_runtime": 8811.41456770897, "_timestamp": 1585517889.8352973, "_step": 447}
{"Episode reward": -99.10579496877959, "Episode length": 999, "Policy Loss": -0.22558115422725677, "Value Loss": 0.038123417645692825, "_runtime": 8812.764781475067, "_timestamp": 1585517891.185511, "_step": 448}
{"Episode reward": 14.858734869227817, "Episode length": 866, "Policy Loss": 0.39461734890937805, "Value Loss": 11.007112503051758, "_runtime": 8814.302688121796, "_timestamp": 1585517892.7234178, "_step": 449}
{"Episode reward": -99.37940110162899, "Episode length": 999, "Policy Loss": -0.3145669102668762, "Value Loss": 0.008333156816661358, "_runtime": 8815.850408315659, "_timestamp": 1585517894.271138, "_step": 450}
{"Episode reward": -98.32581777238268, "Episode length": 999, "Policy Loss": -0.27513834834098816, "Value Loss": 0.028669096529483795, "_runtime": 8817.122955799103, "_timestamp": 1585517895.5436854, "_step": 451}
{"Episode reward": 19.868254586854846, "Episode length": 816, "Policy Loss": 0.5918408036231995, "Value Loss": 11.77161693572998, "_runtime": 8818.683040618896, "_timestamp": 1585517897.1037703, "_step": 452}
{"Episode reward": -99.55693309291443, "Episode length": 999, "Policy Loss": -0.29985684156417847, "Value Loss": 0.01191139779984951, "_runtime": 8819.721023797989, "_timestamp": 1585517898.1417534, "_step": 453}
{"Episode reward": 34.9902389785893, "Episode length": 658, "Policy Loss": 0.6623187065124512, "Value Loss": 14.244735717773438, "_runtime": 8821.26295208931, "_timestamp": 1585517899.6836817, "_step": 454}
{"Episode reward": -99.04413048246377, "Episode length": 999, "Policy Loss": -0.2784785330295563, "Value Loss": 0.11890741437673569, "_runtime": 8822.351220369339, "_timestamp": 1585517900.77195, "_step": 455}
{"Episode reward": 32.44764467444887, "Episode length": 689, "Policy Loss": 0.6900333762168884, "Value Loss": 13.753173828125, "_runtime": 8823.57041144371, "_timestamp": 1585517901.991141, "_step": 456}
{"Episode reward": 22.42028274004042, "Episode length": 789, "Policy Loss": 0.6329888701438904, "Value Loss": 12.550881385803223, "_runtime": 8825.132325410843, "_timestamp": 1585517903.553055, "_step": 457}
{"Episode reward": -98.43216041574047, "Episode length": 999, "Policy Loss": -0.296714186668396, "Value Loss": 0.16252963244915009, "_runtime": 8825.797470092773, "_timestamp": 1585517904.2181997, "_step": 458}
{"Episode reward": 58.515521347308706, "Episode length": 418, "Policy Loss": 1.0273381471633911, "Value Loss": 23.156219482421875, "_runtime": 8826.967654705048, "_timestamp": 1585517905.3883843, "_step": 459}
{"Episode reward": 24.72786707928026, "Episode length": 757, "Policy Loss": 0.6067799925804138, "Value Loss": 12.62346363067627, "_runtime": 8827.673315048218, "_timestamp": 1585517906.0940447, "_step": 460}
{"Episode reward": 56.729759961774654, "Episode length": 438, "Policy Loss": 1.1688226461410522, "Value Loss": 22.25583839416504, "_runtime": 8829.191010475159, "_timestamp": 1585517907.61174, "_step": 461}
{"Episode reward": -99.27544426682438, "Episode length": 999, "Policy Loss": -0.34530219435691833, "Value Loss": 0.009667630307376385, "_runtime": 8830.142855882645, "_timestamp": 1585517908.5635855, "_step": 462}
{"Episode reward": 40.649500049108454, "Episode length": 605, "Policy Loss": 0.6022117137908936, "Value Loss": 15.886579513549805, "_runtime": 8831.647626399994, "_timestamp": 1585517910.068356, "_step": 463}
{"Episode reward": -99.39063502259734, "Episode length": 999, "Policy Loss": -0.44850999116897583, "Value Loss": 0.011531569063663483, "_runtime": 8833.202881336212, "_timestamp": 1585517911.623611, "_step": 464}
{"Episode reward": -99.12579349473098, "Episode length": 999, "Policy Loss": -0.48739346861839294, "Value Loss": 0.008531413041055202, "_runtime": 8834.760507106781, "_timestamp": 1585517913.1812367, "_step": 465}
{"Episode reward": -98.41551664176438, "Episode length": 999, "Policy Loss": -0.3597351610660553, "Value Loss": 0.03261122480034828, "_runtime": 8836.197365045547, "_timestamp": 1585517914.6180947, "_step": 466}
{"Episode reward": 9.787803611525604, "Episode length": 921, "Policy Loss": 0.2944197654724121, "Value Loss": 10.455232620239258, "_runtime": 8837.761586427689, "_timestamp": 1585517916.182316, "_step": 467}
{"Episode reward": -98.9607705154446, "Episode length": 999, "Policy Loss": -0.4815421998500824, "Value Loss": 0.01476670615375042, "_runtime": 8839.149693965912, "_timestamp": 1585517917.5704236, "_step": 468}
{"Episode reward": 12.59111811073565, "Episode length": 887, "Policy Loss": 0.15677614510059357, "Value Loss": 10.822006225585938, "_runtime": 8840.703999042511, "_timestamp": 1585517919.1247287, "_step": 469}
{"Episode reward": -99.6087634523431, "Episode length": 999, "Policy Loss": -0.49957841634750366, "Value Loss": 0.01104969996958971, "_runtime": 8842.270049571991, "_timestamp": 1585517920.6907792, "_step": 470}
{"Episode reward": -99.2931477847988, "Episode length": 999, "Policy Loss": -0.48019734025001526, "Value Loss": 0.019555259495973587, "_runtime": 8843.538882255554, "_timestamp": 1585517921.959612, "_step": 471}
{"Episode reward": 20.225677499354788, "Episode length": 817, "Policy Loss": 0.46098944544792175, "Value Loss": 11.758821487426758, "_runtime": 8844.459436416626, "_timestamp": 1585517922.880166, "_step": 472}
{"Episode reward": 42.772933334714175, "Episode length": 579, "Policy Loss": 0.6074545383453369, "Value Loss": 16.608652114868164, "_runtime": 8846.018381118774, "_timestamp": 1585517924.4391108, "_step": 473}
{"Episode reward": -98.4905966666847, "Episode length": 999, "Policy Loss": -0.44197842478752136, "Value Loss": 0.01588466763496399, "_runtime": 8846.654534816742, "_timestamp": 1585517925.0752645, "_step": 474}
{"Episode reward": 61.51402202327077, "Episode length": 392, "Policy Loss": 1.5513149499893188, "Value Loss": 24.30683708190918, "_runtime": 8847.114874601364, "_timestamp": 1585517925.5356042, "_step": 475}
{"Episode reward": 71.50442521227663, "Episode length": 292, "Policy Loss": 1.62808358669281, "Value Loss": 32.04762268066406, "_runtime": 8848.147702932358, "_timestamp": 1585517926.5684326, "_step": 476}
{"Episode reward": 34.29362314904658, "Episode length": 665, "Policy Loss": 0.41842225193977356, "Value Loss": 14.215007781982422, "_runtime": 8849.665580749512, "_timestamp": 1585517928.0863104, "_step": 477}
{"Episode reward": -99.59021062949469, "Episode length": 999, "Policy Loss": -0.48345863819122314, "Value Loss": 0.02149927243590355, "_runtime": 8851.150774002075, "_timestamp": 1585517929.5715036, "_step": 478}
{"Episode reward": -99.53645237340979, "Episode length": 999, "Policy Loss": -0.5214521884918213, "Value Loss": 0.02072381228208542, "_runtime": 8852.131799221039, "_timestamp": 1585517930.5525289, "_step": 479}
{"Episode reward": 37.499569590368466, "Episode length": 632, "Policy Loss": 0.2867012619972229, "Value Loss": 15.000616073608398, "_runtime": 8853.673962116241, "_timestamp": 1585517932.0946918, "_step": 480}
{"Episode reward": -98.5667210521822, "Episode length": 999, "Policy Loss": -0.4745478630065918, "Value Loss": 0.5205003619194031, "_runtime": 8855.205375909805, "_timestamp": 1585517933.6261055, "_step": 481}
{"Episode reward": -99.62994248664334, "Episode length": 999, "Policy Loss": -0.5564571022987366, "Value Loss": 0.023709218949079514, "_runtime": 8856.070538043976, "_timestamp": 1585517934.4912677, "_step": 482}
{"Episode reward": 44.79796305389529, "Episode length": 556, "Policy Loss": 0.41872769594192505, "Value Loss": 17.87651252746582, "_runtime": 8856.707164049149, "_timestamp": 1585517935.1278937, "_step": 483}
{"Episode reward": 60.611627629877724, "Episode length": 400, "Policy Loss": 0.727816104888916, "Value Loss": 23.78997230529785, "_runtime": 8858.27988910675, "_timestamp": 1585517936.7006187, "_step": 484}
{"Episode reward": -98.91926113317362, "Episode length": 999, "Policy Loss": -0.5941753387451172, "Value Loss": 0.7304643392562866, "_runtime": 8859.789251804352, "_timestamp": 1585517938.2099814, "_step": 485}
{"Episode reward": -99.6219778747514, "Episode length": 999, "Policy Loss": -0.5369827747344971, "Value Loss": 0.011079822666943073, "_runtime": 8861.286951065063, "_timestamp": 1585517939.7076807, "_step": 486}
{"Episode reward": -99.28743463614813, "Episode length": 999, "Policy Loss": -0.5205233693122864, "Value Loss": 0.012835728004574776, "_runtime": 8861.928368091583, "_timestamp": 1585517940.3490977, "_step": 487}
{"Episode reward": 61.08561297869434, "Episode length": 397, "Policy Loss": 1.0883160829544067, "Value Loss": 24.036439895629883, "_runtime": 8862.76685166359, "_timestamp": 1585517941.1875813, "_step": 488}
{"Episode reward": 47.29914018184955, "Episode length": 533, "Policy Loss": 0.8229692578315735, "Value Loss": 17.88728904724121, "_runtime": 8864.086917161942, "_timestamp": 1585517942.5076468, "_step": 489}
{"Episode reward": 15.302283453841156, "Episode length": 857, "Policy Loss": 0.29976508021354675, "Value Loss": 11.03754997253418, "_runtime": 8865.090800523758, "_timestamp": 1585517943.5115302, "_step": 490}
{"Episode reward": 35.03686017267343, "Episode length": 663, "Policy Loss": 0.3675180971622467, "Value Loss": 14.309778213500977, "_runtime": 8866.60262298584, "_timestamp": 1585517945.0233526, "_step": 491}
{"Episode reward": -99.14668385452539, "Episode length": 999, "Policy Loss": -0.5633637309074402, "Value Loss": 0.09189580380916595, "_runtime": 8868.14997267723, "_timestamp": 1585517946.5707023, "_step": 492}
{"Episode reward": -99.36673975471491, "Episode length": 999, "Policy Loss": -0.568017303943634, "Value Loss": 0.0269615538418293, "_runtime": 8869.660514831543, "_timestamp": 1585517948.0812445, "_step": 493}
{"Episode reward": -99.30638891735529, "Episode length": 999, "Policy Loss": -0.5071591138839722, "Value Loss": 0.0380762554705143, "_runtime": 8870.191708087921, "_timestamp": 1585517948.6124377, "_step": 494}
{"Episode reward": 69.02862138092482, "Episode length": 316, "Policy Loss": 1.495003581047058, "Value Loss": 29.632862091064453, "_runtime": 8871.736659526825, "_timestamp": 1585517950.1573892, "_step": 495}
{"Episode reward": -99.48214998145356, "Episode length": 999, "Policy Loss": -0.6100696325302124, "Value Loss": 0.013133800588548183, "_runtime": 8873.29352426529, "_timestamp": 1585517951.714254, "_step": 496}
{"Episode reward": -98.49629085094683, "Episode length": 999, "Policy Loss": -0.4683752655982971, "Value Loss": 0.12619073688983917, "_runtime": 8874.017244815826, "_timestamp": 1585517952.4379745, "_step": 497}
{"Episode reward": 53.0786030596302, "Episode length": 477, "Policy Loss": 1.2331151962280273, "Value Loss": 19.874496459960938, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083, 1.447800874710083]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-17.548381805419922, -16.87273406982422, -16.197086334228516, -15.521439552307129, -14.845792770385742, -14.170145034790039, -13.494497299194336, -12.81885051727295, -12.143203735351562, -11.46755599975586, -10.791908264160156, -10.11626148223877, -9.440613746643066, -8.76496696472168, -8.089319229125977, -7.41367244720459, -6.738024711608887, -6.062376976013184, -5.386730194091797, -4.711082458496094, -4.035435676574707, -3.359787940979004, -2.684141159057617, -2.008493423461914, -1.332845687866211, -0.6571979522705078, 0.0184478759765625, 0.6940956115722656, 1.3697433471679688, 2.045391082763672, 2.721036911010742, 3.3966846466064453, 4.072332382202148, 4.747980117797852, 5.423627853393555, 6.099273681640625, 6.774921417236328, 7.450569152832031, 8.126216888427734, 8.801862716674805, 9.477510452270508, 10.153158187866211, 10.828805923461914, 11.504453659057617, 12.180099487304688, 12.85574722290039, 13.531394958496094, 14.207042694091797, 14.8826904296875, 15.558338165283203, 16.233985900878906, 16.909629821777344, 17.585277557373047, 18.26092529296875, 18.936573028564453, 19.612220764160156, 20.28786849975586, 20.963516235351562, 21.639163970947266, 22.31481170654297, 22.990455627441406, 23.66610336303711, 24.341751098632812, 25.017398834228516, 25.69304656982422]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.2433283030986786, -0.2223326712846756, -0.2013370394706726, -0.1803414225578308, -0.15934577584266663, -0.13835015892982483, -0.11735452711582184, -0.09635889530181885, -0.07536326348781586, -0.054367631673812866, -0.033371999859809875, -0.012376368045806885, 0.008619248867034912, 0.029614895582199097, 0.050610512495040894, 0.07160615921020508, 0.09260177612304688, 0.11359739303588867, 0.13459303975105286, 0.15558865666389465, 0.17658430337905884, 0.19757992029190063, 0.21857556700706482, 0.23957118391990662, 0.2605668008327484, 0.2815624177455902, 0.3025580942630768, 0.3235537111759186, 0.3445493280887604, 0.3655449450016022, 0.38654062151908875, 0.40753623843193054, 0.42853185534477234, 0.44952747225761414, 0.47052308917045593, 0.4915187656879425, 0.5125143527984619, 0.5335099697113037, 0.5545055866241455, 0.5755013227462769, 0.5964969396591187, 0.6174925565719604, 0.6384881734848022, 0.659483790397644, 0.6804794073104858, 0.7014750242233276, 0.7224706411361694, 0.7434662580490112, 0.764461874961853, 0.7854574918746948, 0.8064531087875366, 0.827448844909668, 0.8484444618225098, 0.8694400787353516, 0.8904356956481934, 0.9114313125610352, 0.932426929473877, 0.9534225463867188, 0.9744181632995605, 0.9954137802124023, 1.0164095163345337, 1.0374051332473755, 1.0584007501602173, 1.079396367073059, 1.1003919839859009]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 5.0, 7.0, 6.0, 12.0, 11.0, 18.0, 23.0, 27.0, 15.0, 15.0, 6.0, 6.0, 26.0, 40.0, 35.0, 13.0, 48.0, 44.0, 44.0, 1.0, 6.0, 4.0, 5.0, 5.0, 1.0, 3.0, 14.0, 8.0, 3.0, 3.0, 3.0, 7.0, 6.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-1.5345489978790283, -1.4884226322174072, -1.4422962665557861, -1.396169900894165, -1.3500434160232544, -1.3039170503616333, -1.2577906847000122, -1.2116643190383911, -1.1655378341674805, -1.1194114685058594, -1.0732851028442383, -1.0271587371826172, -0.9810323715209961, -0.9349059462547302, -0.8887795805931091, -0.8426531553268433, -0.7965267896652222, -0.7504004240036011, -0.7042739987373352, -0.6581476330757141, -0.6120212078094482, -0.5658948421478271, -0.519768476486206, -0.47364211082458496, -0.42751574516296387, -0.3813892602920532, -0.33526289463043213, -0.28913652896881104, -0.24301016330718994, -0.19688379764556885, -0.1507573127746582, -0.10463094711303711, -0.058504581451416016, -0.012378215789794922, 0.03374814987182617, 0.07987463474273682, 0.1260010004043579, 0.172127366065979, 0.2182537317276001, 0.2643800973892212, 0.31050658226013184, 0.35663294792175293, 0.402759313583374, 0.4488856792449951, 0.4950120449066162, 0.5411384105682373, 0.5872647762298584, 0.6333911418914795, 0.6795175075531006, 0.7256441116333008, 0.7717704772949219, 0.817896842956543, 0.8640232086181641, 0.9101495742797852, 0.9562759399414062, 1.0024023056030273, 1.0485286712646484, 1.0946550369262695, 1.1407814025878906, 1.1869080066680908, 1.233034372329712, 1.279160737991333, 1.325287103652954, 1.3714134693145752, 1.4175398349761963]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0], "bins": [-3.453089714050293, -3.302565097808838, -3.152040719985962, -3.001516103744507, -2.850991725921631, -2.700467109680176, -2.5499424934387207, -2.3994181156158447, -2.2488937377929688, -2.0983691215515137, -1.9478446245193481, -1.7973201274871826, -1.6467955112457275, -1.496271014213562, -1.3457465171813965, -1.1952221393585205, -1.0446975231170654, -0.8941729068756104, -0.7436485290527344, -0.5931239128112793, -0.4425995349884033, -0.29207491874694824, -0.14155054092407227, 0.008974075317382812, 0.1594986915588379, 0.31002306938171387, 0.46054768562316895, 0.6110720634460449, 0.7615966796875, 0.9121212959289551, 1.062645435333252, 1.213170051574707, 1.363694667816162, 1.5142192840576172, 1.6647439002990723, 1.8152680397033691, 1.9657926559448242, 2.1163172721862793, 2.2668418884277344, 2.4173660278320312, 2.5678906440734863, 2.7184152603149414, 2.8689398765563965, 3.0194644927978516, 3.1699886322021484, 3.3205132484436035, 3.4710378646850586, 3.6215624809265137, 3.7720870971679688, 3.9226112365722656, 4.073135852813721, 4.223660469055176, 4.374185085296631, 4.524709224700928, 4.675233840942383, 4.82575798034668, 4.976283073425293, 5.12680721282959, 5.277332305908203, 5.4278564453125, 5.578380584716797, 5.72890567779541, 5.879429817199707, 6.02995491027832, 6.180479049682617]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 6.0, 4.0, 8.0, 3.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0], "bins": [-6.082770347595215, -5.962225437164307, -5.841681003570557, -5.721136093139648, -5.60059118270874, -5.48004674911499, -5.359501838684082, -5.238956928253174, -5.118412494659424, -4.997867584228516, -4.877323150634766, -4.756778240203857, -4.636233329772949, -4.515688896179199, -4.395143985748291, -4.274599075317383, -4.154054641723633, -4.033509731292725, -3.9129648208618164, -3.7924201488494873, -3.671875476837158, -3.55133056640625, -3.430785894393921, -3.310241222381592, -3.1896963119506836, -3.0691516399383545, -2.9486069679260254, -2.8280622959136963, -2.707517385482788, -2.586972713470459, -2.46642804145813, -2.3458831310272217, -2.2253384590148926, -2.1047937870025635, -1.9842491149902344, -1.8637042045593262, -1.743159294128418, -1.622614860534668, -1.5020699501037598, -1.3815250396728516, -1.2609806060791016, -1.1404356956481934, -1.0198907852172852, -0.8993463516235352, -0.778801441192627, -0.6582565307617188, -0.5377120971679688, -0.41716718673706055, -0.29662227630615234, -0.17607784271240234, -0.05553293228149414, 0.06501150131225586, 0.18555641174316406, 0.30610132217407227, 0.42664575576782227, 0.5471906661987305, 0.6677355766296387, 0.7882800102233887, 0.9088249206542969, 1.029369831085205, 1.149914264678955, 1.2704591751098633, 1.3910040855407715, 1.5115485191345215, 1.6320934295654297]}, "_runtime": 8874.790584802628, "_timestamp": 1585517953.2113144, "_step": 498}
{"Episode reward": 52.686604655859824, "Episode length": 478, "Policy Loss": 0.7215671539306641, "Value Loss": 19.574012756347656, "_runtime": 8874.790584802628, "_timestamp": 1585517953.2113144, "_step": 499}
