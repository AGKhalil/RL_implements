{"Episode reward": -56.400470377470086, "Episode length": 999, "Policy Loss": -0.08169262111186981, "Value Loss": 0.008582026697695255, "_runtime": 14830.480191469193, "_timestamp": 1585584746.3248248, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11050936579704285, "Value Loss": 1.3404524326324463, "_runtime": 14832.011359214783, "_timestamp": 1585584747.8559926, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 61.21736145019531, "Value Loss": 7219.375, "_runtime": 14833.624014854431, "_timestamp": 1585584749.4686482, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4875239431858063, "Value Loss": 158.55252075195312, "_runtime": 14835.202979564667, "_timestamp": 1585584751.047613, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.085000991821289, "Value Loss": 559.5460205078125, "_runtime": 14836.766903400421, "_timestamp": 1585584752.6115367, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.891428470611572, "Value Loss": 73.86116790771484, "_runtime": 14838.372808933258, "_timestamp": 1585584754.2174423, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.634355068206787, "Value Loss": 71.83448028564453, "_runtime": 14839.960242509842, "_timestamp": 1585584755.8048759, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.99080491065979, "Value Loss": 601.8880004882812, "_runtime": 14841.497280359268, "_timestamp": 1585584757.3419137, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4488160014152527, "Value Loss": 4.5430684089660645, "_runtime": 14843.099643230438, "_timestamp": 1585584758.9442766, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.413515090942383, "Value Loss": 5.4917893409729, "_runtime": 14844.721148967743, "_timestamp": 1585584760.5657823, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 7.147512435913086, "Value Loss": 164.6378936767578, "_runtime": 14846.282599925995, "_timestamp": 1585584762.1272333, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.077351570129395, "Value Loss": 46.91781997680664, "_runtime": 14847.885087966919, "_timestamp": 1585584763.7297213, "_step": 11}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.389142036437988, "Value Loss": 811.938232421875, "_runtime": 14849.486005067825, "_timestamp": 1585584765.3306384, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.638324737548828, "Value Loss": 66.05732727050781, "_runtime": 14851.090913534164, "_timestamp": 1585584766.9355469, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.481415748596191, "Value Loss": 75.19819641113281, "_runtime": 14852.706257104874, "_timestamp": 1585584768.5508904, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.6083145141601562, "Value Loss": 93.22806549072266, "_runtime": 14854.309416532516, "_timestamp": 1585584770.1540499, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6591858863830566, "Value Loss": 2.939558982849121, "_runtime": 14855.891826868057, "_timestamp": 1585584771.7364602, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1577303409576416, "Value Loss": 0.3768640458583832, "_runtime": 14857.503749370575, "_timestamp": 1585584773.3483827, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8489186763763428, "Value Loss": 0.16395603120326996, "_runtime": 14859.114781856537, "_timestamp": 1585584774.9594152, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6731621026992798, "Value Loss": 0.07950713485479355, "_runtime": 14860.697430610657, "_timestamp": 1585584776.542064, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5794947147369385, "Value Loss": 1.1650199890136719, "_runtime": 14862.297897815704, "_timestamp": 1585584778.1425312, "_step": 20}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5227011442184448, "Value Loss": 19.990278244018555, "_runtime": 14863.892191886902, "_timestamp": 1585584779.7368252, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0026941299438477, "Value Loss": 32.417205810546875, "_runtime": 14865.479822397232, "_timestamp": 1585584781.3244557, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1836109161376953, "Value Loss": 4.58783483505249, "_runtime": 14867.07959485054, "_timestamp": 1585584782.9242282, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6790281534194946, "Value Loss": 24.215368270874023, "_runtime": 14868.726807117462, "_timestamp": 1585584784.5714405, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.062431812286377, "Value Loss": 5.797600746154785, "_runtime": 14870.302939891815, "_timestamp": 1585584786.1475732, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.44082462787628174, "Value Loss": 3.750922679901123, "_runtime": 14871.90275812149, "_timestamp": 1585584787.7473915, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8984678387641907, "Value Loss": 0.4868535101413727, "_runtime": 14873.50142621994, "_timestamp": 1585584789.3460596, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.812450647354126, "Value Loss": 0.4403381943702698, "_runtime": 14875.08984541893, "_timestamp": 1585584790.9344788, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5754998922348022, "Value Loss": 0.736454427242279, "_runtime": 14876.69209098816, "_timestamp": 1585584792.5367243, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6117932796478271, "Value Loss": 0.598719596862793, "_runtime": 14878.366739749908, "_timestamp": 1585584794.211373, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4513660669326782, "Value Loss": 3.0286190509796143, "_runtime": 14879.994390010834, "_timestamp": 1585584795.8390234, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49144992232322693, "Value Loss": 0.17487792670726776, "_runtime": 14881.60562801361, "_timestamp": 1585584797.4502614, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5687406063079834, "Value Loss": 0.5047255158424377, "_runtime": 14883.23380112648, "_timestamp": 1585584799.0784345, "_step": 33}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6408398747444153, "Value Loss": 0.04113262891769409, "_runtime": 14884.834439516068, "_timestamp": 1585584800.6790729, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5663679242134094, "Value Loss": 0.026873793452978134, "_runtime": 14886.427680492401, "_timestamp": 1585584802.2723138, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49848073720932007, "Value Loss": 0.023253414779901505, "_runtime": 14888.032138347626, "_timestamp": 1585584803.8767717, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.45460745692253113, "Value Loss": 0.02795783057808876, "_runtime": 14889.626719236374, "_timestamp": 1585584805.4713526, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39965829253196716, "Value Loss": 0.02076832205057144, "_runtime": 14891.210774898529, "_timestamp": 1585584807.0554082, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.37840956449508667, "Value Loss": 0.041364237666130066, "_runtime": 14892.859297275543, "_timestamp": 1585584808.7039306, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33280879259109497, "Value Loss": 0.03502339497208595, "_runtime": 14894.45705318451, "_timestamp": 1585584810.3016865, "_step": 40}
{"Episode reward": -99.89942416833192, "Episode length": 999, "Policy Loss": 0.26505106687545776, "Value Loss": 0.31639090180397034, "_runtime": 14896.057959079742, "_timestamp": 1585584811.9025924, "_step": 41}
{"Episode reward": -99.80110169945809, "Episode length": 999, "Policy Loss": 0.2841370105743408, "Value Loss": 0.32789626717567444, "_runtime": 14897.661779403687, "_timestamp": 1585584813.5064127, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24508437514305115, "Value Loss": 0.028776168823242188, "_runtime": 14899.259120941162, "_timestamp": 1585584815.1037543, "_step": 43}
{"Episode reward": -99.85731550037106, "Episode length": 999, "Policy Loss": 0.3753281533718109, "Value Loss": 0.23922081291675568, "_runtime": 14900.868278980255, "_timestamp": 1585584816.7129123, "_step": 44}
{"Episode reward": -99.4771799099768, "Episode length": 999, "Policy Loss": 0.37485772371292114, "Value Loss": 0.20730841159820557, "_runtime": 14902.461301803589, "_timestamp": 1585584818.3059351, "_step": 45}
{"Episode reward": -99.4350179147776, "Episode length": 999, "Policy Loss": 0.33574509620666504, "Value Loss": 0.17616815865039825, "_runtime": 14904.047213315964, "_timestamp": 1585584819.8918467, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2537762224674225, "Value Loss": 0.05100564286112785, "_runtime": 14905.64314198494, "_timestamp": 1585584821.4877753, "_step": 47}
{"Episode reward": -99.47784943507139, "Episode length": 999, "Policy Loss": 0.2705499827861786, "Value Loss": 0.09420035779476166, "_runtime": 14907.237016677856, "_timestamp": 1585584823.08165, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.15729570388793945, "Value Loss": 0.009225715883076191, "_runtime": 14908.829821109772, "_timestamp": 1585584824.6744545, "_step": 49}
{"Episode reward": -99.70381044797527, "Episode length": 999, "Policy Loss": 0.23357084393501282, "Value Loss": 0.07025695592164993, "_runtime": 14910.422965049744, "_timestamp": 1585584826.2675984, "_step": 50}
{"Episode reward": -99.08783928634907, "Episode length": 999, "Policy Loss": 0.23389525711536407, "Value Loss": 0.09332109242677689, "_runtime": 14912.02483534813, "_timestamp": 1585584827.8694687, "_step": 51}
{"Episode reward": -99.00738992882597, "Episode length": 999, "Policy Loss": 0.22936725616455078, "Value Loss": 0.09262047708034515, "_runtime": 14913.62284231186, "_timestamp": 1585584829.4674757, "_step": 52}
{"Episode reward": -99.56812284456892, "Episode length": 999, "Policy Loss": 0.18045060336589813, "Value Loss": 0.05478294938802719, "_runtime": 14915.265162706375, "_timestamp": 1585584831.109796, "_step": 53}
{"Episode reward": -99.28335939785426, "Episode length": 999, "Policy Loss": 0.19641652703285217, "Value Loss": 0.07167370617389679, "_runtime": 14916.86800813675, "_timestamp": 1585584832.7126415, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08291950821876526, "Value Loss": 0.00848628394305706, "_runtime": 14918.467021465302, "_timestamp": 1585584834.3116548, "_step": 55}
{"Episode reward": -99.19190137076357, "Episode length": 999, "Policy Loss": 0.1619892567396164, "Value Loss": 0.06292518228292465, "_runtime": 14920.070886850357, "_timestamp": 1585584835.9155202, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09777769446372986, "Value Loss": 0.023424997925758362, "_runtime": 14921.664363861084, "_timestamp": 1585584837.5089972, "_step": 57}
{"Episode reward": -99.52969303131574, "Episode length": 999, "Policy Loss": 0.12951448559761047, "Value Loss": 0.04407574236392975, "_runtime": 14923.258834838867, "_timestamp": 1585584839.1034682, "_step": 58}
{"Episode reward": -98.87732024702589, "Episode length": 999, "Policy Loss": 0.14142641425132751, "Value Loss": 0.06375513225793839, "_runtime": 14924.85672044754, "_timestamp": 1585584840.7013538, "_step": 59}
{"Episode reward": -99.79126787778674, "Episode length": 999, "Policy Loss": 0.11875738948583603, "Value Loss": 0.0446469746530056, "_runtime": 14926.464606761932, "_timestamp": 1585584842.30924, "_step": 60}
{"Episode reward": -99.05375831642665, "Episode length": 999, "Policy Loss": 0.11861169338226318, "Value Loss": 0.05571978911757469, "_runtime": 14928.056943178177, "_timestamp": 1585584843.9015765, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03663591668009758, "Value Loss": 0.010889389552175999, "_runtime": 14929.651820898056, "_timestamp": 1585584845.4964542, "_step": 62}
{"Episode reward": -99.30085163380646, "Episode length": 999, "Policy Loss": 0.10476849973201752, "Value Loss": 0.04066718742251396, "_runtime": 14931.257643461227, "_timestamp": 1585584847.1022768, "_step": 63}
{"Episode reward": -99.06055607538778, "Episode length": 999, "Policy Loss": 0.09039372205734253, "Value Loss": 0.037739094346761703, "_runtime": 14932.849754095078, "_timestamp": 1585584848.6943874, "_step": 64}
{"Episode reward": -98.96784132619071, "Episode length": 999, "Policy Loss": 0.0910576581954956, "Value Loss": 0.04118683561682701, "_runtime": 14934.449144601822, "_timestamp": 1585584850.293778, "_step": 65}
{"Episode reward": -99.53400684010958, "Episode length": 999, "Policy Loss": 0.07772016525268555, "Value Loss": 0.03090078942477703, "_runtime": 14936.057718038559, "_timestamp": 1585584851.9023514, "_step": 66}
{"Episode reward": -99.88808646625303, "Episode length": 999, "Policy Loss": 0.05819103866815567, "Value Loss": 0.023670678958296776, "_runtime": 14937.647740840912, "_timestamp": 1585584853.4923742, "_step": 67}
{"Episode reward": -99.62569811464915, "Episode length": 999, "Policy Loss": 0.050864677876234055, "Value Loss": 0.019330240786075592, "_runtime": 14939.29074883461, "_timestamp": 1585584855.1353822, "_step": 68}
{"Episode reward": -99.55912477787886, "Episode length": 999, "Policy Loss": 0.04516404867172241, "Value Loss": 0.018522610887885094, "_runtime": 14940.893847703934, "_timestamp": 1585584856.738481, "_step": 69}
{"Episode reward": -98.97468171698482, "Episode length": 999, "Policy Loss": 0.048570845276117325, "Value Loss": 0.024610653519630432, "_runtime": 14942.479947328568, "_timestamp": 1585584858.3245807, "_step": 70}
{"Episode reward": -99.04553603112201, "Episode length": 999, "Policy Loss": 0.058826107531785965, "Value Loss": 0.03222658112645149, "_runtime": 14944.078176498413, "_timestamp": 1585584859.9228098, "_step": 71}
{"Episode reward": -99.15602444550741, "Episode length": 999, "Policy Loss": 0.038086310029029846, "Value Loss": 0.020359890535473824, "_runtime": 14945.662240028381, "_timestamp": 1585584861.5068734, "_step": 72}
{"Episode reward": -99.00175619884936, "Episode length": 999, "Policy Loss": 0.03422129154205322, "Value Loss": 0.020284736528992653, "_runtime": 14947.235455036163, "_timestamp": 1585584863.0800884, "_step": 73}
{"Episode reward": -99.62930589611565, "Episode length": 999, "Policy Loss": 0.008281681686639786, "Value Loss": 0.0072302985936403275, "_runtime": 14948.828129529953, "_timestamp": 1585584864.6727629, "_step": 74}
{"Episode reward": -99.66453570615134, "Episode length": 999, "Policy Loss": 0.00015725551929790527, "Value Loss": 0.004839549772441387, "_runtime": 14950.402920484543, "_timestamp": 1585584866.2475538, "_step": 75}
{"Episode reward": -99.35888380343643, "Episode length": 999, "Policy Loss": 0.0033045569434762, "Value Loss": 0.005898967385292053, "_runtime": 14951.983626127243, "_timestamp": 1585584867.8282595, "_step": 76}
{"Episode reward": -99.6807975990737, "Episode length": 999, "Policy Loss": -0.009437772445380688, "Value Loss": 0.00238010729663074, "_runtime": 14953.57182097435, "_timestamp": 1585584869.4164543, "_step": 77}
{"Episode reward": -98.9709280441549, "Episode length": 999, "Policy Loss": 0.017738044261932373, "Value Loss": 0.013207763433456421, "_runtime": 14955.14887714386, "_timestamp": 1585584870.9935105, "_step": 78}
{"Episode reward": -99.45332073457082, "Episode length": 999, "Policy Loss": -0.009527076035737991, "Value Loss": 0.0022416450083255768, "_runtime": 14956.735071182251, "_timestamp": 1585584872.5797045, "_step": 79}
{"Episode reward": -99.60539751216032, "Episode length": 999, "Policy Loss": -0.016178157180547714, "Value Loss": 0.0014298693276941776, "_runtime": 14958.310630083084, "_timestamp": 1585584874.1552634, "_step": 80}
{"Episode reward": -99.35946689962238, "Episode length": 999, "Policy Loss": -0.01912807859480381, "Value Loss": 0.0011283510830253363, "_runtime": 14959.898483276367, "_timestamp": 1585584875.7431166, "_step": 81}
{"Episode reward": -99.13802568529856, "Episode length": 999, "Policy Loss": -0.015236365608870983, "Value Loss": 0.0016467664390802383, "_runtime": 14961.503620624542, "_timestamp": 1585584877.348254, "_step": 82}
{"Episode reward": -99.6900466160053, "Episode length": 999, "Policy Loss": -0.03231895714998245, "Value Loss": 0.0005372303421609104, "_runtime": 14963.186044454575, "_timestamp": 1585584879.0306778, "_step": 83}
{"Episode reward": -99.68730490514058, "Episode length": 999, "Policy Loss": -0.0246934462338686, "Value Loss": 0.0004146790015511215, "_runtime": 14964.819815397263, "_timestamp": 1585584880.6644487, "_step": 84}
{"Episode reward": -99.289364124375, "Episode length": 999, "Policy Loss": -0.009832965210080147, "Value Loss": 0.0017053697956725955, "_runtime": 14966.420497655869, "_timestamp": 1585584882.265131, "_step": 85}
{"Episode reward": -99.52423403094294, "Episode length": 999, "Policy Loss": -0.026531387120485306, "Value Loss": 0.0003563878417480737, "_runtime": 14968.057355880737, "_timestamp": 1585584883.9019892, "_step": 86}
{"Episode reward": -99.44004454528444, "Episode length": 999, "Policy Loss": -0.024841800332069397, "Value Loss": 0.00034720118856057525, "_runtime": 14969.655557870865, "_timestamp": 1585584885.5001912, "_step": 87}
{"Episode reward": -99.29615893136996, "Episode length": 999, "Policy Loss": -0.025597678497433662, "Value Loss": 0.00037934305146336555, "_runtime": 14971.251494169235, "_timestamp": 1585584887.0961275, "_step": 88}
{"Episode reward": -99.18427473492096, "Episode length": 999, "Policy Loss": -0.008045755326747894, "Value Loss": 0.001087756478227675, "_runtime": 14972.851544618607, "_timestamp": 1585584888.696178, "_step": 89}
{"Episode reward": -99.05606704826926, "Episode length": 999, "Policy Loss": -0.020674994215369225, "Value Loss": 0.00031493313144892454, "_runtime": 14974.459556818008, "_timestamp": 1585584890.3041902, "_step": 90}
{"Episode reward": -99.52460581031053, "Episode length": 999, "Policy Loss": -0.026765277609229088, "Value Loss": 0.000372488284483552, "_runtime": 14976.066284179688, "_timestamp": 1585584891.9109175, "_step": 91}
{"Episode reward": -99.1451779371547, "Episode length": 999, "Policy Loss": -0.02600283734500408, "Value Loss": 0.0004226932069286704, "_runtime": 14977.676889181137, "_timestamp": 1585584893.5215225, "_step": 92}
{"Episode reward": -99.38477109117356, "Episode length": 999, "Policy Loss": -0.019800076261162758, "Value Loss": 0.00020805223903153092, "_runtime": 14979.286231040955, "_timestamp": 1585584895.1308644, "_step": 93}
{"Episode reward": -99.53445598969226, "Episode length": 999, "Policy Loss": -0.03298446908593178, "Value Loss": 0.0011034234194085002, "_runtime": 14980.891326665878, "_timestamp": 1585584896.73596, "_step": 94}
{"Episode reward": -99.02191053212267, "Episode length": 999, "Policy Loss": -0.0034021653700619936, "Value Loss": 0.0006072517717257142, "_runtime": 14982.502644062042, "_timestamp": 1585584898.3472774, "_step": 95}
{"Episode reward": -98.92952010626526, "Episode length": 999, "Policy Loss": -0.011365191079676151, "Value Loss": 0.000192969135241583, "_runtime": 14984.112299919128, "_timestamp": 1585584899.9569333, "_step": 96}
{"Episode reward": -99.17476793436197, "Episode length": 999, "Policy Loss": -0.019234679639339447, "Value Loss": 0.0002954762021545321, "_runtime": 14985.70816373825, "_timestamp": 1585584901.552797, "_step": 97}
{"Episode reward": -99.32934041391664, "Episode length": 999, "Policy Loss": -0.024816643446683884, "Value Loss": 0.0008377155172638595, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414, -12.09738540649414]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0], "bins": [-14.470830917358398, -14.070046424865723, -13.669261932373047, -13.268477439880371, -12.867692947387695, -12.466907501220703, -12.066123008728027, -11.665338516235352, -11.264554023742676, -10.86376953125, -10.462985038757324, -10.062200546264648, -9.661415100097656, -9.260631561279297, -8.859846115112305, -8.459061622619629, -8.058277130126953, -7.657492637634277, -7.256708145141602, -6.855923175811768, -6.45513916015625, -6.054353713989258, -5.653569221496582, -5.252784729003906, -4.8520002365112305, -4.451215744018555, -4.050431251525879, -3.649646759033203, -3.248861312866211, -2.848076820373535, -2.4472923278808594, -2.0465078353881836, -1.6457233428955078, -1.244938850402832, -0.8441543579101562, -0.44336986541748047, -0.04258537292480469, 0.3582000732421875, 0.7589845657348633, 1.159769058227539, 1.5605525970458984, 1.9613380432128906, 2.362123489379883, 2.762907028198242, 3.1636924743652344, 3.5644760131835938, 3.965261459350586, 4.366044998168945, 4.7668304443359375, 5.16761589050293, 5.568399429321289, 5.969184875488281, 6.369968414306641, 6.770753860473633, 7.171537399291992, 7.572322845458984, 7.973108291625977, 8.373891830444336, 8.774677276611328, 9.175460815429688, 9.57624626159668, 9.977029800415039, 10.377815246582031, 10.77859878540039, 11.179384231567383]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5353070497512817, -0.42985084652900696, -0.3243946433067322, -0.218938410282135, -0.11348220705986023, -0.00802600383758545, 0.09743022918701172, 0.2028864026069641, 0.3083426356315613, 0.41379886865615845, 0.5192550420761108, 0.624711275100708, 0.7301675081253052, 0.8356237411499023, 0.94107985496521, 1.0465360879898071, 1.1519923210144043, 1.2574485540390015, 1.3629047870635986, 1.4683610200881958, 1.5738171339035034, 1.6792734861373901, 1.7847295999526978, 1.8901857137680054, 1.995642066001892, 2.10109806060791, 2.206554412841797, 2.3120107650756836, 2.417466640472412, 2.522922992706299, 2.6283793449401855, 2.7338356971740723, 2.839291572570801, 2.9447479248046875, 3.050204277038574, 3.1556601524353027, 3.2611165046691895, 3.366572856903076, 3.472029209136963, 3.5774850845336914, 3.682941436767578, 3.788397789001465, 3.8938541412353516, 3.99931001663208, 4.104766368865967, 4.2102227210998535, 4.315678596496582, 4.421134948730469, 4.5265913009643555, 4.632047176361084, 4.737503528594971, 4.842959880828857, 4.948416233062744, 5.053872108459473, 5.159328460693359, 5.264784812927246, 5.370240688323975, 5.475697040557861, 5.581153392791748, 5.686609268188477, 5.792065620422363, 5.89752197265625, 6.002978324890137, 6.108434200286865, 6.213890552520752]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 6.0, 3.0, 9.0, 8.0, 9.0, 10.0, 13.0, 13.0, 14.0, 39.0, 68.0, 152.0, 63.0, 15.0, 8.0, 7.0, 7.0, 4.0, 4.0, 3.0, 4.0, 4.0, 7.0, 1.0, 4.0, 2.0, 0.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.4812028408050537, -3.358293056488037, -3.2353830337524414, -3.112473249435425, -2.989563465118408, -2.8666534423828125, -2.743743658065796, -2.6208338737487793, -2.4979238510131836, -2.375014066696167, -2.2521042823791504, -2.1291942596435547, -2.006284475326538, -1.8833746910095215, -1.7604647874832153, -1.6375550031661987, -1.5146450996398926, -1.391735315322876, -1.2688252925872803, -1.1459155082702637, -1.023005723953247, -0.9000957012176514, -0.7771859169006348, -0.6542761325836182, -0.5313661098480225, -0.40845632553100586, -0.28554654121398926, -0.16263675689697266, -0.03972673416137695, 0.08318305015563965, 0.20609283447265625, 0.32900285720825195, 0.45191264152526855, 0.5748226642608643, 0.6977322101593018, 0.8206422328948975, 0.9435522556304932, 1.0664618015289307, 1.1893718242645264, 1.312281847000122, 1.4351913928985596, 1.5581014156341553, 1.681011438369751, 1.8039209842681885, 1.9268310070037842, 2.04974102973938, 2.1726505756378174, 2.295560598373413, 2.418470621109009, 2.5413801670074463, 2.664290189743042, 2.7871997356414795, 2.910109758377075, 3.033019781112671, 3.1559293270111084, 3.278839349746704, 3.4017493724823, 3.5246589183807373, 3.647568941116333, 3.7704789638519287, 3.893388509750366, 4.016298294067383, 4.139208793640137, 4.262118339538574, 4.385027885437012]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.092653274536133, -3.9004132747650146, -3.7081732749938965, -3.515933036804199, -3.32369327545166, -3.131453037261963, -2.9392130374908447, -2.7469730377197266, -2.5547330379486084, -2.3624930381774902, -2.170253038406372, -1.978013038635254, -1.7857728004455566, -1.5935328006744385, -1.4012928009033203, -1.2090528011322021, -1.016812801361084, -0.8245728015899658, -0.6323328018188477, -0.4400928020477295, -0.24785280227661133, -0.05561256408691406, 0.136627197265625, 0.32886743545532227, 0.5211076736450195, 0.7133474349975586, 0.9055876731872559, 1.097827434539795, 1.2900676727294922, 1.4823074340820312, 1.6745476722717285, 1.8667874336242676, 2.059027671813965, 2.251267910003662, 2.443507671356201, 2.6357479095458984, 2.8279876708984375, 3.0202279090881348, 3.212467670440674, 3.404707908630371, 3.59694766998291, 3.7891879081726074, 3.9814281463623047, 4.173667907714844, 4.365907669067383, 4.558148384094238, 4.750388145446777, 4.942627906799316, 5.134868621826172, 5.327108383178711, 5.51934814453125, 5.711587905883789, 5.9038286209106445, 6.096068382263184, 6.288308143615723, 6.480547904968262, 6.672788619995117, 6.865028381347656, 7.057268142700195, 7.249508857727051, 7.44174861907959, 7.633988380432129, 7.826228141784668, 8.018468856811523, 8.210708618164062]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 5.0, 6.0, 7.0, 5.0, 3.0, 3.0, 8.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-10.175508499145508, -9.936139106750488, -9.696769714355469, -9.45740032196045, -9.21803092956543, -8.97866153717041, -8.73929214477539, -8.499922752380371, -8.260553359985352, -8.021183967590332, -7.7818145751953125, -7.542445182800293, -7.303075790405273, -7.063706398010254, -6.824337005615234, -6.584967613220215, -6.345598220825195, -6.106228828430176, -5.866859436035156, -5.627490043640137, -5.388120651245117, -5.148751258850098, -4.909381866455078, -4.670012474060059, -4.430643081665039, -4.1912736892700195, -3.951904296875, -3.7125349044799805, -3.473165512084961, -3.2337961196899414, -2.994426727294922, -2.7550573348999023, -2.515687942504883, -2.2763185501098633, -2.0369491577148438, -1.7975797653198242, -1.5582103729248047, -1.3188409805297852, -1.0794715881347656, -0.8401021957397461, -0.6007328033447266, -0.36136341094970703, -0.1219940185546875, 0.11737537384033203, 0.35674476623535156, 0.5961141586303711, 0.8354835510253906, 1.0748529434204102, 1.3142223358154297, 1.5535917282104492, 1.7929611206054688, 2.0323305130004883, 2.271699905395508, 2.5110692977905273, 2.750438690185547, 2.9898080825805664, 3.229177474975586, 3.4685468673706055, 3.707916259765625, 3.9472856521606445, 4.186655044555664, 4.426024436950684, 4.665393829345703, 4.904763221740723, 5.144132614135742]}, "_runtime": 14987.35986328125, "_timestamp": 1585584903.2044966, "_step": 98}
{"Episode reward": -99.29806552550204, "Episode length": 999, "Policy Loss": -0.020735833793878555, "Value Loss": 0.0005215276614762843, "_runtime": 14988.965821266174, "_timestamp": 1585584904.8104546, "_step": 99}
{"Episode reward": -99.51800166596266, "Episode length": 999, "Policy Loss": -0.022131234407424927, "Value Loss": 0.000928172841668129, "_runtime": 14990.567948579788, "_timestamp": 1585584906.412582, "_step": 100}
{"Episode reward": -99.02393845319087, "Episode length": 999, "Policy Loss": -0.006162423174828291, "Value Loss": 9.814812074182555e-05, "_runtime": 14992.167068481445, "_timestamp": 1585584908.0117018, "_step": 101}
{"Episode reward": -99.58382562369182, "Episode length": 999, "Policy Loss": -0.01825270615518093, "Value Loss": 0.0006133235292509198, "_runtime": 14993.76164841652, "_timestamp": 1585584909.6062818, "_step": 102}
{"Episode reward": -99.691298178416, "Episode length": 999, "Policy Loss": -0.018197115510702133, "Value Loss": 0.0007051998982205987, "_runtime": 14995.36267209053, "_timestamp": 1585584911.2073054, "_step": 103}
{"Episode reward": -99.17685581972096, "Episode length": 999, "Policy Loss": -0.009064918383955956, "Value Loss": 0.00015610076661687344, "_runtime": 14996.972237110138, "_timestamp": 1585584912.8168705, "_step": 104}
{"Episode reward": -98.94890211965276, "Episode length": 999, "Policy Loss": -0.0013817263534292579, "Value Loss": 9.838497499004006e-05, "_runtime": 14998.556535720825, "_timestamp": 1585584914.401169, "_step": 105}
{"Episode reward": -99.29698773886817, "Episode length": 999, "Policy Loss": -0.011459402740001678, "Value Loss": 0.0003341066767461598, "_runtime": 15000.151094436646, "_timestamp": 1585584915.9957278, "_step": 106}
{"Episode reward": -98.96233930663858, "Episode length": 999, "Policy Loss": -0.0038102741818875074, "Value Loss": 8.705773507244885e-05, "_runtime": 15001.758989334106, "_timestamp": 1585584917.6036227, "_step": 107}
{"Episode reward": -99.41938265439434, "Episode length": 999, "Policy Loss": -0.008957698941230774, "Value Loss": 0.0002809070283547044, "_runtime": 15003.351811408997, "_timestamp": 1585584919.1964447, "_step": 108}
{"Episode reward": -99.61883709645187, "Episode length": 999, "Policy Loss": -0.008579972200095654, "Value Loss": 0.00028315780218690634, "_runtime": 15004.957313776016, "_timestamp": 1585584920.801947, "_step": 109}
{"Episode reward": -99.85159020074924, "Episode length": 999, "Policy Loss": -0.00794690940529108, "Value Loss": 0.0004233526124153286, "_runtime": 15006.56332230568, "_timestamp": 1585584922.4079556, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.008048778399825096, "Value Loss": 0.00038343286723829806, "_runtime": 15008.152964115143, "_timestamp": 1585584923.9975975, "_step": 111}
{"Episode reward": -99.03761071386286, "Episode length": 999, "Policy Loss": -0.0030026419553905725, "Value Loss": 0.00011591648944886401, "_runtime": 15009.790016889572, "_timestamp": 1585584925.6346502, "_step": 112}
{"Episode reward": -99.74857565979676, "Episode length": 999, "Policy Loss": -0.0050493162125349045, "Value Loss": 0.00022769191127736121, "_runtime": 15011.382885217667, "_timestamp": 1585584927.2275186, "_step": 113}
{"Episode reward": -98.97099516905183, "Episode length": 999, "Policy Loss": -0.00010108375136042014, "Value Loss": 8.039205567911267e-05, "_runtime": 15012.984966516495, "_timestamp": 1585584928.8295999, "_step": 114}
{"Episode reward": -99.3812062514914, "Episode length": 999, "Policy Loss": -0.004720405675470829, "Value Loss": 0.0003042859898414463, "_runtime": 15014.58237028122, "_timestamp": 1585584930.4270036, "_step": 115}
{"Episode reward": -99.27124616569014, "Episode length": 999, "Policy Loss": -0.002621318446472287, "Value Loss": 0.00014990306226536632, "_runtime": 15016.187704324722, "_timestamp": 1585584932.0323377, "_step": 116}
{"Episode reward": -99.13814474677785, "Episode length": 999, "Policy Loss": -0.0007276477408595383, "Value Loss": 0.000100148499768693, "_runtime": 15017.777996063232, "_timestamp": 1585584933.6226294, "_step": 117}
{"Episode reward": -99.02040799135833, "Episode length": 999, "Policy Loss": 0.003312084125354886, "Value Loss": 7.158442895160988e-05, "_runtime": 15019.374173879623, "_timestamp": 1585584935.2188072, "_step": 118}
{"Episode reward": -98.93194320454326, "Episode length": 999, "Policy Loss": 0.0006785354926250875, "Value Loss": 8.403561514569446e-05, "_runtime": 15020.979551553726, "_timestamp": 1585584936.824185, "_step": 119}
{"Episode reward": -99.50232566238812, "Episode length": 999, "Policy Loss": -0.0012570949038490653, "Value Loss": 0.000110998960735742, "_runtime": 15022.575184345245, "_timestamp": 1585584938.4198177, "_step": 120}
{"Episode reward": -99.1303732513256, "Episode length": 999, "Policy Loss": 0.00061571947298944, "Value Loss": 8.467094448860735e-05, "_runtime": 15024.15253329277, "_timestamp": 1585584939.9971666, "_step": 121}
{"Episode reward": -99.28605300808671, "Episode length": 999, "Policy Loss": 0.002998695010319352, "Value Loss": 4.5575539843412116e-05, "_runtime": 15025.804424524307, "_timestamp": 1585584941.6490579, "_step": 122}
{"Episode reward": -99.56582143718549, "Episode length": 999, "Policy Loss": -0.0026537340600043535, "Value Loss": 0.0001471526047680527, "_runtime": 15027.434709787369, "_timestamp": 1585584943.2793431, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0018331590108573437, "Value Loss": 0.00021361596009228379, "_runtime": 15029.035368204117, "_timestamp": 1585584944.8800015, "_step": 124}
{"Episode reward": -99.71831946562048, "Episode length": 999, "Policy Loss": -0.002215418964624405, "Value Loss": 0.00014035501226317137, "_runtime": 15030.642791032791, "_timestamp": 1585584946.4874244, "_step": 125}
{"Episode reward": -98.99645383387247, "Episode length": 999, "Policy Loss": 0.001232498325407505, "Value Loss": 7.759567233733833e-05, "_runtime": 15032.255934238434, "_timestamp": 1585584948.1005676, "_step": 126}
{"Episode reward": -98.98666461933693, "Episode length": 999, "Policy Loss": -0.0010522595839574933, "Value Loss": 0.00011428823199821636, "_runtime": 15033.871529817581, "_timestamp": 1585584949.7161632, "_step": 127}
{"Episode reward": -99.08829401411366, "Episode length": 999, "Policy Loss": 0.0011645351769402623, "Value Loss": 6.877403211547062e-05, "_runtime": 15035.455328941345, "_timestamp": 1585584951.2999623, "_step": 128}
{"Episode reward": -99.61518824779576, "Episode length": 999, "Policy Loss": -0.002318141283467412, "Value Loss": 0.00012482868623919785, "_runtime": 15037.040810585022, "_timestamp": 1585584952.885444, "_step": 129}
{"Episode reward": -99.69160841419294, "Episode length": 999, "Policy Loss": -0.001990742515772581, "Value Loss": 0.0001228554465342313, "_runtime": 15038.623388528824, "_timestamp": 1585584954.4680219, "_step": 130}
{"Episode reward": -99.12306611623774, "Episode length": 999, "Policy Loss": 0.0017803381197154522, "Value Loss": 6.187932012835518e-05, "_runtime": 15040.212554454803, "_timestamp": 1585584956.0571878, "_step": 131}
{"Episode reward": -99.10968776618527, "Episode length": 999, "Policy Loss": -0.000860983447637409, "Value Loss": 8.371384319616482e-05, "_runtime": 15041.796573400497, "_timestamp": 1585584957.6412067, "_step": 132}
{"Episode reward": -99.24392691562811, "Episode length": 999, "Policy Loss": -0.0026798187755048275, "Value Loss": 0.00011583765444811434, "_runtime": 15043.377648353577, "_timestamp": 1585584959.2222817, "_step": 133}
{"Episode reward": -99.41761162748283, "Episode length": 999, "Policy Loss": -0.0014563347212970257, "Value Loss": 6.092577677918598e-05, "_runtime": 15044.963062763214, "_timestamp": 1585584960.807696, "_step": 134}
{"Episode reward": -98.82177338330627, "Episode length": 999, "Policy Loss": 0.0018714736215770245, "Value Loss": 7.502375228796154e-05, "_runtime": 15046.555421352386, "_timestamp": 1585584962.4000547, "_step": 135}
{"Episode reward": -99.42535756007803, "Episode length": 999, "Policy Loss": 0.00012393135693855584, "Value Loss": 4.6179437049431726e-05, "_runtime": 15048.146956920624, "_timestamp": 1585584963.9915903, "_step": 136}
{"Episode reward": -98.93537947341709, "Episode length": 999, "Policy Loss": -0.000679665245115757, "Value Loss": 8.186365448636934e-05, "_runtime": 15049.730719804764, "_timestamp": 1585584965.5753531, "_step": 137}
{"Episode reward": -99.21628914859353, "Episode length": 999, "Policy Loss": -2.6370364139438607e-05, "Value Loss": 5.747961040469818e-05, "_runtime": 15051.325765609741, "_timestamp": 1585584967.170399, "_step": 138}
{"Episode reward": -99.68035362257149, "Episode length": 999, "Policy Loss": -0.0031073223799467087, "Value Loss": 0.00010414449934614822, "_runtime": 15052.903398513794, "_timestamp": 1585584968.7480319, "_step": 139}
{"Episode reward": -99.65554389646147, "Episode length": 999, "Policy Loss": -0.0038498379290103912, "Value Loss": 0.00010795795969897881, "_runtime": 15054.496925354004, "_timestamp": 1585584970.3415587, "_step": 140}
{"Episode reward": -99.5238393461546, "Episode length": 999, "Policy Loss": -0.003729088231921196, "Value Loss": 0.00011015649943146855, "_runtime": 15056.096676826477, "_timestamp": 1585584971.9413102, "_step": 141}
{"Episode reward": -99.70410066436128, "Episode length": 999, "Policy Loss": -0.003240938764065504, "Value Loss": 7.60594048188068e-05, "_runtime": 15057.733139038086, "_timestamp": 1585584973.5777724, "_step": 142}
{"Episode reward": -99.220802157517, "Episode length": 999, "Policy Loss": -0.001680005807429552, "Value Loss": 6.640721403528005e-05, "_runtime": 15059.325800895691, "_timestamp": 1585584975.1704342, "_step": 143}
{"Episode reward": -99.15134895538868, "Episode length": 999, "Policy Loss": -0.0023159708362072706, "Value Loss": 6.49626599624753e-05, "_runtime": 15060.91812491417, "_timestamp": 1585584976.7627583, "_step": 144}
{"Episode reward": -99.48612210863823, "Episode length": 999, "Policy Loss": -0.003434734186157584, "Value Loss": 7.360927702393383e-05, "_runtime": 15062.507409334183, "_timestamp": 1585584978.3520427, "_step": 145}
{"Episode reward": -99.38195229506225, "Episode length": 999, "Policy Loss": -0.003641073126345873, "Value Loss": 8.1704041804187e-05, "_runtime": 15064.105360746384, "_timestamp": 1585584979.949994, "_step": 146}
{"Episode reward": -99.23231353427582, "Episode length": 999, "Policy Loss": -0.003778295824304223, "Value Loss": 9.246589615941048e-05, "_runtime": 15065.709968090057, "_timestamp": 1585584981.5546014, "_step": 147}
{"Episode reward": -99.10963216678559, "Episode length": 999, "Policy Loss": -0.003705669892951846, "Value Loss": 9.452355152461678e-05, "_runtime": 15067.298705101013, "_timestamp": 1585584983.1433384, "_step": 148}
{"Episode reward": -99.18710602287267, "Episode length": 999, "Policy Loss": -0.0016156615456566215, "Value Loss": 5.321201388142072e-05, "_runtime": 15068.906371355057, "_timestamp": 1585584984.7510047, "_step": 149}
{"Episode reward": -99.56508525192179, "Episode length": 999, "Policy Loss": -0.004371614195406437, "Value Loss": 0.0001495887991040945, "_runtime": 15070.511082649231, "_timestamp": 1585584986.355716, "_step": 150}
{"Episode reward": -99.12072373076082, "Episode length": 999, "Policy Loss": -0.0033429197501391172, "Value Loss": 7.700077549088746e-05, "_runtime": 15072.104706525803, "_timestamp": 1585584987.9493399, "_step": 151}
{"Episode reward": -99.16440792049505, "Episode length": 999, "Policy Loss": -0.003948431462049484, "Value Loss": 0.00010167799337068573, "_runtime": 15073.69949054718, "_timestamp": 1585584989.544124, "_step": 152}
{"Episode reward": -99.67842082264013, "Episode length": 999, "Policy Loss": -0.004628677386790514, "Value Loss": 9.325514838565141e-05, "_runtime": 15075.29447722435, "_timestamp": 1585584991.1391106, "_step": 153}
{"Episode reward": -99.69872601964566, "Episode length": 999, "Policy Loss": -0.0042473552748560905, "Value Loss": 8.371123112738132e-05, "_runtime": 15076.888145685196, "_timestamp": 1585584992.732779, "_step": 154}
{"Episode reward": -99.43834498241515, "Episode length": 999, "Policy Loss": -0.0040842448361217976, "Value Loss": 8.886485738912597e-05, "_runtime": 15078.498695611954, "_timestamp": 1585584994.343329, "_step": 155}
{"Episode reward": -99.44259343740967, "Episode length": 999, "Policy Loss": -0.004534307401627302, "Value Loss": 8.605509356129915e-05, "_runtime": 15080.093971967697, "_timestamp": 1585584995.9386053, "_step": 156}
{"Episode reward": -99.18771278359806, "Episode length": 999, "Policy Loss": -0.002058531856164336, "Value Loss": 5.596146729658358e-05, "_runtime": 15081.725244760513, "_timestamp": 1585584997.569878, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0035083824768662453, "Value Loss": 0.00012244783283676952, "_runtime": 15083.313682317734, "_timestamp": 1585584999.1583157, "_step": 158}
{"Episode reward": -99.27145412276056, "Episode length": 999, "Policy Loss": -0.0037570297718048096, "Value Loss": 7.830157119315118e-05, "_runtime": 15084.920983076096, "_timestamp": 1585585000.7656164, "_step": 159}
{"Episode reward": -98.97492174304023, "Episode length": 999, "Policy Loss": -0.003074951469898224, "Value Loss": 8.92196549102664e-05, "_runtime": 15086.525944948196, "_timestamp": 1585585002.3705783, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003418778069317341, "Value Loss": 0.00011494358477648348, "_runtime": 15088.141875505447, "_timestamp": 1585585003.9865088, "_step": 161}
{"Episode reward": -99.07019799054396, "Episode length": 999, "Policy Loss": -0.004397699609398842, "Value Loss": 9.735692583490163e-05, "_runtime": 15089.728758573532, "_timestamp": 1585585005.573392, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.003163084387779236, "Value Loss": 0.00011026279389625415, "_runtime": 15091.307621955872, "_timestamp": 1585585007.1522553, "_step": 163}
{"Episode reward": -99.67950940350524, "Episode length": 999, "Policy Loss": -0.004115361720323563, "Value Loss": 7.99670597189106e-05, "_runtime": 15092.8918030262, "_timestamp": 1585585008.7364364, "_step": 164}
{"Episode reward": -99.27198840741609, "Episode length": 999, "Policy Loss": -0.002712181769311428, "Value Loss": 6.806082819821313e-05, "_runtime": 15094.48566532135, "_timestamp": 1585585010.3302987, "_step": 165}
{"Episode reward": -99.13428483747273, "Episode length": 999, "Policy Loss": -0.0003582639619708061, "Value Loss": 5.716340456274338e-05, "_runtime": 15096.136785268784, "_timestamp": 1585585011.9814186, "_step": 166}
{"Episode reward": -99.59477774110124, "Episode length": 999, "Policy Loss": -0.0034468236844986677, "Value Loss": 6.682652747258544e-05, "_runtime": 15097.76995396614, "_timestamp": 1585585013.6145873, "_step": 167}
{"Episode reward": -98.71089248050458, "Episode length": 999, "Policy Loss": -0.0015188250690698624, "Value Loss": 9.67045416473411e-05, "_runtime": 15099.389702320099, "_timestamp": 1585585015.2343357, "_step": 168}
{"Episode reward": -99.21538295595663, "Episode length": 999, "Policy Loss": -0.0005305352387949824, "Value Loss": 3.799484693445265e-05, "_runtime": 15100.986800909042, "_timestamp": 1585585016.8314342, "_step": 169}
{"Episode reward": -99.12580867786562, "Episode length": 999, "Policy Loss": -0.0021768261212855577, "Value Loss": 6.470233347499743e-05, "_runtime": 15102.599838256836, "_timestamp": 1585585018.4444716, "_step": 170}
{"Episode reward": -99.47377623564621, "Episode length": 999, "Policy Loss": -0.0036787677090615034, "Value Loss": 7.133654435165226e-05, "_runtime": 15104.200114250183, "_timestamp": 1585585020.0447476, "_step": 171}
{"Episode reward": -99.52066879204116, "Episode length": 999, "Policy Loss": -0.0026509573217481375, "Value Loss": 4.299530337448232e-05, "_runtime": 15105.836383342743, "_timestamp": 1585585021.6810167, "_step": 172}
{"Episode reward": -99.35447445905825, "Episode length": 999, "Policy Loss": -0.0031429652590304613, "Value Loss": 6.956826837267727e-05, "_runtime": 15107.437775373459, "_timestamp": 1585585023.2824087, "_step": 173}
{"Episode reward": -99.3956062429277, "Episode length": 999, "Policy Loss": -0.003615305293351412, "Value Loss": 8.581823931308463e-05, "_runtime": 15109.054654359818, "_timestamp": 1585585024.8992877, "_step": 174}
{"Episode reward": -98.91821871203234, "Episode length": 999, "Policy Loss": -0.0013690947089344263, "Value Loss": 7.014500442892313e-05, "_runtime": 15110.653132915497, "_timestamp": 1585585026.4977663, "_step": 175}
{"Episode reward": -99.17877711248507, "Episode length": 999, "Policy Loss": 5.350912033463828e-05, "Value Loss": 5.2500628953566775e-05, "_runtime": 15112.25649356842, "_timestamp": 1585585028.101127, "_step": 176}
{"Episode reward": -99.30232288357594, "Episode length": 999, "Policy Loss": -0.0023474390618503094, "Value Loss": 6.014331302139908e-05, "_runtime": 15113.857500314713, "_timestamp": 1585585029.7021337, "_step": 177}
{"Episode reward": -98.82786633720434, "Episode length": 999, "Policy Loss": 0.00044717825949192047, "Value Loss": 9.359051909996197e-05, "_runtime": 15115.458783864975, "_timestamp": 1585585031.3034172, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.002659833524376154, "Value Loss": 8.847229037201032e-05, "_runtime": 15117.051365613937, "_timestamp": 1585585032.895999, "_step": 179}
{"Episode reward": -99.16463043532397, "Episode length": 999, "Policy Loss": -0.001692732679657638, "Value Loss": 6.062844113330357e-05, "_runtime": 15118.645133018494, "_timestamp": 1585585034.4897664, "_step": 180}
{"Episode reward": -99.18677098145226, "Episode length": 999, "Policy Loss": -0.001238274504430592, "Value Loss": 5.3355517593445256e-05, "_runtime": 15120.239612817764, "_timestamp": 1585585036.0842462, "_step": 181}
{"Episode reward": -98.9419278452688, "Episode length": 999, "Policy Loss": -0.00209351209923625, "Value Loss": 8.027152216527611e-05, "_runtime": 15121.834414482117, "_timestamp": 1585585037.6790478, "_step": 182}
{"Episode reward": -99.64926475333337, "Episode length": 999, "Policy Loss": -0.0024025163147598505, "Value Loss": 4.783233453053981e-05, "_runtime": 15123.430284261703, "_timestamp": 1585585039.2749176, "_step": 183}
{"Episode reward": -98.8481210546695, "Episode length": 999, "Policy Loss": -0.0008636618731543422, "Value Loss": 7.466626993846148e-05, "_runtime": 15125.034067630768, "_timestamp": 1585585040.878701, "_step": 184}
{"Episode reward": -98.85840641560372, "Episode length": 999, "Policy Loss": -0.0014257472939789295, "Value Loss": 7.378476584563032e-05, "_runtime": 15126.64031457901, "_timestamp": 1585585042.484948, "_step": 185}
{"Episode reward": -98.91686832743773, "Episode length": 999, "Policy Loss": -0.0005423830007202923, "Value Loss": 7.2848291893024e-05, "_runtime": 15128.275708198547, "_timestamp": 1585585044.1203415, "_step": 186}
{"Episode reward": -99.18274017579255, "Episode length": 999, "Policy Loss": -0.0006447050836868584, "Value Loss": 5.28292111994233e-05, "_runtime": 15129.86626791954, "_timestamp": 1585585045.7109013, "_step": 187}
{"Episode reward": -98.8692602690256, "Episode length": 999, "Policy Loss": -0.0014858207432553172, "Value Loss": 8.528967009624466e-05, "_runtime": 15131.473849773407, "_timestamp": 1585585047.318483, "_step": 188}
{"Episode reward": -99.13858214050022, "Episode length": 999, "Policy Loss": -0.0008434679475612938, "Value Loss": 5.1816612540278584e-05, "_runtime": 15133.072063207626, "_timestamp": 1585585048.9166965, "_step": 189}
{"Episode reward": -99.27716679387753, "Episode length": 999, "Policy Loss": -0.0010735074756667018, "Value Loss": 4.993647598894313e-05, "_runtime": 15134.672237157822, "_timestamp": 1585585050.5168705, "_step": 190}
{"Episode reward": -99.61101502343298, "Episode length": 999, "Policy Loss": -0.002843153662979603, "Value Loss": 6.31893562967889e-05, "_runtime": 15136.25963640213, "_timestamp": 1585585052.1042697, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0021622832864522934, "Value Loss": 4.175070716883056e-05, "_runtime": 15137.846461772919, "_timestamp": 1585585053.691095, "_step": 192}
{"Episode reward": -99.14519099303033, "Episode length": 999, "Policy Loss": -0.0009147397358901799, "Value Loss": 5.740794222219847e-05, "_runtime": 15139.436221122742, "_timestamp": 1585585055.2808545, "_step": 193}
{"Episode reward": -98.94994561773535, "Episode length": 999, "Policy Loss": -0.0022109101992100477, "Value Loss": 9.563159255776554e-05, "_runtime": 15141.029688358307, "_timestamp": 1585585056.8743217, "_step": 194}
{"Episode reward": -99.26059026027632, "Episode length": 999, "Policy Loss": -0.0014888995792716742, "Value Loss": 5.340698771760799e-05, "_runtime": 15142.626847982407, "_timestamp": 1585585058.4714813, "_step": 195}
{"Episode reward": -98.94292772303432, "Episode length": 999, "Policy Loss": -0.0014807292027398944, "Value Loss": 7.950550207169726e-05, "_runtime": 15144.22285413742, "_timestamp": 1585585060.0674875, "_step": 196}
{"Episode reward": -99.30970310218615, "Episode length": 999, "Policy Loss": -0.0018445966998115182, "Value Loss": 5.559008786804043e-05, "_runtime": 15145.830091714859, "_timestamp": 1585585061.674725, "_step": 197}
{"Episode reward": -99.06608011887876, "Episode length": 999, "Policy Loss": -0.0021087145432829857, "Value Loss": 8.16508472780697e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062, -2.2282485961914062]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0], "bins": [-3.4903271198272705, -3.396541118621826, -3.3027548789978027, -3.2089688777923584, -3.115182876586914, -3.0213968753814697, -2.9276108741760254, -2.833824634552002, -2.7400386333465576, -2.6462526321411133, -2.55246639251709, -2.4586803913116455, -2.364894390106201, -2.271108388900757, -2.1773223876953125, -2.083536148071289, -1.9897501468658447, -1.8959641456604004, -1.8021780252456665, -1.7083919048309326, -1.6146059036254883, -1.520819902420044, -1.4270336627960205, -1.3332476615905762, -1.2394616603851318, -1.1456756591796875, -1.0518896579742432, -0.9581034183502197, -0.8643174171447754, -0.770531415939331, -0.6767451763153076, -0.5829591751098633, -0.48917317390441895, -0.3953871726989746, -0.3016011714935303, -0.20781493186950684, -0.1140289306640625, -0.020242929458618164, 0.07354331016540527, 0.1673293113708496, 0.26111531257629395, 0.3549013137817383, 0.4486873149871826, 0.542473554611206, 0.6362597942352295, 0.7300455570220947, 0.8238317966461182, 0.9176175594329834, 1.0114037990570068, 1.1051900386810303, 1.1989758014678955, 1.292762041091919, 1.3865478038787842, 1.4803340435028076, 1.574120283126831, 1.6679060459136963, 1.7616922855377197, 1.8554785251617432, 1.9492642879486084, 2.043050527572632, 2.1368367671966553, 2.2306225299835205, 2.324408769607544, 2.418194532394409, 2.5119807720184326]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.14839622378349304, -0.12819804251194, -0.10799986124038696, -0.08780167251825333, -0.06760349124670029, -0.04740530997514725, -0.02720712125301361, -0.007008939981460571, 0.013189241290092468, 0.03338742256164551, 0.05358560383319855, 0.07378378510475159, 0.09398198127746582, 0.11418014764785767, 0.1343783438205719, 0.15457651019096375, 0.17477470636367798, 0.1949729025363922, 0.21517106890678406, 0.2353692650794983, 0.25556743144989014, 0.27576562762260437, 0.2959637939929962, 0.31616199016571045, 0.3363601863384247, 0.35655835270881653, 0.3767565190792084, 0.396954745054245, 0.41715291142463684, 0.4373510777950287, 0.45754924416542053, 0.47774747014045715, 0.497945636510849, 0.5181437730789185, 0.5383419990539551, 0.5585402250289917, 0.5787383317947388, 0.5989365577697754, 0.619134783744812, 0.6393328905105591, 0.6595311164855957, 0.6797293424606323, 0.6999274492263794, 0.720125675201416, 0.7403237819671631, 0.7605220079421997, 0.7807202339172363, 0.8009183406829834, 0.82111656665802, 0.8413147926330566, 0.8615128993988037, 0.8817111253738403, 0.9019092321395874, 0.922107458114624, 0.9423056840896606, 0.9625037908554077, 0.9827020168304443, 1.002900242805481, 1.023098349571228, 1.0432965755462646, 1.0634946823120117, 1.0836929082870483, 1.103891134262085, 1.124089241027832, 1.1442874670028687]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 5.0, 4.0, 7.0, 9.0, 12.0, 9.0, 8.0, 12.0, 15.0, 20.0, 32.0, 43.0, 127.0, 58.0, 40.0, 11.0, 9.0, 9.0, 2.0, 9.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.7185694575309753, -0.6950719356536865, -0.6715744733810425, -0.6480769515037537, -0.6245794296264648, -0.601081907749176, -0.5775843858718872, -0.5540869235992432, -0.5305894017219543, -0.5070918798446655, -0.4835943877696991, -0.46009689569473267, -0.43659937381744385, -0.41310185194015503, -0.3896043598651886, -0.36610686779022217, -0.34260934591293335, -0.31911182403564453, -0.2956143319606781, -0.27211683988571167, -0.24861931800842285, -0.22512179613113403, -0.20162433385849, -0.17812681198120117, -0.15462929010391235, -0.13113176822662354, -0.10763424634933472, -0.08413678407669067, -0.060639262199401855, -0.03714174032211304, -0.013644278049468994, 0.009853243827819824, 0.03335076570510864, 0.05684828758239746, 0.08034580945968628, 0.10384327173233032, 0.12734079360961914, 0.15083831548690796, 0.174335777759552, 0.19783329963684082, 0.22133082151412964, 0.24482834339141846, 0.2683258652687073, 0.2918233275413513, 0.31532078981399536, 0.33881837129592896, 0.362315833568573, 0.3858134150505066, 0.40931087732315063, 0.4328083395957947, 0.45630592107772827, 0.4798033833503723, 0.5033009648323059, 0.52679842710495, 0.550295889377594, 0.5737934708595276, 0.5972909331321716, 0.6207883954048157, 0.6442859768867493, 0.6677834391593933, 0.6912809014320374, 0.714778482913971, 0.738275945186615, 0.7617735266685486, 0.7852709889411926]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.795865535736084, -0.7561646699905396, -0.7164638042449951, -0.6767628788948059, -0.6370620131492615, -0.597361147403717, -0.5576602220535278, -0.5179593563079834, -0.47825849056243896, -0.43855762481689453, -0.3988567292690277, -0.3591558337211609, -0.31945496797561646, -0.279754102230072, -0.2400531768798828, -0.20035231113433838, -0.16065144538879395, -0.12095057964324951, -0.08124971389770508, -0.04154878854751587, -0.0018479228019714355, 0.037852942943573, 0.07755386829376221, 0.11725473403930664, 0.15695559978485107, 0.1966564655303955, 0.23635733127593994, 0.2760581970214844, 0.31575918197631836, 0.3554600477218628, 0.3951609134674072, 0.43486177921295166, 0.4745626449584961, 0.5142635107040405, 0.553964376449585, 0.5936652421951294, 0.6333661079406738, 0.6730670928955078, 0.7127679586410522, 0.7524688243865967, 0.7921696901321411, 0.8318705558776855, 0.87157142162323, 0.9112722873687744, 0.9509732723236084, 0.9906741380691528, 1.0303750038146973, 1.0700758695602417, 1.1097767353057861, 1.1494776010513306, 1.189178466796875, 1.228879451751709, 1.2685801982879639, 1.3082811832427979, 1.3479819297790527, 1.3876829147338867, 1.4273838996887207, 1.4670846462249756, 1.5067856311798096, 1.5464863777160645, 1.5861873626708984, 1.6258881092071533, 1.6655890941619873, 1.7052898406982422, 1.7449908256530762]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 5.0, 1.0, 3.0, 7.0, 3.0, 6.0, 5.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0], "bins": [-2.129004955291748, -2.0804054737091064, -2.031806230545044, -1.9832067489624023, -1.9346073865890503, -1.8860079050064087, -1.8374085426330566, -1.788809061050415, -1.740209698677063, -1.691610336303711, -1.6430108547210693, -1.5944114923477173, -1.5458121299743652, -1.4972126483917236, -1.4486132860183716, -1.4000139236450195, -1.351414442062378, -1.3028150796890259, -1.2542157173156738, -1.2056162357330322, -1.1570168733596802, -1.1084175109863281, -1.0598180294036865, -1.0112186670303345, -0.9626193046569824, -0.9140198230743408, -0.8654204607009888, -0.8168210983276367, -0.7682216167449951, -0.7196222543716431, -0.671022891998291, -0.6224234104156494, -0.5738240480422974, -0.5252246856689453, -0.4766252040863037, -0.42802584171295166, -0.3794264793395996, -0.330826997756958, -0.28222763538360596, -0.2336282730102539, -0.1850287914276123, -0.13642942905426025, -0.0878300666809082, -0.0392305850982666, 0.009368896484375, 0.0579681396484375, 0.1065676212310791, 0.1551671028137207, 0.2037663459777832, 0.2523658275604248, 0.3009653091430664, 0.3495645523071289, 0.3981640338897705, 0.4467635154724121, 0.4953627586364746, 0.5439622402191162, 0.5925617218017578, 0.6411609649658203, 0.6897604465484619, 0.7383599281311035, 0.786959171295166, 0.8355586528778076, 0.8841581344604492, 0.9327573776245117, 0.9813568592071533]}, "_runtime": 15147.427913427353, "_timestamp": 1585585063.2725468, "_step": 198}
{"Episode reward": -99.82341256211787, "Episode length": 999, "Policy Loss": -0.001811188762076199, "Value Loss": 3.199512138962746e-05, "_runtime": 15149.023570537567, "_timestamp": 1585585064.8682039, "_step": 199}
{"Episode reward": -99.28025539527125, "Episode length": 999, "Policy Loss": -0.0015313674230128527, "Value Loss": 5.3968011343386024e-05, "_runtime": 15150.619529724121, "_timestamp": 1585585066.464163, "_step": 200}
{"Episode reward": -99.52383934532656, "Episode length": 999, "Policy Loss": -0.0018414546502754092, "Value Loss": 4.726630504592322e-05, "_runtime": 15152.260981559753, "_timestamp": 1585585068.105615, "_step": 201}
{"Episode reward": -99.70316374653686, "Episode length": 999, "Policy Loss": -0.0017845279071480036, "Value Loss": 4.174462810624391e-05, "_runtime": 15153.853510379791, "_timestamp": 1585585069.6981437, "_step": 202}
{"Episode reward": -99.30097779828017, "Episode length": 999, "Policy Loss": -0.0023997672833502293, "Value Loss": 6.97073046467267e-05, "_runtime": 15155.460618257523, "_timestamp": 1585585071.3052516, "_step": 203}
{"Episode reward": -99.08305520850594, "Episode length": 999, "Policy Loss": -0.001729907700791955, "Value Loss": 6.0011323512298986e-05, "_runtime": 15157.066383361816, "_timestamp": 1585585072.9110167, "_step": 204}
{"Episode reward": -99.3879968684978, "Episode length": 999, "Policy Loss": -0.002509595360606909, "Value Loss": 6.283065158640966e-05, "_runtime": 15158.670766592026, "_timestamp": 1585585074.5154, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0017500210087746382, "Value Loss": 6.282958929659799e-05, "_runtime": 15160.269189596176, "_timestamp": 1585585076.113823, "_step": 206}
{"Episode reward": -99.49517258847969, "Episode length": 999, "Policy Loss": -0.0021284972317516804, "Value Loss": 4.567948417388834e-05, "_runtime": 15161.86234664917, "_timestamp": 1585585077.70698, "_step": 207}
{"Episode reward": -99.06959144842467, "Episode length": 999, "Policy Loss": -0.0017443879041820765, "Value Loss": 7.255263335537165e-05, "_runtime": 15163.468849658966, "_timestamp": 1585585079.313483, "_step": 208}
{"Episode reward": -99.24271185451703, "Episode length": 999, "Policy Loss": -0.002411172492429614, "Value Loss": 6.208760169101879e-05, "_runtime": 15165.07773733139, "_timestamp": 1585585080.9223707, "_step": 209}
{"Episode reward": -98.97840638032662, "Episode length": 999, "Policy Loss": -0.0007967446581460536, "Value Loss": 6.874359678477049e-05, "_runtime": 15166.683891534805, "_timestamp": 1585585082.5285249, "_step": 210}
{"Episode reward": -98.79913149746098, "Episode length": 999, "Policy Loss": -0.0013843605993315578, "Value Loss": 8.50669966894202e-05, "_runtime": 15168.289863348007, "_timestamp": 1585585084.1344967, "_step": 211}
{"Episode reward": -99.80120316761078, "Episode length": 999, "Policy Loss": -0.002512355102226138, "Value Loss": 6.0770333220716566e-05, "_runtime": 15169.89686369896, "_timestamp": 1585585085.741497, "_step": 212}
{"Episode reward": -99.04177838287667, "Episode length": 999, "Policy Loss": -0.00014600293070543557, "Value Loss": 5.592945308308117e-05, "_runtime": 15171.49267244339, "_timestamp": 1585585087.3373058, "_step": 213}
{"Episode reward": -99.13623839729158, "Episode length": 999, "Policy Loss": -0.0022183693945407867, "Value Loss": 6.717904761899263e-05, "_runtime": 15173.095920801163, "_timestamp": 1585585088.9405541, "_step": 214}
{"Episode reward": -99.14342641751854, "Episode length": 999, "Policy Loss": -0.0015585204819217324, "Value Loss": 5.934227374382317e-05, "_runtime": 15174.705199480057, "_timestamp": 1585585090.5498328, "_step": 215}
{"Episode reward": -98.72030302576529, "Episode length": 999, "Policy Loss": -0.0018660109490156174, "Value Loss": 0.00010035454033641145, "_runtime": 15176.338028430939, "_timestamp": 1585585092.1826618, "_step": 216}
{"Episode reward": -99.2751923575305, "Episode length": 999, "Policy Loss": -0.001930541591718793, "Value Loss": 5.875064016436227e-05, "_runtime": 15177.92198753357, "_timestamp": 1585585093.7666209, "_step": 217}
{"Episode reward": -98.8641914460269, "Episode length": 999, "Policy Loss": 1.7774978914530948e-05, "Value Loss": 7.649677718291059e-05, "_runtime": 15179.517042398453, "_timestamp": 1585585095.3616757, "_step": 218}
{"Episode reward": -99.43182408039947, "Episode length": 999, "Policy Loss": -0.002184944925829768, "Value Loss": 5.0525643018772826e-05, "_runtime": 15181.112646341324, "_timestamp": 1585585096.9572797, "_step": 219}
{"Episode reward": -99.06114742266476, "Episode length": 999, "Policy Loss": -0.00023112578492145985, "Value Loss": 5.255383439362049e-05, "_runtime": 15182.703016757965, "_timestamp": 1585585098.54765, "_step": 220}
{"Episode reward": -99.60747017143083, "Episode length": 999, "Policy Loss": -0.0026522292755544186, "Value Loss": 5.43946007383056e-05, "_runtime": 15184.297591209412, "_timestamp": 1585585100.1422246, "_step": 221}
{"Episode reward": -98.98545373678517, "Episode length": 999, "Policy Loss": -0.0008258257294073701, "Value Loss": 6.874815153423697e-05, "_runtime": 15185.889614582062, "_timestamp": 1585585101.734248, "_step": 222}
{"Episode reward": -99.5474656871729, "Episode length": 999, "Policy Loss": -0.002273652935400605, "Value Loss": 5.8282628742745146e-05, "_runtime": 15187.47979092598, "_timestamp": 1585585103.3244243, "_step": 223}
{"Episode reward": -99.30673245777332, "Episode length": 999, "Policy Loss": -0.0023380371276289225, "Value Loss": 6.18867707089521e-05, "_runtime": 15189.084289550781, "_timestamp": 1585585104.928923, "_step": 224}
{"Episode reward": -99.03363037126668, "Episode length": 999, "Policy Loss": -0.0017718883464112878, "Value Loss": 7.448941323673353e-05, "_runtime": 15190.68467926979, "_timestamp": 1585585106.5293126, "_step": 225}
{"Episode reward": -99.15232188983622, "Episode length": 999, "Policy Loss": -0.000594183977227658, "Value Loss": 5.3282128646969795e-05, "_runtime": 15192.286974668503, "_timestamp": 1585585108.131608, "_step": 226}
{"Episode reward": -99.09856393893087, "Episode length": 999, "Policy Loss": -0.0018815243383869529, "Value Loss": 6.615121674258262e-05, "_runtime": 15193.88682460785, "_timestamp": 1585585109.731458, "_step": 227}
{"Episode reward": -99.14797492236977, "Episode length": 999, "Policy Loss": -0.0012445709435269237, "Value Loss": 5.3460284107131884e-05, "_runtime": 15195.490444898605, "_timestamp": 1585585111.3350782, "_step": 228}
{"Episode reward": -99.20524559026255, "Episode length": 999, "Policy Loss": -0.0010705686872825027, "Value Loss": 5.2840059652226046e-05, "_runtime": 15197.08812904358, "_timestamp": 1585585112.9327624, "_step": 229}
{"Episode reward": -99.1892838337225, "Episode length": 999, "Policy Loss": -0.0026037481147795916, "Value Loss": 7.14934867573902e-05, "_runtime": 15198.682117938995, "_timestamp": 1585585114.5267513, "_step": 230}
{"Episode reward": -98.94815587697404, "Episode length": 999, "Policy Loss": -0.0009818057296797633, "Value Loss": 7.658795948373154e-05, "_runtime": 15200.319937705994, "_timestamp": 1585585116.164571, "_step": 231}
{"Episode reward": -99.18290841575289, "Episode length": 999, "Policy Loss": -0.0016213033813983202, "Value Loss": 5.6890014093369246e-05, "_runtime": 15201.91492486, "_timestamp": 1585585117.7595582, "_step": 232}
{"Episode reward": -99.80959564803022, "Episode length": 999, "Policy Loss": -0.0016371274832636118, "Value Loss": 2.5995856049121358e-05, "_runtime": 15203.522212266922, "_timestamp": 1585585119.3668456, "_step": 233}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.00173848494887352, "Value Loss": 5.536319440579973e-05, "_runtime": 15205.126443386078, "_timestamp": 1585585120.9710767, "_step": 234}
{"Episode reward": -99.04169511375912, "Episode length": 999, "Policy Loss": -0.001863165176473558, "Value Loss": 7.821269537089393e-05, "_runtime": 15206.730658769608, "_timestamp": 1585585122.575292, "_step": 235}
{"Episode reward": -99.65455978732658, "Episode length": 999, "Policy Loss": -0.002080753445625305, "Value Loss": 4.2486230086069554e-05, "_runtime": 15208.328203678131, "_timestamp": 1585585124.172837, "_step": 236}
{"Episode reward": -98.96981819353319, "Episode length": 999, "Policy Loss": 0.0002531706995796412, "Value Loss": 6.660223880317062e-05, "_runtime": 15209.933460712433, "_timestamp": 1585585125.778094, "_step": 237}
{"Episode reward": -98.9543154086211, "Episode length": 999, "Policy Loss": -0.0014096209779381752, "Value Loss": 6.808290345361456e-05, "_runtime": 15211.538070678711, "_timestamp": 1585585127.382704, "_step": 238}
{"Episode reward": -99.31773023208333, "Episode length": 999, "Policy Loss": -0.0023245408665388823, "Value Loss": 5.899124516872689e-05, "_runtime": 15213.143542051315, "_timestamp": 1585585128.9881754, "_step": 239}
{"Episode reward": -99.01442909409347, "Episode length": 999, "Policy Loss": -0.0012910690857097507, "Value Loss": 6.957129517104477e-05, "_runtime": 15214.747629880905, "_timestamp": 1585585130.5922632, "_step": 240}
{"Episode reward": -99.37640193397134, "Episode length": 999, "Policy Loss": -0.0025313692167401314, "Value Loss": 7.696398824919015e-05, "_runtime": 15216.347047567368, "_timestamp": 1585585132.191681, "_step": 241}
{"Episode reward": -99.02465889738309, "Episode length": 999, "Policy Loss": -0.001508904853835702, "Value Loss": 7.427519449265674e-05, "_runtime": 15217.938180685043, "_timestamp": 1585585133.782814, "_step": 242}
{"Episode reward": -99.1713334497276, "Episode length": 999, "Policy Loss": -0.0013479794142767787, "Value Loss": 6.128729728516191e-05, "_runtime": 15219.53939962387, "_timestamp": 1585585135.384033, "_step": 243}
{"Episode reward": -99.82270852369929, "Episode length": 999, "Policy Loss": -0.0017794391606003046, "Value Loss": 2.5539740818203427e-05, "_runtime": 15221.127709627151, "_timestamp": 1585585136.972343, "_step": 244}
{"Episode reward": -98.99243962456536, "Episode length": 999, "Policy Loss": -0.0014576715184375644, "Value Loss": 7.280401769094169e-05, "_runtime": 15222.76444196701, "_timestamp": 1585585138.6090753, "_step": 245}
{"Episode reward": -99.31352839552187, "Episode length": 999, "Policy Loss": -0.00242693186737597, "Value Loss": 6.718242366332561e-05, "_runtime": 15224.358140945435, "_timestamp": 1585585140.2027743, "_step": 246}
{"Episode reward": -99.4830209863498, "Episode length": 999, "Policy Loss": -0.00135861337184906, "Value Loss": 4.1264011088060215e-05, "_runtime": 15225.950130224228, "_timestamp": 1585585141.7947636, "_step": 247}
{"Episode reward": -99.19772027518013, "Episode length": 999, "Policy Loss": -0.0012410467024892569, "Value Loss": 6.540976028190926e-05, "_runtime": 15227.554497241974, "_timestamp": 1585585143.3991306, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014035026542842388, "Value Loss": 2.989111999340821e-05, "_runtime": 15229.149513721466, "_timestamp": 1585585144.994147, "_step": 249}
{"Episode reward": -99.64389945321726, "Episode length": 999, "Policy Loss": -0.0018930126680061221, "Value Loss": 3.185933383065276e-05, "_runtime": 15230.751833677292, "_timestamp": 1585585146.596467, "_step": 250}
{"Episode reward": -99.52479990405666, "Episode length": 999, "Policy Loss": -0.0025603848043829203, "Value Loss": 5.8413974329596385e-05, "_runtime": 15232.355542898178, "_timestamp": 1585585148.2001762, "_step": 251}
{"Episode reward": -99.26635435098171, "Episode length": 999, "Policy Loss": -0.00044157152296975255, "Value Loss": 4.501430521486327e-05, "_runtime": 15233.957819223404, "_timestamp": 1585585149.8024526, "_step": 252}
{"Episode reward": -99.09144000350248, "Episode length": 999, "Policy Loss": -0.0013513624435290694, "Value Loss": 6.853555532870814e-05, "_runtime": 15235.561938285828, "_timestamp": 1585585151.4065716, "_step": 253}
{"Episode reward": -99.69345108663829, "Episode length": 999, "Policy Loss": -0.002022211905568838, "Value Loss": 3.597159593482502e-05, "_runtime": 15237.155571699142, "_timestamp": 1585585153.000205, "_step": 254}
{"Episode reward": -99.19177427505808, "Episode length": 999, "Policy Loss": -0.001860515563748777, "Value Loss": 5.905479338252917e-05, "_runtime": 15238.75770354271, "_timestamp": 1585585154.602337, "_step": 255}
{"Episode reward": -99.63355027736901, "Episode length": 999, "Policy Loss": -0.0018409686163067818, "Value Loss": 3.3118656574515626e-05, "_runtime": 15240.35988497734, "_timestamp": 1585585156.2045183, "_step": 256}
{"Episode reward": -99.74140669058806, "Episode length": 999, "Policy Loss": -0.0022742548026144505, "Value Loss": 6.244436372071505e-05, "_runtime": 15241.960589885712, "_timestamp": 1585585157.8052232, "_step": 257}
{"Episode reward": -99.44854598605939, "Episode length": 999, "Policy Loss": -0.0029733574483543634, "Value Loss": 5.729481563321315e-05, "_runtime": 15243.567676067352, "_timestamp": 1585585159.4123094, "_step": 258}
{"Episode reward": -99.35848108567879, "Episode length": 999, "Policy Loss": -0.0010437347227707505, "Value Loss": 4.710155917564407e-05, "_runtime": 15245.166224956512, "_timestamp": 1585585161.0108583, "_step": 259}
{"Episode reward": -98.94914406358046, "Episode length": 999, "Policy Loss": -0.0015295192133635283, "Value Loss": 5.955961751169525e-05, "_runtime": 15246.799377441406, "_timestamp": 1585585162.6440108, "_step": 260}
{"Episode reward": -99.49488754484739, "Episode length": 999, "Policy Loss": -0.002304845955222845, "Value Loss": 6.794905493734404e-05, "_runtime": 15248.404449939728, "_timestamp": 1585585164.2490833, "_step": 261}
{"Episode reward": -99.16659375431088, "Episode length": 999, "Policy Loss": -0.0013619564706459641, "Value Loss": 5.7093086070381105e-05, "_runtime": 15250.000130414963, "_timestamp": 1585585165.8447638, "_step": 262}
{"Episode reward": -99.06653426061621, "Episode length": 999, "Policy Loss": -0.001347322715446353, "Value Loss": 6.175594171509147e-05, "_runtime": 15251.609054803848, "_timestamp": 1585585167.4536881, "_step": 263}
{"Episode reward": -99.17434133257704, "Episode length": 999, "Policy Loss": -0.0022345902398228645, "Value Loss": 7.028422987787053e-05, "_runtime": 15253.207638263702, "_timestamp": 1585585169.0522716, "_step": 264}
{"Episode reward": -98.89649401978481, "Episode length": 999, "Policy Loss": -0.0010653265053406358, "Value Loss": 7.362580799963325e-05, "_runtime": 15254.802777767181, "_timestamp": 1585585170.647411, "_step": 265}
{"Episode reward": -99.63605078489384, "Episode length": 999, "Policy Loss": -0.0021118600852787495, "Value Loss": 3.4457447327440605e-05, "_runtime": 15256.398708820343, "_timestamp": 1585585172.2433422, "_step": 266}
{"Episode reward": -99.03653660549996, "Episode length": 999, "Policy Loss": -0.0018536188872531056, "Value Loss": 7.303703023353592e-05, "_runtime": 15257.992445707321, "_timestamp": 1585585173.837079, "_step": 267}
{"Episode reward": -99.75306257270316, "Episode length": 999, "Policy Loss": -0.001707939663901925, "Value Loss": 2.3384462110698223e-05, "_runtime": 15259.589314937592, "_timestamp": 1585585175.4339483, "_step": 268}
{"Episode reward": -99.14781349649334, "Episode length": 999, "Policy Loss": -0.0007448727265000343, "Value Loss": 5.447405783343129e-05, "_runtime": 15261.186457633972, "_timestamp": 1585585177.031091, "_step": 269}
{"Episode reward": -99.26930740585216, "Episode length": 999, "Policy Loss": -0.00013187089643906802, "Value Loss": 4.27716295234859e-05, "_runtime": 15262.795658826828, "_timestamp": 1585585178.6402922, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0015174037544056773, "Value Loss": 3.410846693441272e-05, "_runtime": 15264.376859426498, "_timestamp": 1585585180.2214928, "_step": 271}
{"Episode reward": -99.47305727908592, "Episode length": 999, "Policy Loss": -0.0012451636139303446, "Value Loss": 3.496558565529995e-05, "_runtime": 15265.977153301239, "_timestamp": 1585585181.8217866, "_step": 272}
{"Episode reward": -99.07391815985791, "Episode length": 999, "Policy Loss": 4.0901162719819695e-05, "Value Loss": 5.616283306153491e-05, "_runtime": 15267.573521852493, "_timestamp": 1585585183.4181552, "_step": 273}
{"Episode reward": -99.33078149434539, "Episode length": 999, "Policy Loss": -0.001337506459094584, "Value Loss": 4.138808435527608e-05, "_runtime": 15269.18072772026, "_timestamp": 1585585185.025361, "_step": 274}
{"Episode reward": -98.90981130707485, "Episode length": 999, "Policy Loss": -0.0007904392550699413, "Value Loss": 6.968528032302856e-05, "_runtime": 15270.825094223022, "_timestamp": 1585585186.6697276, "_step": 275}
{"Episode reward": -99.67548100214152, "Episode length": 999, "Policy Loss": -0.002094781957566738, "Value Loss": 4.13667548855301e-05, "_runtime": 15272.431040525436, "_timestamp": 1585585188.2756739, "_step": 276}
{"Episode reward": -99.06004779891418, "Episode length": 999, "Policy Loss": -0.0008317779866047204, "Value Loss": 6.253884930629283e-05, "_runtime": 15274.034227132797, "_timestamp": 1585585189.8788605, "_step": 277}
{"Episode reward": -99.28341898565579, "Episode length": 999, "Policy Loss": -0.0014360679779201746, "Value Loss": 4.879942935076542e-05, "_runtime": 15275.641484498978, "_timestamp": 1585585191.4861178, "_step": 278}
{"Episode reward": -99.3873797996655, "Episode length": 999, "Policy Loss": -0.001719175954349339, "Value Loss": 4.4002383219776675e-05, "_runtime": 15277.236952543259, "_timestamp": 1585585193.081586, "_step": 279}
{"Episode reward": -99.33227792670989, "Episode length": 999, "Policy Loss": -0.0020336152520030737, "Value Loss": 6.527921505039558e-05, "_runtime": 15278.82978796959, "_timestamp": 1585585194.6744213, "_step": 280}
{"Episode reward": -99.07838022282859, "Episode length": 999, "Policy Loss": -0.0004971904563717544, "Value Loss": 5.391281229094602e-05, "_runtime": 15280.435845851898, "_timestamp": 1585585196.2804792, "_step": 281}
{"Episode reward": -99.28788394107498, "Episode length": 999, "Policy Loss": -0.0021327268332242966, "Value Loss": 5.832126407767646e-05, "_runtime": 15282.030325174332, "_timestamp": 1585585197.8749585, "_step": 282}
{"Episode reward": -99.30524065070863, "Episode length": 999, "Policy Loss": -0.002095540054142475, "Value Loss": 6.675472832284868e-05, "_runtime": 15283.622508525848, "_timestamp": 1585585199.4671419, "_step": 283}
{"Episode reward": -99.46096422818201, "Episode length": 999, "Policy Loss": -0.001956204418092966, "Value Loss": 4.169825479038991e-05, "_runtime": 15285.219539880753, "_timestamp": 1585585201.0641732, "_step": 284}
{"Episode reward": -98.94665091298528, "Episode length": 999, "Policy Loss": -0.0010142452083528042, "Value Loss": 6.91504537826404e-05, "_runtime": 15286.796947479248, "_timestamp": 1585585202.6415808, "_step": 285}
{"Episode reward": -99.56248687789666, "Episode length": 999, "Policy Loss": -0.0017980493139475584, "Value Loss": 3.0382414479390718e-05, "_runtime": 15288.382122278214, "_timestamp": 1585585204.2267556, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014537477400153875, "Value Loss": 3.3777396311052144e-05, "_runtime": 15289.964239358902, "_timestamp": 1585585205.8088727, "_step": 287}
{"Episode reward": -98.96268589244947, "Episode length": 999, "Policy Loss": -0.001230503199622035, "Value Loss": 7.301283039851114e-05, "_runtime": 15291.55105304718, "_timestamp": 1585585207.3956864, "_step": 288}
{"Episode reward": -99.40845319888642, "Episode length": 999, "Policy Loss": -0.0022514760494232178, "Value Loss": 5.592150773736648e-05, "_runtime": 15293.13977432251, "_timestamp": 1585585208.9844077, "_step": 289}
{"Episode reward": -99.24025718088163, "Episode length": 999, "Policy Loss": -0.0016879437025636435, "Value Loss": 5.563157901633531e-05, "_runtime": 15294.767898797989, "_timestamp": 1585585210.6125321, "_step": 290}
{"Episode reward": -99.57154169624846, "Episode length": 999, "Policy Loss": -0.0018524972256273031, "Value Loss": 4.064329914399423e-05, "_runtime": 15296.346278190613, "_timestamp": 1585585212.1909115, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013297563418745995, "Value Loss": 3.052577449125238e-05, "_runtime": 15297.930305242538, "_timestamp": 1585585213.7749386, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013242895947769284, "Value Loss": 3.696410931297578e-05, "_runtime": 15299.507412195206, "_timestamp": 1585585215.3520455, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0013575736666098237, "Value Loss": 4.044052184326574e-05, "_runtime": 15301.095507383347, "_timestamp": 1585585216.9401407, "_step": 294}
{"Episode reward": -99.47821881116757, "Episode length": 999, "Policy Loss": -0.002346753142774105, "Value Loss": 6.722413672832772e-05, "_runtime": 15302.692753076553, "_timestamp": 1585585218.5373864, "_step": 295}
{"Episode reward": -99.01445358504088, "Episode length": 999, "Policy Loss": -0.0005629449733532965, "Value Loss": 6.351606862153858e-05, "_runtime": 15304.275033712387, "_timestamp": 1585585220.119667, "_step": 296}
{"Episode reward": -99.55928712047736, "Episode length": 999, "Policy Loss": -0.002158115617930889, "Value Loss": 4.5908120227977633e-05, "_runtime": 15305.867052078247, "_timestamp": 1585585221.7116854, "_step": 297}
{"Episode reward": -99.21860309448296, "Episode length": 999, "Policy Loss": 0.0003660286602098495, "Value Loss": 4.04692291340325e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541, 5.75624942779541]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-6.498578071594238, -6.308074951171875, -6.11757230758667, -5.927069187164307, -5.736566066741943, -5.546063423156738, -5.355560302734375, -5.165057182312012, -4.974554538726807, -4.784051418304443, -4.593548774719238, -4.403045654296875, -4.212542533874512, -4.022039413452148, -3.8315367698669434, -3.64103364944458, -3.450530767440796, -3.2600278854370117, -3.0695247650146484, -2.8790218830108643, -2.68851900100708, -2.498015880584717, -2.3075132369995117, -2.1170101165771484, -1.9265069961547852, -1.73600435256958, -1.5455012321472168, -1.3549981117248535, -1.1644954681396484, -0.9739923477172852, -0.7834892272949219, -0.5929865837097168, -0.4024834632873535, -0.21198034286499023, -0.021477699279785156, 0.16902542114257812, 0.3595285415649414, 0.5500311851501465, 0.7405343055725098, 0.931037425994873, 1.1215400695800781, 1.3120431900024414, 1.5025463104248047, 1.693049430847168, 1.8835515975952148, 2.074054718017578, 2.2645578384399414, 2.4550609588623047, 2.645564079284668, 2.8360671997070312, 3.026569366455078, 3.2170724868774414, 3.4075756072998047, 3.598078727722168, 3.7885818481445312, 3.9790849685668945, 4.169587135314941, 4.360090255737305, 4.550593376159668, 4.741096496582031, 4.9315996170043945, 5.122102737426758, 5.312604904174805, 5.503108024597168, 5.693611145019531]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 2.0], "bins": [-2.956044912338257, -2.9099159240722656, -2.8637869358062744, -2.8176581859588623, -2.771529197692871, -2.72540020942688, -2.6792712211608887, -2.6331422328948975, -2.5870134830474854, -2.540884494781494, -2.494755506515503, -2.4486265182495117, -2.4024977684020996, -2.3563687801361084, -2.310239791870117, -2.264110803604126, -2.2179818153381348, -2.1718530654907227, -2.1257240772247314, -2.0795950889587402, -2.033466100692749, -1.9873371124267578, -1.9412082433700562, -1.895079255104065, -1.8489503860473633, -1.802821397781372, -1.7566925287246704, -1.7105635404586792, -1.664434552192688, -1.6183056831359863, -1.5721766948699951, -1.5260478258132935, -1.4799188375473022, -1.433789849281311, -1.3876609802246094, -1.3415319919586182, -1.2954031229019165, -1.2492741346359253, -1.203145146369934, -1.1570162773132324, -1.1108872890472412, -1.0647584199905396, -1.0186294317245483, -0.9725004434585571, -0.9263715744018555, -0.8802425861358643, -0.834113597869873, -0.7879848480224609, -0.7418558597564697, -0.6957268714904785, -0.6495978832244873, -0.6034688949584961, -0.557340145111084, -0.5112111568450928, -0.46508216857910156, -0.41895318031311035, -0.37282419204711914, -0.32669544219970703, -0.2805664539337158, -0.2344374656677246, -0.1883084774017334, -0.1421794891357422, -0.09605073928833008, -0.04992175102233887, -0.0037927627563476562]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 5.0, 5.0, 6.0, 8.0, 9.0, 5.0, 8.0, 19.0, 56.0, 179.0, 80.0, 23.0, 13.0, 12.0, 11.0, 7.0, 3.0, 5.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-2.2762207984924316, -2.213909864425659, -2.1515986919403076, -2.089287757873535, -2.0269765853881836, -1.9646656513214111, -1.9023545980453491, -1.840043544769287, -1.777732491493225, -1.715421438217163, -1.653110384941101, -1.590799331665039, -1.5284883975982666, -1.466177225112915, -1.4038662910461426, -1.3415552377700806, -1.2792441844940186, -1.2169331312179565, -1.1546220779418945, -1.0923110246658325, -1.0299999713897705, -0.967689037322998, -0.905377984046936, -0.843066930770874, -0.780755877494812, -0.71844482421875, -0.656133770942688, -0.593822717666626, -0.5315117835998535, -0.4692007303237915, -0.4068896770477295, -0.3445786237716675, -0.28226757049560547, -0.219956636428833, -0.15764546394348145, -0.09533452987670898, -0.03302335739135742, 0.02928757667541504, 0.0915987491607666, 0.15390968322753906, 0.21622085571289062, 0.2785317897796631, 0.34084272384643555, 0.4031538963317871, 0.46546483039855957, 0.5277760028839111, 0.5900869369506836, 0.6523981094360352, 0.7147090435028076, 0.7770199775695801, 0.8393311500549316, 0.9016420841217041, 0.9639532566070557, 1.0262641906738281, 1.0885753631591797, 1.1508862972259521, 1.2131972312927246, 1.2755084037780762, 1.3378193378448486, 1.4001305103302002, 1.4624414443969727, 1.5247526168823242, 1.5870635509490967, 1.6493747234344482, 1.7116856575012207]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-5.795581340789795, -5.6572957038879395, -5.519010543823242, -5.380724906921387, -5.242439270019531, -5.104153633117676, -4.9658684730529785, -4.827582836151123, -4.689297676086426, -4.55101203918457, -4.412726402282715, -4.274440765380859, -4.136155605316162, -3.9978699684143066, -3.8595845699310303, -3.721298933029175, -3.5830135345458984, -3.444728136062622, -3.3064424991607666, -3.1681571006774902, -3.0298714637756348, -2.8915860652923584, -2.753300666809082, -2.6150150299072266, -2.47672963142395, -2.338444232940674, -2.2001585960388184, -2.061873197555542, -1.9235877990722656, -1.7853021621704102, -1.6470165252685547, -1.5087313652038574, -1.370445728302002, -1.2321600914001465, -1.0938749313354492, -0.9555892944335938, -0.8173036575317383, -0.679018497467041, -0.5407328605651855, -0.4024472236633301, -0.2641615867614746, -0.12587642669677734, 0.012409210205078125, 0.1506948471069336, 0.28898000717163086, 0.42726564407348633, 0.5655512809753418, 0.7038364410400391, 0.8421220779418945, 0.98040771484375, 1.1186928749084473, 1.2569785118103027, 1.3952641487121582, 1.5335493087768555, 1.671834945678711, 1.8101205825805664, 1.9484057426452637, 2.086691379547119, 2.2249770164489746, 2.36326265335083, 2.5015482902526855, 2.6398329734802246, 2.77811861038208, 2.9164042472839355, 3.054689884185791]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 4.0, 8.0, 7.0, 7.0, 4.0, 7.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.147109031677246, -3.0042364597320557, -2.8613641262054443, -2.718491554260254, -2.5756192207336426, -2.432746648788452, -2.2898740768432617, -2.1470017433166504, -2.00412917137146, -1.861256718635559, -1.7183842658996582, -1.5755116939544678, -1.432639241218567, -1.289766788482666, -1.1468942165374756, -1.0040218830108643, -0.8611493110656738, -0.7182767391204834, -0.5754044055938721, -0.43253183364868164, -0.2896595001220703, -0.14678692817687988, -0.003914356231689453, 0.13895797729492188, 0.2818305492401123, 0.42470312118530273, 0.5675754547119141, 0.7104480266571045, 0.8533205986022949, 0.9961929321289062, 1.1390652656555176, 1.281938076019287, 1.4248104095458984, 1.5676827430725098, 1.7105555534362793, 1.8534278869628906, 1.996300220489502, 2.1391730308532715, 2.282045364379883, 2.424917697906494, 2.5677900314331055, 2.710662841796875, 2.8535351753234863, 2.9964075088500977, 3.139280319213867, 3.2821526527404785, 3.42502498626709, 3.5678977966308594, 3.7107701301574707, 3.853642463684082, 3.9965152740478516, 4.139387607574463, 4.282259941101074, 4.425132751464844, 4.568005084991455, 4.710877418518066, 4.853750228881836, 4.996622085571289, 5.139494895935059, 5.282367706298828, 5.425239562988281, 5.568112373352051, 5.71098518371582, 5.853857040405273, 5.996729850769043]}, "_runtime": 15307.45363664627, "_timestamp": 1585585223.29827, "_step": 298}
{"Episode reward": -99.48610743788967, "Episode length": 999, "Policy Loss": -0.0008208189392462373, "Value Loss": 3.1487794331042096e-05, "_runtime": 15309.031042575836, "_timestamp": 1585585224.875676, "_step": 299}
{"Episode reward": -99.31032311182163, "Episode length": 999, "Policy Loss": -0.0025455697905272245, "Value Loss": 5.698741733795032e-05, "_runtime": 15310.610004425049, "_timestamp": 1585585226.4546378, "_step": 300}
{"Episode reward": -99.20261319376789, "Episode length": 999, "Policy Loss": -0.0016997812781482935, "Value Loss": 5.248970410320908e-05, "_runtime": 15312.180783033371, "_timestamp": 1585585228.0254164, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014029450248926878, "Value Loss": 3.220906728529371e-05, "_runtime": 15313.766497850418, "_timestamp": 1585585229.6111312, "_step": 302}
{"Episode reward": -99.22508291042729, "Episode length": 999, "Policy Loss": -2.050501097983215e-05, "Value Loss": 5.086233068141155e-05, "_runtime": 15315.360712766647, "_timestamp": 1585585231.205346, "_step": 303}
{"Episode reward": -99.15743545885049, "Episode length": 999, "Policy Loss": -0.0010469509288668633, "Value Loss": 5.4350261052604765e-05, "_runtime": 15316.94004201889, "_timestamp": 1585585232.7846754, "_step": 304}
{"Episode reward": -98.95685263963483, "Episode length": 999, "Policy Loss": -0.001962536247447133, "Value Loss": 7.868641841923818e-05, "_runtime": 15318.553121566772, "_timestamp": 1585585234.397755, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0015145459910854697, "Value Loss": 3.689955337904394e-05, "_runtime": 15320.133942842484, "_timestamp": 1585585235.9785762, "_step": 306}
{"Episode reward": -98.9249466476874, "Episode length": 999, "Policy Loss": -0.0012306678108870983, "Value Loss": 7.274294330272824e-05, "_runtime": 15321.724972724915, "_timestamp": 1585585237.569606, "_step": 307}
{"Episode reward": -99.18096420073554, "Episode length": 999, "Policy Loss": -0.0012065835762768984, "Value Loss": 4.577972867991775e-05, "_runtime": 15323.316376924515, "_timestamp": 1585585239.1610103, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001224402105435729, "Value Loss": 1.8440541680320166e-05, "_runtime": 15324.902299642563, "_timestamp": 1585585240.746933, "_step": 309}
{"Episode reward": -99.47913069113224, "Episode length": 999, "Policy Loss": -0.0019795040134340525, "Value Loss": 4.015057493234053e-05, "_runtime": 15326.488312244415, "_timestamp": 1585585242.3329456, "_step": 310}
{"Episode reward": -99.1626399555927, "Episode length": 999, "Policy Loss": -0.001092242426238954, "Value Loss": 5.7026376452995464e-05, "_runtime": 15328.081185817719, "_timestamp": 1585585243.9258192, "_step": 311}
{"Episode reward": -99.49753019075932, "Episode length": 999, "Policy Loss": -0.0014608100755140185, "Value Loss": 3.0655995942652225e-05, "_runtime": 15329.659362792969, "_timestamp": 1585585245.5039961, "_step": 312}
{"Episode reward": -99.54221242025828, "Episode length": 999, "Policy Loss": -0.0020094676874578, "Value Loss": 3.8534177292604e-05, "_runtime": 15331.248379468918, "_timestamp": 1585585247.0930128, "_step": 313}
{"Episode reward": -99.47604757307445, "Episode length": 999, "Policy Loss": -0.0013722670264542103, "Value Loss": 3.268707951065153e-05, "_runtime": 15332.83210682869, "_timestamp": 1585585248.6767402, "_step": 314}
{"Episode reward": -99.32916878488537, "Episode length": 999, "Policy Loss": -0.000708331645000726, "Value Loss": 3.536388248903677e-05, "_runtime": 15334.420595169067, "_timestamp": 1585585250.2652285, "_step": 315}
{"Episode reward": -99.27436349177577, "Episode length": 999, "Policy Loss": -0.0019435936119407415, "Value Loss": 5.540496567846276e-05, "_runtime": 15336.009122371674, "_timestamp": 1585585251.8537557, "_step": 316}
{"Episode reward": -98.87379455732379, "Episode length": 999, "Policy Loss": -0.0012886193580925465, "Value Loss": 7.657802052563056e-05, "_runtime": 15337.597332000732, "_timestamp": 1585585253.4419653, "_step": 317}
{"Episode reward": -99.45033037706615, "Episode length": 999, "Policy Loss": -0.0019563196692615747, "Value Loss": 5.6578566727694124e-05, "_runtime": 15339.25773525238, "_timestamp": 1585585255.1023686, "_step": 318}
{"Episode reward": -99.07339126429909, "Episode length": 999, "Policy Loss": -0.0015022505540400743, "Value Loss": 6.89081207383424e-05, "_runtime": 15340.924741983414, "_timestamp": 1585585256.7693753, "_step": 319}
{"Episode reward": -99.11912500344918, "Episode length": 999, "Policy Loss": -0.000500706082675606, "Value Loss": 5.469519965117797e-05, "_runtime": 15342.529178619385, "_timestamp": 1585585258.373812, "_step": 320}
{"Episode reward": -99.03830024726439, "Episode length": 999, "Policy Loss": -0.0005502658896148205, "Value Loss": 6.487604696303606e-05, "_runtime": 15344.122191429138, "_timestamp": 1585585259.9668248, "_step": 321}
{"Episode reward": -99.16757525985408, "Episode length": 999, "Policy Loss": -0.00067460275022313, "Value Loss": 4.5606077037518844e-05, "_runtime": 15345.72481250763, "_timestamp": 1585585261.5694458, "_step": 322}
{"Episode reward": -99.10080308136341, "Episode length": 999, "Policy Loss": -0.0015893090749159455, "Value Loss": 6.777073576813564e-05, "_runtime": 15347.33134484291, "_timestamp": 1585585263.1759782, "_step": 323}
{"Episode reward": -99.2189432109324, "Episode length": 999, "Policy Loss": -0.0012964506167918444, "Value Loss": 5.656568828271702e-05, "_runtime": 15348.923951387405, "_timestamp": 1585585264.7685847, "_step": 324}
{"Episode reward": -99.02407611854309, "Episode length": 999, "Policy Loss": -0.0012069647200405598, "Value Loss": 6.895071419421583e-05, "_runtime": 15350.515199422836, "_timestamp": 1585585266.3598328, "_step": 325}
{"Episode reward": -99.13395396249587, "Episode length": 999, "Policy Loss": -0.0007447632378898561, "Value Loss": 5.6781773309921846e-05, "_runtime": 15352.111977815628, "_timestamp": 1585585267.9566112, "_step": 326}
{"Episode reward": -99.04765320052171, "Episode length": 999, "Policy Loss": -0.0012458667624741793, "Value Loss": 6.183447112562135e-05, "_runtime": 15353.706167697906, "_timestamp": 1585585269.550801, "_step": 327}
{"Episode reward": -99.13795121744396, "Episode length": 999, "Policy Loss": -0.0011083072749897838, "Value Loss": 6.590055272681639e-05, "_runtime": 15355.289216041565, "_timestamp": 1585585271.1338494, "_step": 328}
{"Episode reward": -99.24895095593311, "Episode length": 999, "Policy Loss": -0.0015171091072261333, "Value Loss": 5.612198947346769e-05, "_runtime": 15356.896066188812, "_timestamp": 1585585272.7406995, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007426331285387278, "Value Loss": 2.1553520127781667e-05, "_runtime": 15358.503903388977, "_timestamp": 1585585274.3485367, "_step": 330}
{"Episode reward": -99.29886664062288, "Episode length": 999, "Policy Loss": -0.0018820413388311863, "Value Loss": 5.499667167896405e-05, "_runtime": 15360.084456682205, "_timestamp": 1585585275.92909, "_step": 331}
{"Episode reward": -99.75860696979822, "Episode length": 999, "Policy Loss": -0.0012003863230347633, "Value Loss": 1.9878663806593977e-05, "_runtime": 15361.689934968948, "_timestamp": 1585585277.5345683, "_step": 332}
{"Episode reward": -99.23965576936044, "Episode length": 999, "Policy Loss": -0.0010082325898110867, "Value Loss": 4.415719013195485e-05, "_runtime": 15363.28772687912, "_timestamp": 1585585279.1323602, "_step": 333}
{"Episode reward": -99.27982133940745, "Episode length": 999, "Policy Loss": -0.0018459247658029199, "Value Loss": 5.77918290218804e-05, "_runtime": 15364.917190551758, "_timestamp": 1585585280.761824, "_step": 334}
{"Episode reward": -99.72931309444228, "Episode length": 999, "Policy Loss": -0.0013077111216261983, "Value Loss": 3.852691952488385e-05, "_runtime": 15366.512122869492, "_timestamp": 1585585282.3567562, "_step": 335}
{"Episode reward": -99.20014287575758, "Episode length": 999, "Policy Loss": -0.000723129662219435, "Value Loss": 5.147002957528457e-05, "_runtime": 15368.11747765541, "_timestamp": 1585585283.962111, "_step": 336}
{"Episode reward": -99.78374982972072, "Episode length": 999, "Policy Loss": -0.000931481015868485, "Value Loss": 1.7977969037019648e-05, "_runtime": 15369.719670057297, "_timestamp": 1585585285.5643034, "_step": 337}
{"Episode reward": -99.05910029497102, "Episode length": 999, "Policy Loss": -0.00045838195364922285, "Value Loss": 5.610440712189302e-05, "_runtime": 15371.326035499573, "_timestamp": 1585585287.1706688, "_step": 338}
{"Episode reward": -99.54130919901387, "Episode length": 999, "Policy Loss": -0.0016200026730075479, "Value Loss": 4.182917109574191e-05, "_runtime": 15372.930186271667, "_timestamp": 1585585288.7748196, "_step": 339}
{"Episode reward": -99.4581619244121, "Episode length": 999, "Policy Loss": -0.001727151102386415, "Value Loss": 4.7292403905885294e-05, "_runtime": 15374.519674062729, "_timestamp": 1585585290.3643074, "_step": 340}
{"Episode reward": -99.43980781770908, "Episode length": 999, "Policy Loss": -0.0018406747840344906, "Value Loss": 4.314376928959973e-05, "_runtime": 15376.125078439713, "_timestamp": 1585585291.9697118, "_step": 341}
{"Episode reward": -99.43830668740088, "Episode length": 999, "Policy Loss": -0.0017644681502133608, "Value Loss": 4.388839806779288e-05, "_runtime": 15377.749582529068, "_timestamp": 1585585293.5942159, "_step": 342}
{"Episode reward": -99.64124552728575, "Episode length": 999, "Policy Loss": -0.0015773674240335822, "Value Loss": 3.1209194276016206e-05, "_runtime": 15379.408628940582, "_timestamp": 1585585295.2532623, "_step": 343}
{"Episode reward": -99.19201357337252, "Episode length": 999, "Policy Loss": -0.0018540376331657171, "Value Loss": 5.6961802329169586e-05, "_runtime": 15381.041740894318, "_timestamp": 1585585296.8863742, "_step": 344}
{"Episode reward": -98.97275837316406, "Episode length": 999, "Policy Loss": -0.0009273356990888715, "Value Loss": 6.136596493888646e-05, "_runtime": 15382.662647485733, "_timestamp": 1585585298.5072808, "_step": 345}
{"Episode reward": -99.09247139817326, "Episode length": 999, "Policy Loss": -0.0013827575603500009, "Value Loss": 5.494838114827871e-05, "_runtime": 15384.26867055893, "_timestamp": 1585585300.113304, "_step": 346}
{"Episode reward": -99.15641252753444, "Episode length": 999, "Policy Loss": -0.0015951547538861632, "Value Loss": 5.572351437876932e-05, "_runtime": 15385.894713163376, "_timestamp": 1585585301.7393465, "_step": 347}
{"Episode reward": -99.12335392764169, "Episode length": 999, "Policy Loss": -0.0011905970750376582, "Value Loss": 5.8321820688433945e-05, "_runtime": 15387.513701915741, "_timestamp": 1585585303.3583353, "_step": 348}
{"Episode reward": -99.03170318219486, "Episode length": 999, "Policy Loss": -0.0017402897356078029, "Value Loss": 6.997125456109643e-05, "_runtime": 15389.166595220566, "_timestamp": 1585585305.0112286, "_step": 349}
{"Episode reward": -98.99322638404522, "Episode length": 999, "Policy Loss": -0.0007408910314552486, "Value Loss": 7.637272210558876e-05, "_runtime": 15390.791564702988, "_timestamp": 1585585306.636198, "_step": 350}
{"Episode reward": -98.91690740950207, "Episode length": 999, "Policy Loss": -0.0014074600767344236, "Value Loss": 7.064237433951348e-05, "_runtime": 15392.390418291092, "_timestamp": 1585585308.2350516, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0009428234770894051, "Value Loss": 2.424272315693088e-05, "_runtime": 15393.989307641983, "_timestamp": 1585585309.833941, "_step": 352}
{"Episode reward": -99.34643884337726, "Episode length": 999, "Policy Loss": -0.0016409946838393807, "Value Loss": 4.708064807346091e-05, "_runtime": 15395.592019557953, "_timestamp": 1585585311.436653, "_step": 353}
{"Episode reward": -98.89803994261827, "Episode length": 999, "Policy Loss": -0.001108081778511405, "Value Loss": 7.261839346028864e-05, "_runtime": 15397.181648492813, "_timestamp": 1585585313.0262818, "_step": 354}
{"Episode reward": -99.42923472961438, "Episode length": 999, "Policy Loss": -0.0018381262198090553, "Value Loss": 4.699320197687484e-05, "_runtime": 15398.782815694809, "_timestamp": 1585585314.627449, "_step": 355}
{"Episode reward": -99.07030403416161, "Episode length": 999, "Policy Loss": -0.001837943447753787, "Value Loss": 7.672471110709012e-05, "_runtime": 15400.375067472458, "_timestamp": 1585585316.2197008, "_step": 356}
{"Episode reward": -99.46410723075832, "Episode length": 999, "Policy Loss": -0.0013536005280911922, "Value Loss": 3.598221519496292e-05, "_runtime": 15401.966830968857, "_timestamp": 1585585317.8114643, "_step": 357}
{"Episode reward": -99.78536662205738, "Episode length": 999, "Policy Loss": -0.0007968184654600918, "Value Loss": 1.580692332936451e-05, "_runtime": 15403.548372983932, "_timestamp": 1585585319.3930063, "_step": 358}
{"Episode reward": -98.9820969225687, "Episode length": 999, "Policy Loss": -0.0011046465951949358, "Value Loss": 7.65770164434798e-05, "_runtime": 15405.129769802094, "_timestamp": 1585585320.9744031, "_step": 359}
{"Episode reward": -99.65662433720176, "Episode length": 999, "Policy Loss": -0.0014333981089293957, "Value Loss": 2.3486183636123314e-05, "_runtime": 15406.72206735611, "_timestamp": 1585585322.5667007, "_step": 360}
{"Episode reward": -99.28318346541361, "Episode length": 999, "Policy Loss": -0.0006920561427250504, "Value Loss": 3.826405372819863e-05, "_runtime": 15408.300493478775, "_timestamp": 1585585324.1451268, "_step": 361}
{"Episode reward": -99.68070114601203, "Episode length": 999, "Policy Loss": -0.001117075327783823, "Value Loss": 2.774481981759891e-05, "_runtime": 15409.88431596756, "_timestamp": 1585585325.7289493, "_step": 362}
{"Episode reward": -99.26427662835711, "Episode length": 999, "Policy Loss": -0.0009423814481124282, "Value Loss": 4.4402659113984555e-05, "_runtime": 15411.466100215912, "_timestamp": 1585585327.3107336, "_step": 363}
{"Episode reward": -99.02012642097274, "Episode length": 999, "Policy Loss": -0.002165185520425439, "Value Loss": 6.846014002803713e-05, "_runtime": 15413.074361562729, "_timestamp": 1585585328.918995, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0010380987077951431, "Value Loss": 1.9449509636615403e-05, "_runtime": 15414.659477472305, "_timestamp": 1585585330.5041108, "_step": 365}
{"Episode reward": -99.5000873554346, "Episode length": 999, "Policy Loss": -0.001019216957502067, "Value Loss": 3.487923459033482e-05, "_runtime": 15416.243865966797, "_timestamp": 1585585332.0884993, "_step": 366}
{"Episode reward": -99.48551744713596, "Episode length": 999, "Policy Loss": -0.001527872052974999, "Value Loss": 3.6194422136759385e-05, "_runtime": 15417.823124885559, "_timestamp": 1585585333.6677582, "_step": 367}
{"Episode reward": -99.38065991104042, "Episode length": 999, "Policy Loss": -0.0020516731310635805, "Value Loss": 5.203422188060358e-05, "_runtime": 15419.404065132141, "_timestamp": 1585585335.2486985, "_step": 368}
{"Episode reward": -99.52251230824012, "Episode length": 999, "Policy Loss": -0.001756765996105969, "Value Loss": 3.9959795685717836e-05, "_runtime": 15420.995764255524, "_timestamp": 1585585336.8403976, "_step": 369}
{"Episode reward": -99.53913469315073, "Episode length": 999, "Policy Loss": -0.0015326074790209532, "Value Loss": 3.91262183256913e-05, "_runtime": 15422.590237617493, "_timestamp": 1585585338.434871, "_step": 370}
{"Episode reward": -99.25938450720501, "Episode length": 999, "Policy Loss": -0.0009541508043184876, "Value Loss": 4.8526730097364634e-05, "_runtime": 15424.169842720032, "_timestamp": 1585585340.014476, "_step": 371}
{"Episode reward": -99.221289733268, "Episode length": 999, "Policy Loss": -0.0013403932098299265, "Value Loss": 5.480004983837716e-05, "_runtime": 15425.761127710342, "_timestamp": 1585585341.605761, "_step": 372}
{"Episode reward": -99.02660155543622, "Episode length": 999, "Policy Loss": -0.0008203365723602474, "Value Loss": 5.4906424338696525e-05, "_runtime": 15427.350274801254, "_timestamp": 1585585343.1949081, "_step": 373}
{"Episode reward": -99.67345592869472, "Episode length": 999, "Policy Loss": -0.0013012901181355119, "Value Loss": 2.048707210633438e-05, "_runtime": 15428.93240237236, "_timestamp": 1585585344.7770357, "_step": 374}
{"Episode reward": -98.85656002140014, "Episode length": 999, "Policy Loss": -0.0018583853961899877, "Value Loss": 8.184985927073285e-05, "_runtime": 15430.525590896606, "_timestamp": 1585585346.3702242, "_step": 375}
{"Episode reward": -99.48452515447731, "Episode length": 999, "Policy Loss": -0.0017416792688891292, "Value Loss": 4.195884321234189e-05, "_runtime": 15432.105695724487, "_timestamp": 1585585347.950329, "_step": 376}
{"Episode reward": -99.27788592215254, "Episode length": 999, "Policy Loss": -0.0018342197872698307, "Value Loss": 4.8307996621588245e-05, "_runtime": 15433.713600873947, "_timestamp": 1585585349.5582342, "_step": 377}
{"Episode reward": -99.52619703426708, "Episode length": 999, "Policy Loss": -0.0019449836108833551, "Value Loss": 4.186206933809444e-05, "_runtime": 15435.33480811119, "_timestamp": 1585585351.1794415, "_step": 378}
{"Episode reward": -99.64046179209419, "Episode length": 999, "Policy Loss": -0.0014284525532275438, "Value Loss": 2.151360058633145e-05, "_runtime": 15436.915862560272, "_timestamp": 1585585352.760496, "_step": 379}
{"Episode reward": -99.78466078712647, "Episode length": 999, "Policy Loss": -0.0008840076043270528, "Value Loss": 1.228590372193139e-05, "_runtime": 15438.490270614624, "_timestamp": 1585585354.334904, "_step": 380}
{"Episode reward": -99.03943800419613, "Episode length": 999, "Policy Loss": -0.0006261178641580045, "Value Loss": 6.206176476553082e-05, "_runtime": 15440.069641590118, "_timestamp": 1585585355.914275, "_step": 381}
{"Episode reward": -99.28493654108587, "Episode length": 999, "Policy Loss": -0.0019834658596664667, "Value Loss": 4.4473297748481855e-05, "_runtime": 15441.638416528702, "_timestamp": 1585585357.4830499, "_step": 382}
{"Episode reward": -99.34979340665762, "Episode length": 999, "Policy Loss": -0.0016570340376347303, "Value Loss": 4.7021218051668257e-05, "_runtime": 15443.219406604767, "_timestamp": 1585585359.06404, "_step": 383}
{"Episode reward": -98.88785450449528, "Episode length": 999, "Policy Loss": -0.0012587152887135744, "Value Loss": 7.738679414615035e-05, "_runtime": 15444.802241563797, "_timestamp": 1585585360.646875, "_step": 384}
{"Episode reward": -99.0501354351477, "Episode length": 999, "Policy Loss": -0.001445174217224121, "Value Loss": 6.659312202828005e-05, "_runtime": 15446.380957365036, "_timestamp": 1585585362.2255907, "_step": 385}
{"Episode reward": -99.33798603900692, "Episode length": 999, "Policy Loss": -0.0016216137446463108, "Value Loss": 4.615135912899859e-05, "_runtime": 15447.954635858536, "_timestamp": 1585585363.7992692, "_step": 386}
{"Episode reward": -99.34961421417705, "Episode length": 999, "Policy Loss": -0.0019428192172199488, "Value Loss": 4.80465023429133e-05, "_runtime": 15449.525888204575, "_timestamp": 1585585365.3705215, "_step": 387}
{"Episode reward": -99.24620847505112, "Episode length": 999, "Policy Loss": -0.0018012236105278134, "Value Loss": 5.66967464692425e-05, "_runtime": 15451.092539310455, "_timestamp": 1585585366.9371727, "_step": 388}
{"Episode reward": -99.0166630921258, "Episode length": 999, "Policy Loss": -0.0007406394579447806, "Value Loss": 6.405701424228027e-05, "_runtime": 15452.686477422714, "_timestamp": 1585585368.5311108, "_step": 389}
{"Episode reward": -99.31583889206867, "Episode length": 999, "Policy Loss": -0.00030269628041423857, "Value Loss": 4.327595524955541e-05, "_runtime": 15454.259920835495, "_timestamp": 1585585370.1045542, "_step": 390}
{"Episode reward": -99.7873964507444, "Episode length": 999, "Policy Loss": -0.0010738717392086983, "Value Loss": 1.3206027688283939e-05, "_runtime": 15455.841251373291, "_timestamp": 1585585371.6858847, "_step": 391}
{"Episode reward": -99.78352510171113, "Episode length": 999, "Policy Loss": -0.0010018222965300083, "Value Loss": 1.4351612662721891e-05, "_runtime": 15457.423899173737, "_timestamp": 1585585373.2685325, "_step": 392}
{"Episode reward": -99.71878507332525, "Episode length": 999, "Policy Loss": -0.0012081011664122343, "Value Loss": 2.4957869754871354e-05, "_runtime": 15459.053881645203, "_timestamp": 1585585374.898515, "_step": 393}
{"Episode reward": -99.69451870462625, "Episode length": 999, "Policy Loss": -0.0008913673809729517, "Value Loss": 1.3921140634920448e-05, "_runtime": 15460.644073486328, "_timestamp": 1585585376.4887068, "_step": 394}
{"Episode reward": -98.94642986264982, "Episode length": 999, "Policy Loss": -0.001552373287267983, "Value Loss": 7.904853555373847e-05, "_runtime": 15462.236558437347, "_timestamp": 1585585378.0811918, "_step": 395}
{"Episode reward": -98.92606479671983, "Episode length": 999, "Policy Loss": -0.0014694564742967486, "Value Loss": 6.947838119231164e-05, "_runtime": 15463.8217523098, "_timestamp": 1585585379.6663857, "_step": 396}
{"Episode reward": -99.768813202035, "Episode length": 999, "Policy Loss": -0.0009487224742770195, "Value Loss": 1.314556175202597e-05, "_runtime": 15465.41311454773, "_timestamp": 1585585381.257748, "_step": 397}
{"Episode reward": -99.2489317261314, "Episode length": 999, "Policy Loss": -0.001377536216750741, "Value Loss": 4.2862237023655325e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215, 4.986578941345215]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.411954879760742, -5.266830921173096, -5.121706962585449, -4.976583003997803, -4.831459045410156, -4.686334609985352, -4.541211128234863, -4.396086692810059, -4.250962734222412, -4.105838775634766, -3.960714817047119, -3.8155908584594727, -3.670466899871826, -3.5253429412841797, -3.380218744277954, -3.2350947856903076, -3.089970827102661, -2.9448468685150146, -2.799722909927368, -2.6545987129211426, -2.509474754333496, -2.3643507957458496, -2.219226837158203, -2.0741028785705566, -1.9289789199829102, -1.7838547229766846, -1.638730764389038, -1.4936068058013916, -1.348482608795166, -1.2033586502075195, -1.058234691619873, -0.9131107330322266, -0.7679867744445801, -0.6228628158569336, -0.4777388572692871, -0.3326148986816406, -0.18749094009399414, -0.042366981506347656, 0.10275745391845703, 0.24788141250610352, 0.39300537109375, 0.5381293296813965, 0.683253288269043, 0.8283772468566895, 0.9735012054443359, 1.1186251640319824, 1.263749122619629, 1.4088730812072754, 1.5539970397949219, 1.6991214752197266, 1.844245433807373, 1.9893693923950195, 2.134493350982666, 2.2796173095703125, 2.424741268157959, 2.5698652267456055, 2.71498966217041, 2.8601131439208984, 3.005237579345703, 3.1503610610961914, 3.295485496520996, 3.4406089782714844, 3.585733413696289, 3.7308568954467773, 3.875981330871582]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0], "bins": [-2.560790777206421, -2.5208122730255127, -2.4808337688446045, -2.4408552646636963, -2.400876760482788, -2.36089825630188, -2.3209197521209717, -2.2809412479400635, -2.2409627437591553, -2.200984239578247, -2.161005973815918, -2.1210274696350098, -2.0810489654541016, -2.0410704612731934, -2.001091957092285, -1.961113452911377, -1.9211349487304688, -1.8811564445495605, -1.8411779403686523, -1.8011994361877441, -1.761220932006836, -1.7212424278259277, -1.6812639236450195, -1.6412854194641113, -1.6013069152832031, -1.561328411102295, -1.5213499069213867, -1.481371521949768, -1.4413930177688599, -1.4014145135879517, -1.3614360094070435, -1.3214575052261353, -1.281479001045227, -1.2415004968643188, -1.2015219926834106, -1.1615434885025024, -1.1215649843215942, -1.081586480140686, -1.0416080951690674, -1.0016295909881592, -0.961651086807251, -0.9216725826263428, -0.8816940784454346, -0.8417155742645264, -0.8017370700836182, -0.76175856590271, -0.7217800617218018, -0.6818015575408936, -0.6418230533599854, -0.6018446683883667, -0.5618661642074585, -0.5218875408172607, -0.48190903663635254, -0.44193053245544434, -0.40195226669311523, -0.36197376251220703, -0.32199525833129883, -0.2820167541503906, -0.24203824996948242, -0.20205974578857422, -0.16208124160766602, -0.12210273742675781, -0.08212423324584961, -0.042145729064941406, -0.002167224884033203]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 4.0, 5.0, 10.0, 7.0, 8.0, 12.0, 22.0, 38.0, 182.0, 100.0, 19.0, 9.0, 11.0, 9.0, 4.0, 3.0, 6.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-2.1356093883514404, -2.0790328979492188, -2.022456645965576, -1.9658801555633545, -1.9093037843704224, -1.8527274131774902, -1.7961509227752686, -1.7395745515823364, -1.6829981803894043, -1.6264218091964722, -1.56984543800354, -1.5132689476013184, -1.4566925764083862, -1.400116205215454, -1.3435397148132324, -1.2869633436203003, -1.2303869724273682, -1.173810601234436, -1.117234230041504, -1.0606577396392822, -1.00408136844635, -0.947504997253418, -0.8909285068511963, -0.8343521356582642, -0.777775764465332, -0.7211993932723999, -0.6646230220794678, -0.6080465316772461, -0.551470160484314, -0.49489378929138184, -0.43831729888916016, -0.381740927696228, -0.3251645565032959, -0.26858818531036377, -0.21201181411743164, -0.15543532371520996, -0.09885907173156738, -0.0422825813293457, 0.014293909072875977, 0.07087016105651855, 0.12744665145874023, 0.18402314186096191, 0.2405993938446045, 0.29717588424682617, 0.35375237464904785, 0.41032862663269043, 0.4669051170349121, 0.5234813690185547, 0.5800578594207764, 0.636634349822998, 0.6932106018066406, 0.7497870922088623, 0.8063633441925049, 0.8629398345947266, 0.9195163249969482, 0.9760925769805908, 1.0326690673828125, 1.0892455577850342, 1.1458218097686768, 1.2023983001708984, 1.2589747905731201, 1.3155510425567627, 1.3721275329589844, 1.428703784942627, 1.4852802753448486]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-4.7739152908325195, -4.655135154724121, -4.536355018615723, -4.417574882507324, -4.298794269561768, -4.180014133453369, -4.061233997344971, -3.9424538612365723, -3.8236734867095947, -3.7048933506011963, -3.5861129760742188, -3.4673328399658203, -3.348552703857422, -3.2297725677490234, -3.110992193222046, -2.9922120571136475, -2.87343168258667, -2.7546515464782715, -2.635871410369873, -2.5170910358428955, -2.398310899734497, -2.2795307636260986, -2.160750389099121, -2.0419702529907227, -1.9231901168823242, -1.8044097423553467, -1.6856296062469482, -1.5668494701385498, -1.4480690956115723, -1.3292889595031738, -1.2105088233947754, -1.0917284488677979, -0.9729483127593994, -0.854168176651001, -0.7353878021240234, -0.616607666015625, -0.49782752990722656, -0.3790473937988281, -0.2602667808532715, -0.14148664474487305, -0.02270650863647461, 0.09607362747192383, 0.21485376358032227, 0.3336338996887207, 0.45241451263427734, 0.5711946487426758, 0.6899747848510742, 0.8087549209594727, 0.9275350570678711, 1.0463151931762695, 1.1650958061218262, 1.2838759422302246, 1.402656078338623, 1.5214362144470215, 1.64021635055542, 1.7589964866638184, 1.877777099609375, 1.9965572357177734, 2.115337371826172, 2.2341175079345703, 2.3528976440429688, 2.471677780151367, 2.590458393096924, 2.7092385292053223, 2.8280186653137207]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 6.0, 10.0, 4.0, 7.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.5228936672210693, -2.418879747390747, -2.3148655891418457, -2.2108516693115234, -2.106837749481201, -2.0028235912323, -1.8988096714019775, -1.7947956323623657, -1.690781593322754, -1.586767554283142, -1.4827535152435303, -1.378739595413208, -1.2747255563735962, -1.1707115173339844, -1.066697597503662, -0.9626835584640503, -0.8586695194244385, -0.7546554803848267, -0.6506414413452148, -0.5466275215148926, -0.4426133632659912, -0.33859944343566895, -0.23458552360534668, -0.1305713653564453, -0.026557445526123047, 0.07745647430419922, 0.18147063255310059, 0.28548455238342285, 0.3894984722137451, 0.4935126304626465, 0.5975265502929688, 0.7015407085418701, 0.8055546283721924, 0.9095685482025146, 1.013582706451416, 1.1175966262817383, 1.2216107845306396, 1.325624704360962, 1.4296386241912842, 1.5336525440216064, 1.637666940689087, 1.7416808605194092, 1.8456947803497314, 1.9497087001800537, 2.053722620010376, 2.1577365398406982, 2.2617509365081787, 2.365764856338501, 2.4697787761688232, 2.5737926959991455, 2.6778066158294678, 2.7818210124969482, 2.8858349323272705, 2.9898488521575928, 3.093862771987915, 3.1978766918182373, 3.3018906116485596, 3.40590500831604, 3.5099189281463623, 3.6139328479766846, 3.717946767807007, 3.821960687637329, 3.9259750843048096, 4.029989242553711, 4.134002685546875]}, "_runtime": 15467.004145860672, "_timestamp": 1585585382.8487792, "_step": 398}
{"Episode reward": -98.85575260747487, "Episode length": 999, "Policy Loss": -0.0008173836977221072, "Value Loss": 7.856909360270947e-05, "_runtime": 15468.588913202286, "_timestamp": 1585585384.4335465, "_step": 399}
{"Episode reward": -99.58537336911505, "Episode length": 999, "Policy Loss": -0.001204075524583459, "Value Loss": 2.7175981813343242e-05, "_runtime": 15470.16886806488, "_timestamp": 1585585386.0135014, "_step": 400}
{"Episode reward": -99.30399726491952, "Episode length": 999, "Policy Loss": -0.0018120959866791964, "Value Loss": 4.747915590996854e-05, "_runtime": 15471.751122713089, "_timestamp": 1585585387.595756, "_step": 401}
{"Episode reward": -99.56303473438989, "Episode length": 999, "Policy Loss": -0.0011014222400262952, "Value Loss": 2.8126385586801916e-05, "_runtime": 15473.341228723526, "_timestamp": 1585585389.185862, "_step": 402}
{"Episode reward": -99.19961344523716, "Episode length": 999, "Policy Loss": -0.0017239185981452465, "Value Loss": 5.410830635810271e-05, "_runtime": 15474.934064149857, "_timestamp": 1585585390.7786975, "_step": 403}
{"Episode reward": -99.19737813004426, "Episode length": 999, "Policy Loss": -0.001710425247438252, "Value Loss": 5.6591736210975796e-05, "_runtime": 15476.52398967743, "_timestamp": 1585585392.368623, "_step": 404}
{"Episode reward": -99.03015619954449, "Episode length": 999, "Policy Loss": -0.0017403146484866738, "Value Loss": 6.721787212882191e-05, "_runtime": 15478.1071331501, "_timestamp": 1585585393.9517665, "_step": 405}
{"Episode reward": -99.546422663998, "Episode length": 999, "Policy Loss": -0.000929484493099153, "Value Loss": 2.9077027647872455e-05, "_runtime": 15479.696526527405, "_timestamp": 1585585395.5411599, "_step": 406}
{"Episode reward": -99.22639078109708, "Episode length": 999, "Policy Loss": -0.001836239593103528, "Value Loss": 6.729993765475228e-05, "_runtime": 15481.280212163925, "_timestamp": 1585585397.1248455, "_step": 407}
{"Episode reward": -99.21203045395585, "Episode length": 999, "Policy Loss": -0.0007092474843375385, "Value Loss": 3.9652011764701456e-05, "_runtime": 15482.912143707275, "_timestamp": 1585585398.756777, "_step": 408}
{"Episode reward": -98.91147269509099, "Episode length": 999, "Policy Loss": -0.001132854842580855, "Value Loss": 7.474116864614189e-05, "_runtime": 15484.50299501419, "_timestamp": 1585585400.3476284, "_step": 409}
{"Episode reward": -99.72121909032309, "Episode length": 999, "Policy Loss": -0.0012579975882545114, "Value Loss": 2.200971903221216e-05, "_runtime": 15486.073430776596, "_timestamp": 1585585401.918064, "_step": 410}
{"Episode reward": -99.0111632547341, "Episode length": 999, "Policy Loss": -0.0012885048054158688, "Value Loss": 6.863768794573843e-05, "_runtime": 15487.668654680252, "_timestamp": 1585585403.513288, "_step": 411}
{"Episode reward": -98.93699141394787, "Episode length": 999, "Policy Loss": -0.0005791835719719529, "Value Loss": 6.78489959682338e-05, "_runtime": 15489.250056028366, "_timestamp": 1585585405.0946894, "_step": 412}
{"Episode reward": -99.89515819685658, "Episode length": 999, "Policy Loss": -0.0006090995157137513, "Value Loss": 1.0606508112687152e-05, "_runtime": 15490.83425951004, "_timestamp": 1585585406.6788929, "_step": 413}
{"Episode reward": -98.93858967824991, "Episode length": 999, "Policy Loss": -0.0017119725234806538, "Value Loss": 7.824026397429407e-05, "_runtime": 15492.415585756302, "_timestamp": 1585585408.260219, "_step": 414}
{"Episode reward": -99.67712166219593, "Episode length": 999, "Policy Loss": -0.0011468721786513925, "Value Loss": 2.8781478249584325e-05, "_runtime": 15493.999954462051, "_timestamp": 1585585409.8445878, "_step": 415}
{"Episode reward": -98.89382299232915, "Episode length": 999, "Policy Loss": -0.0008661241154186428, "Value Loss": 7.214583456516266e-05, "_runtime": 15495.573463201523, "_timestamp": 1585585411.4180965, "_step": 416}
{"Episode reward": -99.38294618232587, "Episode length": 999, "Policy Loss": -0.0007949949940666556, "Value Loss": 4.032012657262385e-05, "_runtime": 15497.160389184952, "_timestamp": 1585585413.0050225, "_step": 417}
{"Episode reward": -99.39418414077082, "Episode length": 999, "Policy Loss": -0.0009772247867658734, "Value Loss": 4.347300637164153e-05, "_runtime": 15498.741305112839, "_timestamp": 1585585414.5859385, "_step": 418}
{"Episode reward": -99.4541068857344, "Episode length": 999, "Policy Loss": -0.0008772187866270542, "Value Loss": 3.607724647736177e-05, "_runtime": 15500.324958324432, "_timestamp": 1585585416.1695917, "_step": 419}
{"Episode reward": -99.8832991271151, "Episode length": 999, "Policy Loss": -0.0005531517090275884, "Value Loss": 8.015213097678497e-06, "_runtime": 15501.919726133347, "_timestamp": 1585585417.7643595, "_step": 420}
{"Episode reward": -99.06184421029258, "Episode length": 999, "Policy Loss": -0.0009306048159487545, "Value Loss": 6.566564115928486e-05, "_runtime": 15503.511561632156, "_timestamp": 1585585419.356195, "_step": 421}
{"Episode reward": -99.32327708044919, "Episode length": 999, "Policy Loss": -0.0013928923290222883, "Value Loss": 5.3806357755092904e-05, "_runtime": 15505.103530406952, "_timestamp": 1585585420.9481637, "_step": 422}
{"Episode reward": -98.78275132728655, "Episode length": 999, "Policy Loss": -0.001082488801330328, "Value Loss": 8.367952250409871e-05, "_runtime": 15506.734293460846, "_timestamp": 1585585422.5789268, "_step": 423}
{"Episode reward": -99.45396014630603, "Episode length": 999, "Policy Loss": -0.0016200513346120715, "Value Loss": 3.87822074117139e-05, "_runtime": 15508.324456453323, "_timestamp": 1585585424.1690898, "_step": 424}
{"Episode reward": -99.8161062754171, "Episode length": 999, "Policy Loss": -0.0006633528391830623, "Value Loss": 1.18403768283315e-05, "_runtime": 15509.91934800148, "_timestamp": 1585585425.7639813, "_step": 425}
{"Episode reward": -99.03849447067313, "Episode length": 999, "Policy Loss": -0.0017931025940924883, "Value Loss": 7.761946471873671e-05, "_runtime": 15511.510594129562, "_timestamp": 1585585427.3552275, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006196867907419801, "Value Loss": 1.157958286057692e-05, "_runtime": 15513.102692365646, "_timestamp": 1585585428.9473257, "_step": 427}
{"Episode reward": -98.98082780721616, "Episode length": 999, "Policy Loss": -0.0008017744403332472, "Value Loss": 7.367879879893735e-05, "_runtime": 15514.687366724014, "_timestamp": 1585585430.532, "_step": 428}
{"Episode reward": -99.02460845646783, "Episode length": 999, "Policy Loss": -0.000795853731688112, "Value Loss": 6.157837924547493e-05, "_runtime": 15516.269637346268, "_timestamp": 1585585432.1142707, "_step": 429}
{"Episode reward": -99.25822675967738, "Episode length": 999, "Policy Loss": -0.0018440401181578636, "Value Loss": 4.726109909825027e-05, "_runtime": 15517.849204301834, "_timestamp": 1585585433.6938376, "_step": 430}
{"Episode reward": -99.28649605646207, "Episode length": 999, "Policy Loss": -0.0010330884251743555, "Value Loss": 4.9743004638003185e-05, "_runtime": 15519.431104183197, "_timestamp": 1585585435.2757375, "_step": 431}
{"Episode reward": -99.05378498664528, "Episode length": 999, "Policy Loss": -0.0013776578707620502, "Value Loss": 7.442684727720916e-05, "_runtime": 15521.025328874588, "_timestamp": 1585585436.8699622, "_step": 432}
{"Episode reward": -99.23193194621331, "Episode length": 999, "Policy Loss": -0.0010560790542513132, "Value Loss": 5.010149834561162e-05, "_runtime": 15522.614677667618, "_timestamp": 1585585438.459311, "_step": 433}
{"Episode reward": -99.52118626120344, "Episode length": 999, "Policy Loss": -0.0012233415618538857, "Value Loss": 3.70907764590811e-05, "_runtime": 15524.20770740509, "_timestamp": 1585585440.0523407, "_step": 434}
{"Episode reward": -99.04477145639476, "Episode length": 999, "Policy Loss": -0.0016068473923951387, "Value Loss": 6.665923137916252e-05, "_runtime": 15525.801234960556, "_timestamp": 1585585441.6458683, "_step": 435}
{"Episode reward": -99.15286533347675, "Episode length": 999, "Policy Loss": -0.0011135759996250272, "Value Loss": 6.15756944171153e-05, "_runtime": 15527.392615795135, "_timestamp": 1585585443.2372491, "_step": 436}
{"Episode reward": -99.77060275787899, "Episode length": 999, "Policy Loss": -0.0007151067839004099, "Value Loss": 1.2653865269385278e-05, "_runtime": 15528.987421751022, "_timestamp": 1585585444.832055, "_step": 437}
{"Episode reward": -99.74035583453055, "Episode length": 999, "Policy Loss": -0.000898336642421782, "Value Loss": 1.3693193068320397e-05, "_runtime": 15530.607482910156, "_timestamp": 1585585446.4521163, "_step": 438}
{"Episode reward": -99.39077278943587, "Episode length": 999, "Policy Loss": -0.0014730169204995036, "Value Loss": 4.253255974617787e-05, "_runtime": 15532.188189268112, "_timestamp": 1585585448.0328226, "_step": 439}
{"Episode reward": -98.92293309918507, "Episode length": 999, "Policy Loss": -0.0018137568840757012, "Value Loss": 7.982883107615635e-05, "_runtime": 15533.775129795074, "_timestamp": 1585585449.6197631, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006818029214628041, "Value Loss": 1.873232213256415e-05, "_runtime": 15535.394490718842, "_timestamp": 1585585451.239124, "_step": 441}
{"Episode reward": -99.37078148320622, "Episode length": 999, "Policy Loss": -0.0015825446462258697, "Value Loss": 5.5499836889794096e-05, "_runtime": 15537.084775209427, "_timestamp": 1585585452.9294086, "_step": 442}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006697585340589285, "Value Loss": 1.874581903393846e-05, "_runtime": 15538.727397441864, "_timestamp": 1585585454.5720308, "_step": 443}
{"Episode reward": -99.19004476172391, "Episode length": 999, "Policy Loss": -0.0011935344664379954, "Value Loss": 5.639729351969436e-05, "_runtime": 15540.35656094551, "_timestamp": 1585585456.2011943, "_step": 444}
{"Episode reward": -99.18613447119561, "Episode length": 999, "Policy Loss": -0.0007157583022490144, "Value Loss": 5.110992060508579e-05, "_runtime": 15541.975170135498, "_timestamp": 1585585457.8198035, "_step": 445}
{"Episode reward": -99.11509922247707, "Episode length": 999, "Policy Loss": -0.001463214517571032, "Value Loss": 5.481527841766365e-05, "_runtime": 15543.593648910522, "_timestamp": 1585585459.4382823, "_step": 446}
{"Episode reward": -99.62677441837084, "Episode length": 999, "Policy Loss": -0.000961459765676409, "Value Loss": 1.734938268782571e-05, "_runtime": 15545.22597193718, "_timestamp": 1585585461.0706053, "_step": 447}
{"Episode reward": -99.50855858551527, "Episode length": 999, "Policy Loss": -0.00162672926671803, "Value Loss": 2.7148680601385422e-05, "_runtime": 15546.847132444382, "_timestamp": 1585585462.6917658, "_step": 448}
{"Episode reward": -99.4977360966237, "Episode length": 999, "Policy Loss": -0.0013154417974874377, "Value Loss": 2.56420680670999e-05, "_runtime": 15548.472149133682, "_timestamp": 1585585464.3167825, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008729109540581703, "Value Loss": 1.3546784430218395e-05, "_runtime": 15550.089373588562, "_timestamp": 1585585465.934007, "_step": 450}
{"Episode reward": -99.69277747127057, "Episode length": 999, "Policy Loss": -0.0012179187033325434, "Value Loss": 1.830931068980135e-05, "_runtime": 15551.722806215286, "_timestamp": 1585585467.5674396, "_step": 451}
{"Episode reward": -99.2634991736631, "Episode length": 999, "Policy Loss": -0.0017763484502211213, "Value Loss": 5.322337892721407e-05, "_runtime": 15553.400841712952, "_timestamp": 1585585469.245475, "_step": 452}
{"Episode reward": -99.44782028256807, "Episode length": 999, "Policy Loss": -0.001864801743067801, "Value Loss": 4.467508915695362e-05, "_runtime": 15555.016540527344, "_timestamp": 1585585470.8611739, "_step": 453}
{"Episode reward": -99.4538096897937, "Episode length": 999, "Policy Loss": -0.0010586658027023077, "Value Loss": 3.651934821391478e-05, "_runtime": 15556.64588046074, "_timestamp": 1585585472.4905138, "_step": 454}
{"Episode reward": -99.18143852096551, "Episode length": 999, "Policy Loss": -0.0014731389237567782, "Value Loss": 4.907309266855009e-05, "_runtime": 15558.274515151978, "_timestamp": 1585585474.1191485, "_step": 455}
{"Episode reward": -99.61856196639202, "Episode length": 999, "Policy Loss": -0.001456498634070158, "Value Loss": 2.0017345377709717e-05, "_runtime": 15559.884917020798, "_timestamp": 1585585475.7295504, "_step": 456}
{"Episode reward": -99.77429012657875, "Episode length": 999, "Policy Loss": -0.0012267990969121456, "Value Loss": 1.870892992883455e-05, "_runtime": 15561.510094881058, "_timestamp": 1585585477.3547282, "_step": 457}
{"Episode reward": -99.45099119851156, "Episode length": 999, "Policy Loss": -0.0018941095331683755, "Value Loss": 3.713634214363992e-05, "_runtime": 15563.136155605316, "_timestamp": 1585585478.980789, "_step": 458}
{"Episode reward": -98.80285097035635, "Episode length": 999, "Policy Loss": -0.001949584111571312, "Value Loss": 8.450549648841843e-05, "_runtime": 15564.76372218132, "_timestamp": 1585585480.6083555, "_step": 459}
{"Episode reward": -99.34225198916144, "Episode length": 999, "Policy Loss": -0.0019133990863338113, "Value Loss": 4.530588194029406e-05, "_runtime": 15566.377034425735, "_timestamp": 1585585482.2216678, "_step": 460}
{"Episode reward": -99.58649992626647, "Episode length": 999, "Policy Loss": -0.0014788389671593904, "Value Loss": 2.0593679437297396e-05, "_runtime": 15567.987712144852, "_timestamp": 1585585483.8323455, "_step": 461}
{"Episode reward": -99.22515601823166, "Episode length": 999, "Policy Loss": -0.001465345500037074, "Value Loss": 4.669038389693014e-05, "_runtime": 15569.602433681488, "_timestamp": 1585585485.447067, "_step": 462}
{"Episode reward": -99.36618136324381, "Episode length": 999, "Policy Loss": -0.0015549648087471724, "Value Loss": 4.5760385546600446e-05, "_runtime": 15571.214421987534, "_timestamp": 1585585487.0590553, "_step": 463}
{"Episode reward": -98.98119733250644, "Episode length": 999, "Policy Loss": -0.0017184668686240911, "Value Loss": 6.965751526877284e-05, "_runtime": 15572.85107588768, "_timestamp": 1585585488.6957092, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008520680712535977, "Value Loss": 9.542728548694868e-06, "_runtime": 15574.468864679337, "_timestamp": 1585585490.313498, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006808813195675611, "Value Loss": 1.3923798178439029e-05, "_runtime": 15576.094488859177, "_timestamp": 1585585491.9391222, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007718848064541817, "Value Loss": 1.7019332517520525e-05, "_runtime": 15577.754972219467, "_timestamp": 1585585493.5996056, "_step": 467}
{"Episode reward": -99.37768402031995, "Episode length": 999, "Policy Loss": -0.0011228917865082622, "Value Loss": 4.1778770537348464e-05, "_runtime": 15579.363426923752, "_timestamp": 1585585495.2080603, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007055596215650439, "Value Loss": 1.3523792404157575e-05, "_runtime": 15580.976029872894, "_timestamp": 1585585496.8206632, "_step": 469}
{"Episode reward": -99.36566794449031, "Episode length": 999, "Policy Loss": -0.0009752232581377029, "Value Loss": 3.6273915611673146e-05, "_runtime": 15582.59670996666, "_timestamp": 1585585498.4413433, "_step": 470}
{"Episode reward": -98.94067204226079, "Episode length": 999, "Policy Loss": -0.0016286364989355206, "Value Loss": 7.268958870554343e-05, "_runtime": 15584.228482961655, "_timestamp": 1585585500.0731163, "_step": 471}
{"Episode reward": -98.93204433092261, "Episode length": 999, "Policy Loss": -0.0012830400373786688, "Value Loss": 7.581536192446947e-05, "_runtime": 15585.866111755371, "_timestamp": 1585585501.710745, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0008016274659894407, "Value Loss": 1.3778003449260723e-05, "_runtime": 15587.495899915695, "_timestamp": 1585585503.3405333, "_step": 473}
{"Episode reward": -99.08881721009539, "Episode length": 999, "Policy Loss": -0.001547577092424035, "Value Loss": 6.444624159485102e-05, "_runtime": 15589.124867916107, "_timestamp": 1585585504.9695013, "_step": 474}
{"Episode reward": -99.41572067918896, "Episode length": 999, "Policy Loss": -0.0016143635148182511, "Value Loss": 3.9606853533769026e-05, "_runtime": 15590.742149829865, "_timestamp": 1585585506.5867832, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006675799959339201, "Value Loss": 1.58874590852065e-05, "_runtime": 15592.364785909653, "_timestamp": 1585585508.2094193, "_step": 476}
{"Episode reward": -99.63646277126485, "Episode length": 999, "Policy Loss": -0.0011386880651116371, "Value Loss": 2.5506509700790048e-05, "_runtime": 15593.985186815262, "_timestamp": 1585585509.8298202, "_step": 477}
{"Episode reward": -99.06184470654145, "Episode length": 999, "Policy Loss": -0.0013516315957531333, "Value Loss": 6.515873974421993e-05, "_runtime": 15595.606157541275, "_timestamp": 1585585511.450791, "_step": 478}
{"Episode reward": -99.48645227755814, "Episode length": 999, "Policy Loss": -0.0015792218036949635, "Value Loss": 3.881912198266946e-05, "_runtime": 15597.22826218605, "_timestamp": 1585585513.0728955, "_step": 479}
{"Episode reward": -99.54783987820892, "Episode length": 999, "Policy Loss": -0.0014447183348238468, "Value Loss": 3.389941775822081e-05, "_runtime": 15598.849287986755, "_timestamp": 1585585514.6939213, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0006748982705175877, "Value Loss": 1.6700207197573036e-05, "_runtime": 15600.475105524063, "_timestamp": 1585585516.3197389, "_step": 481}
{"Episode reward": -99.55029047277579, "Episode length": 999, "Policy Loss": -0.0013031241251155734, "Value Loss": 2.979676537506748e-05, "_runtime": 15602.139806747437, "_timestamp": 1585585517.98444, "_step": 482}
{"Episode reward": -99.46435177432264, "Episode length": 999, "Policy Loss": -0.0015129032544791698, "Value Loss": 3.2954201742541045e-05, "_runtime": 15603.773649454117, "_timestamp": 1585585519.6182828, "_step": 483}
{"Episode reward": -99.06461681207949, "Episode length": 999, "Policy Loss": -0.0011823554523289204, "Value Loss": 6.221632793312892e-05, "_runtime": 15605.391179323196, "_timestamp": 1585585521.2358127, "_step": 484}
{"Episode reward": -99.66840473954963, "Episode length": 999, "Policy Loss": -0.001047378871589899, "Value Loss": 2.1126075807842426e-05, "_runtime": 15607.015892982483, "_timestamp": 1585585522.8605263, "_step": 485}
{"Episode reward": -99.07806922415796, "Episode length": 999, "Policy Loss": -0.0003051750245504081, "Value Loss": 5.853663242305629e-05, "_runtime": 15608.638585329056, "_timestamp": 1585585524.4832187, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0007760539883747697, "Value Loss": 9.922192475642078e-06, "_runtime": 15610.275744915009, "_timestamp": 1585585526.1203783, "_step": 487}
{"Episode reward": -98.87576998725574, "Episode length": 999, "Policy Loss": -0.001705390284769237, "Value Loss": 7.880537305027246e-05, "_runtime": 15611.902911901474, "_timestamp": 1585585527.7475452, "_step": 488}
{"Episode reward": -98.92023294995514, "Episode length": 999, "Policy Loss": -0.0011388316052034497, "Value Loss": 7.090268627507612e-05, "_runtime": 15613.5300385952, "_timestamp": 1585585529.374672, "_step": 489}
{"Episode reward": -99.44107079449519, "Episode length": 999, "Policy Loss": -0.001690194010734558, "Value Loss": 3.7505731597775593e-05, "_runtime": 15615.159385442734, "_timestamp": 1585585531.0040188, "_step": 490}
{"Episode reward": -99.14831658162863, "Episode length": 999, "Policy Loss": -0.0011285239597782493, "Value Loss": 4.847653690376319e-05, "_runtime": 15616.794291496277, "_timestamp": 1585585532.6389248, "_step": 491}
{"Episode reward": -99.02242540855552, "Episode length": 999, "Policy Loss": -0.001364113762974739, "Value Loss": 5.758125553256832e-05, "_runtime": 15618.425972223282, "_timestamp": 1585585534.2706056, "_step": 492}
{"Episode reward": -99.27825881238607, "Episode length": 999, "Policy Loss": -0.00012675226025748998, "Value Loss": 3.859780917991884e-05, "_runtime": 15620.045998573303, "_timestamp": 1585585535.890632, "_step": 493}
{"Episode reward": -99.01784673567643, "Episode length": 999, "Policy Loss": -0.0010109151480719447, "Value Loss": 6.03256921749562e-05, "_runtime": 15621.660272359848, "_timestamp": 1585585537.5049057, "_step": 494}
{"Episode reward": -98.83795886614544, "Episode length": 999, "Policy Loss": -0.0008551790378987789, "Value Loss": 9.00969680515118e-05, "_runtime": 15623.275918483734, "_timestamp": 1585585539.1205518, "_step": 495}
{"Episode reward": -99.07048747402041, "Episode length": 999, "Policy Loss": -0.001129627344198525, "Value Loss": 6.35052056168206e-05, "_runtime": 15624.883531093597, "_timestamp": 1585585540.7281644, "_step": 496}
{"Episode reward": -99.34838571583506, "Episode length": 999, "Policy Loss": -0.0005653816624544561, "Value Loss": 4.67402242065873e-05, "_runtime": 15626.531630277634, "_timestamp": 1585585542.3762636, "_step": 497}
{"Episode reward": -99.30282872873073, "Episode length": 999, "Policy Loss": -0.0012052325764670968, "Value Loss": 4.599445310304873e-05, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734, -4.505855560302734]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], "bins": [-3.775895595550537, -3.645070791244507, -3.5142462253570557, -3.3834214210510254, -3.252596855163574, -3.121772050857544, -2.9909472465515137, -2.8601226806640625, -2.7292978763580322, -2.598473072052002, -2.467648506164551, -2.3368237018585205, -2.2059988975524902, -2.075174331665039, -1.9443495273590088, -1.813524842262268, -1.6827001571655273, -1.551875352859497, -1.421050786972046, -1.2902259826660156, -1.1594014167785645, -1.0285766124725342, -0.8977518081665039, -0.7669272422790527, -0.6361024379730225, -0.5052776336669922, -0.374453067779541, -0.24362826347351074, -0.11280345916748047, 0.018021106719970703, 0.14884591102600098, 0.27967071533203125, 0.4104952812194824, 0.5413198471069336, 0.672144889831543, 0.8029694557189941, 0.9337940216064453, 1.0646190643310547, 1.1954436302185059, 1.326268196105957, 1.4570927619934082, 1.5879178047180176, 1.7187423706054688, 1.84956693649292, 1.9803919792175293, 2.1112165451049805, 2.2420411109924316, 2.372866153717041, 2.503690719604492, 2.6345152854919434, 2.7653403282165527, 2.896164894104004, 3.026989459991455, 3.1578145027160645, 3.2886390686035156, 3.419463634490967, 3.550288677215576, 3.6811132431030273, 3.8119378089904785, 3.9427623748779297, 4.073587417602539, 4.20441198348999, 4.3352370262146, 4.466061115264893, 4.596886157989502]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0005803182139061391, 0.036726225167512894, 0.07287213206291199, 0.10901803523302078, 0.14516393840312958, 0.18130984902381897, 0.21745574474334717, 0.25360167026519775, 0.28974756598472595, 0.32589346170425415, 0.36203938722610474, 0.39818528294563293, 0.43433117866516113, 0.4704771041870117, 0.5066230297088623, 0.5427688956260681, 0.5789148211479187, 0.6150607466697693, 0.6512066125869751, 0.6873525381088257, 0.7234984636306763, 0.7596443295478821, 0.7957902550697327, 0.8319361805915833, 0.8680820465087891, 0.9042279720306396, 0.9403738975524902, 0.9765198230743408, 1.0126657485961914, 1.0488115549087524, 1.084957480430603, 1.1211034059524536, 1.1572493314743042, 1.1933952569961548, 1.2295411825180054, 1.265687108039856, 1.301832914352417, 1.3379788398742676, 1.3741247653961182, 1.4102706909179688, 1.4464166164398193, 1.48256254196167, 1.518708348274231, 1.5548542737960815, 1.5910001993179321, 1.6271461248397827, 1.6632920503616333, 1.6994379758834839, 1.735583782196045, 1.7717297077178955, 1.807875633239746, 1.8440215587615967, 1.8801674842834473, 1.9163134098052979, 1.9524593353271484, 1.9886051416397095, 2.0247511863708496, 2.0608971118927, 2.0970427989959717, 2.1331887245178223, 2.169334650039673, 2.2054805755615234, 2.241626501083374, 2.2777724266052246, 2.313918352127075]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 4.0, 1.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 3.0, 7.0, 8.0, 12.0, 14.0, 13.0, 18.0, 256.0, 44.0, 23.0, 13.0, 9.0, 10.0, 7.0, 6.0, 7.0, 3.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.297247052192688, -1.2488617897033691, -1.2004764080047607, -1.152091145515442, -1.1037057638168335, -1.0553205013275146, -1.0069351196289062, -0.9585498571395874, -0.9101645946502686, -0.8617792129516602, -0.8133939504623413, -0.7650086283683777, -0.7166233062744141, -0.6682379841804504, -0.6198527216911316, -0.571467399597168, -0.5230820775032043, -0.4746967554092407, -0.4263114333152771, -0.37792617082595825, -0.32954084873199463, -0.28115546703338623, -0.23277020454406738, -0.18438494205474854, -0.13599956035614014, -0.08761429786682129, -0.03922891616821289, 0.009156346321105957, 0.057541608810424805, 0.1059269905090332, 0.15431225299835205, 0.20269763469696045, 0.2510828971862793, 0.29946815967559814, 0.34785354137420654, 0.3962388038635254, 0.4446241855621338, 0.49300944805145264, 0.5413947105407715, 0.5897800922393799, 0.6381653547286987, 0.6865507364273071, 0.7349361181259155, 0.7833212614059448, 0.8317066431045532, 0.8800920248031616, 0.9284771680831909, 0.9768625497817993, 1.0252479314804077, 1.073633074760437, 1.1220184564590454, 1.1704038381576538, 1.2187892198562622, 1.2671743631362915, 1.3155597448349, 1.3639451265335083, 1.4123302698135376, 1.460715651512146, 1.5091010332107544, 1.5574861764907837, 1.605871558189392, 1.6542569398880005, 1.7026423215866089, 1.7510274648666382, 1.7994128465652466]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.1695504188537598, -2.0733747482299805, -1.9771990776062012, -1.8810234069824219, -1.7848477363586426, -1.6886720657348633, -1.5924965143203735, -1.4963208436965942, -1.400145173072815, -1.3039695024490356, -1.2077938318252563, -1.111618161201477, -1.0154426097869873, -0.919266939163208, -0.8230912685394287, -0.7269155979156494, -0.6307399272918701, -0.5345642566680908, -0.4383885860443115, -0.3422129154205322, -0.24603724479675293, -0.14986157417297363, -0.053685903549194336, 0.04248976707458496, 0.13866519927978516, 0.23484086990356445, 0.33101654052734375, 0.42719221115112305, 0.5233678817749023, 0.6195435523986816, 0.7157192230224609, 0.8118948936462402, 0.9080705642700195, 1.0042462348937988, 1.1004219055175781, 1.1965975761413574, 1.2927732467651367, 1.388948917388916, 1.4851245880126953, 1.5813002586364746, 1.677475929260254, 1.773651361465454, 1.8698272705078125, 1.9660029411315918, 2.062178611755371, 2.1583542823791504, 2.2545299530029297, 2.350705623626709, 2.44688081741333, 2.5430564880371094, 2.6392321586608887, 2.735407829284668, 2.8315834999084473, 2.9277591705322266, 3.023934841156006, 3.120110511779785, 3.2162861824035645, 3.3124618530273438, 3.408637523651123, 3.5048131942749023, 3.6009888648986816, 3.697164535522461, 3.7933402061462402, 3.8895158767700195, 3.985691547393799]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 5.0, 2.0, 4.0, 4.0, 8.0, 10.0, 6.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-3.6136600971221924, -3.5266406536102295, -3.4396212100982666, -3.3526015281677246, -3.2655820846557617, -3.178562641143799, -3.091543197631836, -3.004523754119873, -2.917504072189331, -2.830484628677368, -2.7434651851654053, -2.6564455032348633, -2.5694260597229004, -2.4824066162109375, -2.3953871726989746, -2.3083677291870117, -2.221348285675049, -2.134328842163086, -2.047309160232544, -1.960289716720581, -1.8732701539993286, -1.7862507104873657, -1.6992311477661133, -1.6122117042541504, -1.5251922607421875, -1.4381728172302246, -1.3511531352996826, -1.2641336917877197, -1.1771142482757568, -1.090094804763794, -1.003075122833252, -0.9160556793212891, -0.8290362358093262, -0.7420167922973633, -0.6549973487854004, -0.5679776668548584, -0.4809582233428955, -0.3939387798309326, -0.3069193363189697, -0.21989965438842773, -0.13288021087646484, -0.04586076736450195, 0.04115867614746094, 0.12817811965942383, 0.21519780158996582, 0.3022172451019287, 0.3892366886138916, 0.4762561321258545, 0.5632755756378174, 0.6502950191497803, 0.7373144626617432, 0.8243343830108643, 0.9113538265228271, 0.99837327003479, 1.085392713546753, 1.1724121570587158, 1.2594316005706787, 1.3464510440826416, 1.4334704875946045, 1.5204899311065674, 1.6075098514556885, 1.6945292949676514, 1.7815487384796143, 1.8685681819915771, 1.95558762550354]}, "_runtime": 15628.15955042839, "_timestamp": 1585585544.0041838, "_step": 498}
{"Episode reward": -99.23620042610426, "Episode length": 999, "Policy Loss": -0.0012624170631170273, "Value Loss": 5.3579879022436216e-05, "_runtime": 15628.15955042839, "_timestamp": 1585585544.0041838, "_step": 499}
