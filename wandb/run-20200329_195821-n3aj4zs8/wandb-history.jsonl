{"Episode reward": -59.44118572111024, "Episode length": 999, "Policy Loss": -0.0870978981256485, "Value Loss": 0.005604962352663279, "_runtime": 2841.8421409130096, "_timestamp": 1585511920.2628706, "_step": 0}
{"Episode reward": -95.97191252893485, "Episode length": 999, "Policy Loss": 0.7263790369033813, "Value Loss": 197.39370727539062, "_runtime": 2842.62730550766, "_timestamp": 1585511921.0480351, "_step": 1}
{"Episode reward": 48.10065619090628, "Episode length": 525, "Policy Loss": -5.246663570404053, "Value Loss": 1309.1043701171875, "_runtime": 2843.127328634262, "_timestamp": 1585511921.5480583, "_step": 2}
{"Episode reward": 71.19494408965097, "Episode length": 289, "Policy Loss": -182.64215087890625, "Value Loss": 11204.544921875, "_runtime": 2843.865278482437, "_timestamp": 1585511922.2860081, "_step": 3}
{"Episode reward": 52.945335559313726, "Episode length": 472, "Policy Loss": -0.01655096933245659, "Value Loss": 921.6439819335938, "_runtime": 2844.897975206375, "_timestamp": 1585511923.3187048, "_step": 4}
{"Episode reward": 31.828297913609603, "Episode length": 683, "Policy Loss": -4.275680065155029, "Value Loss": 3142.14013671875, "_runtime": 2846.393873691559, "_timestamp": 1585511924.8146033, "_step": 5}
{"Episode reward": -99.71553320633107, "Episode length": 999, "Policy Loss": -3.614751100540161, "Value Loss": 383.4093933105469, "_runtime": 2847.958651304245, "_timestamp": 1585511926.379381, "_step": 6}
{"Episode reward": -99.81083279261226, "Episode length": 999, "Policy Loss": -1.3812254667282104, "Value Loss": 24.151870727539062, "_runtime": 2849.490228652954, "_timestamp": 1585511927.9109583, "_step": 7}
{"Episode reward": -99.80131666660169, "Episode length": 999, "Policy Loss": -0.6966851353645325, "Value Loss": 1.043500542640686, "_runtime": 2851.0357460975647, "_timestamp": 1585511929.4564757, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.27882057428359985, "Value Loss": 0.41501161456108093, "_runtime": 2852.5925211906433, "_timestamp": 1585511931.0132508, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10248976945877075, "Value Loss": 1.5043832063674927, "_runtime": 2854.1511042118073, "_timestamp": 1585511932.5718338, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7602124214172363, "Value Loss": 5.891769886016846, "_runtime": 2855.715303182602, "_timestamp": 1585511934.1360328, "_step": 11}
{"Episode reward": -99.72742585595557, "Episode length": 999, "Policy Loss": 1.2501308917999268, "Value Loss": 7.710010051727295, "_runtime": 2857.2653620243073, "_timestamp": 1585511935.6860917, "_step": 12}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1358071565628052, "Value Loss": 2.0259206295013428, "_runtime": 2858.8384306430817, "_timestamp": 1585511937.2591603, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4795417785644531, "Value Loss": 1.1793338060379028, "_runtime": 2860.398555278778, "_timestamp": 1585511938.819285, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.6972190141677856, "Value Loss": 6.8080220222473145, "_runtime": 2860.669299840927, "_timestamp": 1585511939.0900295, "_step": 15}
{"Episode reward": 86.68543644091118, "Episode length": 134, "Policy Loss": 7.42537260055542, "Value Loss": 133.62742614746094, "_runtime": 2861.063963651657, "_timestamp": 1585511939.4846933, "_step": 16}
{"Episode reward": 77.39999999999995, "Episode length": 226, "Policy Loss": 5.5068206787109375, "Value Loss": 95.9656753540039, "_runtime": 2862.6156780719757, "_timestamp": 1585511941.0364077, "_step": 17}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2747764587402344, "Value Loss": 27.356529235839844, "_runtime": 2864.0941355228424, "_timestamp": 1585511942.5148652, "_step": 18}
{"Episode reward": 0.9714064569691772, "Episode length": 992, "Policy Loss": 3.5254664421081543, "Value Loss": 84.31975555419922, "_runtime": 2865.309947013855, "_timestamp": 1585511943.7306767, "_step": 19}
{"Episode reward": 17.82683776458765, "Episode length": 823, "Policy Loss": 2.9667649269104004, "Value Loss": 272.4163818359375, "_runtime": 2866.4217281341553, "_timestamp": 1585511944.8424578, "_step": 20}
{"Episode reward": 29.230579289421186, "Episode length": 708, "Policy Loss": 2.9873671531677246, "Value Loss": 41.09113693237305, "_runtime": 2867.9737243652344, "_timestamp": 1585511946.394454, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0014837980270386, "Value Loss": 46.62016296386719, "_runtime": 2868.9806249141693, "_timestamp": 1585511947.4013546, "_step": 22}
{"Episode reward": 34.578267012535974, "Episode length": 655, "Policy Loss": 2.9838905334472656, "Value Loss": 46.1915283203125, "_runtime": 2870.5292580127716, "_timestamp": 1585511948.9499876, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9058222770690918, "Value Loss": 5.685561180114746, "_runtime": 2872.1328139305115, "_timestamp": 1585511950.5535436, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.9403269290924072, "Value Loss": 21.666112899780273, "_runtime": 2873.6520783901215, "_timestamp": 1585511952.072808, "_step": 25}
{"Episode reward": -99.86293803602317, "Episode length": 999, "Policy Loss": 2.282681941986084, "Value Loss": 2.643771171569824, "_runtime": 2875.2075729370117, "_timestamp": 1585511953.6283026, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.949680805206299, "Value Loss": 25.455066680908203, "_runtime": 2876.76899933815, "_timestamp": 1585511955.189729, "_step": 27}
{"Episode reward": -99.72127275802056, "Episode length": 999, "Policy Loss": 2.9730374813079834, "Value Loss": 15.378589630126953, "_runtime": 2878.3215363025665, "_timestamp": 1585511956.742266, "_step": 28}
{"Episode reward": -99.80011828997964, "Episode length": 999, "Policy Loss": 2.920877456665039, "Value Loss": 12.616992950439453, "_runtime": 2879.618413925171, "_timestamp": 1585511958.0391436, "_step": 29}
{"Episode reward": 17.037472872343358, "Episode length": 830, "Policy Loss": 3.5387465953826904, "Value Loss": 21.814559936523438, "_runtime": 2881.179987668991, "_timestamp": 1585511959.6007173, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6318001747131348, "Value Loss": 4.122604846954346, "_runtime": 2882.738085269928, "_timestamp": 1585511961.158815, "_step": 31}
{"Episode reward": -99.84493679441371, "Episode length": 999, "Policy Loss": 2.4360532760620117, "Value Loss": 1.1859593391418457, "_runtime": 2884.1186742782593, "_timestamp": 1585511962.539404, "_step": 32}
{"Episode reward": 11.702607051355542, "Episode length": 884, "Policy Loss": -53.5579833984375, "Value Loss": 2546.690673828125, "_runtime": 2884.6914660930634, "_timestamp": 1585511963.1121957, "_step": 33}
{"Episode reward": 65.69999999999979, "Episode length": 343, "Policy Loss": 62.51520538330078, "Value Loss": 140.2241973876953, "_runtime": 2886.2389237880707, "_timestamp": 1585511964.6596534, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.871983528137207, "Value Loss": 76.83564758300781, "_runtime": 2887.8017377853394, "_timestamp": 1585511966.2224674, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.670628070831299, "Value Loss": 60.60808563232422, "_runtime": 2889.2938730716705, "_timestamp": 1585511967.7146027, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.579862117767334, "Value Loss": 28.603961944580078, "_runtime": 2890.850621700287, "_timestamp": 1585511969.2713513, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.358481407165527, "Value Loss": 53.07451248168945, "_runtime": 2892.418459415436, "_timestamp": 1585511970.839189, "_step": 38}
{"Episode reward": -99.73311140294987, "Episode length": 999, "Policy Loss": -22.54192352294922, "Value Loss": 208.6623992919922, "_runtime": 2893.9926257133484, "_timestamp": 1585511972.4133554, "_step": 39}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.6808600425720215, "Value Loss": 12.714737892150879, "_runtime": 2895.5537135601044, "_timestamp": 1585511973.9744432, "_step": 40}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.283384799957275, "Value Loss": 4.659017086029053, "_runtime": 2897.126990556717, "_timestamp": 1585511975.5477202, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.976048469543457, "Value Loss": 5.968757152557373, "_runtime": 2898.6740522384644, "_timestamp": 1585511977.0947819, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.338587999343872, "Value Loss": 33.887794494628906, "_runtime": 2900.2398936748505, "_timestamp": 1585511978.6606233, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.76947021484375, "Value Loss": 1.4758435487747192, "_runtime": 2901.8129391670227, "_timestamp": 1585511980.2336688, "_step": 44}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6090918779373169, "Value Loss": 115.78514099121094, "_runtime": 2903.370445728302, "_timestamp": 1585511981.7911754, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0375869274139404, "Value Loss": 4.71576452255249, "_runtime": 2904.915674686432, "_timestamp": 1585511983.3364043, "_step": 46}
{"Episode reward": -99.86208915647526, "Episode length": 999, "Policy Loss": -1.8722171783447266, "Value Loss": 0.5189573168754578, "_runtime": 2906.474942445755, "_timestamp": 1585511984.895672, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1466495990753174, "Value Loss": 2.2461400032043457, "_runtime": 2908.026717185974, "_timestamp": 1585511986.4474468, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8469369411468506, "Value Loss": 22.097774505615234, "_runtime": 2909.591061115265, "_timestamp": 1585511988.0117908, "_step": 49}
{"Episode reward": -99.7516528933104, "Episode length": 999, "Policy Loss": -0.674636721611023, "Value Loss": 12.317590713500977, "_runtime": 2911.1528811454773, "_timestamp": 1585511989.5736108, "_step": 50}
{"Episode reward": -99.84213782517996, "Episode length": 999, "Policy Loss": -1.686528205871582, "Value Loss": 2.1993181705474854, "_runtime": 2912.7045290470123, "_timestamp": 1585511991.1252587, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.210606575012207, "Value Loss": 0.23694512248039246, "_runtime": 2914.261237382889, "_timestamp": 1585511992.681967, "_step": 52}
{"Episode reward": -99.68497693634569, "Episode length": 999, "Policy Loss": -3.5307576656341553, "Value Loss": 1.8606330156326294, "_runtime": 2915.8267529010773, "_timestamp": 1585511994.2474825, "_step": 53}
{"Episode reward": -99.70544487811136, "Episode length": 999, "Policy Loss": -10.117890357971191, "Value Loss": 2.430774450302124, "_runtime": 2917.418181180954, "_timestamp": 1585511995.8389108, "_step": 54}
{"Episode reward": -99.3871820401247, "Episode length": 999, "Policy Loss": -0.5805950164794922, "Value Loss": 1.940638780593872, "_runtime": 2918.9716942310333, "_timestamp": 1585511997.3924239, "_step": 55}
{"Episode reward": -99.43968927269432, "Episode length": 999, "Policy Loss": -5.514411449432373, "Value Loss": 3.56577730178833, "_runtime": 2920.5430991649628, "_timestamp": 1585511998.9638288, "_step": 56}
{"Episode reward": -99.70933235923233, "Episode length": 999, "Policy Loss": 0.49397772550582886, "Value Loss": 1.16155207157135, "_runtime": 2922.107819080353, "_timestamp": 1585512000.5285487, "_step": 57}
{"Episode reward": -99.49411371970348, "Episode length": 999, "Policy Loss": -0.2870173752307892, "Value Loss": 1.8701918125152588, "_runtime": 2923.672832250595, "_timestamp": 1585512002.093562, "_step": 58}
{"Episode reward": -99.42481369298108, "Episode length": 999, "Policy Loss": 0.5155598521232605, "Value Loss": 0.6219845414161682, "_runtime": 2925.2400453090668, "_timestamp": 1585512003.660775, "_step": 59}
{"Episode reward": -99.74008828787926, "Episode length": 999, "Policy Loss": 0.17054414749145508, "Value Loss": 1.2369811534881592, "_runtime": 2926.804836511612, "_timestamp": 1585512005.2255661, "_step": 60}
{"Episode reward": -99.70104304262584, "Episode length": 999, "Policy Loss": -0.51458740234375, "Value Loss": 0.7217651009559631, "_runtime": 2928.360489845276, "_timestamp": 1585512006.7812195, "_step": 61}
{"Episode reward": -99.64048904245696, "Episode length": 999, "Policy Loss": -0.4750646948814392, "Value Loss": 1.0833513736724854, "_runtime": 2929.9098393917084, "_timestamp": 1585512008.330569, "_step": 62}
{"Episode reward": -99.53421054947187, "Episode length": 999, "Policy Loss": -0.36973974108695984, "Value Loss": 0.8506602644920349, "_runtime": 2931.463726758957, "_timestamp": 1585512009.8844564, "_step": 63}
{"Episode reward": -99.74482647525006, "Episode length": 999, "Policy Loss": -0.2802790701389313, "Value Loss": 0.251751571893692, "_runtime": 2933.0299570560455, "_timestamp": 1585512011.4506867, "_step": 64}
{"Episode reward": -99.6473771147649, "Episode length": 999, "Policy Loss": -0.7013579607009888, "Value Loss": 0.575094997882843, "_runtime": 2934.5993580818176, "_timestamp": 1585512013.0200877, "_step": 65}
{"Episode reward": -99.45729917902254, "Episode length": 999, "Policy Loss": -0.41283392906188965, "Value Loss": 0.6887285113334656, "_runtime": 2936.1643698215485, "_timestamp": 1585512014.5850995, "_step": 66}
{"Episode reward": -99.86370730540703, "Episode length": 999, "Policy Loss": -0.9008221626281738, "Value Loss": 0.2244621217250824, "_runtime": 2937.7288269996643, "_timestamp": 1585512016.1495566, "_step": 67}
{"Episode reward": -99.4896501274975, "Episode length": 999, "Policy Loss": -0.6995707750320435, "Value Loss": 0.39563149213790894, "_runtime": 2939.29763174057, "_timestamp": 1585512017.7183614, "_step": 68}
{"Episode reward": -99.74969224156672, "Episode length": 999, "Policy Loss": -0.9484277367591858, "Value Loss": 0.2702353000640869, "_runtime": 2940.890801668167, "_timestamp": 1585512019.3115313, "_step": 69}
{"Episode reward": -99.62071994859586, "Episode length": 999, "Policy Loss": -0.9548513889312744, "Value Loss": 0.48751476407051086, "_runtime": 2942.4459154605865, "_timestamp": 1585512020.866645, "_step": 70}
{"Episode reward": -99.64580811480945, "Episode length": 999, "Policy Loss": -0.9481420516967773, "Value Loss": 0.38453784584999084, "_runtime": 2944.0081555843353, "_timestamp": 1585512022.4288852, "_step": 71}
{"Episode reward": -99.72586817544885, "Episode length": 999, "Policy Loss": -0.667904257774353, "Value Loss": 0.7749696373939514, "_runtime": 2945.5631132125854, "_timestamp": 1585512023.9838428, "_step": 72}
{"Episode reward": -99.73610087262247, "Episode length": 999, "Policy Loss": -1.2485305070877075, "Value Loss": 0.31217148900032043, "_runtime": 2947.1276965141296, "_timestamp": 1585512025.5484262, "_step": 73}
{"Episode reward": -99.72785002598631, "Episode length": 999, "Policy Loss": -0.763617992401123, "Value Loss": 0.6262730360031128, "_runtime": 2948.685824394226, "_timestamp": 1585512027.106554, "_step": 74}
{"Episode reward": -99.70923472417957, "Episode length": 999, "Policy Loss": -1.1360304355621338, "Value Loss": 0.4338226914405823, "_runtime": 2950.2430605888367, "_timestamp": 1585512028.6637902, "_step": 75}
{"Episode reward": -99.74795945179801, "Episode length": 999, "Policy Loss": -1.0652854442596436, "Value Loss": 0.3563401401042938, "_runtime": 2951.808735370636, "_timestamp": 1585512030.229465, "_step": 76}
{"Episode reward": -99.49353708159316, "Episode length": 999, "Policy Loss": -0.9571551084518433, "Value Loss": 0.5177335739135742, "_runtime": 2953.3674890995026, "_timestamp": 1585512031.7882187, "_step": 77}
{"Episode reward": -99.80000877762073, "Episode length": 999, "Policy Loss": -0.5474752187728882, "Value Loss": 0.42482835054397583, "_runtime": 2954.920980453491, "_timestamp": 1585512033.34171, "_step": 78}
{"Episode reward": -99.75398534957645, "Episode length": 999, "Policy Loss": -0.842153787612915, "Value Loss": 0.33646267652511597, "_runtime": 2956.4747965335846, "_timestamp": 1585512034.8955262, "_step": 79}
{"Episode reward": -99.71476991543145, "Episode length": 999, "Policy Loss": -0.7732852697372437, "Value Loss": 0.37555816769599915, "_runtime": 2958.033947467804, "_timestamp": 1585512036.454677, "_step": 80}
{"Episode reward": -99.60839383310733, "Episode length": 999, "Policy Loss": -0.8601776957511902, "Value Loss": 0.1470489203929901, "_runtime": 2959.5988767147064, "_timestamp": 1585512038.0196064, "_step": 81}
{"Episode reward": -99.67047302659928, "Episode length": 999, "Policy Loss": -0.8997254371643066, "Value Loss": 0.06639471650123596, "_runtime": 2961.1652505397797, "_timestamp": 1585512039.5859802, "_step": 82}
{"Episode reward": -99.72669753752517, "Episode length": 999, "Policy Loss": -0.7060483694076538, "Value Loss": 0.08125125616788864, "_runtime": 2962.7325348854065, "_timestamp": 1585512041.1532645, "_step": 83}
{"Episode reward": -99.6760376302964, "Episode length": 999, "Policy Loss": -0.7460293173789978, "Value Loss": 0.08698417991399765, "_runtime": 2964.334866285324, "_timestamp": 1585512042.755596, "_step": 84}
{"Episode reward": -99.61402071812634, "Episode length": 999, "Policy Loss": -0.8542911410331726, "Value Loss": 0.12556838989257812, "_runtime": 2965.902983903885, "_timestamp": 1585512044.3237135, "_step": 85}
{"Episode reward": -99.79371704332915, "Episode length": 999, "Policy Loss": -0.6058818101882935, "Value Loss": 0.06673943251371384, "_runtime": 2967.471760034561, "_timestamp": 1585512045.8924897, "_step": 86}
{"Episode reward": -99.16807604129521, "Episode length": 999, "Policy Loss": -0.47026368975639343, "Value Loss": 0.12594491243362427, "_runtime": 2969.0265820026398, "_timestamp": 1585512047.4473116, "_step": 87}
{"Episode reward": -99.71971950197918, "Episode length": 999, "Policy Loss": -0.5697633624076843, "Value Loss": 0.18333138525485992, "_runtime": 2970.5832760334015, "_timestamp": 1585512049.0040057, "_step": 88}
{"Episode reward": -99.76175479248492, "Episode length": 999, "Policy Loss": -0.5090062022209167, "Value Loss": 0.1435776650905609, "_runtime": 2972.1530656814575, "_timestamp": 1585512050.5737953, "_step": 89}
{"Episode reward": -99.79880170211987, "Episode length": 999, "Policy Loss": -0.5429055094718933, "Value Loss": 0.09136826545000076, "_runtime": 2973.7010402679443, "_timestamp": 1585512052.12177, "_step": 90}
{"Episode reward": -99.32224342522234, "Episode length": 999, "Policy Loss": -0.6842123866081238, "Value Loss": 0.09900353848934174, "_runtime": 2975.2776322364807, "_timestamp": 1585512053.6983619, "_step": 91}
{"Episode reward": -99.5649843659287, "Episode length": 999, "Policy Loss": -0.7278817892074585, "Value Loss": 0.14348682761192322, "_runtime": 2976.8437416553497, "_timestamp": 1585512055.2644713, "_step": 92}
{"Episode reward": -99.45115310373228, "Episode length": 999, "Policy Loss": -0.5074111223220825, "Value Loss": 0.06891990453004837, "_runtime": 2978.401127576828, "_timestamp": 1585512056.8218572, "_step": 93}
{"Episode reward": -99.68338315989683, "Episode length": 999, "Policy Loss": -0.5596721172332764, "Value Loss": 0.02095172367990017, "_runtime": 2979.958352327347, "_timestamp": 1585512058.379082, "_step": 94}
{"Episode reward": -99.71236360922782, "Episode length": 999, "Policy Loss": -0.5649187564849854, "Value Loss": 0.03927003964781761, "_runtime": 2981.516205072403, "_timestamp": 1585512059.9369347, "_step": 95}
{"Episode reward": -99.52727342362446, "Episode length": 999, "Policy Loss": -0.6095512509346008, "Value Loss": 0.054943546652793884, "_runtime": 2983.083272218704, "_timestamp": 1585512061.5040019, "_step": 96}
{"Episode reward": -99.72603402054379, "Episode length": 999, "Policy Loss": -0.5961556434631348, "Value Loss": 0.04198704659938812, "_runtime": 2984.6497192382812, "_timestamp": 1585512063.0704489, "_step": 97}
{"Episode reward": -99.89298931828095, "Episode length": 999, "Policy Loss": -0.5573654174804688, "Value Loss": 0.046815335750579834, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625, -1509.2379150390625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-326807.125, -321651.0, -316494.90625, -311338.78125, -306182.65625, -301026.5625, -295870.4375, -290714.3125, -285558.1875, -280402.09375, -275245.96875, -270089.875, -264933.75, -259777.625, -254621.515625, -249465.40625, -244309.28125, -239153.15625, -233997.046875, -228840.9375, -223684.8125, -218528.703125, -213372.59375, -208216.46875, -203060.359375, -197904.25, -192748.125, -187592.015625, -182435.90625, -177279.78125, -172123.671875, -166967.546875, -161811.4375, -156655.328125, -151499.203125, -146343.09375, -141186.96875, -136030.859375, -130874.75, -125718.625, -120562.515625, -115406.40625, -110250.28125, -105094.171875, -99938.0625, -94781.9375, -89625.828125, -84469.703125, -79313.59375, -74157.484375, -69001.359375, -63845.25, -58689.125, -53533.03125, -48376.90625, -43220.78125, -38064.6875, -32908.5625, -27752.4375, -22596.3125, -17440.21875, -12284.09375, -7127.96875, -1971.875, 3184.25]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-5235.04541015625, -5064.04833984375, -4893.05078125, -4722.0537109375, -4551.056640625, -4380.0595703125, -4209.0625, -4038.06494140625, -3867.06787109375, -3696.07080078125, -3525.073486328125, -3354.076171875, -3183.0791015625, -3012.08203125, -2841.084716796875, -2670.08740234375, -2499.09033203125, -2328.09326171875, -2157.095947265625, -1986.0986328125, -1815.1015625, -1644.1044921875, -1473.107177734375, -1302.10986328125, -1131.11279296875, -960.11572265625, -789.11865234375, -618.12109375, -447.1240234375, -276.126953125, -105.12939453125, 65.86767578125, 236.86474609375, 407.86181640625, 578.85888671875, 749.8564453125, 920.853515625, 1091.8505859375, 1262.84814453125, 1433.84521484375, 1604.84228515625, 1775.83935546875, 1946.83642578125, 2117.833984375, 2288.8310546875, 2459.828125, 2630.82568359375, 2801.82275390625, 2972.81982421875, 3143.81689453125, 3314.81396484375, 3485.81103515625, 3656.80810546875, 3827.80615234375, 3998.80322265625, 4169.80029296875, 4340.79736328125, 4511.79443359375, 4682.79150390625, 4853.78857421875, 5024.78662109375, 5195.78369140625, 5366.78076171875, 5537.77783203125, 5708.77490234375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 5.0, 7.0, 7.0, 5.0, 8.0, 8.0, 10.0, 24.0, 27.0, 314.0, 24.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], "bins": [-93626.7265625, -90711.8984375, -87797.0703125, -84882.2421875, -81967.4140625, -79052.5859375, -76137.7578125, -73222.9296875, -70308.1015625, -67393.2734375, -64478.4453125, -61563.6171875, -58648.7890625, -55733.9609375, -52819.1328125, -49904.3046875, -46989.4765625, -44074.6484375, -41159.8203125, -38244.9921875, -35330.1640625, -32415.3359375, -29500.5078125, -26585.6796875, -23670.8515625, -20756.0234375, -17841.1953125, -14926.3671875, -12011.5390625, -9096.7109375, -6181.8828125, -3267.0546875, -352.2265625, 2562.6015625, 5477.4296875, 8392.2578125, 11307.0859375, 14221.9140625, 17136.7421875, 20051.5703125, 22966.3984375, 25881.2265625, 28796.0546875, 31710.8828125, 34625.7109375, 37540.5390625, 40455.3671875, 43370.1953125, 46285.0234375, 49199.8515625, 52114.6796875, 55029.5078125, 57944.3359375, 60859.1640625, 63773.9921875, 66688.8203125, 69603.6484375, 72518.4765625, 75433.3046875, 78348.1328125, 81262.9609375, 84177.7890625, 87092.6171875, 90007.4453125, 92922.2734375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 8.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-434607.96875, -424815.90625, -415023.8125, -405231.75, -395439.65625, -385647.59375, -375855.5, -366063.4375, -356271.375, -346479.28125, -336687.21875, -326895.125, -317103.0625, -307311.0, -297518.9375, -287726.84375, -277934.75, -268142.6875, -258350.609375, -248558.546875, -238766.46875, -228974.390625, -219182.3125, -209390.234375, -199598.15625, -189806.09375, -180014.015625, -170221.9375, -160429.875, -150637.78125, -140845.71875, -131053.625, -121261.5625, -111469.5, -101677.40625, -91885.34375, -82093.25, -72301.1875, -62509.125, -52717.03125, -42924.96875, -33132.875, -23340.8125, -13548.75, -3756.65625, 6035.40625, 15827.5, 25619.5625, 35411.65625, 45203.71875, 54995.78125, 64787.875, 74579.9375, 84372.03125, 94164.09375, 103956.15625, 113748.21875, 123540.34375, 133332.40625, 143124.46875, 152916.53125, 162708.59375, 172500.71875, 182292.78125, 192084.84375]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 17.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], "bins": [-621161.75, -606884.5625, -592607.3125, -578330.125, -564052.875, -549775.6875, -535498.5, -521221.25, -506944.0625, -492666.84375, -478389.625, -464112.40625, -449835.1875, -435558.0, -421280.75, -407003.5625, -392726.34375, -378449.125, -364171.9375, -349894.71875, -335617.5, -321340.28125, -307063.0625, -292785.84375, -278508.625, -264231.4375, -249954.21875, -235677.0, -221399.78125, -207122.5625, -192845.375, -178568.15625, -164290.9375, -150013.71875, -135736.5, -121459.3125, -107182.09375, -92904.875, -78627.6875, -64350.4375, -50073.25, -35796.0, -21518.8125, -7241.625, 7035.625, 21312.8125, 35590.0625, 49867.25, 64144.5, 78421.6875, 92698.875, 106976.125, 121253.3125, 135530.5625, 149807.75, 164084.9375, 178362.1875, 192639.375, 206916.625, 221193.8125, 235471.0, 249748.25, 264025.4375, 278302.6875, 292579.875]}, "_runtime": 2986.2104597091675, "_timestamp": 1585512064.6311893, "_step": 98}
{"Episode reward": -99.75496998501973, "Episode length": 999, "Policy Loss": -0.5599662065505981, "Value Loss": 0.05476447194814682, "_runtime": 2987.810391187668, "_timestamp": 1585512066.2311208, "_step": 99}
{"Episode reward": -99.65562507244161, "Episode length": 999, "Policy Loss": -0.500164270401001, "Value Loss": 0.05562374368309975, "_runtime": 2989.365313053131, "_timestamp": 1585512067.7860427, "_step": 100}
{"Episode reward": -99.74776287864923, "Episode length": 999, "Policy Loss": -0.6077736616134644, "Value Loss": 0.055682115256786346, "_runtime": 2990.9134607315063, "_timestamp": 1585512069.3341904, "_step": 101}
{"Episode reward": -99.791582720512, "Episode length": 999, "Policy Loss": -0.5444105267524719, "Value Loss": 0.0477653443813324, "_runtime": 2992.480594396591, "_timestamp": 1585512070.901324, "_step": 102}
{"Episode reward": -99.67227538411278, "Episode length": 999, "Policy Loss": -0.554835319519043, "Value Loss": 0.08107244223356247, "_runtime": 2994.046553850174, "_timestamp": 1585512072.4672835, "_step": 103}
{"Episode reward": -99.47731958011583, "Episode length": 999, "Policy Loss": -0.589194118976593, "Value Loss": 0.04379303753376007, "_runtime": 2995.6136310100555, "_timestamp": 1585512074.0343606, "_step": 104}
{"Episode reward": -99.76963007124462, "Episode length": 999, "Policy Loss": -0.4966695308685303, "Value Loss": 0.04533863440155983, "_runtime": 2997.1806049346924, "_timestamp": 1585512075.6013346, "_step": 105}
{"Episode reward": -99.8002772260676, "Episode length": 999, "Policy Loss": -0.4983573257923126, "Value Loss": 0.03699939697980881, "_runtime": 2998.7456386089325, "_timestamp": 1585512077.1663682, "_step": 106}
{"Episode reward": -99.529028366297, "Episode length": 999, "Policy Loss": -0.5056450963020325, "Value Loss": 0.04672842472791672, "_runtime": 3000.303997039795, "_timestamp": 1585512078.7247267, "_step": 107}
{"Episode reward": -99.8194858257347, "Episode length": 999, "Policy Loss": -0.4412330090999603, "Value Loss": 0.017908161506056786, "_runtime": 3001.8573961257935, "_timestamp": 1585512080.2781258, "_step": 108}
{"Episode reward": -99.7460213521103, "Episode length": 999, "Policy Loss": -0.5638909935951233, "Value Loss": 0.06958941370248795, "_runtime": 3003.410485982895, "_timestamp": 1585512081.8312156, "_step": 109}
{"Episode reward": -99.42784208886043, "Episode length": 999, "Policy Loss": -0.5115997791290283, "Value Loss": 0.05298897624015808, "_runtime": 3004.975507259369, "_timestamp": 1585512083.396237, "_step": 110}
{"Episode reward": -99.42726638534951, "Episode length": 999, "Policy Loss": -0.5238330364227295, "Value Loss": 0.05338524654507637, "_runtime": 3006.5399680137634, "_timestamp": 1585512084.9606977, "_step": 111}
{"Episode reward": -99.61736899991382, "Episode length": 999, "Policy Loss": -0.4214334487915039, "Value Loss": 0.03651160001754761, "_runtime": 3008.105080842972, "_timestamp": 1585512086.5258105, "_step": 112}
{"Episode reward": -99.80774647179125, "Episode length": 999, "Policy Loss": -0.4758879542350769, "Value Loss": 0.06416131556034088, "_runtime": 3009.6998059749603, "_timestamp": 1585512088.1205356, "_step": 113}
{"Episode reward": -99.679290498273, "Episode length": 999, "Policy Loss": -0.3577311933040619, "Value Loss": 0.022020721808075905, "_runtime": 3011.256733417511, "_timestamp": 1585512089.677463, "_step": 114}
{"Episode reward": -99.54551538737606, "Episode length": 999, "Policy Loss": -0.39059945940971375, "Value Loss": 0.026129083707928658, "_runtime": 3012.807985305786, "_timestamp": 1585512091.228715, "_step": 115}
{"Episode reward": -99.86007610332445, "Episode length": 999, "Policy Loss": -0.37941092252731323, "Value Loss": 0.031519122421741486, "_runtime": 3014.373222589493, "_timestamp": 1585512092.7939522, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3869400918483734, "Value Loss": 0.018971724435687065, "_runtime": 3015.927372455597, "_timestamp": 1585512094.348102, "_step": 117}
{"Episode reward": -99.66410821017787, "Episode length": 999, "Policy Loss": -0.38375213742256165, "Value Loss": 0.019204730167984962, "_runtime": 3017.4817955493927, "_timestamp": 1585512095.9025252, "_step": 118}
{"Episode reward": -99.70719368205086, "Episode length": 999, "Policy Loss": -0.36720243096351624, "Value Loss": 0.020607609301805496, "_runtime": 3019.0252273082733, "_timestamp": 1585512097.445957, "_step": 119}
{"Episode reward": -99.6543745343308, "Episode length": 999, "Policy Loss": -0.45002880692481995, "Value Loss": 0.023024508729577065, "_runtime": 3020.579866170883, "_timestamp": 1585512099.0005958, "_step": 120}
{"Episode reward": -99.36347129232824, "Episode length": 999, "Policy Loss": -0.35994720458984375, "Value Loss": 0.021581638604402542, "_runtime": 3022.138700246811, "_timestamp": 1585512100.55943, "_step": 121}
{"Episode reward": -99.72387898734748, "Episode length": 999, "Policy Loss": -0.5346817970275879, "Value Loss": 0.07674821466207504, "_runtime": 3023.704293012619, "_timestamp": 1585512102.1250226, "_step": 122}
{"Episode reward": -99.66477126128858, "Episode length": 999, "Policy Loss": -0.3712104558944702, "Value Loss": 0.040705278515815735, "_runtime": 3025.269950866699, "_timestamp": 1585512103.6906805, "_step": 123}
{"Episode reward": -99.74727712320025, "Episode length": 999, "Policy Loss": -0.4045310616493225, "Value Loss": 0.05161662772297859, "_runtime": 3026.8383779525757, "_timestamp": 1585512105.2591076, "_step": 124}
{"Episode reward": -99.79735207606433, "Episode length": 999, "Policy Loss": -0.40310797095298767, "Value Loss": 0.05156762897968292, "_runtime": 3028.4050347805023, "_timestamp": 1585512106.8257644, "_step": 125}
{"Episode reward": -99.70304842190679, "Episode length": 999, "Policy Loss": -0.35341107845306396, "Value Loss": 0.02533121220767498, "_runtime": 3029.9595787525177, "_timestamp": 1585512108.3803084, "_step": 126}
{"Episode reward": -99.69689935983868, "Episode length": 999, "Policy Loss": -0.3980948030948639, "Value Loss": 0.04025081545114517, "_runtime": 3031.5256962776184, "_timestamp": 1585512109.946426, "_step": 127}
{"Episode reward": -99.87150589311355, "Episode length": 999, "Policy Loss": -0.34083348512649536, "Value Loss": 0.016581224277615547, "_runtime": 3033.105737686157, "_timestamp": 1585512111.5264673, "_step": 128}
{"Episode reward": -99.82945500016073, "Episode length": 999, "Policy Loss": -0.31825026869773865, "Value Loss": 0.01646353118121624, "_runtime": 3034.6701290607452, "_timestamp": 1585512113.0908587, "_step": 129}
{"Episode reward": -99.68711868009066, "Episode length": 999, "Policy Loss": -0.4126126170158386, "Value Loss": 0.038311365991830826, "_runtime": 3036.2255566120148, "_timestamp": 1585512114.6462862, "_step": 130}
{"Episode reward": -99.88686367422203, "Episode length": 999, "Policy Loss": -0.314900666475296, "Value Loss": 0.021386174485087395, "_runtime": 3037.7790722846985, "_timestamp": 1585512116.199802, "_step": 131}
{"Episode reward": -99.44220359911682, "Episode length": 999, "Policy Loss": -0.280422568321228, "Value Loss": 0.023193638771772385, "_runtime": 3039.3437547683716, "_timestamp": 1585512117.7644844, "_step": 132}
{"Episode reward": -99.7791340323882, "Episode length": 999, "Policy Loss": -0.33253195881843567, "Value Loss": 0.022198636084794998, "_runtime": 3040.8862907886505, "_timestamp": 1585512119.3070204, "_step": 133}
{"Episode reward": -99.86075890399376, "Episode length": 999, "Policy Loss": -0.2754192352294922, "Value Loss": 0.01679547131061554, "_runtime": 3042.4465811252594, "_timestamp": 1585512120.8673108, "_step": 134}
{"Episode reward": -99.50445970541193, "Episode length": 999, "Policy Loss": -0.25018417835235596, "Value Loss": 0.013543159700930119, "_runtime": 3043.9993381500244, "_timestamp": 1585512122.4200678, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2920723259449005, "Value Loss": 0.025808965787291527, "_runtime": 3045.562206029892, "_timestamp": 1585512123.9829357, "_step": 136}
{"Episode reward": -99.85828572171128, "Episode length": 999, "Policy Loss": -0.25882595777511597, "Value Loss": 0.029126949608325958, "_runtime": 3047.1290221214294, "_timestamp": 1585512125.5497518, "_step": 137}
{"Episode reward": -99.82431355474843, "Episode length": 999, "Policy Loss": -0.3320862650871277, "Value Loss": 0.03089463710784912, "_runtime": 3048.69291806221, "_timestamp": 1585512127.1136477, "_step": 138}
{"Episode reward": -99.58520449291875, "Episode length": 999, "Policy Loss": -0.23062336444854736, "Value Loss": 0.01722358912229538, "_runtime": 3050.2555527687073, "_timestamp": 1585512128.6762824, "_step": 139}
{"Episode reward": -99.71425716878778, "Episode length": 999, "Policy Loss": -0.32123422622680664, "Value Loss": 0.027510477229952812, "_runtime": 3051.8208570480347, "_timestamp": 1585512130.2415867, "_step": 140}
{"Episode reward": -99.72787404971902, "Episode length": 999, "Policy Loss": -0.23362237215042114, "Value Loss": 0.014300856739282608, "_runtime": 3053.386050462723, "_timestamp": 1585512131.80678, "_step": 141}
{"Episode reward": -99.71254469873836, "Episode length": 999, "Policy Loss": -0.24140703678131104, "Value Loss": 0.015329957008361816, "_runtime": 3054.939640522003, "_timestamp": 1585512133.3603702, "_step": 142}
{"Episode reward": -99.61252412816113, "Episode length": 999, "Policy Loss": -0.2634775638580322, "Value Loss": 0.02057310938835144, "_runtime": 3056.531068086624, "_timestamp": 1585512134.9517977, "_step": 143}
{"Episode reward": -99.78335641194907, "Episode length": 999, "Policy Loss": -0.2342783361673355, "Value Loss": 0.009128773584961891, "_runtime": 3058.07572889328, "_timestamp": 1585512136.4964585, "_step": 144}
{"Episode reward": -99.55617545389454, "Episode length": 999, "Policy Loss": -0.25301647186279297, "Value Loss": 0.0215799268335104, "_runtime": 3059.6379437446594, "_timestamp": 1585512138.0586734, "_step": 145}
{"Episode reward": -99.33521547429146, "Episode length": 999, "Policy Loss": -0.2168654054403305, "Value Loss": 0.012983602471649647, "_runtime": 3061.203160762787, "_timestamp": 1585512139.6238904, "_step": 146}
{"Episode reward": -99.62534696571294, "Episode length": 999, "Policy Loss": -0.24417708814144135, "Value Loss": 0.03444244712591171, "_runtime": 3062.7559967041016, "_timestamp": 1585512141.1767263, "_step": 147}
{"Episode reward": -99.80851881652931, "Episode length": 999, "Policy Loss": -0.2290530800819397, "Value Loss": 0.01855119690299034, "_runtime": 3064.299985408783, "_timestamp": 1585512142.720715, "_step": 148}
{"Episode reward": -99.69615035058713, "Episode length": 999, "Policy Loss": -0.2360786646604538, "Value Loss": 0.016390595585107803, "_runtime": 3065.8709206581116, "_timestamp": 1585512144.2916503, "_step": 149}
{"Episode reward": -99.77009557152493, "Episode length": 999, "Policy Loss": -0.19071397185325623, "Value Loss": 0.01869725063443184, "_runtime": 3067.4150512218475, "_timestamp": 1585512145.8357809, "_step": 150}
{"Episode reward": -99.8326990133403, "Episode length": 999, "Policy Loss": -0.18933096528053284, "Value Loss": 0.00953061506152153, "_runtime": 3068.967993736267, "_timestamp": 1585512147.3887234, "_step": 151}
{"Episode reward": -99.69712276615766, "Episode length": 999, "Policy Loss": -0.1914234310388565, "Value Loss": 0.018518585711717606, "_runtime": 3070.5319159030914, "_timestamp": 1585512148.9526455, "_step": 152}
{"Episode reward": -99.51624084544497, "Episode length": 999, "Policy Loss": -0.24962617456912994, "Value Loss": 0.02401837520301342, "_runtime": 3072.0858130455017, "_timestamp": 1585512150.5065427, "_step": 153}
{"Episode reward": -99.71970346786854, "Episode length": 999, "Policy Loss": -0.18814167380332947, "Value Loss": 0.019486689940094948, "_runtime": 3073.649654150009, "_timestamp": 1585512152.0703838, "_step": 154}
{"Episode reward": -99.81952707767347, "Episode length": 999, "Policy Loss": -0.19407545030117035, "Value Loss": 0.01278881635516882, "_runtime": 3075.2131712436676, "_timestamp": 1585512153.633901, "_step": 155}
{"Episode reward": -99.76332684562495, "Episode length": 999, "Policy Loss": -0.15110363066196442, "Value Loss": 0.011670839041471481, "_runtime": 3076.7752668857574, "_timestamp": 1585512155.1959965, "_step": 156}
{"Episode reward": -99.71480650511275, "Episode length": 999, "Policy Loss": -0.1977539211511612, "Value Loss": 0.015898048877716064, "_runtime": 3078.3393054008484, "_timestamp": 1585512156.760035, "_step": 157}
{"Episode reward": -99.44705806139328, "Episode length": 999, "Policy Loss": -0.17308975756168365, "Value Loss": 0.012750615365803242, "_runtime": 3079.918630361557, "_timestamp": 1585512158.33936, "_step": 158}
{"Episode reward": -99.41296335631378, "Episode length": 999, "Policy Loss": -0.21639977395534515, "Value Loss": 0.015874894335865974, "_runtime": 3081.469672679901, "_timestamp": 1585512159.8904023, "_step": 159}
{"Episode reward": -99.80661119885453, "Episode length": 999, "Policy Loss": -0.12359392642974854, "Value Loss": 0.008178449235856533, "_runtime": 3083.022761106491, "_timestamp": 1585512161.4434907, "_step": 160}
{"Episode reward": -99.76696510243617, "Episode length": 999, "Policy Loss": -0.18116696178913116, "Value Loss": 0.017901143059134483, "_runtime": 3084.5794718265533, "_timestamp": 1585512163.0002015, "_step": 161}
{"Episode reward": -99.68527550391885, "Episode length": 999, "Policy Loss": -0.15609367191791534, "Value Loss": 0.006555397994816303, "_runtime": 3086.1323556900024, "_timestamp": 1585512164.5530853, "_step": 162}
{"Episode reward": -99.76420697755972, "Episode length": 999, "Policy Loss": -0.15233713388442993, "Value Loss": 0.00913472194224596, "_runtime": 3087.6965692043304, "_timestamp": 1585512166.1172988, "_step": 163}
{"Episode reward": -99.64284673440132, "Episode length": 999, "Policy Loss": -0.17164283990859985, "Value Loss": 0.008812480606138706, "_runtime": 3089.2630620002747, "_timestamp": 1585512167.6837916, "_step": 164}
{"Episode reward": -99.75534821161861, "Episode length": 999, "Policy Loss": -0.13950665295124054, "Value Loss": 0.010038278996944427, "_runtime": 3090.829220056534, "_timestamp": 1585512169.2499497, "_step": 165}
{"Episode reward": -99.72431236477917, "Episode length": 999, "Policy Loss": -0.20993748307228088, "Value Loss": 0.016451142728328705, "_runtime": 3092.3939547538757, "_timestamp": 1585512170.8146844, "_step": 166}
{"Episode reward": -99.74580864915485, "Episode length": 999, "Policy Loss": -0.1339816451072693, "Value Loss": 0.009443093091249466, "_runtime": 3093.9470274448395, "_timestamp": 1585512172.367757, "_step": 167}
{"Episode reward": -99.65635183809653, "Episode length": 999, "Policy Loss": -0.1340113878250122, "Value Loss": 0.008338093757629395, "_runtime": 3095.503494977951, "_timestamp": 1585512173.9242246, "_step": 168}
{"Episode reward": -99.36255684688317, "Episode length": 999, "Policy Loss": -0.26057711243629456, "Value Loss": 0.02732408046722412, "_runtime": 3097.0474846363068, "_timestamp": 1585512175.4682143, "_step": 169}
{"Episode reward": -99.62350182457973, "Episode length": 999, "Policy Loss": -0.163529634475708, "Value Loss": 0.014618831686675549, "_runtime": 3098.599732398987, "_timestamp": 1585512177.020462, "_step": 170}
{"Episode reward": -99.66511617646769, "Episode length": 999, "Policy Loss": -0.18360535800457, "Value Loss": 0.016723494976758957, "_runtime": 3100.1552634239197, "_timestamp": 1585512178.575993, "_step": 171}
{"Episode reward": -99.6160959692306, "Episode length": 999, "Policy Loss": -0.13401854038238525, "Value Loss": 0.013039200566709042, "_runtime": 3101.7588863372803, "_timestamp": 1585512180.179616, "_step": 172}
{"Episode reward": -99.73852882253387, "Episode length": 999, "Policy Loss": -0.23087646067142487, "Value Loss": 0.025996845215559006, "_runtime": 3103.32336974144, "_timestamp": 1585512181.7440994, "_step": 173}
{"Episode reward": -99.38255199124897, "Episode length": 999, "Policy Loss": -0.08478955924510956, "Value Loss": 0.018326327204704285, "_runtime": 3104.874637365341, "_timestamp": 1585512183.295367, "_step": 174}
{"Episode reward": -99.80551320947568, "Episode length": 999, "Policy Loss": -0.10238489508628845, "Value Loss": 0.009268865920603275, "_runtime": 3106.43297624588, "_timestamp": 1585512184.853706, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1979304403066635, "Value Loss": 0.02690056711435318, "_runtime": 3107.988570213318, "_timestamp": 1585512186.4092999, "_step": 176}
{"Episode reward": -99.56715244733967, "Episode length": 999, "Policy Loss": -0.10022334009408951, "Value Loss": 0.023481089621782303, "_runtime": 3109.547360897064, "_timestamp": 1585512187.9680905, "_step": 177}
{"Episode reward": -99.4979747118659, "Episode length": 999, "Policy Loss": -0.1298728734254837, "Value Loss": 0.015888119116425514, "_runtime": 3111.114087343216, "_timestamp": 1585512189.534817, "_step": 178}
{"Episode reward": -99.69746992474329, "Episode length": 999, "Policy Loss": -0.16434961557388306, "Value Loss": 0.029741303995251656, "_runtime": 3112.6805374622345, "_timestamp": 1585512191.101267, "_step": 179}
{"Episode reward": -99.79227542290324, "Episode length": 999, "Policy Loss": -0.10557988286018372, "Value Loss": 0.009406764060258865, "_runtime": 3114.2462356090546, "_timestamp": 1585512192.6669652, "_step": 180}
{"Episode reward": -99.28935908353205, "Episode length": 999, "Policy Loss": -0.21228155493736267, "Value Loss": 0.02059284597635269, "_runtime": 3115.8078932762146, "_timestamp": 1585512194.228623, "_step": 181}
{"Episode reward": -99.75178668497739, "Episode length": 999, "Policy Loss": -0.08915163576602936, "Value Loss": 0.0207932498306036, "_runtime": 3117.363664627075, "_timestamp": 1585512195.7843943, "_step": 182}
{"Episode reward": -99.62606215493005, "Episode length": 999, "Policy Loss": -0.16143551468849182, "Value Loss": 0.03230191767215729, "_runtime": 3118.905131340027, "_timestamp": 1585512197.325861, "_step": 183}
{"Episode reward": -99.75191199788685, "Episode length": 999, "Policy Loss": -0.08933139592409134, "Value Loss": 0.014864995144307613, "_runtime": 3120.4722023010254, "_timestamp": 1585512198.892932, "_step": 184}
{"Episode reward": -99.52848479442808, "Episode length": 999, "Policy Loss": -0.10710202157497406, "Value Loss": 0.017309265211224556, "_runtime": 3122.025817632675, "_timestamp": 1585512200.4465473, "_step": 185}
{"Episode reward": -99.74788896630163, "Episode length": 999, "Policy Loss": -0.07724455744028091, "Value Loss": 0.012804771773517132, "_runtime": 3123.5796711444855, "_timestamp": 1585512202.0004008, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07748116552829742, "Value Loss": 0.013414603658020496, "_runtime": 3125.1800706386566, "_timestamp": 1585512203.6008003, "_step": 187}
{"Episode reward": -99.450161261003, "Episode length": 999, "Policy Loss": -0.07346583157777786, "Value Loss": 0.00736971152946353, "_runtime": 3126.7470996379852, "_timestamp": 1585512205.1678293, "_step": 188}
{"Episode reward": -99.62594815869883, "Episode length": 999, "Policy Loss": -0.10349778831005096, "Value Loss": 0.017862267792224884, "_runtime": 3128.311489343643, "_timestamp": 1585512206.732219, "_step": 189}
{"Episode reward": -99.73565682784486, "Episode length": 999, "Policy Loss": -0.11052077263593674, "Value Loss": 0.027219070121645927, "_runtime": 3129.8670043945312, "_timestamp": 1585512208.287734, "_step": 190}
{"Episode reward": -99.83204877024842, "Episode length": 999, "Policy Loss": -0.21801802515983582, "Value Loss": 0.03288756683468819, "_runtime": 3131.43204665184, "_timestamp": 1585512209.8527763, "_step": 191}
{"Episode reward": -99.68879179645472, "Episode length": 999, "Policy Loss": -0.07175027579069138, "Value Loss": 0.021170537918806076, "_runtime": 3132.9956471920013, "_timestamp": 1585512211.4163768, "_step": 192}
{"Episode reward": -99.76634241295984, "Episode length": 999, "Policy Loss": -0.11196094751358032, "Value Loss": 0.02779393456876278, "_runtime": 3134.5508258342743, "_timestamp": 1585512212.9715555, "_step": 193}
{"Episode reward": -99.67629907680109, "Episode length": 999, "Policy Loss": -0.019088905304670334, "Value Loss": 0.025458039715886116, "_runtime": 3136.115335702896, "_timestamp": 1585512214.5360653, "_step": 194}
{"Episode reward": -99.58356434617761, "Episode length": 999, "Policy Loss": -0.07805274426937103, "Value Loss": 0.016158320009708405, "_runtime": 3137.6773183345795, "_timestamp": 1585512216.098048, "_step": 195}
{"Episode reward": -99.89012651967792, "Episode length": 999, "Policy Loss": -0.056999120861291885, "Value Loss": 0.011905488558113575, "_runtime": 3139.2410984039307, "_timestamp": 1585512217.661828, "_step": 196}
{"Episode reward": -99.25134945333755, "Episode length": 999, "Policy Loss": -0.053188204765319824, "Value Loss": 0.022337252274155617, "_runtime": 3140.8068380355835, "_timestamp": 1585512219.2275677, "_step": 197}
{"Episode reward": -99.3359356239556, "Episode length": 999, "Policy Loss": -0.08333376795053482, "Value Loss": 0.025702327489852905, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625, 116120.1640625]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-116120.1640625, -71035.6875, -25951.21875, 19133.2578125, 64217.7265625, 109302.1953125, 154386.6875, 199471.15625, 244555.625, 289640.09375, 334724.5625, 379809.03125, 424893.53125, 469977.96875, 515062.46875, 560146.875, 605231.375, 650315.875, 695400.3125, 740484.8125, 785569.25, 830653.75, 875738.1875, 920822.6875, 965907.1875, 1010991.6875, 1056076.125, 1101160.625, 1146245.125, 1191329.625, 1236414.0, 1281498.5, 1326583.0, 1371667.5, 1416752.0, 1461836.375, 1506920.875, 1552005.375, 1597089.875, 1642174.25, 1687258.75, 1732343.25, 1777427.75, 1822512.25, 1867596.625, 1912681.125, 1957765.625, 2002850.125, 2047934.625, 2093019.125, 2138103.5, 2183187.75, 2228272.25, 2273356.75, 2318441.25, 2363525.75, 2408610.25, 2453694.75, 2498779.25, 2543863.75, 2588948.0, 2634032.5, 2679117.0, 2724201.5, 2769286.0]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-438042.59375, -428415.625, -418788.65625, -409161.65625, -399534.6875, -389907.71875, -380280.75, -370653.78125, -361026.8125, -351399.8125, -341772.84375, -332145.875, -322518.90625, -312891.9375, -303264.9375, -293637.96875, -284011.0, -274384.03125, -264757.0625, -255130.078125, -245503.09375, -235876.125, -226249.15625, -216622.171875, -206995.203125, -197368.234375, -187741.25, -178114.28125, -168487.3125, -158860.34375, -149233.34375, -139606.375, -129979.40625, -120352.4375, -110725.46875, -101098.46875, -91471.5, -81844.53125, -72217.5625, -62590.59375, -52963.59375, -43336.625, -33709.65625, -24082.6875, -14455.71875, -4828.75, 4798.25, 14425.21875, 24052.1875, 33679.15625, 43306.125, 52933.125, 62560.09375, 72187.0625, 81814.03125, 91441.03125, 101067.96875, 110694.96875, 120321.90625, 129948.90625, 139575.90625, 149202.84375, 158829.84375, 168456.78125, 178083.78125]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 5.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 4.0, 3.0, 5.0, 5.0, 5.0, 15.0, 15.0, 13.0, 287.0, 17.0, 27.0, 19.0, 11.0, 8.0, 9.0, 17.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0], "bins": [-2592755.0, -2535773.25, -2478791.75, -2421810.0, -2364828.5, -2307846.75, -2250865.25, -2193883.5, -2136902.0, -2079920.25, -2022938.625, -1965957.0, -1908975.25, -1851993.75, -1795012.0, -1738030.375, -1681048.75, -1624067.125, -1567085.5, -1510103.875, -1453122.25, -1396140.5, -1339158.875, -1282177.25, -1225195.625, -1168214.0, -1111232.375, -1054250.75, -997269.0, -940287.375, -883305.75, -826324.125, -769342.5, -712360.875, -655379.25, -598397.625, -541416.0, -484434.25, -427452.75, -370471.0, -313489.5, -256507.75, -199526.0, -142544.5, -85562.75, -28581.25, 28400.5, 85382.0, 142363.75, 199345.5, 256327.0, 313308.75, 370290.25, 427272.0, 484253.5, 541235.25, 598217.0, 655198.5, 712180.25, 769161.75, 826143.5, 883125.0, 940106.75, 997088.25, 1054070.0]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6007594.0, -5705014.0, -5402434.5, -5099855.0, -4797275.0, -4494695.0, -4192115.5, -3889535.75, -3586956.0, -3284376.25, -2981796.5, -2679216.75, -2376637.0, -2074057.25, -1771477.5, -1468898.0, -1166318.0, -863738.0, -561158.5, -258579.0, 44001.0, 346581.0, 649160.5, 951740.0, 1254320.0, 1556900.0, 1859479.5, 2162059.0, 2464639.0, 2767219.0, 3069798.0, 3372378.0, 3674958.0, 3977538.0, 4280118.0, 4582697.0, 4885277.0, 5187857.0, 5490436.0, 5793016.0, 6095596.0, 6398176.0, 6700756.0, 7003335.0, 7305915.0, 7608495.0, 7911074.0, 8213654.0, 8516234.0, 8818814.0, 9121394.0, 9423973.0, 9726553.0, 10029133.0, 10331712.0, 10634292.0, 10936872.0, 11239452.0, 11542032.0, 11844612.0, 12147190.0, 12449770.0, 12752350.0, 13054930.0, 13357510.0]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 3.0, 12.0, 3.0, 5.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0], "bins": [-8350737.5, -8161780.0, -7972822.5, -7783865.0, -7594907.5, -7405950.0, -7216992.0, -7028034.5, -6839077.0, -6650119.5, -6461162.0, -6272204.5, -6083247.0, -5894289.5, -5705332.0, -5516374.0, -5327417.0, -5138459.0, -4949502.0, -4760544.0, -4571586.5, -4382629.0, -4193671.5, -4004714.0, -3815756.5, -3626799.0, -3437841.5, -3248883.5, -3059926.0, -2870968.5, -2682011.0, -2493053.5, -2304096.0, -2115138.5, -1926181.0, -1737223.5, -1548266.0, -1359308.5, -1170350.5, -981393.0, -792435.5, -603478.0, -414520.5, -225563.0, -36605.5, 152352.5, 341309.5, 530267.5, 719224.5, 908182.5, 1097139.5, 1286097.5, 1475054.5, 1664012.5, 1852970.5, 2041927.5, 2230885.5, 2419842.5, 2608800.5, 2797757.5, 2986715.5, 3175672.5, 3364630.5, 3553587.5, 3742545.5]}, "_runtime": 3142.3632142543793, "_timestamp": 1585512220.783944, "_step": 198}
{"Episode reward": -99.78910974606772, "Episode length": 999, "Policy Loss": -0.08347875624895096, "Value Loss": 0.01389307901263237, "_runtime": 3143.922100543976, "_timestamp": 1585512222.3428302, "_step": 199}
{"Episode reward": -99.46728239145442, "Episode length": 999, "Policy Loss": -0.06625984609127045, "Value Loss": 0.02738076075911522, "_runtime": 3145.466789007187, "_timestamp": 1585512223.8875186, "_step": 200}
{"Episode reward": -99.83525548449111, "Episode length": 999, "Policy Loss": -0.06253879517316818, "Value Loss": 0.017282629385590553, "_runtime": 3147.0236253738403, "_timestamp": 1585512225.444355, "_step": 201}
{"Episode reward": -99.69802597483947, "Episode length": 999, "Policy Loss": -0.1343039721250534, "Value Loss": 0.025828687474131584, "_runtime": 3148.625287294388, "_timestamp": 1585512227.046017, "_step": 202}
{"Episode reward": -99.73829208815413, "Episode length": 999, "Policy Loss": -0.06434568762779236, "Value Loss": 0.014822760596871376, "_runtime": 3150.191663503647, "_timestamp": 1585512228.6123931, "_step": 203}
{"Episode reward": -99.47901575833441, "Episode length": 999, "Policy Loss": -0.0533885695040226, "Value Loss": 0.012935183942317963, "_runtime": 3151.755695104599, "_timestamp": 1585512230.1764247, "_step": 204}
{"Episode reward": -99.76846210732917, "Episode length": 999, "Policy Loss": -0.05920574069023132, "Value Loss": 0.01571253314614296, "_runtime": 3153.3209371566772, "_timestamp": 1585512231.7416668, "_step": 205}
{"Episode reward": -99.60172840422048, "Episode length": 999, "Policy Loss": -0.11579705774784088, "Value Loss": 0.017583241686224937, "_runtime": 3154.8650217056274, "_timestamp": 1585512233.2857513, "_step": 206}
{"Episode reward": -99.64396953373283, "Episode length": 999, "Policy Loss": -0.0654577761888504, "Value Loss": 0.03118233010172844, "_runtime": 3156.4182901382446, "_timestamp": 1585512234.8390198, "_step": 207}
{"Episode reward": -99.55815917966045, "Episode length": 999, "Policy Loss": -0.03301820158958435, "Value Loss": 0.012184076942503452, "_runtime": 3157.9845163822174, "_timestamp": 1585512236.405246, "_step": 208}
{"Episode reward": -99.7249471177388, "Episode length": 999, "Policy Loss": -0.042579688131809235, "Value Loss": 0.015523845329880714, "_runtime": 3159.538957834244, "_timestamp": 1585512237.9596875, "_step": 209}
{"Episode reward": -99.71782082797878, "Episode length": 999, "Policy Loss": -0.025451453402638435, "Value Loss": 0.012298505753278732, "_runtime": 3161.0895433425903, "_timestamp": 1585512239.510273, "_step": 210}
{"Episode reward": -99.37836267735635, "Episode length": 999, "Policy Loss": -0.08421994745731354, "Value Loss": 0.024883948266506195, "_runtime": 3162.643206834793, "_timestamp": 1585512241.0639365, "_step": 211}
{"Episode reward": -99.71694407611946, "Episode length": 999, "Policy Loss": -0.028755024075508118, "Value Loss": 0.01617998629808426, "_runtime": 3164.1979801654816, "_timestamp": 1585512242.6187098, "_step": 212}
{"Episode reward": -99.52778303870558, "Episode length": 999, "Policy Loss": -0.03958955034613609, "Value Loss": 0.018970180302858353, "_runtime": 3165.7611215114594, "_timestamp": 1585512244.1818511, "_step": 213}
{"Episode reward": -99.72592315511844, "Episode length": 999, "Policy Loss": -0.022161738947033882, "Value Loss": 0.025054868310689926, "_runtime": 3167.330235719681, "_timestamp": 1585512245.7509654, "_step": 214}
{"Episode reward": -99.74630257757241, "Episode length": 999, "Policy Loss": -0.010139324702322483, "Value Loss": 0.010322070680558681, "_runtime": 3168.904578924179, "_timestamp": 1585512247.3253086, "_step": 215}
{"Episode reward": -99.6754489036263, "Episode length": 999, "Policy Loss": -0.015837855637073517, "Value Loss": 0.024731967598199844, "_runtime": 3170.47802400589, "_timestamp": 1585512248.8987536, "_step": 216}
{"Episode reward": -99.73826940893638, "Episode length": 999, "Policy Loss": 0.011076687835156918, "Value Loss": 0.02711576782166958, "_runtime": 3172.092392683029, "_timestamp": 1585512250.5131223, "_step": 217}
{"Episode reward": -99.74403420597793, "Episode length": 999, "Policy Loss": -0.022338667884469032, "Value Loss": 0.014266491867601871, "_runtime": 3173.6664254665375, "_timestamp": 1585512252.087155, "_step": 218}
{"Episode reward": -99.523031750454, "Episode length": 999, "Policy Loss": -0.032345034182071686, "Value Loss": 0.016081811860203743, "_runtime": 3175.2386593818665, "_timestamp": 1585512253.659389, "_step": 219}
{"Episode reward": -99.43542954358136, "Episode length": 999, "Policy Loss": -0.04107000306248665, "Value Loss": 0.014311138540506363, "_runtime": 3176.812373161316, "_timestamp": 1585512255.2331028, "_step": 220}
{"Episode reward": -99.51381819023271, "Episode length": 999, "Policy Loss": -0.16930857300758362, "Value Loss": 0.04120767489075661, "_runtime": 3178.3670637607574, "_timestamp": 1585512256.7877934, "_step": 221}
{"Episode reward": -99.64315578992996, "Episode length": 999, "Policy Loss": -0.06064692512154579, "Value Loss": 0.029773643240332603, "_runtime": 3179.929745912552, "_timestamp": 1585512258.3504755, "_step": 222}
{"Episode reward": -99.73347498007782, "Episode length": 999, "Policy Loss": -0.05392499640583992, "Value Loss": 0.008859467692673206, "_runtime": 3181.493497133255, "_timestamp": 1585512259.9142268, "_step": 223}
{"Episode reward": -99.33962342156873, "Episode length": 999, "Policy Loss": -0.04305272549390793, "Value Loss": 0.028157416731119156, "_runtime": 3183.0696334838867, "_timestamp": 1585512261.4903631, "_step": 224}
{"Episode reward": -99.70136265887274, "Episode length": 999, "Policy Loss": -0.0779314935207367, "Value Loss": 0.02653452754020691, "_runtime": 3184.6458537578583, "_timestamp": 1585512263.0665834, "_step": 225}
{"Episode reward": -99.52394634535639, "Episode length": 999, "Policy Loss": -0.0801733136177063, "Value Loss": 0.03547607734799385, "_runtime": 3186.2225348949432, "_timestamp": 1585512264.6432645, "_step": 226}
{"Episode reward": -99.62260213943524, "Episode length": 999, "Policy Loss": -0.06654345989227295, "Value Loss": 0.016474146395921707, "_runtime": 3187.8001294136047, "_timestamp": 1585512266.220859, "_step": 227}
{"Episode reward": -99.7117638076705, "Episode length": 999, "Policy Loss": 0.00971323810517788, "Value Loss": 0.03190474584698677, "_runtime": 3189.3519492149353, "_timestamp": 1585512267.7726789, "_step": 228}
{"Episode reward": -99.77549443144677, "Episode length": 999, "Policy Loss": -0.05113210901618004, "Value Loss": 0.014567703008651733, "_runtime": 3190.908164024353, "_timestamp": 1585512269.3288937, "_step": 229}
{"Episode reward": -99.76751350359851, "Episode length": 999, "Policy Loss": -0.06880676001310349, "Value Loss": 0.045086007565259933, "_runtime": 3192.474534034729, "_timestamp": 1585512270.8952637, "_step": 230}
{"Episode reward": -99.81527906136913, "Episode length": 999, "Policy Loss": -0.016604676842689514, "Value Loss": 0.011529183946549892, "_runtime": 3194.0403757095337, "_timestamp": 1585512272.4611053, "_step": 231}
{"Episode reward": -99.85891761779645, "Episode length": 999, "Policy Loss": -0.019374702125787735, "Value Loss": 0.008104795590043068, "_runtime": 3195.6395704746246, "_timestamp": 1585512274.0603, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.001667719567194581, "Value Loss": 0.02531811036169529, "_runtime": 3197.203052043915, "_timestamp": 1585512275.6237817, "_step": 233}
{"Episode reward": -99.71155397058111, "Episode length": 999, "Policy Loss": -0.14395375549793243, "Value Loss": 0.07674580067396164, "_runtime": 3198.7669475078583, "_timestamp": 1585512277.1876771, "_step": 234}
{"Episode reward": -99.70786694632703, "Episode length": 999, "Policy Loss": -0.15230967104434967, "Value Loss": 0.08388704806566238, "_runtime": 3200.3090903759003, "_timestamp": 1585512278.72982, "_step": 235}
{"Episode reward": -99.42849030973943, "Episode length": 999, "Policy Loss": -0.0017315541626885533, "Value Loss": 0.03964716196060181, "_runtime": 3201.8756663799286, "_timestamp": 1585512280.296396, "_step": 236}
{"Episode reward": -99.77002482432732, "Episode length": 999, "Policy Loss": -0.06724948436021805, "Value Loss": 0.01734127290546894, "_runtime": 3203.430377483368, "_timestamp": 1585512281.8511071, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05511930212378502, "Value Loss": 0.032059285789728165, "_runtime": 3204.99485373497, "_timestamp": 1585512283.4155834, "_step": 238}
{"Episode reward": -99.6999112859334, "Episode length": 999, "Policy Loss": -0.04651424288749695, "Value Loss": 0.04617598280310631, "_runtime": 3206.549835205078, "_timestamp": 1585512284.9705648, "_step": 239}
{"Episode reward": -99.78463313728432, "Episode length": 999, "Policy Loss": -0.012394806370139122, "Value Loss": 0.06027988716959953, "_runtime": 3208.1024885177612, "_timestamp": 1585512286.5232182, "_step": 240}
{"Episode reward": -99.80814708033436, "Episode length": 999, "Policy Loss": -0.04311540350317955, "Value Loss": 0.029174014925956726, "_runtime": 3209.659565925598, "_timestamp": 1585512288.0802956, "_step": 241}
{"Episode reward": -99.80793248796695, "Episode length": 999, "Policy Loss": -0.06837376207113266, "Value Loss": 0.015504631213843822, "_runtime": 3211.203374862671, "_timestamp": 1585512289.6241045, "_step": 242}
{"Episode reward": -99.82163432137902, "Episode length": 999, "Policy Loss": -0.04105842858552933, "Value Loss": 0.08110178261995316, "_runtime": 3212.753578186035, "_timestamp": 1585512291.1743078, "_step": 243}
{"Episode reward": -99.80142442406948, "Episode length": 999, "Policy Loss": -0.01933126151561737, "Value Loss": 0.014566523022949696, "_runtime": 3214.3180696964264, "_timestamp": 1585512292.7387993, "_step": 244}
{"Episode reward": -99.71215434617076, "Episode length": 999, "Policy Loss": 0.0030590880196541548, "Value Loss": 0.020704001188278198, "_runtime": 3215.8868827819824, "_timestamp": 1585512294.3076124, "_step": 245}
{"Episode reward": -99.66394829405333, "Episode length": 999, "Policy Loss": 0.001121459063142538, "Value Loss": 0.031122038140892982, "_runtime": 3217.4773020744324, "_timestamp": 1585512295.8980317, "_step": 246}
{"Episode reward": -99.8305380359278, "Episode length": 999, "Policy Loss": -0.09749579429626465, "Value Loss": 0.142252579331398, "_runtime": 3219.0397398471832, "_timestamp": 1585512297.4604695, "_step": 247}
{"Episode reward": -99.62096510051418, "Episode length": 999, "Policy Loss": 0.08365679532289505, "Value Loss": 0.04962022602558136, "_runtime": 3220.593977212906, "_timestamp": 1585512299.0147069, "_step": 248}
{"Episode reward": -99.50590169616488, "Episode length": 999, "Policy Loss": -0.024135658517479897, "Value Loss": 0.020726149901747704, "_runtime": 3222.1509239673615, "_timestamp": 1585512300.5716536, "_step": 249}
{"Episode reward": -99.81593236554554, "Episode length": 999, "Policy Loss": -0.002024152083322406, "Value Loss": 0.05399864912033081, "_runtime": 3223.7155742645264, "_timestamp": 1585512302.136304, "_step": 250}
{"Episode reward": -99.67690081009502, "Episode length": 999, "Policy Loss": -0.039129115641117096, "Value Loss": 0.04744778200984001, "_runtime": 3225.2568864822388, "_timestamp": 1585512303.6776161, "_step": 251}
{"Episode reward": -99.65382668943937, "Episode length": 999, "Policy Loss": -0.07650449126958847, "Value Loss": 0.0671950951218605, "_runtime": 3226.822551727295, "_timestamp": 1585512305.2432814, "_step": 252}
{"Episode reward": -99.87512204358215, "Episode length": 999, "Policy Loss": -0.05544870346784592, "Value Loss": 0.06561991572380066, "_runtime": 3228.3872044086456, "_timestamp": 1585512306.807934, "_step": 253}
{"Episode reward": -99.80000781302122, "Episode length": 999, "Policy Loss": -0.0968639999628067, "Value Loss": 0.1701185703277588, "_runtime": 3229.958570241928, "_timestamp": 1585512308.3792999, "_step": 254}
{"Episode reward": -99.68532172900166, "Episode length": 999, "Policy Loss": -0.44184449315071106, "Value Loss": 0.19282104074954987, "_runtime": 3231.509989261627, "_timestamp": 1585512309.930719, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1135745495557785, "Value Loss": 0.039525482803583145, "_runtime": 3233.05495262146, "_timestamp": 1585512311.4756823, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.14503377676010132, "Value Loss": 0.10341260582208633, "_runtime": 3234.6128509044647, "_timestamp": 1585512313.0335805, "_step": 257}
{"Episode reward": -99.71797852914986, "Episode length": 999, "Policy Loss": -0.06090201810002327, "Value Loss": 0.11210478097200394, "_runtime": 3236.163604259491, "_timestamp": 1585512314.584334, "_step": 258}
{"Episode reward": -99.80783932413863, "Episode length": 999, "Policy Loss": -0.08579833805561066, "Value Loss": 0.08240841329097748, "_runtime": 3237.729242324829, "_timestamp": 1585512316.149972, "_step": 259}
{"Episode reward": -99.74533739704499, "Episode length": 999, "Policy Loss": -0.06362733244895935, "Value Loss": 0.15887749195098877, "_runtime": 3239.2935831546783, "_timestamp": 1585512317.7143128, "_step": 260}
{"Episode reward": -99.67056595117968, "Episode length": 999, "Policy Loss": -0.01365888025611639, "Value Loss": 0.1931614875793457, "_runtime": 3240.895523786545, "_timestamp": 1585512319.3162534, "_step": 261}
{"Episode reward": -99.70736701136782, "Episode length": 999, "Policy Loss": -0.06743601709604263, "Value Loss": 0.10312270373106003, "_runtime": 3242.4476726055145, "_timestamp": 1585512320.8684022, "_step": 262}
{"Episode reward": -99.56856724787364, "Episode length": 999, "Policy Loss": -0.058316413313150406, "Value Loss": 0.03852521628141403, "_runtime": 3244.0013585090637, "_timestamp": 1585512322.4220881, "_step": 263}
{"Episode reward": -99.72519950577849, "Episode length": 999, "Policy Loss": -0.06647913157939911, "Value Loss": 0.07464578747749329, "_runtime": 3245.55229640007, "_timestamp": 1585512323.973026, "_step": 264}
{"Episode reward": -99.83426525290567, "Episode length": 999, "Policy Loss": -0.06005469337105751, "Value Loss": 0.08494563400745392, "_runtime": 3247.1048414707184, "_timestamp": 1585512325.525571, "_step": 265}
{"Episode reward": -99.85229380130629, "Episode length": 999, "Policy Loss": -0.0745907798409462, "Value Loss": 0.02977774664759636, "_runtime": 3248.672642469406, "_timestamp": 1585512327.093372, "_step": 266}
{"Episode reward": -99.60901993894839, "Episode length": 999, "Policy Loss": -0.013344415463507175, "Value Loss": 0.11522992700338364, "_runtime": 3250.236032962799, "_timestamp": 1585512328.6567626, "_step": 267}
{"Episode reward": -99.81352640355331, "Episode length": 999, "Policy Loss": -0.17453058063983917, "Value Loss": 0.3527860939502716, "_runtime": 3251.799045562744, "_timestamp": 1585512330.2197752, "_step": 268}
{"Episode reward": -99.87120170630375, "Episode length": 999, "Policy Loss": -0.04133392497897148, "Value Loss": 0.183222696185112, "_runtime": 3253.3796792030334, "_timestamp": 1585512331.8004088, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09351947158575058, "Value Loss": 0.08578954637050629, "_runtime": 3254.9273569583893, "_timestamp": 1585512333.3480866, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.045043546706438065, "Value Loss": 0.12546083331108093, "_runtime": 3256.479337453842, "_timestamp": 1585512334.900067, "_step": 271}
{"Episode reward": -99.75284285927053, "Episode length": 999, "Policy Loss": -0.15201888978481293, "Value Loss": 0.037413306534290314, "_runtime": 3258.0231301784515, "_timestamp": 1585512336.4438598, "_step": 272}
{"Episode reward": -99.74073146853668, "Episode length": 999, "Policy Loss": -0.15768961608409882, "Value Loss": 0.11397174000740051, "_runtime": 3259.5634801387787, "_timestamp": 1585512337.9842098, "_step": 273}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1884874701499939, "Value Loss": 0.09790869802236557, "_runtime": 3261.103736639023, "_timestamp": 1585512339.5244663, "_step": 274}
{"Episode reward": -99.82351515926281, "Episode length": 999, "Policy Loss": -0.12555550038814545, "Value Loss": 0.06363961845636368, "_runtime": 3262.6693046092987, "_timestamp": 1585512341.0900342, "_step": 275}
{"Episode reward": -99.54475505000889, "Episode length": 999, "Policy Loss": 0.01441072765737772, "Value Loss": 0.04959166795015335, "_runtime": 3264.2655506134033, "_timestamp": 1585512342.6862803, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10931842774152756, "Value Loss": 0.03540094196796417, "_runtime": 3265.819335460663, "_timestamp": 1585512344.240065, "_step": 277}
{"Episode reward": -99.70852986857386, "Episode length": 999, "Policy Loss": -0.054617058485746384, "Value Loss": 0.04936628043651581, "_runtime": 3267.385565519333, "_timestamp": 1585512345.8062952, "_step": 278}
{"Episode reward": -99.74795016071702, "Episode length": 999, "Policy Loss": -0.04398320987820625, "Value Loss": 0.058994535356760025, "_runtime": 3268.948801755905, "_timestamp": 1585512347.3695314, "_step": 279}
{"Episode reward": -99.73969698815843, "Episode length": 999, "Policy Loss": -0.13346251845359802, "Value Loss": 0.038281265646219254, "_runtime": 3270.5144736766815, "_timestamp": 1585512348.9352033, "_step": 280}
{"Episode reward": -99.67018030139887, "Episode length": 999, "Policy Loss": -0.07571122795343399, "Value Loss": 0.0420822948217392, "_runtime": 3272.0711238384247, "_timestamp": 1585512350.4918535, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.05916788429021835, "Value Loss": 0.028398077934980392, "_runtime": 3273.6141736507416, "_timestamp": 1585512352.0349033, "_step": 282}
{"Episode reward": -99.43708202857387, "Episode length": 999, "Policy Loss": -0.08531492948532104, "Value Loss": 0.0248111505061388, "_runtime": 3275.176369190216, "_timestamp": 1585512353.5970988, "_step": 283}
{"Episode reward": -99.8587697309428, "Episode length": 999, "Policy Loss": -0.0491202175617218, "Value Loss": 0.005350754130631685, "_runtime": 3276.745155096054, "_timestamp": 1585512355.1658847, "_step": 284}
{"Episode reward": -99.66066133358015, "Episode length": 999, "Policy Loss": -0.07600507140159607, "Value Loss": 0.08835086971521378, "_runtime": 3278.3079912662506, "_timestamp": 1585512356.728721, "_step": 285}
{"Episode reward": -99.71501870484796, "Episode length": 999, "Policy Loss": -0.2941237986087799, "Value Loss": 0.07409245520830154, "_runtime": 3279.862817287445, "_timestamp": 1585512358.283547, "_step": 286}
{"Episode reward": -99.84944706000248, "Episode length": 999, "Policy Loss": -0.11238844692707062, "Value Loss": 0.0191031564027071, "_runtime": 3281.4165863990784, "_timestamp": 1585512359.837316, "_step": 287}
{"Episode reward": -99.80047652460495, "Episode length": 999, "Policy Loss": -0.15101955831050873, "Value Loss": 0.01801249012351036, "_runtime": 3282.97088766098, "_timestamp": 1585512361.3916173, "_step": 288}
{"Episode reward": -99.88296038657288, "Episode length": 999, "Policy Loss": -0.14653684198856354, "Value Loss": 0.02951742149889469, "_runtime": 3284.5350682735443, "_timestamp": 1585512362.955798, "_step": 289}
{"Episode reward": -99.80152971111616, "Episode length": 999, "Policy Loss": -0.1694156378507614, "Value Loss": 0.0662597268819809, "_runtime": 3286.087943792343, "_timestamp": 1585512364.5086734, "_step": 290}
{"Episode reward": -99.72784673253504, "Episode length": 999, "Policy Loss": 0.03654967620968819, "Value Loss": 0.08913756161928177, "_runtime": 3287.68652844429, "_timestamp": 1585512366.107258, "_step": 291}
{"Episode reward": -99.85532457763189, "Episode length": 999, "Policy Loss": -0.1706627905368805, "Value Loss": 0.028824688866734505, "_runtime": 3289.2276566028595, "_timestamp": 1585512367.6483862, "_step": 292}
{"Episode reward": -99.81730182207981, "Episode length": 999, "Policy Loss": -0.12275883555412292, "Value Loss": 0.01430779229849577, "_runtime": 3290.795653820038, "_timestamp": 1585512369.2163835, "_step": 293}
{"Episode reward": -99.83047398486967, "Episode length": 999, "Policy Loss": -0.0802362933754921, "Value Loss": 0.017138861119747162, "_runtime": 3292.359668970108, "_timestamp": 1585512370.7803986, "_step": 294}
{"Episode reward": -99.61586256733518, "Episode length": 999, "Policy Loss": -0.04636600613594055, "Value Loss": 0.03993772715330124, "_runtime": 3293.9238979816437, "_timestamp": 1585512372.3446276, "_step": 295}
{"Episode reward": -99.79720874551882, "Episode length": 999, "Policy Loss": 0.0006032607052475214, "Value Loss": 0.027169791981577873, "_runtime": 3295.4942321777344, "_timestamp": 1585512373.9149618, "_step": 296}
{"Episode reward": -99.82333158625778, "Episode length": 999, "Policy Loss": 4.156406794209033e-05, "Value Loss": 0.09573301672935486, "_runtime": 3297.059248685837, "_timestamp": 1585512375.4799783, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10086187720298767, "Value Loss": 0.05579201504588127, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375, -5107.90234375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0], "bins": [-292378.15625, -287729.9375, -283081.71875, -278433.5, -273785.28125, -269137.0625, -264488.84375, -259840.625, -255192.40625, -250544.1875, -245895.96875, -241247.734375, -236599.515625, -231951.296875, -227303.078125, -222654.859375, -218006.640625, -213358.421875, -208710.203125, -204061.984375, -199413.765625, -194765.53125, -190117.3125, -185469.09375, -180820.875, -176172.65625, -171524.4375, -166876.21875, -162228.0, -157579.78125, -152931.5625, -148283.34375, -143635.125, -138986.90625, -134338.6875, -129690.46875, -125042.25, -120394.03125, -115745.8125, -111097.59375, -106449.375, -101801.140625, -97152.921875, -92504.703125, -87856.484375, -83208.265625, -78560.046875, -73911.828125, -69263.609375, -64615.390625, -59967.171875, -55318.953125, -50670.734375, -46022.515625, -41374.296875, -36726.078125, -32077.84375, -27429.625, -22781.40625, -18133.1875, -13484.96875, -8836.75, -4188.53125, 459.6875, 5107.90625]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-8033.22119140625, -7603.0869140625, -7172.9521484375, -6742.81787109375, -6312.68359375, -5882.548828125, -5452.41455078125, -5022.2802734375, -4592.1455078125, -4162.01123046875, -3731.876953125, -3301.74267578125, -2871.60791015625, -2441.4736328125, -2011.33935546875, -1581.20458984375, -1151.0703125, -720.93603515625, -290.80126953125, 139.3330078125, 569.46728515625, 999.60205078125, 1429.73583984375, 1859.87060546875, 2290.00537109375, 2720.13916015625, 3150.27392578125, 3580.40869140625, 4010.54248046875, 4440.67724609375, 4870.81201171875, 5300.94580078125, 5731.08056640625, 6161.21533203125, 6591.34912109375, 7021.48388671875, 7451.61865234375, 7881.75244140625, 8311.88671875, 8742.021484375, 9172.15625, 9602.291015625, 10032.42578125, 10462.560546875, 10892.693359375, 11322.828125, 11752.962890625, 12183.09765625, 12613.232421875, 13043.3671875, 13473.5, 13903.634765625, 14333.76953125, 14763.904296875, 15194.0390625, 15624.173828125, 16054.306640625, 16484.44140625, 16914.576171875, 17344.7109375, 17774.845703125, 18204.98046875, 18635.11328125, 19065.248046875, 19495.3828125]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 3.0, 1.0, 3.0, 5.0, 36.0, 34.0, 4.0, 11.0, 6.0, 8.0, 280.0, 6.0, 18.0, 18.0, 1.0, 0.0, 1.0, 5.0, 3.0, 1.0, 1.0, 3.0, 5.0, 6.0, 1.0, 3.0, 3.0, 6.0, 6.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 3.0], "bins": [-54451.6640625, -51536.078125, -48620.48828125, -45704.90234375, -42789.3125, -39873.7265625, -36958.140625, -34042.5546875, -31126.96484375, -28211.376953125, -25295.7890625, -22380.203125, -19464.6171875, -16549.02734375, -13633.44140625, -10717.8515625, -7802.265625, -4886.6796875, -1971.08984375, 944.49609375, 3860.0859375, 6775.671875, 9691.2578125, 12606.84375, 15522.4296875, 18438.0234375, 21353.609375, 24269.1953125, 27184.78125, 30100.3671875, 33015.9609375, 35931.546875, 38847.1328125, 41762.71875, 44678.3046875, 47593.8984375, 50509.484375, 53425.0703125, 56340.65625, 59256.2421875, 62171.8359375, 65087.421875, 68003.0078125, 70918.59375, 73834.1796875, 76749.7734375, 79665.3515625, 82580.9453125, 85496.5234375, 88412.1171875, 91327.7109375, 94243.2890625, 97158.8828125, 100074.4609375, 102990.0546875, 105905.6484375, 108821.2265625, 111736.8203125, 114652.3984375, 117567.9921875, 120483.5859375, 123399.1640625, 126314.7578125, 129230.3359375, 132145.9375]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 6.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-775393.625, -758363.3125, -741333.0625, -724302.75, -707272.4375, -690242.125, -673211.875, -656181.5625, -639151.25, -622121.0, -605090.6875, -588060.375, -571030.125, -553999.8125, -536969.5, -519939.1875, -502908.90625, -485878.625, -468848.3125, -451818.03125, -434787.71875, -417757.4375, -400727.125, -383696.84375, -366666.5625, -349636.25, -332605.96875, -315575.65625, -298545.375, -281515.0625, -264484.78125, -247454.5, -230424.1875, -213393.875, -196363.625, -179333.3125, -162303.0, -145272.6875, -128242.4375, -111212.125, -94181.8125, -77151.5625, -60121.25, -43090.9375, -26060.625, -9030.375, 7999.9375, 25030.25, 42060.5, 59090.8125, 76121.125, 93151.4375, 110181.6875, 127212.0, 144242.3125, 161272.625, 178302.875, 195333.1875, 212363.5, 229393.75, 246424.0625, 263454.375, 280484.625, 297515.0, 314545.25]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 4.0, 2.0, 0.0, 1.0, 2.0, 2.0, 6.0, 12.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0], "bins": [-478368.40625, -467861.78125, -457355.15625, -446848.5625, -436341.9375, -425835.3125, -415328.6875, -404822.0625, -394315.4375, -383808.84375, -373302.21875, -362795.59375, -352288.96875, -341782.375, -331275.75, -320769.125, -310262.5, -299755.875, -289249.25, -278742.625, -268236.03125, -257729.40625, -247222.78125, -236716.171875, -226209.546875, -215702.9375, -205196.3125, -194689.6875, -184183.0625, -173676.4375, -163169.84375, -152663.21875, -142156.59375, -131649.96875, -121143.34375, -110636.75, -100130.125, -89623.5, -79116.875, -68610.25, -58103.65625, -47597.03125, -37090.40625, -26583.78125, -16077.15625, -5570.53125, 4936.0625, 15442.6875, 25949.3125, 36455.9375, 46962.53125, 57469.15625, 67975.78125, 78482.40625, 88989.03125, 99495.65625, 110002.28125, 120508.90625, 131015.53125, 141522.09375, 152028.71875, 162535.34375, 173041.96875, 183548.59375, 194055.21875]}, "_runtime": 3298.6223514080048, "_timestamp": 1585512377.043081, "_step": 298}
{"Episode reward": -99.73385081907588, "Episode length": 999, "Policy Loss": -0.05519052594900131, "Value Loss": 0.027702732011675835, "_runtime": 3300.178338289261, "_timestamp": 1585512378.599068, "_step": 299}
{"Episode reward": -99.65708265146102, "Episode length": 999, "Policy Loss": -0.09348707646131516, "Value Loss": 0.0346955731511116, "_runtime": 3301.7354600429535, "_timestamp": 1585512380.1561897, "_step": 300}
{"Episode reward": -99.77892056349525, "Episode length": 999, "Policy Loss": -0.1175871193408966, "Value Loss": 0.02176121063530445, "_runtime": 3303.29204249382, "_timestamp": 1585512381.7127721, "_step": 301}
{"Episode reward": -99.73457455113392, "Episode length": 999, "Policy Loss": -0.18822675943374634, "Value Loss": 0.0582173690199852, "_runtime": 3304.8587641716003, "_timestamp": 1585512383.2794938, "_step": 302}
{"Episode reward": -99.68858951302107, "Episode length": 999, "Policy Loss": -0.11938412487506866, "Value Loss": 0.11875363439321518, "_runtime": 3306.4138004779816, "_timestamp": 1585512384.83453, "_step": 303}
{"Episode reward": -99.8001225256347, "Episode length": 999, "Policy Loss": -0.02519022300839424, "Value Loss": 0.057497162371873856, "_runtime": 3307.979619026184, "_timestamp": 1585512386.4003487, "_step": 304}
{"Episode reward": -99.72846213227464, "Episode length": 999, "Policy Loss": -0.051326554268598557, "Value Loss": 0.03097924403846264, "_runtime": 3309.5738377571106, "_timestamp": 1585512387.9945674, "_step": 305}
{"Episode reward": -99.8050902784788, "Episode length": 999, "Policy Loss": -0.04560667276382446, "Value Loss": 0.00881271157413721, "_runtime": 3311.136967420578, "_timestamp": 1585512389.557697, "_step": 306}
{"Episode reward": -99.73979466028838, "Episode length": 999, "Policy Loss": -0.004982913378626108, "Value Loss": 0.02858174964785576, "_runtime": 3312.704659461975, "_timestamp": 1585512391.125389, "_step": 307}
{"Episode reward": -99.76164508727823, "Episode length": 999, "Policy Loss": 0.09080388396978378, "Value Loss": 0.06960725784301758, "_runtime": 3314.2615959644318, "_timestamp": 1585512392.6823256, "_step": 308}
{"Episode reward": -99.73235693324683, "Episode length": 999, "Policy Loss": 0.04281306639313698, "Value Loss": 0.04641096666455269, "_runtime": 3315.818243265152, "_timestamp": 1585512394.238973, "_step": 309}
{"Episode reward": -99.84247166449065, "Episode length": 999, "Policy Loss": 0.08108651638031006, "Value Loss": 0.018452366814017296, "_runtime": 3317.383910179138, "_timestamp": 1585512395.8046398, "_step": 310}
{"Episode reward": -99.73625635028104, "Episode length": 999, "Policy Loss": -0.08189211040735245, "Value Loss": 0.13682173192501068, "_runtime": 3318.940586566925, "_timestamp": 1585512397.3613162, "_step": 311}
{"Episode reward": -99.77296867052785, "Episode length": 999, "Policy Loss": -0.1327134668827057, "Value Loss": 0.05140046030282974, "_runtime": 3320.508111000061, "_timestamp": 1585512398.9288406, "_step": 312}
{"Episode reward": -99.61899669003805, "Episode length": 999, "Policy Loss": -0.03275402635335922, "Value Loss": 0.02999105304479599, "_runtime": 3322.0717067718506, "_timestamp": 1585512400.4924364, "_step": 313}
{"Episode reward": -99.8118415966616, "Episode length": 999, "Policy Loss": -0.08944351971149445, "Value Loss": 0.038725998252630234, "_runtime": 3323.6411669254303, "_timestamp": 1585512402.0618966, "_step": 314}
{"Episode reward": -99.66930623494416, "Episode length": 999, "Policy Loss": -0.17529520392417908, "Value Loss": 0.029447294771671295, "_runtime": 3325.2059557437897, "_timestamp": 1585512403.6266854, "_step": 315}
{"Episode reward": -99.88601945726106, "Episode length": 999, "Policy Loss": -0.11419382691383362, "Value Loss": 0.05022674798965454, "_runtime": 3326.775139570236, "_timestamp": 1585512405.1958692, "_step": 316}
{"Episode reward": -99.54024982841075, "Episode length": 999, "Policy Loss": -0.06711351871490479, "Value Loss": 0.11154280602931976, "_runtime": 3328.3399517536163, "_timestamp": 1585512406.7606814, "_step": 317}
{"Episode reward": -99.49025126335978, "Episode length": 999, "Policy Loss": -0.1757912039756775, "Value Loss": 0.08517708629369736, "_runtime": 3329.9039618968964, "_timestamp": 1585512408.3246915, "_step": 318}
{"Episode reward": -99.80004522927472, "Episode length": 999, "Policy Loss": -0.038109537214040756, "Value Loss": 0.04531906545162201, "_runtime": 3331.4605526924133, "_timestamp": 1585512409.8812823, "_step": 319}
{"Episode reward": -99.62911194760143, "Episode length": 999, "Policy Loss": -0.1362651139497757, "Value Loss": 0.045865535736083984, "_runtime": 3333.064256668091, "_timestamp": 1585512411.4849863, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.032322000712156296, "Value Loss": 0.016356971114873886, "_runtime": 3334.628685951233, "_timestamp": 1585512413.0494156, "_step": 321}
{"Episode reward": -99.51024748736388, "Episode length": 999, "Policy Loss": -0.028613746166229248, "Value Loss": 0.03889385983347893, "_runtime": 3336.182915687561, "_timestamp": 1585512414.6036453, "_step": 322}
{"Episode reward": -99.80263054285903, "Episode length": 999, "Policy Loss": -0.030488796532154083, "Value Loss": 0.04868513345718384, "_runtime": 3337.726105451584, "_timestamp": 1585512416.146835, "_step": 323}
{"Episode reward": -99.5806859357065, "Episode length": 999, "Policy Loss": 0.003399129491299391, "Value Loss": 0.008818564005196095, "_runtime": 3339.2893583774567, "_timestamp": 1585512417.710088, "_step": 324}
{"Episode reward": -99.82901443748129, "Episode length": 999, "Policy Loss": -0.023167667910456657, "Value Loss": 0.010656367056071758, "_runtime": 3340.852417945862, "_timestamp": 1585512419.2731476, "_step": 325}
{"Episode reward": -99.80764209984196, "Episode length": 999, "Policy Loss": -0.03656087443232536, "Value Loss": 0.011966723017394543, "_runtime": 3342.406724214554, "_timestamp": 1585512420.8274539, "_step": 326}
{"Episode reward": -99.52687813183366, "Episode length": 999, "Policy Loss": -0.05892952159047127, "Value Loss": 0.01802240125834942, "_runtime": 3343.9699301719666, "_timestamp": 1585512422.3906598, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.06138104945421219, "Value Loss": 0.014794274233281612, "_runtime": 3345.532376050949, "_timestamp": 1585512423.9531057, "_step": 328}
{"Episode reward": -99.70772538604076, "Episode length": 999, "Policy Loss": -0.09984709322452545, "Value Loss": 0.022383062168955803, "_runtime": 3347.096254825592, "_timestamp": 1585512425.5169845, "_step": 329}
{"Episode reward": -99.836195087804, "Episode length": 999, "Policy Loss": -0.1286446750164032, "Value Loss": 0.011838802136480808, "_runtime": 3348.6614603996277, "_timestamp": 1585512427.08219, "_step": 330}
{"Episode reward": -99.71039904714712, "Episode length": 999, "Policy Loss": -0.0676993876695633, "Value Loss": 0.020796388387680054, "_runtime": 3350.2272646427155, "_timestamp": 1585512428.6479943, "_step": 331}
{"Episode reward": -99.75372240881991, "Episode length": 999, "Policy Loss": -0.05913249030709267, "Value Loss": 0.02820160984992981, "_runtime": 3351.7856736183167, "_timestamp": 1585512430.2064033, "_step": 332}
{"Episode reward": -99.49087915043128, "Episode length": 999, "Policy Loss": -0.01619509793817997, "Value Loss": 0.038963206112384796, "_runtime": 3353.327634572983, "_timestamp": 1585512431.7483642, "_step": 333}
{"Episode reward": -99.7947259962148, "Episode length": 999, "Policy Loss": -0.016529271379113197, "Value Loss": 0.025326242670416832, "_runtime": 3354.883901834488, "_timestamp": 1585512433.3046315, "_step": 334}
{"Episode reward": -99.70382368191414, "Episode length": 999, "Policy Loss": -0.03764266148209572, "Value Loss": 0.00971147045493126, "_runtime": 3356.4749195575714, "_timestamp": 1585512434.8956492, "_step": 335}
{"Episode reward": -99.722527906955, "Episode length": 999, "Policy Loss": -0.05164528265595436, "Value Loss": 0.020464429631829262, "_runtime": 3358.031793832779, "_timestamp": 1585512436.4525235, "_step": 336}
{"Episode reward": -99.78200637443591, "Episode length": 999, "Policy Loss": 0.003037579357624054, "Value Loss": 0.03232874348759651, "_runtime": 3359.5858039855957, "_timestamp": 1585512438.0065336, "_step": 337}
{"Episode reward": -99.80832242220501, "Episode length": 999, "Policy Loss": 0.011191332712769508, "Value Loss": 0.017275642603635788, "_runtime": 3361.152801513672, "_timestamp": 1585512439.5735312, "_step": 338}
{"Episode reward": -99.68461257392782, "Episode length": 999, "Policy Loss": 0.018832968547940254, "Value Loss": 0.02291085757315159, "_runtime": 3362.7074749469757, "_timestamp": 1585512441.1282046, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005757815670222044, "Value Loss": 0.014627048745751381, "_runtime": 3364.2620964050293, "_timestamp": 1585512442.682826, "_step": 340}
{"Episode reward": -99.4851956242181, "Episode length": 999, "Policy Loss": -0.08907120674848557, "Value Loss": 0.0226371418684721, "_runtime": 3365.8147587776184, "_timestamp": 1585512444.2354884, "_step": 341}
{"Episode reward": -99.82385974265495, "Episode length": 999, "Policy Loss": -0.012995774857699871, "Value Loss": 0.008410402573645115, "_runtime": 3367.3679156303406, "_timestamp": 1585512445.7886453, "_step": 342}
{"Episode reward": -99.85422442402553, "Episode length": 999, "Policy Loss": -0.0835694670677185, "Value Loss": 0.032435979694128036, "_runtime": 3368.933761358261, "_timestamp": 1585512447.354491, "_step": 343}
{"Episode reward": -99.76862205295912, "Episode length": 999, "Policy Loss": -0.03859156370162964, "Value Loss": 0.01766728051006794, "_runtime": 3370.487538576126, "_timestamp": 1585512448.9082682, "_step": 344}
{"Episode reward": -99.76863364303723, "Episode length": 999, "Policy Loss": -0.04480376094579697, "Value Loss": 0.0121318893507123, "_runtime": 3372.0503792762756, "_timestamp": 1585512450.471109, "_step": 345}
{"Episode reward": -99.83598941359529, "Episode length": 999, "Policy Loss": -0.07894717901945114, "Value Loss": 0.013078412972390652, "_runtime": 3373.6154873371124, "_timestamp": 1585512452.036217, "_step": 346}
{"Episode reward": -99.8170333661125, "Episode length": 999, "Policy Loss": -0.01669330894947052, "Value Loss": 0.032443709671497345, "_runtime": 3375.167169570923, "_timestamp": 1585512453.5878992, "_step": 347}
{"Episode reward": -99.52147011141585, "Episode length": 999, "Policy Loss": -0.0749659463763237, "Value Loss": 0.03293301910161972, "_runtime": 3376.7316677570343, "_timestamp": 1585512455.1523974, "_step": 348}
{"Episode reward": -99.89308056868472, "Episode length": 999, "Policy Loss": -0.04526448994874954, "Value Loss": 0.02337847277522087, "_runtime": 3378.298248529434, "_timestamp": 1585512456.7189782, "_step": 349}
{"Episode reward": -99.5957033184422, "Episode length": 999, "Policy Loss": -0.04678713530302048, "Value Loss": 0.01525080669671297, "_runtime": 3379.887763977051, "_timestamp": 1585512458.3084936, "_step": 350}
{"Episode reward": -99.70343373071816, "Episode length": 999, "Policy Loss": -0.023266106843948364, "Value Loss": 0.022366730496287346, "_runtime": 3381.4518847465515, "_timestamp": 1585512459.8726144, "_step": 351}
{"Episode reward": -99.55545601271886, "Episode length": 999, "Policy Loss": 0.0003081033646594733, "Value Loss": 0.013930954970419407, "_runtime": 3383.0161261558533, "_timestamp": 1585512461.4368558, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.024657340720295906, "Value Loss": 0.01502260472625494, "_runtime": 3384.580207824707, "_timestamp": 1585512463.0009375, "_step": 353}
{"Episode reward": -99.55657828818316, "Episode length": 999, "Policy Loss": -0.024290628731250763, "Value Loss": 0.0335400216281414, "_runtime": 3386.1426084041595, "_timestamp": 1585512464.563338, "_step": 354}
{"Episode reward": -99.64656653832506, "Episode length": 999, "Policy Loss": -0.015243749134242535, "Value Loss": 0.021899275481700897, "_runtime": 3387.7049939632416, "_timestamp": 1585512466.1257236, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.04571431502699852, "Value Loss": 0.05773001164197922, "_runtime": 3389.267234325409, "_timestamp": 1585512467.687964, "_step": 356}
{"Episode reward": -99.73022187815259, "Episode length": 999, "Policy Loss": -0.05904803425073624, "Value Loss": 0.020045362412929535, "_runtime": 3390.821798324585, "_timestamp": 1585512469.242528, "_step": 357}
{"Episode reward": -99.82963747093314, "Episode length": 999, "Policy Loss": -0.08647087216377258, "Value Loss": 0.05270163714885712, "_runtime": 3392.387182235718, "_timestamp": 1585512470.8079119, "_step": 358}
{"Episode reward": -99.76678252257267, "Episode length": 999, "Policy Loss": -0.04948869347572327, "Value Loss": 0.03831976652145386, "_runtime": 3393.949555873871, "_timestamp": 1585512472.3702855, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08708436787128448, "Value Loss": 0.03726797550916672, "_runtime": 3395.5145580768585, "_timestamp": 1585512473.9352877, "_step": 360}
{"Episode reward": -99.88394760349625, "Episode length": 999, "Policy Loss": -0.026335641741752625, "Value Loss": 0.021696487441658974, "_runtime": 3397.0800380706787, "_timestamp": 1585512475.5007677, "_step": 361}
{"Episode reward": -99.8900726580047, "Episode length": 999, "Policy Loss": -0.008963637053966522, "Value Loss": 0.012388456612825394, "_runtime": 3398.633818626404, "_timestamp": 1585512477.0545483, "_step": 362}
{"Episode reward": -99.8606043813969, "Episode length": 999, "Policy Loss": 0.05592404305934906, "Value Loss": 0.036976490169763565, "_runtime": 3400.1980130672455, "_timestamp": 1585512478.6187427, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.044378865510225296, "Value Loss": 0.10970750451087952, "_runtime": 3401.741528749466, "_timestamp": 1585512480.1622584, "_step": 364}
{"Episode reward": -99.79684999782918, "Episode length": 999, "Policy Loss": 0.028064889833331108, "Value Loss": 0.0514601394534111, "_runtime": 3403.32820725441, "_timestamp": 1585512481.748937, "_step": 365}
{"Episode reward": -99.8629913107478, "Episode length": 999, "Policy Loss": -0.04201646149158478, "Value Loss": 0.03641582652926445, "_runtime": 3404.893676996231, "_timestamp": 1585512483.3144066, "_step": 366}
{"Episode reward": -99.71626838315139, "Episode length": 999, "Policy Loss": -0.03621320426464081, "Value Loss": 0.011272447183728218, "_runtime": 3406.45493888855, "_timestamp": 1585512484.8756685, "_step": 367}
{"Episode reward": -99.66459793486564, "Episode length": 999, "Policy Loss": -0.01415910106152296, "Value Loss": 0.0693395808339119, "_runtime": 3408.0185306072235, "_timestamp": 1585512486.4392602, "_step": 368}
{"Episode reward": -99.87999950761302, "Episode length": 999, "Policy Loss": -0.04816047102212906, "Value Loss": 0.04559142142534256, "_runtime": 3409.581089735031, "_timestamp": 1585512488.0018194, "_step": 369}
{"Episode reward": -99.78733070064197, "Episode length": 999, "Policy Loss": -0.09071629494428635, "Value Loss": 0.06674329936504364, "_runtime": 3411.144484758377, "_timestamp": 1585512489.5652144, "_step": 370}
{"Episode reward": -99.83181656692038, "Episode length": 999, "Policy Loss": -0.02067479118704796, "Value Loss": 0.03566645085811615, "_runtime": 3412.700341463089, "_timestamp": 1585512491.121071, "_step": 371}
{"Episode reward": -99.72881342109619, "Episode length": 999, "Policy Loss": -0.03932773694396019, "Value Loss": 0.028318224474787712, "_runtime": 3414.2648730278015, "_timestamp": 1585512492.6856027, "_step": 372}
{"Episode reward": -99.89686937564844, "Episode length": 999, "Policy Loss": 0.0022608237341046333, "Value Loss": 0.03383440524339676, "_runtime": 3415.8268280029297, "_timestamp": 1585512494.2475576, "_step": 373}
{"Episode reward": -99.65139465948445, "Episode length": 999, "Policy Loss": -0.018964620307087898, "Value Loss": 0.016719648614525795, "_runtime": 3417.369580745697, "_timestamp": 1585512495.7903104, "_step": 374}
{"Episode reward": -99.67396481942713, "Episode length": 999, "Policy Loss": -0.08313737064599991, "Value Loss": 0.387625515460968, "_runtime": 3418.9272468090057, "_timestamp": 1585512497.3479764, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.046876873821020126, "Value Loss": 0.0877290591597557, "_runtime": 3420.489685535431, "_timestamp": 1585512498.9104152, "_step": 376}
{"Episode reward": -99.7835399449789, "Episode length": 999, "Policy Loss": -0.17196200788021088, "Value Loss": 0.045258358120918274, "_runtime": 3422.041438102722, "_timestamp": 1585512500.4621677, "_step": 377}
{"Episode reward": -99.67144552741526, "Episode length": 999, "Policy Loss": -0.1131424605846405, "Value Loss": 0.22790193557739258, "_runtime": 3423.594284772873, "_timestamp": 1585512502.0150144, "_step": 378}
{"Episode reward": -99.83913119472423, "Episode length": 999, "Policy Loss": -0.08037812262773514, "Value Loss": 0.16948091983795166, "_runtime": 3425.195784807205, "_timestamp": 1585512503.6165144, "_step": 379}
{"Episode reward": -99.80003143781656, "Episode length": 999, "Policy Loss": -0.08196638524532318, "Value Loss": 0.05325162038207054, "_runtime": 3426.738033056259, "_timestamp": 1585512505.1587627, "_step": 380}
{"Episode reward": -99.56424918314303, "Episode length": 999, "Policy Loss": -0.036169469356536865, "Value Loss": 0.02352311462163925, "_runtime": 3428.2890179157257, "_timestamp": 1585512506.7097476, "_step": 381}
{"Episode reward": -99.7331284903689, "Episode length": 999, "Policy Loss": -0.101588174700737, "Value Loss": 0.053275417536497116, "_runtime": 3429.8326783180237, "_timestamp": 1585512508.253408, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09027028828859329, "Value Loss": 0.07834417372941971, "_runtime": 3431.3974978923798, "_timestamp": 1585512509.8182275, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.020250245928764343, "Value Loss": 0.08862833678722382, "_runtime": 3432.9596362113953, "_timestamp": 1585512511.3803658, "_step": 384}
{"Episode reward": -99.77420893991227, "Episode length": 999, "Policy Loss": 0.03859841451048851, "Value Loss": 0.025392180308699608, "_runtime": 3434.524692773819, "_timestamp": 1585512512.9454224, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.027620557695627213, "Value Loss": 0.10218895226716995, "_runtime": 3436.0809864997864, "_timestamp": 1585512514.5017161, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08553379029035568, "Value Loss": 0.012340128421783447, "_runtime": 3437.6456940174103, "_timestamp": 1585512516.0664237, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.09528225660324097, "Value Loss": 0.061000123620033264, "_runtime": 3439.2219479084015, "_timestamp": 1585512517.6426775, "_step": 388}
{"Episode reward": -99.82183126380993, "Episode length": 999, "Policy Loss": -0.17950350046157837, "Value Loss": 0.1266384720802307, "_runtime": 3440.777461528778, "_timestamp": 1585512519.1981912, "_step": 389}
{"Episode reward": -99.80149608254293, "Episode length": 999, "Policy Loss": -0.1142587885260582, "Value Loss": 0.03922070190310478, "_runtime": 3442.3296468257904, "_timestamp": 1585512520.7503765, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.048932865262031555, "Value Loss": 0.04411564767360687, "_runtime": 3443.89581823349, "_timestamp": 1585512522.3165479, "_step": 391}
{"Episode reward": -99.72797621881915, "Episode length": 999, "Policy Loss": -0.05318600684404373, "Value Loss": 0.0424996018409729, "_runtime": 3445.4606578350067, "_timestamp": 1585512523.8813875, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0469149574637413, "Value Loss": 0.13986720144748688, "_runtime": 3447.023882627487, "_timestamp": 1585512525.4446123, "_step": 393}
{"Episode reward": -99.85385899180407, "Episode length": 999, "Policy Loss": -0.04410111904144287, "Value Loss": 0.003969609271734953, "_runtime": 3448.625654697418, "_timestamp": 1585512527.0463843, "_step": 394}
{"Episode reward": -99.78526583434873, "Episode length": 999, "Policy Loss": -0.061894237995147705, "Value Loss": 0.0063100638799369335, "_runtime": 3450.1906247138977, "_timestamp": 1585512528.6113544, "_step": 395}
{"Episode reward": -99.83082201480725, "Episode length": 999, "Policy Loss": -0.06461518257856369, "Value Loss": 0.016148163005709648, "_runtime": 3451.7437579631805, "_timestamp": 1585512530.1644876, "_step": 396}
{"Episode reward": -99.72115786084767, "Episode length": 999, "Policy Loss": -0.06910789757966995, "Value Loss": 0.010366518050432205, "_runtime": 3453.2966718673706, "_timestamp": 1585512531.7174015, "_step": 397}
{"Episode reward": -99.78243316197629, "Episode length": 999, "Policy Loss": -0.07565490156412125, "Value Loss": 0.004835913423448801, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603, -0.07045436650514603]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 7.0], "bins": [-8.054855346679688, -7.9278950691223145, -7.800934791564941, -7.67397403717041, -7.547013759613037, -7.420053482055664, -7.293093204498291, -7.166132926940918, -7.039172172546387, -6.912211894989014, -6.785251617431641, -6.658291339874268, -6.5313310623168945, -6.404370307922363, -6.277410507202148, -6.150449752807617, -6.023489475250244, -5.896529197692871, -5.76956844329834, -5.642608642578125, -5.515647888183594, -5.388687610626221, -5.261727333068848, -5.134766578674316, -5.007806777954102, -4.88084602355957, -4.753885746002197, -4.626925468444824, -4.499965190887451, -4.373004913330078, -4.246044158935547, -4.119083881378174, -3.992123603820801, -3.8651633262634277, -3.7382030487060547, -3.6112422943115234, -3.4842820167541504, -3.3573217391967773, -3.2303614616394043, -3.1034011840820312, -2.9764404296875, -2.849480152130127, -2.722519874572754, -2.595559597015381, -2.468599319458008, -2.3416390419006348, -2.2146782875061035, -2.0877180099487305, -1.9607577323913574, -1.8337974548339844, -1.7068371772766113, -1.57987642288208, -1.452916145324707, -1.325955867767334, -1.198995590209961, -1.072035312652588, -0.9450750350952148, -0.8181142807006836, -0.6911540031433105, -0.5641937255859375, -0.43723344802856445, -0.3102731704711914, -0.18331241607666016, -0.05635213851928711, 0.07060813903808594]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.11391830444335938, -0.11067734658718109, -0.1074363961815834, -0.10419543832540512, -0.10095448791980743, -0.09771353006362915, -0.09447257220745087, -0.09123161435127258, -0.0879906639456749, -0.08474971354007721, -0.08150875568389893, -0.07826779782772064, -0.07502683997154236, -0.07178588956594467, -0.06854493170976639, -0.0653039813041687, -0.06206302344799042, -0.05882206931710243, -0.05558111518621445, -0.05234015733003616, -0.04909920692443848, -0.04585824906826019, -0.04261729121208191, -0.03937634080648422, -0.03613538295030594, -0.032894425094127655, -0.029653474688529968, -0.026412516832351685, -0.0231715589761734, -0.019930608570575714, -0.01668965071439743, -0.013448700308799744, -0.01020774245262146, -0.006966784596443176, -0.0037258341908454895, -0.0004848763346672058, 0.002756074070930481, 0.005997031927108765, 0.009237989783287048, 0.012478947639465332, 0.015719890594482422, 0.018960848450660706, 0.02220180630683899, 0.025442764163017273, 0.028683722019195557, 0.03192467987537384, 0.03516562283039093, 0.038406580686569214, 0.0416475385427475, 0.04488849639892578, 0.048129454255104065, 0.051370397210121155, 0.05461135506629944, 0.05785231292247772, 0.061093270778656006, 0.06433422863483429, 0.06757518649101257, 0.07081612944602966, 0.07405708730220795, 0.07729804515838623, 0.08053900301456451, 0.0837799608707428, 0.08702090382575989, 0.09026186168193817, 0.09350281953811646]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 5.0, 1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 8.0, 16.0, 28.0, 35.0, 18.0, 184.0, 26.0, 11.0, 19.0, 11.0, 7.0, 11.0, 4.0, 4.0, 7.0, 10.0, 9.0, 6.0, 5.0, 7.0, 1.0, 7.0, 4.0, 5.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0], "bins": [-0.6465553045272827, -0.6277775168418884, -0.6089997291564941, -0.5902219414710999, -0.5714441537857056, -0.5526663661003113, -0.533888578414917, -0.5151107907295227, -0.4963330030441284, -0.47755521535873413, -0.45877742767333984, -0.43999963998794556, -0.42122185230255127, -0.402444064617157, -0.3836662769317627, -0.3648884892463684, -0.3461107015609741, -0.32733291387557983, -0.30855512619018555, -0.28977733850479126, -0.270999550819397, -0.2522217631340027, -0.2334439754486084, -0.2146661877632141, -0.19588840007781982, -0.17711061239242554, -0.15833282470703125, -0.13955503702163696, -0.12077724933624268, -0.10199946165084839, -0.0832216739654541, -0.06444388628005981, -0.04566609859466553, -0.02688831090927124, -0.008110523223876953, 0.010667264461517334, 0.02944505214691162, 0.04822283983230591, 0.0670006275177002, 0.08577841520309448, 0.10455620288848877, 0.12333399057388306, 0.14211177825927734, 0.16088956594467163, 0.17966735363006592, 0.1984451413154602, 0.2172229290008545, 0.23600071668624878, 0.25477850437164307, 0.27355629205703735, 0.29233407974243164, 0.3111118674278259, 0.3298896551132202, 0.3486674427986145, 0.3674452304840088, 0.3862229585647583, 0.40500080585479736, 0.4237786531448364, 0.44255638122558594, 0.46133410930633545, 0.4801119565963745, 0.4988898038864136, 0.5176675319671631, 0.5364452600479126, 0.5552231073379517]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.9248812198638916, -1.8853877782821655, -1.845894455909729, -1.806401014328003, -1.7669076919555664, -1.7274142503738403, -1.6879208087921143, -1.6484274864196777, -1.6089340448379517, -1.5694406032562256, -1.529947280883789, -1.490453839302063, -1.450960397720337, -1.4114670753479004, -1.3719736337661743, -1.3324801921844482, -1.2929868698120117, -1.2534935474395752, -1.2140001058578491, -1.174506664276123, -1.1350133419036865, -1.0955199003219604, -1.0560264587402344, -1.0165331363677979, -0.9770396947860718, -0.9375463128089905, -0.8980529308319092, -0.8585594892501831, -0.819066047668457, -0.7795727252960205, -0.7400792837142944, -0.7005859613418579, -0.6610925197601318, -0.6215990781784058, -0.5821057558059692, -0.5426123142242432, -0.5031189918518066, -0.46362555027008057, -0.4241321086883545, -0.38463878631591797, -0.3451453447341919, -0.3056519031524658, -0.2661585807800293, -0.22666513919830322, -0.18717169761657715, -0.14767837524414062, -0.10818493366241455, -0.06869161128997803, -0.029198169708251953, 0.010295271873474121, 0.049788594245910645, 0.08928203582763672, 0.12877535820007324, 0.16826891899108887, 0.2077622413635254, 0.24725556373596191, 0.28674912452697754, 0.32624244689941406, 0.3657357692718506, 0.4052290916442871, 0.44472265243530273, 0.48421597480773926, 0.5237092971801758, 0.5632028579711914, 0.6026961803436279]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 5.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 6.0, 14.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.7463778257369995, -0.7290512323379517, -0.7117246389389038, -0.6943981051445007, -0.6770715117454529, -0.659744918346405, -0.6424183249473572, -0.6250917315483093, -0.6077651977539062, -0.5904386043548584, -0.5731120109558105, -0.5557854175567627, -0.5384588241577148, -0.521132230758667, -0.5038056373596191, -0.48647910356521606, -0.4691525101661682, -0.45182591676712036, -0.4344993531703949, -0.41717275977134705, -0.3998461961746216, -0.38251960277557373, -0.3651930093765259, -0.3478664457798004, -0.33053985238075256, -0.3132132589817047, -0.29588669538497925, -0.2785601019859314, -0.26123350858688354, -0.2439069151878357, -0.22658038139343262, -0.20925378799438477, -0.19192719459533691, -0.17460060119628906, -0.1572740077972412, -0.13994747400283813, -0.12262088060379028, -0.10529428720474243, -0.08796769380569458, -0.07064110040664673, -0.05331456661224365, -0.0359879732131958, -0.01866137981414795, -0.0013347864151000977, 0.015991806983947754, 0.033318400382995605, 0.05064493417739868, 0.06797152757644653, 0.08529812097549438, 0.10262471437454224, 0.11995130777359009, 0.13727784156799316, 0.15460443496704102, 0.17193102836608887, 0.18925762176513672, 0.20658421516418457, 0.22391080856323242, 0.2412373423576355, 0.2585639953613281, 0.2758904695510864, 0.2932170629501343, 0.31054365634918213, 0.32787024974823, 0.34519684314727783, 0.3625234365463257]}, "_runtime": 3454.85192322731, "_timestamp": 1585512533.2726529, "_step": 398}
{"Episode reward": -99.80096683241287, "Episode length": 999, "Policy Loss": -0.04920745640993118, "Value Loss": 0.10237778723239899, "_runtime": 3456.410478115082, "_timestamp": 1585512534.8312078, "_step": 399}
{"Episode reward": -99.80904326476016, "Episode length": 999, "Policy Loss": -0.02420838549733162, "Value Loss": 0.04730488732457161, "_runtime": 3457.9671511650085, "_timestamp": 1585512536.3878808, "_step": 400}
{"Episode reward": -99.73424451386097, "Episode length": 999, "Policy Loss": -0.03655611351132393, "Value Loss": 0.1107039600610733, "_runtime": 3459.523734807968, "_timestamp": 1585512537.9444644, "_step": 401}
{"Episode reward": -99.79322364276602, "Episode length": 999, "Policy Loss": -0.06460437178611755, "Value Loss": 0.06923399120569229, "_runtime": 3461.0915908813477, "_timestamp": 1585512539.5123205, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.042253442108631134, "Value Loss": 0.08685124665498734, "_runtime": 3462.6632916927338, "_timestamp": 1585512541.0840213, "_step": 403}
{"Episode reward": -99.70647741558356, "Episode length": 999, "Policy Loss": -0.06913264095783234, "Value Loss": 0.1092059388756752, "_runtime": 3464.2424898147583, "_timestamp": 1585512542.6632195, "_step": 404}
{"Episode reward": -99.8403126306818, "Episode length": 999, "Policy Loss": -0.027110319584608078, "Value Loss": 0.15382497012615204, "_runtime": 3465.8008210659027, "_timestamp": 1585512544.2215507, "_step": 405}
{"Episode reward": -99.80005252668494, "Episode length": 999, "Policy Loss": -0.03141798451542854, "Value Loss": 0.04824444651603699, "_runtime": 3467.37876701355, "_timestamp": 1585512545.7994967, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07379209250211716, "Value Loss": 0.028117677196860313, "_runtime": 3468.946628808975, "_timestamp": 1585512547.3673584, "_step": 407}
{"Episode reward": -99.8791691556559, "Episode length": 999, "Policy Loss": -0.02580823190510273, "Value Loss": 0.018876541405916214, "_runtime": 3470.5232813358307, "_timestamp": 1585512548.944011, "_step": 408}
{"Episode reward": -99.77408760073168, "Episode length": 999, "Policy Loss": -0.023393899202346802, "Value Loss": 0.09797640144824982, "_runtime": 3472.1386930942535, "_timestamp": 1585512550.5594227, "_step": 409}
{"Episode reward": -99.63758908897807, "Episode length": 999, "Policy Loss": -0.022128626704216003, "Value Loss": 0.1486874222755432, "_runtime": 3473.71715426445, "_timestamp": 1585512552.137884, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.005903310142457485, "Value Loss": 0.06746818125247955, "_runtime": 3475.2837924957275, "_timestamp": 1585512553.7045221, "_step": 411}
{"Episode reward": -99.88366822535032, "Episode length": 999, "Policy Loss": -0.06523915380239487, "Value Loss": 0.08659297972917557, "_runtime": 3476.8588860034943, "_timestamp": 1585512555.2796156, "_step": 412}
{"Episode reward": -99.86879155374923, "Episode length": 999, "Policy Loss": -0.10692819952964783, "Value Loss": 0.0341302827000618, "_runtime": 3478.420264482498, "_timestamp": 1585512556.8409941, "_step": 413}
{"Episode reward": -99.8595753326998, "Episode length": 999, "Policy Loss": -0.10138081014156342, "Value Loss": 0.12866199016571045, "_runtime": 3479.985741853714, "_timestamp": 1585512558.4064715, "_step": 414}
{"Episode reward": -99.69744512662152, "Episode length": 999, "Policy Loss": -0.045225925743579865, "Value Loss": 0.04075724631547928, "_runtime": 3481.530260324478, "_timestamp": 1585512559.95099, "_step": 415}
{"Episode reward": -99.84483439931508, "Episode length": 999, "Policy Loss": -0.04603457450866699, "Value Loss": 0.03451815992593765, "_runtime": 3483.081890106201, "_timestamp": 1585512561.5026197, "_step": 416}
{"Episode reward": -99.70188416829879, "Episode length": 999, "Policy Loss": -0.067972831428051, "Value Loss": 0.20151899755001068, "_runtime": 3484.623416185379, "_timestamp": 1585512563.0441458, "_step": 417}
{"Episode reward": -99.79906415610988, "Episode length": 999, "Policy Loss": 0.01850992441177368, "Value Loss": 0.07830061763525009, "_runtime": 3486.1887032985687, "_timestamp": 1585512564.609433, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.07400409132242203, "Value Loss": 0.027668409049510956, "_runtime": 3487.754893064499, "_timestamp": 1585512566.1756227, "_step": 419}
{"Episode reward": -99.74800959573919, "Episode length": 999, "Policy Loss": -0.10593079775571823, "Value Loss": 0.08732355386018753, "_runtime": 3489.3209462165833, "_timestamp": 1585512567.7416759, "_step": 420}
{"Episode reward": -99.818505120276, "Episode length": 999, "Policy Loss": -0.09483698010444641, "Value Loss": 0.07489287853240967, "_runtime": 3490.8882653713226, "_timestamp": 1585512569.308995, "_step": 421}
{"Episode reward": -99.60077408139084, "Episode length": 999, "Policy Loss": -0.043594956398010254, "Value Loss": 0.042164139449596405, "_runtime": 3492.464670419693, "_timestamp": 1585512570.8854, "_step": 422}
{"Episode reward": -99.58153544602958, "Episode length": 999, "Policy Loss": 0.10867202281951904, "Value Loss": 0.16684576869010925, "_runtime": 3494.0277688503265, "_timestamp": 1585512572.4484985, "_step": 423}
{"Episode reward": -99.81899138092855, "Episode length": 999, "Policy Loss": -0.04137102887034416, "Value Loss": 0.011358498595654964, "_runtime": 3495.6159949302673, "_timestamp": 1585512574.0367246, "_step": 424}
{"Episode reward": -99.87547159576648, "Episode length": 999, "Policy Loss": -0.08131904900074005, "Value Loss": 0.043912310153245926, "_runtime": 3497.193948984146, "_timestamp": 1585512575.6146786, "_step": 425}
{"Episode reward": -99.80002226987715, "Episode length": 999, "Policy Loss": -0.08235003799200058, "Value Loss": 0.053645581007003784, "_runtime": 3498.761677503586, "_timestamp": 1585512577.1824071, "_step": 426}
{"Episode reward": -99.78146936926076, "Episode length": 999, "Policy Loss": -0.09871697425842285, "Value Loss": 0.07002279907464981, "_runtime": 3500.3355967998505, "_timestamp": 1585512578.7563264, "_step": 427}
{"Episode reward": -99.80999488311214, "Episode length": 999, "Policy Loss": -0.029729584231972694, "Value Loss": 0.07481320947408676, "_runtime": 3501.914857149124, "_timestamp": 1585512580.3355868, "_step": 428}
{"Episode reward": -99.83832809515158, "Episode length": 999, "Policy Loss": -0.06152932718396187, "Value Loss": 0.018693357706069946, "_runtime": 3503.4810671806335, "_timestamp": 1585512581.9017968, "_step": 429}
{"Episode reward": -99.61882283633902, "Episode length": 999, "Policy Loss": -0.0011484319111332297, "Value Loss": 0.04180396348237991, "_runtime": 3505.04896736145, "_timestamp": 1585512583.469697, "_step": 430}
{"Episode reward": -99.77217109037781, "Episode length": 999, "Policy Loss": -0.06252793967723846, "Value Loss": 0.3516811728477478, "_runtime": 3506.607045173645, "_timestamp": 1585512585.0277748, "_step": 431}
{"Episode reward": -99.8258090541684, "Episode length": 999, "Policy Loss": -0.07027486711740494, "Value Loss": 0.026582106947898865, "_runtime": 3508.1757876873016, "_timestamp": 1585512586.5965173, "_step": 432}
{"Episode reward": -99.709828981034, "Episode length": 999, "Policy Loss": -0.07739219069480896, "Value Loss": 0.05827684327960014, "_runtime": 3509.7409665584564, "_timestamp": 1585512588.1616962, "_step": 433}
{"Episode reward": -99.78032188713411, "Episode length": 999, "Policy Loss": -0.04325694590806961, "Value Loss": 0.20392374694347382, "_runtime": 3511.3089821338654, "_timestamp": 1585512589.7297118, "_step": 434}
{"Episode reward": -99.73372004311885, "Episode length": 999, "Policy Loss": -0.0636153295636177, "Value Loss": 0.1374116837978363, "_runtime": 3512.8897774219513, "_timestamp": 1585512591.310507, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17408649623394012, "Value Loss": 0.23641780018806458, "_runtime": 3514.466644048691, "_timestamp": 1585512592.8873737, "_step": 436}
{"Episode reward": -99.74615463719131, "Episode length": 999, "Policy Loss": -0.1572871059179306, "Value Loss": 0.3274294435977936, "_runtime": 3516.046396970749, "_timestamp": 1585512594.4671266, "_step": 437}
{"Episode reward": -99.7144584244336, "Episode length": 999, "Policy Loss": -0.1662789285182953, "Value Loss": 0.2156403362751007, "_runtime": 3517.6509082317352, "_timestamp": 1585512596.0716379, "_step": 438}
{"Episode reward": -99.83469802476326, "Episode length": 999, "Policy Loss": -0.35040971636772156, "Value Loss": 0.5961090922355652, "_runtime": 3518.3783116340637, "_timestamp": 1585512596.7990413, "_step": 439}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 1.4024746417999268, "Value Loss": 21.18779754638672, "_runtime": 3519.957556962967, "_timestamp": 1585512598.3782866, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.30122143030166626, "Value Loss": 0.1066790372133255, "_runtime": 3521.5231664180756, "_timestamp": 1585512599.943896, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.24250060319900513, "Value Loss": 0.09373994171619415, "_runtime": 3523.030811548233, "_timestamp": 1585512601.4515412, "_step": 442}
{"Episode reward": -99.84921556860068, "Episode length": 999, "Policy Loss": -0.2771623432636261, "Value Loss": 0.09844709187746048, "_runtime": 3524.600370645523, "_timestamp": 1585512603.0211003, "_step": 443}
{"Episode reward": -99.78530749250065, "Episode length": 999, "Policy Loss": -0.1723753809928894, "Value Loss": 0.06996195018291473, "_runtime": 3525.999182701111, "_timestamp": 1585512604.4199123, "_step": 444}
{"Episode reward": 10.7183185189039, "Episode length": 893, "Policy Loss": 0.7060163021087646, "Value Loss": 11.219651222229004, "_runtime": 3526.490958929062, "_timestamp": 1585512604.9116886, "_step": 445}
{"Episode reward": 71.0716929759829, "Episode length": 290, "Policy Loss": 2.2283143997192383, "Value Loss": 32.95064163208008, "_runtime": 3528.0589435100555, "_timestamp": 1585512606.4796731, "_step": 446}
{"Episode reward": -99.83351819151872, "Episode length": 999, "Policy Loss": -0.573209285736084, "Value Loss": 0.455705851316452, "_runtime": 3529.6088466644287, "_timestamp": 1585512608.0295763, "_step": 447}
{"Episode reward": -99.8020871642963, "Episode length": 999, "Policy Loss": -0.8423495888710022, "Value Loss": 3.283398151397705, "_runtime": 3531.1072573661804, "_timestamp": 1585512609.527987, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5538029670715332, "Value Loss": 1.1006155014038086, "_runtime": 3532.433341741562, "_timestamp": 1585512610.8540714, "_step": 449}
{"Episode reward": 15.824629116058858, "Episode length": 842, "Policy Loss": 0.663761556148529, "Value Loss": 12.05211067199707, "_runtime": 3533.851685523987, "_timestamp": 1585512612.2724152, "_step": 450}
{"Episode reward": 8.600000000000918, "Episode length": 914, "Policy Loss": 0.6169488430023193, "Value Loss": 9.067204475402832, "_runtime": 3535.398075580597, "_timestamp": 1585512613.8188052, "_step": 451}
{"Episode reward": -99.84964468479016, "Episode length": 999, "Policy Loss": -0.49250102043151855, "Value Loss": 0.08019525557756424, "_runtime": 3536.7433881759644, "_timestamp": 1585512615.1641178, "_step": 452}
{"Episode reward": 13.847639971879005, "Episode length": 862, "Policy Loss": 0.09273552149534225, "Value Loss": 13.66174602508545, "_runtime": 3537.379454612732, "_timestamp": 1585512615.8001842, "_step": 453}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": 1.3870302438735962, "Value Loss": 25.228883743286133, "_runtime": 3538.116541624069, "_timestamp": 1585512616.5372713, "_step": 454}
{"Episode reward": 53.399999999999615, "Episode length": 466, "Policy Loss": 1.2462759017944336, "Value Loss": 21.214584350585938, "_runtime": 3538.942745447159, "_timestamp": 1585512617.363475, "_step": 455}
{"Episode reward": 47.29999999999953, "Episode length": 527, "Policy Loss": 1.5193088054656982, "Value Loss": 18.938648223876953, "_runtime": 3540.0014724731445, "_timestamp": 1585512618.422202, "_step": 456}
{"Episode reward": 30.24634146876602, "Episode length": 700, "Policy Loss": 0.5057364106178284, "Value Loss": 13.494789123535156, "_runtime": 3541.522097826004, "_timestamp": 1585512619.9428275, "_step": 457}
{"Episode reward": 1.7292668573571461, "Episode length": 984, "Policy Loss": -0.1338459551334381, "Value Loss": 6.8792243003845215, "_runtime": 3543.0351696014404, "_timestamp": 1585512621.4558992, "_step": 458}
{"Episode reward": -99.84604828506569, "Episode length": 999, "Policy Loss": -0.8661105632781982, "Value Loss": 0.5707956552505493, "_runtime": 3544.536821126938, "_timestamp": 1585512622.9575508, "_step": 459}
{"Episode reward": 0.5462300507365541, "Episode length": 998, "Policy Loss": -0.075031578540802, "Value Loss": 10.400641441345215, "_runtime": 3546.0848846435547, "_timestamp": 1585512624.5056143, "_step": 460}
{"Episode reward": -99.77267817603284, "Episode length": 999, "Policy Loss": -0.4219168424606323, "Value Loss": 0.027340002357959747, "_runtime": 3547.612450361252, "_timestamp": 1585512626.03318, "_step": 461}
{"Episode reward": -99.71321065034579, "Episode length": 999, "Policy Loss": -0.10755495727062225, "Value Loss": 0.34804946184158325, "_runtime": 3548.8934347629547, "_timestamp": 1585512627.3141644, "_step": 462}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 0.8660655617713928, "Value Loss": 13.017672538757324, "_runtime": 3549.5873963832855, "_timestamp": 1585512628.008126, "_step": 463}
{"Episode reward": 56.79999999999966, "Episode length": 432, "Policy Loss": 1.7046005725860596, "Value Loss": 28.393714904785156, "_runtime": 3551.141914367676, "_timestamp": 1585512629.562644, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5138332843780518, "Value Loss": 0.729848325252533, "_runtime": 3552.6762030124664, "_timestamp": 1585512631.0969326, "_step": 465}
{"Episode reward": -99.71709991134564, "Episode length": 999, "Policy Loss": -2.5763659477233887, "Value Loss": 5.087759017944336, "_runtime": 3554.175062417984, "_timestamp": 1585512632.595792, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.123903512954712, "Value Loss": 19.603906631469727, "_runtime": 3555.45348072052, "_timestamp": 1585512633.8742104, "_step": 467}
{"Episode reward": 18.157623746153334, "Episode length": 819, "Policy Loss": -1.522836685180664, "Value Loss": 64.47576904296875, "_runtime": 3556.999074459076, "_timestamp": 1585512635.419804, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6991974115371704, "Value Loss": 0.5312215685844421, "_runtime": 3557.3883049488068, "_timestamp": 1585512635.8090346, "_step": 469}
{"Episode reward": 77.9635068676434, "Episode length": 221, "Policy Loss": 2.1267669200897217, "Value Loss": 54.6707878112793, "_runtime": 3558.9280223846436, "_timestamp": 1585512637.348752, "_step": 470}
{"Episode reward": -99.84020755030075, "Episode length": 999, "Policy Loss": 2.468175172805786, "Value Loss": 8.179909706115723, "_runtime": 3560.484950065613, "_timestamp": 1585512638.9056797, "_step": 471}
{"Episode reward": -99.76384221659833, "Episode length": 999, "Policy Loss": 4.001464366912842, "Value Loss": 1.5920066833496094, "_runtime": 3561.974535226822, "_timestamp": 1585512640.3952649, "_step": 472}
{"Episode reward": -99.86724120117584, "Episode length": 999, "Policy Loss": 4.861281871795654, "Value Loss": 4.059144496917725, "_runtime": 3563.3939135074615, "_timestamp": 1585512641.8146431, "_step": 473}
{"Episode reward": 8.930297337473334, "Episode length": 912, "Policy Loss": 8.066311836242676, "Value Loss": 148.4676513671875, "_runtime": 3564.966740846634, "_timestamp": 1585512643.3874705, "_step": 474}
{"Episode reward": -99.82122664907807, "Episode length": 999, "Policy Loss": 4.907690525054932, "Value Loss": 1.771161437034607, "_runtime": 3566.4830524921417, "_timestamp": 1585512644.9037821, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.6727304458618164, "Value Loss": 49.527313232421875, "_runtime": 3568.0317595005035, "_timestamp": 1585512646.4524891, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.2309484481811523, "Value Loss": 44.85057830810547, "_runtime": 3569.5778257846832, "_timestamp": 1585512647.9985554, "_step": 477}
{"Episode reward": -99.50903072627122, "Episode length": 999, "Policy Loss": 1.5318807363510132, "Value Loss": 15.519556999206543, "_runtime": 3570.6110808849335, "_timestamp": 1585512649.0318105, "_step": 478}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": 1.2014638185501099, "Value Loss": 21.30877113342285, "_runtime": 3572.1621375083923, "_timestamp": 1585512650.5828671, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1454333066940308, "Value Loss": 4.8034467697143555, "_runtime": 3573.215693950653, "_timestamp": 1585512651.6364236, "_step": 480}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": -1.5698734521865845, "Value Loss": 59.496498107910156, "_runtime": 3574.723014831543, "_timestamp": 1585512653.1437445, "_step": 481}
{"Episode reward": -99.86620917180413, "Episode length": 999, "Policy Loss": -3.279794216156006, "Value Loss": 8.325167655944824, "_runtime": 3576.2647774219513, "_timestamp": 1585512654.685507, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.3044514656066895, "Value Loss": 7.054609775543213, "_runtime": 3577.7776403427124, "_timestamp": 1585512656.19837, "_step": 483}
{"Episode reward": -99.80059943357342, "Episode length": 999, "Policy Loss": -4.6635613441467285, "Value Loss": 12.650253295898438, "_runtime": 3579.306206703186, "_timestamp": 1585512657.7269363, "_step": 484}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.984158039093018, "Value Loss": 8.455245971679688, "_runtime": 3580.847050666809, "_timestamp": 1585512659.2677803, "_step": 485}
{"Episode reward": -99.78973977137217, "Episode length": 999, "Policy Loss": -4.556937217712402, "Value Loss": 38.836666107177734, "_runtime": 3582.187564611435, "_timestamp": 1585512660.6082942, "_step": 486}
{"Episode reward": 12.799990817532631, "Episode length": 873, "Policy Loss": -3.0893518924713135, "Value Loss": 33.894344329833984, "_runtime": 3583.354594230652, "_timestamp": 1585512661.7753239, "_step": 487}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": -2.1602561473846436, "Value Loss": 30.374982833862305, "_runtime": 3584.905403137207, "_timestamp": 1585512663.3261328, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.180924654006958, "Value Loss": 2.509230852127075, "_runtime": 3586.4501984119415, "_timestamp": 1585512664.870928, "_step": 489}
{"Episode reward": -99.79590131379524, "Episode length": 999, "Policy Loss": -1.354111671447754, "Value Loss": 0.1468666046857834, "_runtime": 3588.0019648075104, "_timestamp": 1585512666.4226944, "_step": 490}
{"Episode reward": -99.8261959541575, "Episode length": 999, "Policy Loss": -0.7028278112411499, "Value Loss": 0.3605271875858307, "_runtime": 3589.539149045944, "_timestamp": 1585512667.9598787, "_step": 491}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16938422620296478, "Value Loss": 0.5283601880073547, "_runtime": 3591.0771429538727, "_timestamp": 1585512669.4978726, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.28174737095832825, "Value Loss": 0.7342808842658997, "_runtime": 3591.714129924774, "_timestamp": 1585512670.1348596, "_step": 493}
{"Episode reward": 59.996162619348326, "Episode length": 401, "Policy Loss": 2.3048465251922607, "Value Loss": 35.39989471435547, "_runtime": 3593.2641983032227, "_timestamp": 1585512671.684928, "_step": 494}
{"Episode reward": -99.68898407034438, "Episode length": 999, "Policy Loss": 0.8002684712409973, "Value Loss": 0.9167553782463074, "_runtime": 3594.8249592781067, "_timestamp": 1585512673.245689, "_step": 495}
{"Episode reward": -99.79116057874495, "Episode length": 999, "Policy Loss": 0.8378950357437134, "Value Loss": 0.1576705127954483, "_runtime": 3596.323504924774, "_timestamp": 1585512674.7442346, "_step": 496}
{"Episode reward": -99.89033351540425, "Episode length": 999, "Policy Loss": 0.8655385971069336, "Value Loss": 0.13809339702129364, "_runtime": 3596.961954832077, "_timestamp": 1585512675.3826845, "_step": 497}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 3.0055038928985596, "Value Loss": 27.879404067993164, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072, 0.1405252367258072]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.14052526652812958, 0.24455000460147858, 0.6296252608299255, 1.0147005319595337, 1.3997758626937866, 1.7848511934280396, 2.169926166534424, 2.5550014972686768, 2.9400768280029297, 3.3251521587371826, 3.7102274894714355, 4.095302581787109, 4.480377674102783, 4.865453243255615, 5.250528335571289, 5.635603904724121, 6.020678997039795, 6.405754089355469, 6.790829658508301, 7.175904750823975, 7.560980319976807, 7.946054935455322, 8.331130981445312, 8.716206550598145, 9.10128116607666, 9.486356735229492, 9.871432304382324, 10.256507873535156, 10.641582489013672, 11.026658058166504, 11.411733627319336, 11.796808242797852, 12.181883811950684, 12.566959381103516, 12.952033996582031, 13.337109565734863, 13.722185134887695, 14.107259750366211, 14.492335319519043, 14.877410888671875, 15.262486457824707, 15.647561073303223, 16.032634735107422, 16.41771125793457, 16.802785873413086, 17.1878604888916, 17.57293701171875, 17.958011627197266, 18.34308624267578, 18.72816276550293, 19.113237380981445, 19.498313903808594, 19.88338851928711, 20.268463134765625, 20.653539657592773, 21.03861427307129, 21.423688888549805, 21.808765411376953, 22.19384002685547, 22.578914642333984, 22.963991165161133, 23.34906578063965, 23.734140396118164, 24.119216918945312, 24.504291534423828]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.37794679403305054, -0.36559155583381653, -0.3532363176345825, -0.3408811092376709, -0.3285258710384369, -0.3161706328392029, -0.30381542444229126, -0.29146018624305725, -0.27910494804382324, -0.26674970984458923, -0.2543944716453552, -0.2420392632484436, -0.2296840250492096, -0.21732878684997559, -0.20497356355190277, -0.19261834025382996, -0.18026310205459595, -0.16790786385536194, -0.15555264055728912, -0.1431974172592163, -0.1308421790599823, -0.11848694086074829, -0.10613173246383667, -0.09377649426460266, -0.08142125606536865, -0.06906601786613464, -0.056710779666900635, -0.044355571269989014, -0.032000333070755005, -0.019645094871520996, -0.007289886474609375, 0.005065351724624634, 0.017420589923858643, 0.02977582812309265, 0.04213106632232666, 0.05448627471923828, 0.06684151291847229, 0.0791967511177063, 0.09155195951461792, 0.10390719771385193, 0.11626243591308594, 0.12861764430999756, 0.14097291231155396, 0.15332812070846558, 0.1656833291053772, 0.1780385971069336, 0.19039380550384521, 0.2027490735054016, 0.21510428190231323, 0.22745949029922485, 0.23981475830078125, 0.25216996669769287, 0.26452523469924927, 0.2768804430961609, 0.2892356514930725, 0.3015909194946289, 0.3139461278915405, 0.32630133628845215, 0.33865660429000854, 0.35101181268692017, 0.3633670210838318, 0.3757222890853882, 0.3880774974822998, 0.4004327654838562, 0.4127879738807678]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 4.0, 2.0, 5.0, 5.0, 10.0, 10.0, 10.0, 13.0, 25.0, 296.0, 39.0, 22.0, 18.0, 11.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4.450235843658447, -4.295451641082764, -4.140666961669922, -3.9858827590942383, -3.8310985565185547, -3.676314353942871, -3.5215299129486084, -3.3667454719543457, -3.211961269378662, -3.0571770668029785, -2.902392625808716, -2.747608184814453, -2.5928239822387695, -2.438039779663086, -2.2832553386688232, -2.1284708976745605, -1.973686695098877, -1.8189024925231934, -1.6641180515289307, -1.509333610534668, -1.3545494079589844, -1.1997652053833008, -1.044980764389038, -0.8901963233947754, -0.7354121208190918, -0.5806279182434082, -0.4258437156677246, -0.2710590362548828, -0.11627483367919922, 0.038509368896484375, 0.19329404830932617, 0.34807825088500977, 0.5028624534606934, 0.657646656036377, 0.8124308586120605, 0.9672155380249023, 1.121999740600586, 1.2767839431762695, 1.4315686225891113, 1.586352825164795, 1.7411370277404785, 1.895921230316162, 2.0507054328918457, 2.2054901123046875, 2.360274314880371, 2.5150585174560547, 2.6698431968688965, 2.82462739944458, 2.9794116020202637, 3.1341958045959473, 3.288980007171631, 3.4437646865844727, 3.598548412322998, 3.753333568572998, 3.9081177711486816, 4.062901973724365, 4.217686176300049, 4.372470378875732, 4.527254581451416, 4.6820387840271, 4.8368239402771, 4.991608142852783, 5.146392345428467, 5.30117654800415, 5.455960750579834]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.505542278289795, -2.4159722328186035, -2.326402187347412, -2.2368321418762207, -2.1472623348236084, -2.057692289352417, -1.9681222438812256, -1.8785521984100342, -1.7889821529388428, -1.699412226676941, -1.6098421812057495, -1.5202722549438477, -1.4307022094726562, -1.3411321640014648, -1.2515621185302734, -1.1619921922683716, -1.0724221467971802, -0.9828521013259888, -0.8932821750640869, -0.8037121295928955, -0.7141420841217041, -0.6245721578598022, -0.5350021123886108, -0.445432186126709, -0.3558621406555176, -0.26629209518432617, -0.17672204971313477, -0.08715200424194336, 0.002418041229248047, 0.09198784828186035, 0.18155789375305176, 0.27112793922424316, 0.36069798469543457, 0.450268030166626, 0.5398380756378174, 0.6294081211090088, 0.7189779281616211, 0.8085479736328125, 0.8981180191040039, 0.9876880645751953, 1.0772581100463867, 1.1668281555175781, 1.2563979625701904, 1.3459680080413818, 1.4355380535125732, 1.5251078605651855, 1.614677906036377, 1.7042479515075684, 1.7938179969787598, 1.8833880424499512, 1.9729580879211426, 2.062528133392334, 2.1520981788635254, 2.241668224334717, 2.331238269805908, 2.4208083152770996, 2.510378360748291, 2.5999484062194824, 2.6895179748535156, 2.779088020324707, 2.8686580657958984, 2.95822811126709, 3.0477981567382812, 3.1373682022094727, 3.226938247680664]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 0.0, 4.0, 1.0, 5.0, 1.0, 2.0, 4.0, 6.0, 7.0, 5.0, 6.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.572600841522217, -2.505446672439575, -2.4382925033569336, -2.371138334274292, -2.3039841651916504, -2.236829996109009, -2.169675827026367, -2.1025216579437256, -2.035367488861084, -1.9682133197784424, -1.9010591506958008, -1.8339049816131592, -1.7667508125305176, -1.699596643447876, -1.6324424743652344, -1.5652883052825928, -1.4981341361999512, -1.4309799671173096, -1.363825798034668, -1.2966716289520264, -1.2295174598693848, -1.1623632907867432, -1.0952091217041016, -1.02805495262146, -0.9609007835388184, -0.8937466144561768, -0.8265924453735352, -0.7594382762908936, -0.692284107208252, -0.6251299381256104, -0.5579757690429688, -0.49082159996032715, -0.42366743087768555, -0.35651326179504395, -0.28935909271240234, -0.22220492362976074, -0.15505075454711914, -0.08789658546447754, -0.020742416381835938, 0.046411752700805664, 0.11356592178344727, 0.18072009086608887, 0.24787425994873047, 0.31502842903137207, 0.38218259811401367, 0.4493367671966553, 0.5164909362792969, 0.5836451053619385, 0.6507992744445801, 0.7179534435272217, 0.7851076126098633, 0.8522617816925049, 0.9194159507751465, 0.9865701198577881, 1.0537242889404297, 1.1208784580230713, 1.188032627105713, 1.2551867961883545, 1.322340965270996, 1.3894951343536377, 1.4566493034362793, 1.5238032341003418, 1.5909576416015625, 1.6581120491027832, 1.7252659797668457]}, "_runtime": 3598.513708591461, "_timestamp": 1585512676.9344382, "_step": 498}
{"Episode reward": -99.71917711812863, "Episode length": 999, "Policy Loss": 0.9108572602272034, "Value Loss": 0.47024399042129517, "_runtime": 3598.513708591461, "_timestamp": 1585512676.9344382, "_step": 499}
