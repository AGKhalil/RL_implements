{"Episode reward": 68.03256573491663, "Episode length": 860, "Policy Loss": 0.08266496658325195, "Value Loss": 11.707646369934082, "_runtime": 8258.532792329788, "_timestamp": 1585578174.3774257, "_step": 0}
{"Episode reward": -97.55890643571382, "Episode length": 999, "Policy Loss": -0.7249995470046997, "Value Loss": 7.051173210144043, "_runtime": 8258.734845876694, "_timestamp": 1585578174.5794792, "_step": 1}
{"Episode reward": 87.153438262863, "Episode length": 134, "Policy Loss": -24.07298469543457, "Value Loss": 553.2350463867188, "_runtime": 8260.290389537811, "_timestamp": 1585578176.1350229, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.40775203704834, "Value Loss": 780.0198364257812, "_runtime": 8260.514475822449, "_timestamp": 1585578176.3591092, "_step": 3}
{"Episode reward": 89.2937772215384, "Episode length": 108, "Policy Loss": 92.51142883300781, "Value Loss": 7118.10400390625, "_runtime": 8261.235312223434, "_timestamp": 1585578177.0799456, "_step": 4}
{"Episode reward": 51.13505611979593, "Episode length": 497, "Policy Loss": -2.2436046600341797, "Value Loss": 24.260080337524414, "_runtime": 8262.807935476303, "_timestamp": 1585578178.6525688, "_step": 5}
{"Episode reward": -99.19784505918014, "Episode length": 999, "Policy Loss": 1.7318438291549683, "Value Loss": 79.47916412353516, "_runtime": 8264.309972524643, "_timestamp": 1585578180.1546059, "_step": 6}
{"Episode reward": -99.12302165236017, "Episode length": 999, "Policy Loss": 14.133869171142578, "Value Loss": 427.2969970703125, "_runtime": 8265.064210653305, "_timestamp": 1585578180.908844, "_step": 7}
{"Episode reward": 51.11996639050443, "Episode length": 492, "Policy Loss": 19.419689178466797, "Value Loss": 251.77796936035156, "_runtime": 8265.673966407776, "_timestamp": 1585578181.5185997, "_step": 8}
{"Episode reward": 63.90366744773892, "Episode length": 365, "Policy Loss": 20.953536987304688, "Value Loss": 216.62203979492188, "_runtime": 8266.283600568771, "_timestamp": 1585578182.128234, "_step": 9}
{"Episode reward": 61.85243375182081, "Episode length": 383, "Policy Loss": 3.2100884914398193, "Value Loss": 99.92929077148438, "_runtime": 8266.873881340027, "_timestamp": 1585578182.7185147, "_step": 10}
{"Episode reward": 60.98772465828051, "Episode length": 391, "Policy Loss": 8.2260160446167, "Value Loss": 84.38253021240234, "_runtime": 8267.920596837997, "_timestamp": 1585578183.7652302, "_step": 11}
{"Episode reward": 29.815054030623003, "Episode length": 702, "Policy Loss": 3.0410807132720947, "Value Loss": 16.62938117980957, "_runtime": 8269.4339158535, "_timestamp": 1585578185.2785492, "_step": 12}
{"Episode reward": -99.79319925382593, "Episode length": 999, "Policy Loss": 1.45878005027771, "Value Loss": 1.1027252674102783, "_runtime": 8270.404288053513, "_timestamp": 1585578186.2489214, "_step": 13}
{"Episode reward": 39.09999999999941, "Episode length": 609, "Policy Loss": 1.4785927534103394, "Value Loss": 30.96584129333496, "_runtime": 8271.933997631073, "_timestamp": 1585578187.778631, "_step": 14}
{"Episode reward": -99.81234674788871, "Episode length": 999, "Policy Loss": 0.22201219201087952, "Value Loss": 15.260957717895508, "_runtime": 8273.14540219307, "_timestamp": 1585578188.9900355, "_step": 15}
{"Episode reward": 23.400000000000077, "Episode length": 766, "Policy Loss": -0.21466504037380219, "Value Loss": 53.21051788330078, "_runtime": 8274.683046340942, "_timestamp": 1585578190.5276797, "_step": 16}
{"Episode reward": -99.74444376649195, "Episode length": 999, "Policy Loss": -0.8056775331497192, "Value Loss": 27.88070297241211, "_runtime": 8276.234631061554, "_timestamp": 1585578192.0792644, "_step": 17}
{"Episode reward": -99.81742899417738, "Episode length": 999, "Policy Loss": -0.6730573177337646, "Value Loss": 23.713680267333984, "_runtime": 8277.7926466465, "_timestamp": 1585578193.63728, "_step": 18}
{"Episode reward": -99.71683418545733, "Episode length": 999, "Policy Loss": -0.3544066548347473, "Value Loss": 12.34022045135498, "_runtime": 8279.351575613022, "_timestamp": 1585578195.196209, "_step": 19}
{"Episode reward": -99.86266716867546, "Episode length": 999, "Policy Loss": -0.9485244750976562, "Value Loss": 14.464637756347656, "_runtime": 8280.7232503891, "_timestamp": 1585578196.5678837, "_step": 20}
{"Episode reward": 12.817903771135704, "Episode length": 873, "Policy Loss": -1.2851355075836182, "Value Loss": 36.19620132446289, "_runtime": 8281.63440656662, "_timestamp": 1585578197.47904, "_step": 21}
{"Episode reward": 43.78690623412788, "Episode length": 563, "Policy Loss": -1.0088186264038086, "Value Loss": 41.078125, "_runtime": 8282.592105388641, "_timestamp": 1585578198.4367387, "_step": 22}
{"Episode reward": 39.782238137721436, "Episode length": 603, "Policy Loss": 0.08447812497615814, "Value Loss": 21.652183532714844, "_runtime": 8283.47329902649, "_timestamp": 1585578199.3179324, "_step": 23}
{"Episode reward": 44.299999999999486, "Episode length": 557, "Policy Loss": -0.20334377884864807, "Value Loss": 21.70627212524414, "_runtime": 8284.538052797318, "_timestamp": 1585578200.3826861, "_step": 24}
{"Episode reward": 30.999999999999645, "Episode length": 690, "Policy Loss": -0.5865770578384399, "Value Loss": 15.691020965576172, "_runtime": 8286.063426494598, "_timestamp": 1585578201.9080598, "_step": 25}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.73493492603302, "Value Loss": 0.65498286485672, "_runtime": 8287.59791469574, "_timestamp": 1585578203.442548, "_step": 26}
{"Episode reward": -99.8004556012326, "Episode length": 999, "Policy Loss": -1.8632621765136719, "Value Loss": 0.0801190435886383, "_runtime": 8288.614971876144, "_timestamp": 1585578204.4596052, "_step": 27}
{"Episode reward": 35.4930090367788, "Episode length": 646, "Policy Loss": -0.7927698493003845, "Value Loss": 15.5689697265625, "_runtime": 8290.178873062134, "_timestamp": 1585578206.0235064, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.267043352127075, "Value Loss": 0.10206025838851929, "_runtime": 8291.755327939987, "_timestamp": 1585578207.5999613, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.463399648666382, "Value Loss": 0.16018155217170715, "_runtime": 8293.300553321838, "_timestamp": 1585578209.1451867, "_step": 30}
{"Episode reward": -99.71542795933645, "Episode length": 999, "Policy Loss": -2.668712854385376, "Value Loss": 0.4946700930595398, "_runtime": 8294.428762435913, "_timestamp": 1585578210.2733958, "_step": 31}
{"Episode reward": 31.380934070050344, "Episode length": 687, "Policy Loss": -1.7199631929397583, "Value Loss": 14.288512229919434, "_runtime": 8296.00863456726, "_timestamp": 1585578211.853268, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.068535089492798, "Value Loss": 1.8797026872634888, "_runtime": 8297.405358076096, "_timestamp": 1585578213.2499914, "_step": 33}
{"Episode reward": 11.743855236378309, "Episode length": 883, "Policy Loss": -2.586923837661743, "Value Loss": 13.41232681274414, "_runtime": 8298.763432741165, "_timestamp": 1585578214.608066, "_step": 34}
{"Episode reward": 12.165409749747042, "Episode length": 879, "Policy Loss": -2.313457727432251, "Value Loss": 11.873327255249023, "_runtime": 8300.345751523972, "_timestamp": 1585578216.1903849, "_step": 35}
{"Episode reward": -99.70326208353369, "Episode length": 999, "Policy Loss": -3.547300338745117, "Value Loss": 3.650616407394409, "_runtime": 8301.102183580399, "_timestamp": 1585578216.946817, "_step": 36}
{"Episode reward": 52.82039038799664, "Episode length": 472, "Policy Loss": -1.9373626708984375, "Value Loss": 24.115449905395508, "_runtime": 8302.661575317383, "_timestamp": 1585578218.5062087, "_step": 37}
{"Episode reward": -99.86434029489615, "Episode length": 999, "Policy Loss": -3.305696487426758, "Value Loss": 1.437571406364441, "_runtime": 8304.244844198227, "_timestamp": 1585578220.0894775, "_step": 38}
{"Episode reward": -99.8666917860494, "Episode length": 999, "Policy Loss": -3.3104135990142822, "Value Loss": 1.027799367904663, "_runtime": 8305.410737991333, "_timestamp": 1585578221.2553713, "_step": 39}
{"Episode reward": 24.09986409544949, "Episode length": 760, "Policy Loss": -2.4306092262268066, "Value Loss": 13.518843650817871, "_runtime": 8306.04336977005, "_timestamp": 1585578221.888003, "_step": 40}
{"Episode reward": 61.5648229973388, "Episode length": 387, "Policy Loss": -1.8254101276397705, "Value Loss": 28.100221633911133, "_runtime": 8307.614542007446, "_timestamp": 1585578223.4591753, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.316096067428589, "Value Loss": 0.4007229804992676, "_runtime": 8308.852533817291, "_timestamp": 1585578224.6971672, "_step": 42}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": -3.030046224594116, "Value Loss": 18.905189514160156, "_runtime": 8310.124361753464, "_timestamp": 1585578225.968995, "_step": 43}
{"Episode reward": 15.900000000000503, "Episode length": 841, "Policy Loss": -2.802955389022827, "Value Loss": 14.306933403015137, "_runtime": 8311.26649594307, "_timestamp": 1585578227.1111293, "_step": 44}
{"Episode reward": 28.382648943271278, "Episode length": 718, "Policy Loss": -2.525559663772583, "Value Loss": 15.665396690368652, "_runtime": 8312.832050323486, "_timestamp": 1585578228.6766837, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.2851333618164062, "Value Loss": 1.372309923171997, "_runtime": 8313.617819309235, "_timestamp": 1585578229.4624527, "_step": 46}
{"Episode reward": 50.97770574092823, "Episode length": 491, "Policy Loss": -1.488760232925415, "Value Loss": 19.827754974365234, "_runtime": 8314.49053311348, "_timestamp": 1585578230.3351665, "_step": 47}
{"Episode reward": 44.45937883472019, "Episode length": 556, "Policy Loss": -1.6215150356292725, "Value Loss": 17.854154586791992, "_runtime": 8316.066718101501, "_timestamp": 1585578231.9113514, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.1616039276123047, "Value Loss": 0.7756415009498596, "_runtime": 8317.63079881668, "_timestamp": 1585578233.4754322, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.043243169784546, "Value Loss": 0.42217978835105896, "_runtime": 8319.168833255768, "_timestamp": 1585578235.0134666, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.875939130783081, "Value Loss": 0.17201338708400726, "_runtime": 8319.915884971619, "_timestamp": 1585578235.7605183, "_step": 51}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": -1.2695491313934326, "Value Loss": 21.67591094970703, "_runtime": 8320.612379312515, "_timestamp": 1585578236.4570127, "_step": 52}
{"Episode reward": 57.18426185918473, "Episode length": 429, "Policy Loss": -0.7755832672119141, "Value Loss": 23.23845863342285, "_runtime": 8321.685960054398, "_timestamp": 1585578237.5305934, "_step": 53}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": -1.3649694919586182, "Value Loss": 14.715778350830078, "_runtime": 8323.211508274078, "_timestamp": 1585578239.0561416, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.638169527053833, "Value Loss": 0.12689745426177979, "_runtime": 8324.736577033997, "_timestamp": 1585578240.5812104, "_step": 55}
{"Episode reward": -99.80511923767486, "Episode length": 999, "Policy Loss": -2.600588798522949, "Value Loss": 0.12115107476711273, "_runtime": 8326.275880098343, "_timestamp": 1585578242.1205134, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5197880268096924, "Value Loss": 0.12093886733055115, "_runtime": 8327.84029841423, "_timestamp": 1585578243.6849318, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.52795147895813, "Value Loss": 0.10465101897716522, "_runtime": 8329.398505687714, "_timestamp": 1585578245.243139, "_step": 58}
{"Episode reward": -99.68581460743451, "Episode length": 999, "Policy Loss": -2.4235501289367676, "Value Loss": 0.13026782870292664, "_runtime": 8330.09539937973, "_timestamp": 1585578245.9400327, "_step": 59}
{"Episode reward": 57.699999999999676, "Episode length": 423, "Policy Loss": -0.4537412226200104, "Value Loss": 23.58108901977539, "_runtime": 8331.189107894897, "_timestamp": 1585578247.0337412, "_step": 60}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": -1.215973138809204, "Value Loss": 14.64929485321045, "_runtime": 8332.735570669174, "_timestamp": 1585578248.580204, "_step": 61}
{"Episode reward": -99.82642351537804, "Episode length": 999, "Policy Loss": -2.309148073196411, "Value Loss": 0.11655476689338684, "_runtime": 8333.344188928604, "_timestamp": 1585578249.1888223, "_step": 62}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": -0.29499611258506775, "Value Loss": 25.839096069335938, "_runtime": 8333.590288877487, "_timestamp": 1585578249.4349222, "_step": 63}
{"Episode reward": 86.88095272099602, "Episode length": 132, "Policy Loss": 3.751976490020752, "Value Loss": 75.61140441894531, "_runtime": 8334.78665137291, "_timestamp": 1585578250.6312847, "_step": 64}
{"Episode reward": 22.600000000000122, "Episode length": 774, "Policy Loss": -1.1928616762161255, "Value Loss": 12.94393253326416, "_runtime": 8336.285636901855, "_timestamp": 1585578252.1302702, "_step": 65}
{"Episode reward": -99.63816234245759, "Episode length": 999, "Policy Loss": -2.188781261444092, "Value Loss": 0.07941032946109772, "_runtime": 8337.484844446182, "_timestamp": 1585578253.3294778, "_step": 66}
{"Episode reward": 18.499860015139348, "Episode length": 816, "Policy Loss": -1.136462688446045, "Value Loss": 12.326613426208496, "_runtime": 8338.767646551132, "_timestamp": 1585578254.61228, "_step": 67}
{"Episode reward": 17.447286173236037, "Episode length": 827, "Policy Loss": -1.1382747888565063, "Value Loss": 12.140341758728027, "_runtime": 8340.29081439972, "_timestamp": 1585578256.1354477, "_step": 68}
{"Episode reward": -99.76298100175197, "Episode length": 999, "Policy Loss": -2.0753731727600098, "Value Loss": 0.08014120161533356, "_runtime": 8340.837219238281, "_timestamp": 1585578256.6818526, "_step": 69}
{"Episode reward": 65.69999999999979, "Episode length": 343, "Policy Loss": 0.74172443151474, "Value Loss": 29.150360107421875, "_runtime": 8342.372249126434, "_timestamp": 1585578258.2168825, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.0341784954071045, "Value Loss": 0.07451131939888, "_runtime": 8343.951926231384, "_timestamp": 1585578259.7965596, "_step": 71}
{"Episode reward": -99.86708718612651, "Episode length": 999, "Policy Loss": -2.0117859840393066, "Value Loss": 0.07293681800365448, "_runtime": 8345.366425037384, "_timestamp": 1585578261.2110584, "_step": 72}
{"Episode reward": 5.589653788508073, "Episode length": 945, "Policy Loss": -1.2000341415405273, "Value Loss": 10.596765518188477, "_runtime": 8346.935251951218, "_timestamp": 1585578262.7798853, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9640254974365234, "Value Loss": 0.06348781287670135, "_runtime": 8348.076892614365, "_timestamp": 1585578263.921526, "_step": 74}
{"Episode reward": 27.699999999999832, "Episode length": 723, "Policy Loss": -0.8447858095169067, "Value Loss": 13.797416687011719, "_runtime": 8348.73009467125, "_timestamp": 1585578264.574728, "_step": 75}
{"Episode reward": 58.89999999999969, "Episode length": 411, "Policy Loss": 0.019287096336483955, "Value Loss": 24.25069236755371, "_runtime": 8349.417874336243, "_timestamp": 1585578265.2625077, "_step": 76}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": -0.03626468777656555, "Value Loss": 23.63235092163086, "_runtime": 8350.961080789566, "_timestamp": 1585578266.8057141, "_step": 77}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8944880962371826, "Value Loss": 0.05759640410542488, "_runtime": 8351.924954652786, "_timestamp": 1585578267.769588, "_step": 78}
{"Episode reward": 36.13567928671774, "Episode length": 639, "Policy Loss": -0.6484712362289429, "Value Loss": 15.583868026733398, "_runtime": 8353.427587509155, "_timestamp": 1585578269.2722208, "_step": 79}
{"Episode reward": -99.83764134049275, "Episode length": 999, "Policy Loss": -1.8395756483078003, "Value Loss": 0.05491304770112038, "_runtime": 8354.988314628601, "_timestamp": 1585578270.832948, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8243907690048218, "Value Loss": 0.056190405040979385, "_runtime": 8356.511179924011, "_timestamp": 1585578272.3558133, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8252766132354736, "Value Loss": 0.053262535482645035, "_runtime": 8358.066850662231, "_timestamp": 1585578273.911484, "_step": 82}
{"Episode reward": -99.87938653379538, "Episode length": 999, "Policy Loss": -1.7764900922775269, "Value Loss": 0.05214750021696091, "_runtime": 8359.632946252823, "_timestamp": 1585578275.4775796, "_step": 83}
{"Episode reward": -99.61812287391956, "Episode length": 999, "Policy Loss": -1.7709403038024902, "Value Loss": 0.05245526134967804, "_runtime": 8360.155647277832, "_timestamp": 1585578276.0002806, "_step": 84}
{"Episode reward": 68.89999999999984, "Episode length": 311, "Policy Loss": 0.783378541469574, "Value Loss": 31.914379119873047, "_runtime": 8361.703566789627, "_timestamp": 1585578277.5482001, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7414239645004272, "Value Loss": 0.0491604208946228, "_runtime": 8363.280217170715, "_timestamp": 1585578279.1248505, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.727356195449829, "Value Loss": 0.04880565032362938, "_runtime": 8363.656861543655, "_timestamp": 1585578279.501495, "_step": 87}
{"Episode reward": 76.7950736268423, "Episode length": 233, "Policy Loss": 1.6174076795578003, "Value Loss": 42.562767028808594, "_runtime": 8365.195874929428, "_timestamp": 1585578281.0405083, "_step": 88}
{"Episode reward": -99.86505706347386, "Episode length": 999, "Policy Loss": -1.6903074979782104, "Value Loss": 0.0463472343981266, "_runtime": 8366.770760536194, "_timestamp": 1585578282.6153939, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.672214150428772, "Value Loss": 0.048771344125270844, "_runtime": 8367.611509799957, "_timestamp": 1585578283.4561431, "_step": 90}
{"Episode reward": 43.749647532402946, "Episode length": 563, "Policy Loss": -0.24229931831359863, "Value Loss": 17.64969253540039, "_runtime": 8369.161618947983, "_timestamp": 1585578285.0062523, "_step": 91}
{"Episode reward": -99.80062377601722, "Episode length": 999, "Policy Loss": -1.6619101762771606, "Value Loss": 0.05212674289941788, "_runtime": 8370.758985757828, "_timestamp": 1585578286.603619, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.646240472793579, "Value Loss": 0.045425161719322205, "_runtime": 8372.24283003807, "_timestamp": 1585578288.0874634, "_step": 93}
{"Episode reward": 0.9000000000013557, "Episode length": 991, "Policy Loss": -0.8551401495933533, "Value Loss": 10.098834991455078, "_runtime": 8373.80597114563, "_timestamp": 1585578289.6506045, "_step": 94}
{"Episode reward": -99.7300849273787, "Episode length": 999, "Policy Loss": -1.6246411800384521, "Value Loss": 0.046914394944906235, "_runtime": 8375.38035273552, "_timestamp": 1585578291.224986, "_step": 95}
{"Episode reward": -99.8078177306787, "Episode length": 999, "Policy Loss": -1.600603461265564, "Value Loss": 0.045896705240011215, "_runtime": 8376.68556547165, "_timestamp": 1585578292.5301988, "_step": 96}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": -0.6936556100845337, "Value Loss": 11.84406852722168, "_runtime": 8378.011617898941, "_timestamp": 1585578293.8562512, "_step": 97}
{"Episode reward": 15.500000000000526, "Episode length": 845, "Policy Loss": -0.6673533320426941, "Value Loss": 11.748956680297852, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776, 0.136728435754776]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12587136030197144, 0.10726052522659302, 0.34039241075515747, 0.5735242962837219, 0.8066561818122864, 1.039788007736206, 1.2729198932647705, 1.506051778793335, 1.7391836643218994, 1.9723155498504639, 2.2054474353790283, 2.4385793209075928, 2.6717112064361572, 2.9048430919647217, 3.137974977493286, 3.3711068630218506, 3.604238748550415, 3.8373706340789795, 4.070502758026123, 4.3036346435546875, 4.536766529083252, 4.769898414611816, 5.003030300140381, 5.236162185668945, 5.46929407119751, 5.702425956726074, 5.935557842254639, 6.168689727783203, 6.401821613311768, 6.634953498840332, 6.8680853843688965, 7.101217269897461, 7.334349155426025, 7.56748104095459, 7.800612926483154, 8.033744812011719, 8.266876220703125, 8.500007629394531, 8.733139991760254, 8.966272354125977, 9.199403762817383, 9.432535171508789, 9.665667533874512, 9.898799896240234, 10.13193130493164, 10.365062713623047, 10.59819507598877, 10.831327438354492, 11.064458847045898, 11.297590255737305, 11.530722618103027, 11.76385498046875, 11.996986389160156, 12.230117797851562, 12.463250160217285, 12.696382522583008, 12.929513931274414, 13.16264533996582, 13.395777702331543, 13.628910064697266, 13.862041473388672, 14.095172882080078, 14.3283052444458, 14.561437606811523, 14.79456901550293]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.1770450323820114, -0.1676432490348816, -0.15824146568775177, -0.14883968234062195, -0.13943791389465332, -0.1300361156463623, -0.12063434720039368, -0.11123256385326385, -0.10183078050613403, -0.09242899715900421, -0.08302721381187439, -0.07362543791532516, -0.06422365456819534, -0.05482187122106552, -0.045420095324516296, -0.036018311977386475, -0.026616528630256653, -0.01721474528312683, -0.00781296193599701, 0.0015888214111328125, 0.010990604758262634, 0.020392373204231262, 0.029794156551361084, 0.039195939898490906, 0.04859772324562073, 0.05799950659275055, 0.06740128993988037, 0.07680307328701019, 0.08620484173297882, 0.09560663998126984, 0.10500840842723846, 0.11441020667552948, 0.12381197512149811, 0.13321374356746674, 0.14261554181575775, 0.15201731026172638, 0.1614191085100174, 0.17082087695598602, 0.18022267520427704, 0.18962444365024567, 0.19902624189853668, 0.2084280103445053, 0.21782977879047394, 0.22723157703876495, 0.23663334548473358, 0.2460351437330246, 0.25543689727783203, 0.26483869552612305, 0.27424049377441406, 0.2836422324180603, 0.2930440306663513, 0.30244582891464233, 0.31184762716293335, 0.3212493658065796, 0.3306511640548706, 0.3400529623031616, 0.34945470094680786, 0.3588564991950989, 0.3682582974433899, 0.37766003608703613, 0.38706183433532715, 0.39646363258361816, 0.4058654308319092, 0.4152671694755554, 0.42466896772384644]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 5.0, 2.0, 7.0, 4.0, 32.0, 28.0, 12.0, 3.0, 0.0, 0.0, 0.0, 288.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 3.0, 4.0, 7.0, 3.0, 9.0, 1.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 4.0, 4.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 3.0], "bins": [-1.0281931161880493, -0.9733229279518127, -0.9184527397155762, -0.8635826110839844, -0.808712363243103, -0.7538422346115112, -0.6989720463752747, -0.6441018581390381, -0.5892316699028015, -0.5343614816665649, -0.47949129343032837, -0.4246211051940918, -0.3697509765625, -0.3148807883262634, -0.26001060009002686, -0.20514041185379028, -0.1502702236175537, -0.09540003538131714, -0.040529847145080566, 0.01434028148651123, 0.06921052932739258, 0.12408065795898438, 0.17895090579986572, 0.23382103443145752, 0.2886911630630493, 0.34356141090393066, 0.39843153953552246, 0.4533017873764038, 0.5081719160079956, 0.563042163848877, 0.6179122924804688, 0.6727825403213501, 0.7276526689529419, 0.7825227975845337, 0.837393045425415, 0.8922631740570068, 0.9471334218978882, 1.00200355052948, 1.0568736791610718, 1.1117440462112427, 1.1666141748428345, 1.2214843034744263, 1.276354432106018, 1.3312245607376099, 1.3860949277877808, 1.4409650564193726, 1.4958351850509644, 1.5507053136825562, 1.605575442314148, 1.6604458093643188, 1.7153159379959106, 1.7701860666275024, 1.8250561952590942, 1.8799265623092651, 1.934796690940857, 1.9896668195724487, 2.04453706741333, 2.099407196044922, 2.1542773246765137, 2.2091474533081055, 2.2640175819396973, 2.318887710571289, 2.373758316040039, 2.428628444671631, 2.4834985733032227]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [6.0, 5.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.10866707563400269, -0.08045393228530884, -0.05224079638719559, -0.024027660489082336, 0.004185482859611511, 0.03239862620830536, 0.06061175465583801, 0.08882489800453186, 0.11703804135322571, 0.14525118470191956, 0.1734643280506134, 0.20167747139930725, 0.2298905849456787, 0.25810372829437256, 0.2863168716430664, 0.31453001499176025, 0.3427431583404541, 0.37095630168914795, 0.3991694450378418, 0.42738258838653564, 0.4555957317352295, 0.48380887508392334, 0.5120220184326172, 0.540235161781311, 0.5684482455253601, 0.596661388874054, 0.6248745322227478, 0.6530876755714417, 0.6813008189201355, 0.7095139622688293, 0.7377271056175232, 0.765940248966217, 0.7941533923149109, 0.8223665356636047, 0.8505796790122986, 0.8787928223609924, 0.9070059657096863, 0.9352191090583801, 0.963432252407074, 0.9916453957557678, 1.0198585987091064, 1.0480716228485107, 1.0762848854064941, 1.1044979095458984, 1.1327111721038818, 1.1609241962432861, 1.1891374588012695, 1.2173504829406738, 1.2455635070800781, 1.2737767696380615, 1.3019897937774658, 1.3302030563354492, 1.3584160804748535, 1.386629343032837, 1.4148423671722412, 1.4430556297302246, 1.471268653869629, 1.4994819164276123, 1.5276949405670166, 1.555908203125, 1.5841212272644043, 1.6123344898223877, 1.640547513961792, 1.6687607765197754, 1.6969738006591797]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 2.0, 3.0, 4.0, 12.0, 7.0], "bins": [-0.874506413936615, -0.8594982028007507, -0.8444899320602417, -0.8294817209243774, -0.8144735097885132, -0.7994652390480042, -0.7844570279121399, -0.7694487571716309, -0.7544405460357666, -0.7394323348999023, -0.7244241237640381, -0.709415853023529, -0.6944076418876648, -0.6793993711471558, -0.6643911600112915, -0.6493829488754272, -0.6343746781349182, -0.619366466999054, -0.6043581962585449, -0.5893499851226807, -0.5743417739868164, -0.5593335628509521, -0.5443252921104431, -0.5293170213699341, -0.5143088102340698, -0.49930059909820557, -0.4842923581600189, -0.46928414702415466, -0.454275906085968, -0.43926766514778137, -0.4242594242095947, -0.40925121307373047, -0.3942429721355438, -0.3792347311973572, -0.3642265200614929, -0.3492182493209839, -0.33421003818511963, -0.31920182704925537, -0.30419355630874634, -0.2891853451728821, -0.2741771340370178, -0.2591688632965088, -0.24416065216064453, -0.22915244102478027, -0.21414417028427124, -0.19913595914840698, -0.18412768840789795, -0.1691194772720337, -0.15411126613616943, -0.1391029953956604, -0.12409478425979614, -0.10908657312393188, -0.09407830238342285, -0.0790700912475586, -0.06406188011169434, -0.0490536093711853, -0.034045398235321045, -0.019037187099456787, -0.004028916358947754, 0.010979294776916504, 0.025987565517425537, 0.040995776653289795, 0.05600398778915405, 0.07101225852966309, 0.08602046966552734]}, "_runtime": 8379.33617067337, "_timestamp": 1585578295.180804, "_step": 98}
{"Episode reward": 14.800000000000566, "Episode length": 852, "Policy Loss": -0.6407632827758789, "Value Loss": 11.63778018951416, "_runtime": 8380.442984819412, "_timestamp": 1585578296.2876182, "_step": 99}
{"Episode reward": 28.99999999999976, "Episode length": 710, "Policy Loss": -0.5014916658401489, "Value Loss": 14.002358436584473, "_runtime": 8381.326566696167, "_timestamp": 1585578297.1712, "_step": 100}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": -0.182008758187294, "Value Loss": 17.676132202148438, "_runtime": 8382.440787792206, "_timestamp": 1585578298.2854211, "_step": 101}
{"Episode reward": 28.56728778295198, "Episode length": 715, "Policy Loss": -0.488741010427475, "Value Loss": 13.853872299194336, "_runtime": 8383.979344844818, "_timestamp": 1585578299.8239782, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5240273475646973, "Value Loss": 0.04673183709383011, "_runtime": 8385.365778446198, "_timestamp": 1585578301.2104118, "_step": 103}
{"Episode reward": 9.49009254637727, "Episode length": 906, "Policy Loss": -0.7044190764427185, "Value Loss": 10.94427490234375, "_runtime": 8386.90288233757, "_timestamp": 1585578302.7475157, "_step": 104}
{"Episode reward": -99.81018585301796, "Episode length": 999, "Policy Loss": -1.5139654874801636, "Value Loss": 0.05043025314807892, "_runtime": 8388.142537117004, "_timestamp": 1585578303.9871705, "_step": 105}
{"Episode reward": 19.717782568931867, "Episode length": 803, "Policy Loss": -0.5652197599411011, "Value Loss": 12.34398365020752, "_runtime": 8389.688185691833, "_timestamp": 1585578305.532819, "_step": 106}
{"Episode reward": -99.88606910705427, "Episode length": 999, "Policy Loss": -1.5322611331939697, "Value Loss": 0.04570448026061058, "_runtime": 8391.256955385208, "_timestamp": 1585578307.1015887, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.513250708580017, "Value Loss": 0.04632411524653435, "_runtime": 8391.504547834396, "_timestamp": 1585578307.3491812, "_step": 108}
{"Episode reward": 87.00000000000003, "Episode length": 130, "Policy Loss": 4.5648651123046875, "Value Loss": 75.83003997802734, "_runtime": 8392.518527507782, "_timestamp": 1585578308.3631608, "_step": 109}
{"Episode reward": 35.199999999999406, "Episode length": 648, "Policy Loss": -0.35692888498306274, "Value Loss": 15.251254081726074, "_runtime": 8393.204246044159, "_timestamp": 1585578309.0488794, "_step": 110}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 0.4034155607223511, "Value Loss": 24.846994400024414, "_runtime": 8394.687450885773, "_timestamp": 1585578310.5320842, "_step": 111}
{"Episode reward": -99.89746500290791, "Episode length": 999, "Policy Loss": -1.532607913017273, "Value Loss": 0.0454944409430027, "_runtime": 8396.218819379807, "_timestamp": 1585578312.0634527, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5506950616836548, "Value Loss": 0.051576610654592514, "_runtime": 8396.979390621185, "_timestamp": 1585578312.824024, "_step": 113}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": -0.0699988454580307, "Value Loss": 19.805736541748047, "_runtime": 8397.953846216202, "_timestamp": 1585578313.7984796, "_step": 114}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": -0.3493591248989105, "Value Loss": 15.724550247192383, "_runtime": 8399.51086974144, "_timestamp": 1585578315.355503, "_step": 115}
{"Episode reward": -99.8001074258224, "Episode length": 999, "Policy Loss": -1.5387654304504395, "Value Loss": 0.09032552689313889, "_runtime": 8401.023494958878, "_timestamp": 1585578316.8681283, "_step": 116}
{"Episode reward": -99.8270962865078, "Episode length": 999, "Policy Loss": -1.5987730026245117, "Value Loss": 0.13442961871623993, "_runtime": 8402.543357133865, "_timestamp": 1585578318.3879905, "_step": 117}
{"Episode reward": -99.86161828376213, "Episode length": 999, "Policy Loss": -1.579027771949768, "Value Loss": 0.1036418005824089, "_runtime": 8404.099304199219, "_timestamp": 1585578319.9439375, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5380727052688599, "Value Loss": 0.05597495660185814, "_runtime": 8405.659355163574, "_timestamp": 1585578321.5039885, "_step": 119}
{"Episode reward": -99.88800510316948, "Episode length": 999, "Policy Loss": -1.5670703649520874, "Value Loss": 0.0714043453335762, "_runtime": 8407.205711126328, "_timestamp": 1585578323.0503445, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.581954002380371, "Value Loss": 0.09730466455221176, "_runtime": 8408.778722524643, "_timestamp": 1585578324.6233559, "_step": 121}
{"Episode reward": -99.8453995205448, "Episode length": 999, "Policy Loss": -1.5263707637786865, "Value Loss": 0.05386443808674812, "_runtime": 8410.334517717361, "_timestamp": 1585578326.179151, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5381027460098267, "Value Loss": 0.06505399942398071, "_runtime": 8411.32876753807, "_timestamp": 1585578327.1734009, "_step": 123}
{"Episode reward": 37.199999999999385, "Episode length": 628, "Policy Loss": -0.27251002192497253, "Value Loss": 15.651362419128418, "_runtime": 8412.887819051743, "_timestamp": 1585578328.7324524, "_step": 124}
{"Episode reward": -99.80422324575343, "Episode length": 999, "Policy Loss": -1.4969600439071655, "Value Loss": 0.10005486011505127, "_runtime": 8414.455222845078, "_timestamp": 1585578330.2998562, "_step": 125}
{"Episode reward": -99.708960586878, "Episode length": 999, "Policy Loss": -1.4882478713989258, "Value Loss": 0.050866998732089996, "_runtime": 8415.355085134506, "_timestamp": 1585578331.1997185, "_step": 126}
{"Episode reward": 42.099999999999454, "Episode length": 579, "Policy Loss": 0.017680976539850235, "Value Loss": 16.970439910888672, "_runtime": 8416.955797672272, "_timestamp": 1585578332.800431, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4767698049545288, "Value Loss": 0.10572671890258789, "_runtime": 8417.780458211899, "_timestamp": 1585578333.6250916, "_step": 128}
{"Episode reward": 48.51031503081276, "Episode length": 515, "Policy Loss": 0.1731388419866562, "Value Loss": 19.087690353393555, "_runtime": 8419.31359052658, "_timestamp": 1585578335.1582239, "_step": 129}
{"Episode reward": -99.82410353757301, "Episode length": 999, "Policy Loss": -1.4119890928268433, "Value Loss": 0.05800943821668625, "_runtime": 8420.882761240005, "_timestamp": 1585578336.7273946, "_step": 130}
{"Episode reward": -99.80016872919956, "Episode length": 999, "Policy Loss": -1.435789704322815, "Value Loss": 0.08456624299287796, "_runtime": 8422.398081541061, "_timestamp": 1585578338.242715, "_step": 131}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3985341787338257, "Value Loss": 0.04573741927742958, "_runtime": 8423.960657835007, "_timestamp": 1585578339.8052912, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4376599788665771, "Value Loss": 0.14176005125045776, "_runtime": 8425.523916721344, "_timestamp": 1585578341.36855, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.37287175655365, "Value Loss": 0.04925038665533066, "_runtime": 8426.73231959343, "_timestamp": 1585578342.576953, "_step": 134}
{"Episode reward": 22.686793802678707, "Episode length": 774, "Policy Loss": -0.3644666373729706, "Value Loss": 12.710317611694336, "_runtime": 8428.28235912323, "_timestamp": 1585578344.1269925, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3097058534622192, "Value Loss": 0.039988551288843155, "_runtime": 8429.857030630112, "_timestamp": 1585578345.701664, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3341575860977173, "Value Loss": 0.04892999678850174, "_runtime": 8431.394386529922, "_timestamp": 1585578347.2390199, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2972862720489502, "Value Loss": 0.03443427383899689, "_runtime": 8432.592546224594, "_timestamp": 1585578348.4371796, "_step": 138}
{"Episode reward": 23.400000000000077, "Episode length": 766, "Policy Loss": -0.2647550702095032, "Value Loss": 12.835512161254883, "_runtime": 8434.162236213684, "_timestamp": 1585578350.0068696, "_step": 139}
{"Episode reward": -99.71903417743603, "Episode length": 999, "Policy Loss": -1.2569565773010254, "Value Loss": 0.03941168636083603, "_runtime": 8435.724430561066, "_timestamp": 1585578351.569064, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.275421380996704, "Value Loss": 0.07676312327384949, "_runtime": 8437.265791654587, "_timestamp": 1585578353.110425, "_step": 141}
{"Episode reward": -99.80323863783711, "Episode length": 999, "Policy Loss": -1.2567118406295776, "Value Loss": 0.07080674916505814, "_runtime": 8438.817657709122, "_timestamp": 1585578354.662291, "_step": 142}
{"Episode reward": 0.5634573452188505, "Episode length": 995, "Policy Loss": -0.4439121186733246, "Value Loss": 9.89389705657959, "_runtime": 8440.414779186249, "_timestamp": 1585578356.2594125, "_step": 143}
{"Episode reward": -99.84216593541065, "Episode length": 999, "Policy Loss": -1.194969654083252, "Value Loss": 0.054731812328100204, "_runtime": 8441.9799721241, "_timestamp": 1585578357.8246055, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.167114496231079, "Value Loss": 0.038201939314603806, "_runtime": 8443.559618473053, "_timestamp": 1585578359.4042518, "_step": 145}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.193247675895691, "Value Loss": 0.0889403373003006, "_runtime": 8445.129128694534, "_timestamp": 1585578360.973762, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1658412218093872, "Value Loss": 0.057892490178346634, "_runtime": 8445.9048037529, "_timestamp": 1585578361.749437, "_step": 147}
{"Episode reward": 52.240553188975504, "Episode length": 478, "Policy Loss": 0.4828660190105438, "Value Loss": 20.6225643157959, "_runtime": 8447.099382162094, "_timestamp": 1585578362.9440155, "_step": 148}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": -0.1473732441663742, "Value Loss": 13.0387601852417, "_runtime": 8448.44161105156, "_timestamp": 1585578364.2862444, "_step": 149}
{"Episode reward": 14.300000000000594, "Episode length": 857, "Policy Loss": -0.1521829515695572, "Value Loss": 11.501986503601074, "_runtime": 8449.967319011688, "_timestamp": 1585578365.8119524, "_step": 150}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0857185125350952, "Value Loss": 0.02575835958123207, "_runtime": 8451.515971899033, "_timestamp": 1585578367.3606052, "_step": 151}
{"Episode reward": -99.71831641793112, "Episode length": 999, "Policy Loss": -1.0772731304168701, "Value Loss": 0.026585200801491737, "_runtime": 8452.801890611649, "_timestamp": 1585578368.646524, "_step": 152}
{"Episode reward": 18.483223881479717, "Episode length": 816, "Policy Loss": 0.040109071880578995, "Value Loss": 12.08633804321289, "_runtime": 8454.37130188942, "_timestamp": 1585578370.2159352, "_step": 153}
{"Episode reward": -99.73425657749037, "Episode length": 999, "Policy Loss": -1.0515483617782593, "Value Loss": 0.029507223516702652, "_runtime": 8455.956684589386, "_timestamp": 1585578371.801318, "_step": 154}
{"Episode reward": -99.85681905895332, "Episode length": 999, "Policy Loss": -1.049138069152832, "Value Loss": 0.02892126515507698, "_runtime": 8456.955055952072, "_timestamp": 1585578372.7996893, "_step": 155}
{"Episode reward": 37.42059480957626, "Episode length": 627, "Policy Loss": 0.18301181495189667, "Value Loss": 15.710856437683105, "_runtime": 8457.88886141777, "_timestamp": 1585578373.7334948, "_step": 156}
{"Episode reward": 41.19999999999944, "Episode length": 588, "Policy Loss": 0.23819921910762787, "Value Loss": 16.752958297729492, "_runtime": 8458.918566942215, "_timestamp": 1585578374.7632003, "_step": 157}
{"Episode reward": 35.673466560150814, "Episode length": 644, "Policy Loss": 0.18674622476100922, "Value Loss": 15.279664039611816, "_runtime": 8459.389618396759, "_timestamp": 1585578375.2342517, "_step": 158}
{"Episode reward": 71.52835468649852, "Episode length": 285, "Policy Loss": 1.578490972518921, "Value Loss": 34.477073669433594, "_runtime": 8460.237933158875, "_timestamp": 1585578376.0825665, "_step": 159}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 0.33305537700653076, "Value Loss": 17.867795944213867, "_runtime": 8461.774133205414, "_timestamp": 1585578377.6187665, "_step": 160}
{"Episode reward": -99.80348365455725, "Episode length": 999, "Policy Loss": -1.0506236553192139, "Value Loss": 0.0350959487259388, "_runtime": 8463.279451847076, "_timestamp": 1585578379.1240852, "_step": 161}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0614084005355835, "Value Loss": 0.029509274289011955, "_runtime": 8464.820580005646, "_timestamp": 1585578380.6652133, "_step": 162}
{"Episode reward": 1.8000000000013046, "Episode length": 982, "Policy Loss": -0.2876362204551697, "Value Loss": 10.005288124084473, "_runtime": 8466.3883497715, "_timestamp": 1585578382.232983, "_step": 163}
{"Episode reward": -99.83052117386693, "Episode length": 999, "Policy Loss": -1.0424823760986328, "Value Loss": 0.04530380666255951, "_runtime": 8467.938303947449, "_timestamp": 1585578383.7829373, "_step": 164}
{"Episode reward": -99.74679603585834, "Episode length": 999, "Policy Loss": -1.0819388628005981, "Value Loss": 0.06566136330366135, "_runtime": 8469.513805627823, "_timestamp": 1585578385.358439, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0540571212768555, "Value Loss": 0.039184097200632095, "_runtime": 8470.971113443375, "_timestamp": 1585578386.8157468, "_step": 166}
{"Episode reward": 8.397137492896064, "Episode length": 917, "Policy Loss": -0.24965006113052368, "Value Loss": 10.700878143310547, "_runtime": 8472.544193983078, "_timestamp": 1585578388.3888273, "_step": 167}
{"Episode reward": -99.65404526218633, "Episode length": 999, "Policy Loss": -1.099319577217102, "Value Loss": 0.056380003690719604, "_runtime": 8474.11596083641, "_timestamp": 1585578389.9605942, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0682588815689087, "Value Loss": 0.09958545118570328, "_runtime": 8475.366940021515, "_timestamp": 1585578391.2115734, "_step": 169}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": -0.13542845845222473, "Value Loss": 12.495367050170898, "_runtime": 8476.946110963821, "_timestamp": 1585578392.7907443, "_step": 170}
{"Episode reward": -99.8040347430841, "Episode length": 999, "Policy Loss": -1.0869108438491821, "Value Loss": 0.049898963421583176, "_runtime": 8477.598949193954, "_timestamp": 1585578393.4435825, "_step": 171}
{"Episode reward": 60.15358651727409, "Episode length": 399, "Policy Loss": 0.8234695792198181, "Value Loss": 24.510915756225586, "_runtime": 8479.146154642105, "_timestamp": 1585578394.990788, "_step": 172}
{"Episode reward": -99.8070329848663, "Episode length": 999, "Policy Loss": -0.9953346848487854, "Value Loss": 0.04515789821743965, "_runtime": 8480.491654872894, "_timestamp": 1585578396.3362882, "_step": 173}
{"Episode reward": 14.000000000000611, "Episode length": 860, "Policy Loss": -0.22407084703445435, "Value Loss": 11.472790718078613, "_runtime": 8481.998131752014, "_timestamp": 1585578397.842765, "_step": 174}
{"Episode reward": -99.82528308445914, "Episode length": 999, "Policy Loss": -1.076756238937378, "Value Loss": 0.11965449154376984, "_runtime": 8483.565207004547, "_timestamp": 1585578399.4098403, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0614515542984009, "Value Loss": 0.1868901252746582, "_runtime": 8484.784247636795, "_timestamp": 1585578400.628881, "_step": 176}
{"Episode reward": 21.520941292657696, "Episode length": 786, "Policy Loss": -0.11925827711820602, "Value Loss": 12.551868438720703, "_runtime": 8486.11234498024, "_timestamp": 1585578401.9569783, "_step": 177}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": -0.18134143948554993, "Value Loss": 11.478925704956055, "_runtime": 8487.72743844986, "_timestamp": 1585578403.5720718, "_step": 178}
{"Episode reward": -99.65591511949758, "Episode length": 999, "Policy Loss": -0.9883565306663513, "Value Loss": 0.029507411643862724, "_runtime": 8488.221507072449, "_timestamp": 1585578404.0661404, "_step": 179}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 1.5988397598266602, "Value Loss": 32.568443298339844, "_runtime": 8489.77405333519, "_timestamp": 1585578405.6186867, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9805108904838562, "Value Loss": 0.04266118258237839, "_runtime": 8491.34970164299, "_timestamp": 1585578407.194335, "_step": 181}
{"Episode reward": -99.80483602620521, "Episode length": 999, "Policy Loss": -0.9846503734588623, "Value Loss": 0.05239895358681679, "_runtime": 8492.612789869308, "_timestamp": 1585578408.4574232, "_step": 182}
{"Episode reward": 15.58082532053865, "Episode length": 846, "Policy Loss": -0.09846415370702744, "Value Loss": 11.616119384765625, "_runtime": 8493.030164003372, "_timestamp": 1585578408.8747973, "_step": 183}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 2.0855658054351807, "Value Loss": 40.59288024902344, "_runtime": 8494.599243879318, "_timestamp": 1585578410.4438772, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9532944560050964, "Value Loss": 0.07212928682565689, "_runtime": 8496.142807245255, "_timestamp": 1585578411.9874406, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9863941669464111, "Value Loss": 0.04637903720140457, "_runtime": 8497.63541007042, "_timestamp": 1585578413.4800434, "_step": 186}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9954103827476501, "Value Loss": 0.030406521633267403, "_runtime": 8499.214206933975, "_timestamp": 1585578415.0588403, "_step": 187}
{"Episode reward": -99.87219138762308, "Episode length": 999, "Policy Loss": -0.9885830283164978, "Value Loss": 0.05906252935528755, "_runtime": 8500.598010540009, "_timestamp": 1585578416.442644, "_step": 188}
{"Episode reward": 10.51490066191262, "Episode length": 896, "Policy Loss": -0.15294618904590607, "Value Loss": 10.964829444885254, "_runtime": 8502.134629487991, "_timestamp": 1585578417.9792628, "_step": 189}
{"Episode reward": -99.8000016474151, "Episode length": 999, "Policy Loss": -0.949333906173706, "Value Loss": 0.05153952166438103, "_runtime": 8503.719701766968, "_timestamp": 1585578419.564335, "_step": 190}
{"Episode reward": -99.83215078264335, "Episode length": 999, "Policy Loss": -0.9597774147987366, "Value Loss": 0.06809043884277344, "_runtime": 8505.134507894516, "_timestamp": 1585578420.9791412, "_step": 191}
{"Episode reward": 9.300000000000878, "Episode length": 907, "Policy Loss": -0.14726075530052185, "Value Loss": 10.818826675415039, "_runtime": 8506.520553588867, "_timestamp": 1585578422.365187, "_step": 192}
{"Episode reward": 10.300000000000821, "Episode length": 897, "Policy Loss": -0.1457693874835968, "Value Loss": 10.886087417602539, "_runtime": 8508.099484920502, "_timestamp": 1585578423.9441183, "_step": 193}
{"Episode reward": -99.83685165792564, "Episode length": 999, "Policy Loss": -0.9492261409759521, "Value Loss": 0.03566266968846321, "_runtime": 8509.653013944626, "_timestamp": 1585578425.4976473, "_step": 194}
{"Episode reward": -99.74644815781946, "Episode length": 999, "Policy Loss": -0.9550157785415649, "Value Loss": 0.06538187712430954, "_runtime": 8511.233887910843, "_timestamp": 1585578427.0785213, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9724281430244446, "Value Loss": 0.04270894452929497, "_runtime": 8511.89872264862, "_timestamp": 1585578427.743356, "_step": 196}
{"Episode reward": 59.2999999999997, "Episode length": 407, "Policy Loss": 0.8605328798294067, "Value Loss": 24.012636184692383, "_runtime": 8513.050089120865, "_timestamp": 1585578428.8947225, "_step": 197}
{"Episode reward": 25.99999999999993, "Episode length": 740, "Policy Loss": 0.0940338745713234, "Value Loss": 13.189847946166992, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747, 0.17866185307502747]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.23282063007354736, 0.09850361943244934, 0.42982786893844604, 0.7611521482467651, 1.0924763679504395, 1.4238005876541138, 1.7551249265670776, 2.086449146270752, 2.4177732467651367, 2.7490978240966797, 3.0804219245910645, 3.411746025085449, 3.743070602416992, 4.074394702911377, 4.405718803405762, 4.737043380737305, 5.0683674812316895, 5.399691581726074, 5.731016159057617, 6.062340259552002, 6.393664360046387, 6.72498893737793, 7.0563130378723145, 7.387637138366699, 7.718961715698242, 8.050285339355469, 8.381609916687012, 8.712934494018555, 9.044258117675781, 9.375582695007324, 9.706907272338867, 10.038230895996094, 10.369555473327637, 10.70088005065918, 11.032203674316406, 11.36352825164795, 11.694852828979492, 12.026176452636719, 12.357501029968262, 12.688825607299805, 13.020149230957031, 13.351473808288574, 13.682798385620117, 14.014122009277344, 14.345446586608887, 14.67677116394043, 15.008094787597656, 15.3394193649292, 15.670743942260742, 16.00206756591797, 16.333391189575195, 16.664716720581055, 16.99604034423828, 17.327363967895508, 17.658689498901367, 17.990013122558594, 18.32133674621582, 18.65266227722168, 18.983985900878906, 19.315309524536133, 19.646635055541992, 19.97795867919922, 20.309282302856445, 20.640607833862305, 20.97193145751953]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.19176790118217468, -0.17972548305988312, -0.16768306493759155, -0.1556406468153, -0.14359822869300842, -0.13155581057071686, -0.11951339244842529, -0.10747097432613373, -0.09542855620384216, -0.0833861380815506, -0.07134371995925903, -0.05930130183696747, -0.0472588837146759, -0.03521646559238434, -0.023174047470092773, -0.011131629347801208, 0.0009107887744903564, 0.012953206896781921, 0.024995625019073486, 0.03703804314136505, 0.049080461263656616, 0.06112286448478699, 0.07316529750823975, 0.0852077305316925, 0.09725013375282288, 0.10929253697395325, 0.121334969997406, 0.13337740302085876, 0.14541980624198914, 0.1574622094631195, 0.16950464248657227, 0.18154707551002502, 0.1935894787311554, 0.20563188195228577, 0.21767431497573853, 0.22971674799919128, 0.24175915122032166, 0.253801554441452, 0.2658439874649048, 0.27788642048835754, 0.2899288237094879, 0.3019712269306183, 0.31401363015174866, 0.3260560929775238, 0.3380984961986542, 0.35014089941978455, 0.3621833622455597, 0.37422576546669006, 0.38626816868782043, 0.3983105719089508, 0.4103529751300812, 0.4223954379558563, 0.4344378411769867, 0.44648024439811707, 0.4585227072238922, 0.4705651104450226, 0.48260751366615295, 0.4946499168872833, 0.5066922903060913, 0.5187348127365112, 0.5307772159576416, 0.542819619178772, 0.5548620223999023, 0.5669044256210327, 0.5789468288421631]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 4.0, 3.0, 4.0, 1.0, 0.0, 0.0, 1.0, 5.0, 12.0, 9.0, 37.0, 14.0, 15.0, 0.0, 0.0, 0.0, 254.0, 34.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 4.0, 4.0, 7.0, 4.0, 8.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0], "bins": [-1.1689854860305786, -1.102933406829834, -1.0368812084197998, -0.9708290696144104, -0.904776930809021, -0.8387247920036316, -0.7726726531982422, -0.7066205143928528, -0.6405683755874634, -0.574516236782074, -0.5084640979766846, -0.44241195917129517, -0.37635982036590576, -0.31030768156051636, -0.24425554275512695, -0.17820340394973755, -0.11215126514434814, -0.046099066734313965, 0.019953012466430664, 0.08600509166717529, 0.15205729007720947, 0.21810948848724365, 0.2841615676879883, 0.3502136468887329, 0.4162658452987671, 0.48231804370880127, 0.5483701229095459, 0.6144222021102905, 0.6804744005203247, 0.7465265989303589, 0.8125786781311035, 0.8786307573318481, 0.9446829557418823, 1.0107351541519165, 1.0767873525619507, 1.1428393125534058, 1.20889151096344, 1.2749437093734741, 1.3409956693649292, 1.4070478677749634, 1.4731000661849976, 1.5391522645950317, 1.605204463005066, 1.671256422996521, 1.7373086214065552, 1.8033608198165894, 1.8694127798080444, 1.9354649782180786, 2.0015172958374023, 2.0675692558288574, 2.1336216926574707, 2.199673652648926, 2.265725612640381, 2.331778049468994, 2.397830009460449, 2.4638819694519043, 2.5299344062805176, 2.5959863662719727, 2.662038803100586, 2.728090763092041, 2.794142723083496, 2.8601951599121094, 2.9262471199035645, 2.9922995567321777, 3.058351516723633]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15313245356082916, -0.11486706882715225, -0.07660168409347534, -0.03833629935979843, -7.0914626121521e-05, 0.03819446265697479, 0.0764598548412323, 0.11472524702548981, 0.15299062430858612, 0.19125600159168243, 0.22952137887477875, 0.26778680086135864, 0.30605214834213257, 0.34431755542755127, 0.38258296251296997, 0.4208483099937439, 0.4591137170791626, 0.4973791241645813, 0.5356444716453552, 0.5739098787307739, 0.6121752262115479, 0.6504406332969666, 0.6887060403823853, 0.7269713878631592, 0.7652367949485779, 0.8035022020339966, 0.8417675495147705, 0.8800328969955444, 0.9182983636856079, 0.9565637111663818, 0.9948290586471558, 1.0330945253372192, 1.0713598728179932, 1.109625220298767, 1.1478906869888306, 1.1861560344696045, 1.2244213819503784, 1.262686848640442, 1.3009521961212158, 1.3392175436019897, 1.3774828910827637, 1.4157483577728271, 1.454013705253601, 1.492279052734375, 1.5305445194244385, 1.5688098669052124, 1.6070752143859863, 1.6453406810760498, 1.6836060285568237, 1.7218713760375977, 1.7601368427276611, 1.798402190208435, 1.836667537689209, 1.8749330043792725, 1.9131982326507568, 1.9514636993408203, 1.9897291660308838, 2.027994394302368, 2.0662598609924316, 2.104525327682495, 2.1427905559539795, 2.181056022644043, 2.2193214893341064, 2.257586717605591, 2.2958521842956543]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 1.0, 2.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0], "bins": [-1.3268468379974365, -1.3007344007492065, -1.2746219635009766, -1.2485096454620361, -1.2223972082138062, -1.1962847709655762, -1.1701723337173462, -1.1440598964691162, -1.1179475784301758, -1.0918351411819458, -1.0657227039337158, -1.0396102666854858, -1.0134978294372559, -0.9873854517936707, -0.9612730145454407, -0.9351606369018555, -0.9090481996536255, -0.8829357624053955, -0.8568233847618103, -0.8307109475135803, -0.8045985698699951, -0.7784861326217651, -0.7523736953735352, -0.72626131772995, -0.70014888048172, -0.67403644323349, -0.6479240655899048, -0.6218116283416748, -0.5956991910934448, -0.5695868134498596, -0.5434743762016296, -0.5173619985580444, -0.49124956130981445, -0.4651371240615845, -0.43902474641799927, -0.4129123091697693, -0.3867999315261841, -0.3606874942779541, -0.3345750570297241, -0.30846261978149414, -0.2823503017425537, -0.25623786449432373, -0.23012542724609375, -0.20401298999786377, -0.1779005527496338, -0.1517881155014038, -0.12567579746246338, -0.0995633602142334, -0.07345092296600342, -0.04733848571777344, -0.021226048469543457, 0.004886269569396973, 0.030998706817626953, 0.057111144065856934, 0.08322358131408691, 0.1093360185623169, 0.13544845581054688, 0.1615607738494873, 0.18767321109771729, 0.21378564834594727, 0.23989808559417725, 0.2660105228424072, 0.29212284088134766, 0.31823527812957764, 0.3443477153778076]}, "_runtime": 8514.47276210785, "_timestamp": 1585578430.3173954, "_step": 198}
{"Episode reward": 8.427839806211182, "Episode length": 917, "Policy Loss": -0.12292005121707916, "Value Loss": 10.690500259399414, "_runtime": 8515.989988803864, "_timestamp": 1585578431.8346221, "_step": 199}
{"Episode reward": -99.78828023224929, "Episode length": 999, "Policy Loss": -0.942438006401062, "Value Loss": 0.04794464260339737, "_runtime": 8517.53111577034, "_timestamp": 1585578433.375749, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9186586737632751, "Value Loss": 0.02893402799963951, "_runtime": 8518.820653676987, "_timestamp": 1585578434.665287, "_step": 201}
{"Episode reward": 17.489167207386757, "Episode length": 826, "Policy Loss": -0.0054399603977799416, "Value Loss": 11.878281593322754, "_runtime": 8520.342621088028, "_timestamp": 1585578436.1872544, "_step": 202}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": -0.23352926969528198, "Value Loss": 10.171895027160645, "_runtime": 8521.928078174591, "_timestamp": 1585578437.7727115, "_step": 203}
{"Episode reward": -99.85661680698254, "Episode length": 999, "Policy Loss": -0.9273091554641724, "Value Loss": 0.06481081247329712, "_runtime": 8523.484709739685, "_timestamp": 1585578439.329343, "_step": 204}
{"Episode reward": -99.80816276706615, "Episode length": 999, "Policy Loss": -0.9130786657333374, "Value Loss": 0.028357461094856262, "_runtime": 8525.04306602478, "_timestamp": 1585578440.8876994, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9120885133743286, "Value Loss": 0.0206036064773798, "_runtime": 8526.264610767365, "_timestamp": 1585578442.109244, "_step": 206}
{"Episode reward": 23.100000000000094, "Episode length": 769, "Policy Loss": 0.02547992765903473, "Value Loss": 12.737685203552246, "_runtime": 8527.824832677841, "_timestamp": 1585578443.669466, "_step": 207}
{"Episode reward": -99.80485214628139, "Episode length": 999, "Policy Loss": -0.9006693959236145, "Value Loss": 0.07433749735355377, "_runtime": 8528.523228883743, "_timestamp": 1585578444.3678622, "_step": 208}
{"Episode reward": 57.39999999999967, "Episode length": 426, "Policy Loss": 0.9884807467460632, "Value Loss": 22.873939514160156, "_runtime": 8530.090149402618, "_timestamp": 1585578445.9347827, "_step": 209}
{"Episode reward": -99.8936053887927, "Episode length": 999, "Policy Loss": -0.9304724931716919, "Value Loss": 0.09529327601194382, "_runtime": 8531.66666507721, "_timestamp": 1585578447.5112984, "_step": 210}
{"Episode reward": -99.80093469619611, "Episode length": 999, "Policy Loss": -0.8844064474105835, "Value Loss": 0.04184519127011299, "_runtime": 8533.191500902176, "_timestamp": 1585578449.0361342, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9337815046310425, "Value Loss": 0.08746645599603653, "_runtime": 8534.810147047043, "_timestamp": 1585578450.6547804, "_step": 212}
{"Episode reward": -99.86475219726422, "Episode length": 999, "Policy Loss": -0.8670041561126709, "Value Loss": 0.08169299364089966, "_runtime": 8536.390150308609, "_timestamp": 1585578452.2347836, "_step": 213}
{"Episode reward": -99.81589957214752, "Episode length": 999, "Policy Loss": -0.874689519405365, "Value Loss": 0.03238429129123688, "_runtime": 8537.947887659073, "_timestamp": 1585578453.792521, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8513174057006836, "Value Loss": 0.026180652901530266, "_runtime": 8539.538764238358, "_timestamp": 1585578455.3833976, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.860336184501648, "Value Loss": 0.10566382110118866, "_runtime": 8540.751216888428, "_timestamp": 1585578456.5958502, "_step": 216}
{"Episode reward": 23.300000000000082, "Episode length": 767, "Policy Loss": 0.46381062269210815, "Value Loss": 12.73557186126709, "_runtime": 8542.317111253738, "_timestamp": 1585578458.1617446, "_step": 217}
{"Episode reward": -99.8840538892881, "Episode length": 999, "Policy Loss": -0.8066875338554382, "Value Loss": 0.025221752002835274, "_runtime": 8543.311907052994, "_timestamp": 1585578459.1565404, "_step": 218}
{"Episode reward": 37.46418405799134, "Episode length": 627, "Policy Loss": 0.3793695271015167, "Value Loss": 15.602400779724121, "_runtime": 8544.13093996048, "_timestamp": 1585578459.9755733, "_step": 219}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 0.6151406168937683, "Value Loss": 18.792043685913086, "_runtime": 8545.403618574142, "_timestamp": 1585578461.248252, "_step": 220}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": 0.13717077672481537, "Value Loss": 11.998344421386719, "_runtime": 8546.932206392288, "_timestamp": 1585578462.7768397, "_step": 221}
{"Episode reward": -99.80053465515235, "Episode length": 999, "Policy Loss": -0.8222569823265076, "Value Loss": 0.0361909456551075, "_runtime": 8547.940922260284, "_timestamp": 1585578463.7855556, "_step": 222}
{"Episode reward": 33.89999999999948, "Episode length": 661, "Policy Loss": 0.43297913670539856, "Value Loss": 14.832216262817383, "_runtime": 8549.261557340622, "_timestamp": 1585578465.1061907, "_step": 223}
{"Episode reward": 14.800000000000566, "Episode length": 852, "Policy Loss": 0.09466733038425446, "Value Loss": 11.515536308288574, "_runtime": 8550.810098409653, "_timestamp": 1585578466.6547318, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8110119104385376, "Value Loss": 0.019901765510439873, "_runtime": 8552.336438417435, "_timestamp": 1585578468.1810718, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8361419439315796, "Value Loss": 0.07732478529214859, "_runtime": 8552.826622962952, "_timestamp": 1585578468.6712563, "_step": 226}
{"Episode reward": 70.99786137938486, "Episode length": 291, "Policy Loss": 1.8121247291564941, "Value Loss": 33.531089782714844, "_runtime": 8553.64357829094, "_timestamp": 1585578469.4882116, "_step": 227}
{"Episode reward": 48.19999999999954, "Episode length": 518, "Policy Loss": 0.6100919842720032, "Value Loss": 18.90547752380371, "_runtime": 8555.196833848953, "_timestamp": 1585578471.0414672, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.818045437335968, "Value Loss": 0.053666289895772934, "_runtime": 8555.81927371025, "_timestamp": 1585578471.663907, "_step": 229}
{"Episode reward": 59.00957364439934, "Episode length": 410, "Policy Loss": 0.9148926734924316, "Value Loss": 24.020654678344727, "_runtime": 8557.366607189178, "_timestamp": 1585578473.2112405, "_step": 230}
{"Episode reward": -99.84728241115668, "Episode length": 999, "Policy Loss": -0.81670081615448, "Value Loss": 0.04135396331548691, "_runtime": 8558.917028903961, "_timestamp": 1585578474.7616622, "_step": 231}
{"Episode reward": -99.79224080713327, "Episode length": 999, "Policy Loss": -0.8478703498840332, "Value Loss": 0.06829997897148132, "_runtime": 8560.417338371277, "_timestamp": 1585578476.2619717, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8362039923667908, "Value Loss": 0.028913365676999092, "_runtime": 8561.529440879822, "_timestamp": 1585578477.3740742, "_step": 233}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.24952693283557892, "Value Loss": 13.88083267211914, "_runtime": 8563.089828252792, "_timestamp": 1585578478.9344616, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8004603385925293, "Value Loss": 0.03582688048481941, "_runtime": 8563.987117052078, "_timestamp": 1585578479.8317504, "_step": 235}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.43183284997940063, "Value Loss": 16.88676643371582, "_runtime": 8565.521389007568, "_timestamp": 1585578481.3660223, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8713090419769287, "Value Loss": 0.03843190148472786, "_runtime": 8567.084843158722, "_timestamp": 1585578482.9294765, "_step": 237}
{"Episode reward": -99.80208981046313, "Episode length": 999, "Policy Loss": -0.841224730014801, "Value Loss": 0.034506164491176605, "_runtime": 8568.032555103302, "_timestamp": 1585578483.8771884, "_step": 238}
{"Episode reward": 37.79999999999939, "Episode length": 622, "Policy Loss": 0.528433084487915, "Value Loss": 15.675968170166016, "_runtime": 8569.492039680481, "_timestamp": 1585578485.336673, "_step": 239}
{"Episode reward": 6.008875823021995, "Episode length": 940, "Policy Loss": -0.05796860530972481, "Value Loss": 10.432191848754883, "_runtime": 8571.05606675148, "_timestamp": 1585578486.9007, "_step": 240}
{"Episode reward": -99.83641574419894, "Episode length": 999, "Policy Loss": -0.8354926109313965, "Value Loss": 0.01578066498041153, "_runtime": 8572.5775847435, "_timestamp": 1585578488.422218, "_step": 241}
{"Episode reward": -99.81679779030243, "Episode length": 999, "Policy Loss": -0.8491132259368896, "Value Loss": 0.03378027677536011, "_runtime": 8574.128638744354, "_timestamp": 1585578489.973272, "_step": 242}
{"Episode reward": -99.80285012870887, "Episode length": 999, "Policy Loss": -0.8930081725120544, "Value Loss": 0.14181648194789886, "_runtime": 8574.771695137024, "_timestamp": 1585578490.6163285, "_step": 243}
{"Episode reward": 61.37381985811489, "Episode length": 388, "Policy Loss": 1.070794939994812, "Value Loss": 25.056350708007812, "_runtime": 8576.314964294434, "_timestamp": 1585578492.1595976, "_step": 244}
{"Episode reward": -99.81296663659019, "Episode length": 999, "Policy Loss": -0.8120428323745728, "Value Loss": 0.03746863827109337, "_runtime": 8577.883504390717, "_timestamp": 1585578493.7281377, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8613959550857544, "Value Loss": 0.06799905747175217, "_runtime": 8579.37924361229, "_timestamp": 1585578495.223877, "_step": 246}
{"Episode reward": -99.70086467275256, "Episode length": 999, "Policy Loss": -0.8333383798599243, "Value Loss": 0.05243151634931564, "_runtime": 8580.975760698318, "_timestamp": 1585578496.820394, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8310708403587341, "Value Loss": 0.020131420344114304, "_runtime": 8582.53563952446, "_timestamp": 1585578498.3802729, "_step": 248}
{"Episode reward": -99.80211370140174, "Episode length": 999, "Policy Loss": -0.8438759446144104, "Value Loss": 0.04125117138028145, "_runtime": 8584.091421365738, "_timestamp": 1585578499.9360547, "_step": 249}
{"Episode reward": -99.75859994776408, "Episode length": 999, "Policy Loss": -0.8086614608764648, "Value Loss": 0.01997196301817894, "_runtime": 8585.575528383255, "_timestamp": 1585578501.4201617, "_step": 250}
{"Episode reward": 5.952145086229919, "Episode length": 941, "Policy Loss": 0.1017531231045723, "Value Loss": 10.352184295654297, "_runtime": 8587.146934986115, "_timestamp": 1585578502.9915683, "_step": 251}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7976807355880737, "Value Loss": 0.023318815976381302, "_runtime": 8588.708554983139, "_timestamp": 1585578504.5531883, "_step": 252}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8077959418296814, "Value Loss": 0.023744815960526466, "_runtime": 8590.276247501373, "_timestamp": 1585578506.1208808, "_step": 253}
{"Episode reward": -99.87987672425666, "Episode length": 999, "Policy Loss": -0.7867741584777832, "Value Loss": 0.027474375441670418, "_runtime": 8591.838188886642, "_timestamp": 1585578507.6828222, "_step": 254}
{"Episode reward": -99.73665126347775, "Episode length": 999, "Policy Loss": -0.8611548542976379, "Value Loss": 0.15885311365127563, "_runtime": 8593.403635978699, "_timestamp": 1585578509.2482693, "_step": 255}
{"Episode reward": -99.82445186460251, "Episode length": 999, "Policy Loss": -0.7697705626487732, "Value Loss": 0.04021597281098366, "_runtime": 8594.657570838928, "_timestamp": 1585578510.5022042, "_step": 256}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.20113146305084229, "Value Loss": 12.285489082336426, "_runtime": 8596.217157125473, "_timestamp": 1585578512.0617905, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7674039006233215, "Value Loss": 0.030352691188454628, "_runtime": 8597.787148952484, "_timestamp": 1585578513.6317823, "_step": 258}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7470830082893372, "Value Loss": 0.017004862427711487, "_runtime": 8599.327850580215, "_timestamp": 1585578515.172484, "_step": 259}
{"Episode reward": -99.81140875965217, "Episode length": 999, "Policy Loss": -0.732101321220398, "Value Loss": 0.01766296662390232, "_runtime": 8600.890059947968, "_timestamp": 1585578516.7346933, "_step": 260}
{"Episode reward": -99.80986122526089, "Episode length": 999, "Policy Loss": -0.7125077843666077, "Value Loss": 0.010477370582520962, "_runtime": 8602.445510864258, "_timestamp": 1585578518.2901442, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7152958512306213, "Value Loss": 0.014972470700740814, "_runtime": 8604.049673557281, "_timestamp": 1585578519.894307, "_step": 262}
{"Episode reward": -99.81697335392097, "Episode length": 999, "Policy Loss": -0.6867488622665405, "Value Loss": 0.02184058167040348, "_runtime": 8604.444880247116, "_timestamp": 1585578520.2895136, "_step": 263}
{"Episode reward": 78.29999999999997, "Episode length": 217, "Policy Loss": 3.0820207595825195, "Value Loss": 44.9525260925293, "_runtime": 8606.002841949463, "_timestamp": 1585578521.8474753, "_step": 264}
{"Episode reward": -99.80021178871253, "Episode length": 999, "Policy Loss": -0.6834745407104492, "Value Loss": 0.03448313847184181, "_runtime": 8607.10021352768, "_timestamp": 1585578522.9448469, "_step": 265}
{"Episode reward": 30.799999999999656, "Episode length": 692, "Policy Loss": 0.3952600657939911, "Value Loss": 14.100665092468262, "_runtime": 8608.589593172073, "_timestamp": 1585578524.4342265, "_step": 266}
{"Episode reward": -99.76372944787005, "Episode length": 999, "Policy Loss": -0.6986056566238403, "Value Loss": 0.016428904607892036, "_runtime": 8610.155142068863, "_timestamp": 1585578525.9997754, "_step": 267}
{"Episode reward": -99.81724094487586, "Episode length": 999, "Policy Loss": -0.6937277913093567, "Value Loss": 0.02264612540602684, "_runtime": 8611.607965946198, "_timestamp": 1585578527.4525993, "_step": 268}
{"Episode reward": 5.427054701164522, "Episode length": 946, "Policy Loss": 0.07555101811885834, "Value Loss": 10.332013130187988, "_runtime": 8613.155813455582, "_timestamp": 1585578529.0004468, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6965912580490112, "Value Loss": 0.013741386123001575, "_runtime": 8614.723814487457, "_timestamp": 1585578530.5684478, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.716293215751648, "Value Loss": 0.04258524253964424, "_runtime": 8616.287892341614, "_timestamp": 1585578532.1325257, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6929086446762085, "Value Loss": 0.01583997532725334, "_runtime": 8617.833854913712, "_timestamp": 1585578533.6784883, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7034677863121033, "Value Loss": 0.07978934794664383, "_runtime": 8618.422864437103, "_timestamp": 1585578534.2674978, "_step": 273}
{"Episode reward": 65.31651322734447, "Episode length": 349, "Policy Loss": 0.9390643835067749, "Value Loss": 28.3251895904541, "_runtime": 8619.986074447632, "_timestamp": 1585578535.8307078, "_step": 274}
{"Episode reward": -99.66386795267324, "Episode length": 999, "Policy Loss": -0.7209447026252747, "Value Loss": 0.08575300127267838, "_runtime": 8621.539139270782, "_timestamp": 1585578537.3837726, "_step": 275}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6532167792320251, "Value Loss": 0.026194311678409576, "_runtime": 8623.041379213333, "_timestamp": 1585578538.8860126, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6718587875366211, "Value Loss": 0.06072254851460457, "_runtime": 8624.610463380814, "_timestamp": 1585578540.4550967, "_step": 277}
{"Episode reward": -99.75370679274062, "Episode length": 999, "Policy Loss": -0.6500308513641357, "Value Loss": 0.01343142706900835, "_runtime": 8626.171904087067, "_timestamp": 1585578542.0165374, "_step": 278}
{"Episode reward": -99.7960847683237, "Episode length": 999, "Policy Loss": -0.6428889036178589, "Value Loss": 0.012443718500435352, "_runtime": 8626.902646064758, "_timestamp": 1585578542.7472794, "_step": 279}
{"Episode reward": 54.39999999999963, "Episode length": 456, "Policy Loss": 1.1324374675750732, "Value Loss": 21.34992218017578, "_runtime": 8628.509942054749, "_timestamp": 1585578544.3545754, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6266980767250061, "Value Loss": 0.009849916212260723, "_runtime": 8629.553889513016, "_timestamp": 1585578545.3985229, "_step": 281}
{"Episode reward": 33.699723515565935, "Episode length": 664, "Policy Loss": 0.5154628753662109, "Value Loss": 14.781842231750488, "_runtime": 8630.157262086868, "_timestamp": 1585578546.0018954, "_step": 282}
{"Episode reward": 60.09999999999971, "Episode length": 399, "Policy Loss": 1.472711443901062, "Value Loss": 24.52301597595215, "_runtime": 8631.708270549774, "_timestamp": 1585578547.552904, "_step": 283}
{"Episode reward": -99.80072495080391, "Episode length": 999, "Policy Loss": -0.6232721209526062, "Value Loss": 0.01647130586206913, "_runtime": 8633.225054264069, "_timestamp": 1585578549.0696876, "_step": 284}
{"Episode reward": -99.80169409671659, "Episode length": 999, "Policy Loss": -0.6304400563240051, "Value Loss": 0.049390535801649094, "_runtime": 8634.718072652817, "_timestamp": 1585578550.562706, "_step": 285}
{"Episode reward": -99.82033908702293, "Episode length": 999, "Policy Loss": -0.6187176704406738, "Value Loss": 0.019666211679577827, "_runtime": 8635.646394014359, "_timestamp": 1585578551.4910274, "_step": 286}
{"Episode reward": 41.08908065408412, "Episode length": 590, "Policy Loss": 0.6341461539268494, "Value Loss": 16.51478385925293, "_runtime": 8636.698617458344, "_timestamp": 1585578552.5432508, "_step": 287}
{"Episode reward": 32.06531635485548, "Episode length": 680, "Policy Loss": 0.6681121587753296, "Value Loss": 14.432001113891602, "_runtime": 8638.231219053268, "_timestamp": 1585578554.0758524, "_step": 288}
{"Episode reward": -99.82898649908462, "Episode length": 999, "Policy Loss": -0.622177004814148, "Value Loss": 0.014322306029498577, "_runtime": 8639.675858259201, "_timestamp": 1585578555.5204916, "_step": 289}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 0.13326086103916168, "Value Loss": 10.335723876953125, "_runtime": 8641.194249868393, "_timestamp": 1585578557.0388832, "_step": 290}
{"Episode reward": -99.88292734622816, "Episode length": 999, "Policy Loss": -0.5987260341644287, "Value Loss": 0.03539049252867699, "_runtime": 8642.509892940521, "_timestamp": 1585578558.3545263, "_step": 291}
{"Episode reward": 14.400000000000588, "Episode length": 856, "Policy Loss": 0.3108808994293213, "Value Loss": 11.39388656616211, "_runtime": 8644.05296254158, "_timestamp": 1585578559.897596, "_step": 292}
{"Episode reward": -99.84415466226497, "Episode length": 999, "Policy Loss": -0.6927956938743591, "Value Loss": 0.1808016002178192, "_runtime": 8645.605230093002, "_timestamp": 1585578561.4498634, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6238493323326111, "Value Loss": 0.025447692722082138, "_runtime": 8647.136624574661, "_timestamp": 1585578562.981258, "_step": 294}
{"Episode reward": -99.83201940692821, "Episode length": 999, "Policy Loss": -0.6098377108573914, "Value Loss": 0.025598708540201187, "_runtime": 8648.695411205292, "_timestamp": 1585578564.5400445, "_step": 295}
{"Episode reward": -99.75419179145108, "Episode length": 999, "Policy Loss": -0.6098426580429077, "Value Loss": 0.03196406364440918, "_runtime": 8650.241007328033, "_timestamp": 1585578566.0856407, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6110151410102844, "Value Loss": 0.02258765511214733, "_runtime": 8651.831735610962, "_timestamp": 1585578567.676369, "_step": 297}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5995152592658997, "Value Loss": 0.013583309017121792, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137, -0.007908685132861137]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.48339173197746277, -0.47571516036987305, -0.4680385887622833, -0.4603620171546936, -0.4526854455471039, -0.44500887393951416, -0.4373323321342468, -0.4296557605266571, -0.4219791889190674, -0.41430261731147766, -0.40662604570388794, -0.3989494740962982, -0.3912729024887085, -0.3835963308811188, -0.37591975927352905, -0.3682432174682617, -0.3605666160583496, -0.3528900742530823, -0.34521347284317017, -0.33753693103790283, -0.3298603594303131, -0.3221837878227234, -0.31450721621513367, -0.30683064460754395, -0.2991540729999542, -0.2914775013923645, -0.28380095958709717, -0.27612435817718506, -0.2684478163719177, -0.2607712149620056, -0.2530946731567383, -0.24541810154914856, -0.23774152994155884, -0.23006495833396912, -0.2223883867263794, -0.21471181511878967, -0.20703524351119995, -0.19935867190361023, -0.1916821300983429, -0.18400555849075317, -0.17632898688316345, -0.16865241527557373, -0.160975843667984, -0.1532992720603943, -0.14562270045280457, -0.13794612884521484, -0.13026955723762512, -0.1225929856300354, -0.11491641402244568, -0.10723987221717834, -0.09956330060958862, -0.0918867290019989, -0.08421015739440918, -0.07653358578681946, -0.06885701417922974, -0.061180442571640015, -0.05350387096405029, -0.04582729935646057, -0.03815072774887085, -0.030474185943603516, -0.022797614336013794, -0.015121042728424072, -0.007444471120834351, 0.0002321004867553711, 0.007908672094345093]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0], "bins": [-0.025153832510113716, -0.02476080320775509, -0.02436777576804161, -0.023974746465682983, -0.023581717163324356, -0.023188689723610878, -0.02279566042125225, -0.022402632981538773, -0.022009603679180145, -0.021616574376821518, -0.02122354507446289, -0.020830517634749413, -0.020437488332390785, -0.020044460892677307, -0.01965143159031868, -0.019258402287960052, -0.018865374848246574, -0.018472345545887947, -0.01807931810617447, -0.01768628880381584, -0.017293259501457214, -0.016900230199098587, -0.01650720275938511, -0.01611417531967163, -0.015721146017313004, -0.015328116714954376, -0.014935088343918324, -0.014542059041559696, -0.014149030670523643, -0.01375600229948759, -0.013362973928451538, -0.01296994462609291, -0.012576916255056858, -0.012183887884020805, -0.011790858581662178, -0.011397830210626125, -0.011004801839590073, -0.01061177346855402, -0.010218744166195393, -0.00982571579515934, -0.009432686492800713, -0.009039659053087234, -0.008646629750728607, -0.00825360044836998, -0.007860573008656502, -0.0074675437062978745, -0.007074516266584396, -0.006681486964225769, -0.006288457661867142, -0.005895430222153664, -0.005502400919795036, -0.005109371617436409, -0.004716344177722931, -0.004323314875364304, -0.003930285573005676, -0.003537258133292198, -0.003144228830933571, -0.0027511995285749435, -0.0023581720888614655, -0.001965142786502838, -0.00157211534678936, -0.0011790860444307327, -0.0007860567420721054, -0.0003930293023586273, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 2.0, 6.0, 1.0, 1.0, 3.0, 3.0, 3.0, 5.0, 6.0, 2.0, 5.0, 3.0, 6.0, 4.0, 0.0, 2.0, 3.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 10.0, 22.0, 305.0, 3.0, 8.0, 2.0, 2.0, 0.0, 10.0, 19.0, 19.0, 12.0, 4.0, 7.0, 1.0, 4.0], "bins": [-0.08963263034820557, -0.08785136044025421, -0.08607008308172226, -0.0842888131737709, -0.08250754326581955, -0.0807262659072876, -0.07894499599933624, -0.07716372609138489, -0.07538245618343353, -0.07360117882490158, -0.07181990891695023, -0.07003863155841827, -0.06825736165046692, -0.06647609174251556, -0.06469482183456421, -0.06291354447603226, -0.0611322745680809, -0.05935100466012955, -0.057569731026887894, -0.05578845739364624, -0.054007187485694885, -0.05222591385245323, -0.05044464021921158, -0.04866337031126022, -0.04688209667801857, -0.045100823044776917, -0.04331955313682556, -0.04153827950358391, -0.039757005870342255, -0.0379757359623909, -0.036194462329149246, -0.03441319242119789, -0.03263191878795624, -0.030850645154714584, -0.02906937524676323, -0.027288101613521576, -0.02550683170557022, -0.02372555434703827, -0.021944284439086914, -0.02016301453113556, -0.018381744623184204, -0.016600467264652252, -0.014819197356700897, -0.013037927448749542, -0.01125665009021759, -0.009475380182266235, -0.00769411027431488, -0.0059128329157829285, -0.0041315630078315735, -0.0023502930998802185, -0.0005690157413482666, 0.0012122541666030884, 0.0029935240745544434, 0.004774801433086395, 0.00655607134103775, 0.008337341248989105, 0.010118618607521057, 0.011899888515472412, 0.013681158423423767, 0.015462428331375122, 0.017243705689907074, 0.01902497559785843, 0.020806245505809784, 0.022587522864341736, 0.02436879277229309]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.1107189804315567, -0.10814006626605988, -0.10556115210056305, -0.10298224538564682, -0.10040333122015, -0.09782441705465317, -0.09524550288915634, -0.09266659617424011, -0.09008768200874329, -0.08750876784324646, -0.08492985367774963, -0.08235093951225281, -0.07977202534675598, -0.07719311863183975, -0.07461420446634293, -0.0720352977514267, -0.06945638358592987, -0.06687746942043304, -0.06429855525493622, -0.06171964108943939, -0.059140730649232864, -0.05656181648373604, -0.05398290604352951, -0.051403991878032684, -0.04882507771253586, -0.04624616354703903, -0.0436672568321228, -0.04108834266662598, -0.03850942850112915, -0.035930514335632324, -0.033351607620716095, -0.03077269345521927, -0.028193779289722443, -0.025614865124225616, -0.02303595095872879, -0.02045704424381256, -0.017878130078315735, -0.015299215912818909, -0.012720301747322083, -0.010141395032405853, -0.007562480866909027, -0.004983566701412201, -0.0024046525359153748, 0.00017426162958145142, 0.0027531683444976807, 0.005332082509994507, 0.007910996675491333, 0.01048991084098816, 0.013068825006484985, 0.01564773917198181, 0.018226653337478638, 0.02080555260181427, 0.023384466767311096, 0.025963380932807922, 0.02854229509830475, 0.031121209263801575, 0.0337001234292984, 0.03627903759479523, 0.03885795176029205, 0.04143686592578888, 0.04401576519012451, 0.04659467935562134, 0.049173593521118164, 0.05175250768661499, 0.054331421852111816]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 3.0, 2.0, 0.0, 0.0, 2.0, 2.0, 7.0, 4.0, 7.0], "bins": [-0.05129001662135124, -0.050463952124118805, -0.04963788762688637, -0.04881182685494423, -0.04798576235771179, -0.047159697860479355, -0.04633363336324692, -0.04550756886601448, -0.04468150809407234, -0.043855443596839905, -0.04302937909960747, -0.04220331460237503, -0.04137725383043289, -0.040551189333200455, -0.03972512483596802, -0.03889906033873558, -0.03807299584150314, -0.037246935069561005, -0.03642087057232857, -0.03559480607509613, -0.03476874157786369, -0.033942677080631256, -0.03311661630868912, -0.03229054808616638, -0.03146448731422424, -0.030638422816991806, -0.029812360182404518, -0.02898629568517208, -0.028160231187939644, -0.027334168553352356, -0.02650810405611992, -0.02568204142153263, -0.024855976924300194, -0.024029912427067757, -0.02320384979248047, -0.02237778529524803, -0.021551722660660744, -0.020725658163428307, -0.01989959552884102, -0.01907353103160858, -0.018247466534376144, -0.017421402037143707, -0.01659534126520157, -0.01576927676796913, -0.014943212270736694, -0.014117147773504257, -0.01329108327627182, -0.012465022504329681, -0.011638958007097244, -0.010812893509864807, -0.00998682901263237, -0.009160764515399933, -0.008334703743457794, -0.007508639246225357, -0.00668257474899292, -0.005856510251760483, -0.005030445754528046, -0.004204384982585907, -0.00337832048535347, -0.0025522559881210327, -0.0017261914908885956, -0.0009001269936561584, -7.406622171401978e-05, 0.0007519982755184174, 0.0015780627727508545]}, "_runtime": 8653.393606901169, "_timestamp": 1585578569.2382402, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5944541096687317, "Value Loss": 0.017649397253990173, "_runtime": 8654.945902347565, "_timestamp": 1585578570.7905357, "_step": 299}
{"Episode reward": -99.80924257971206, "Episode length": 999, "Policy Loss": -0.5966466665267944, "Value Loss": 0.016980869695544243, "_runtime": 8656.489693164825, "_timestamp": 1585578572.3343265, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6144737601280212, "Value Loss": 0.07631043344736099, "_runtime": 8657.3812084198, "_timestamp": 1585578573.2258418, "_step": 301}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.8714133501052856, "Value Loss": 17.27071762084961, "_runtime": 8658.937636137009, "_timestamp": 1585578574.7822695, "_step": 302}
{"Episode reward": -99.80441861748555, "Episode length": 999, "Policy Loss": -0.5775743722915649, "Value Loss": 0.0259194765239954, "_runtime": 8660.490888357162, "_timestamp": 1585578576.3355217, "_step": 303}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5691577196121216, "Value Loss": 0.01222104113548994, "_runtime": 8662.006729364395, "_timestamp": 1585578577.8513627, "_step": 304}
{"Episode reward": -99.83409308278793, "Episode length": 999, "Policy Loss": -0.5659149885177612, "Value Loss": 0.0181060042232275, "_runtime": 8663.563376665115, "_timestamp": 1585578579.40801, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5483426451683044, "Value Loss": 0.009297523647546768, "_runtime": 8664.725112915039, "_timestamp": 1585578580.5697463, "_step": 306}
{"Episode reward": 25.90738992057733, "Episode length": 741, "Policy Loss": 0.4072224795818329, "Value Loss": 13.208353042602539, "_runtime": 8665.37816619873, "_timestamp": 1585578581.2227995, "_step": 307}
{"Episode reward": 59.84154998660058, "Episode length": 403, "Policy Loss": 1.3301916122436523, "Value Loss": 24.374658584594727, "_runtime": 8666.890380859375, "_timestamp": 1585578582.7350142, "_step": 308}
{"Episode reward": 2.357157708612604, "Episode length": 978, "Policy Loss": 0.4578859210014343, "Value Loss": 9.957185745239258, "_runtime": 8667.292159557343, "_timestamp": 1585578583.136793, "_step": 309}
{"Episode reward": 76.87039242647583, "Episode length": 232, "Policy Loss": 2.583895206451416, "Value Loss": 42.060306549072266, "_runtime": 8668.61608171463, "_timestamp": 1585578584.460715, "_step": 310}
{"Episode reward": 12.200000000000713, "Episode length": 878, "Policy Loss": 0.3020995855331421, "Value Loss": 11.104316711425781, "_runtime": 8670.167303085327, "_timestamp": 1585578586.0119364, "_step": 311}
{"Episode reward": -99.82030606902997, "Episode length": 999, "Policy Loss": -0.5748925805091858, "Value Loss": 0.09184657782316208, "_runtime": 8671.403136730194, "_timestamp": 1585578587.24777, "_step": 312}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.2135694921016693, "Value Loss": 11.875794410705566, "_runtime": 8672.947031736374, "_timestamp": 1585578588.791665, "_step": 313}
{"Episode reward": -99.80238263644138, "Episode length": 999, "Policy Loss": -0.5715358853340149, "Value Loss": 0.044654641300439835, "_runtime": 8674.538249731064, "_timestamp": 1585578590.382883, "_step": 314}
{"Episode reward": -99.88558282591262, "Episode length": 999, "Policy Loss": -0.5698640942573547, "Value Loss": 0.03846823051571846, "_runtime": 8676.067334651947, "_timestamp": 1585578591.911968, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6214750409126282, "Value Loss": 0.0298463087528944, "_runtime": 8676.905121326447, "_timestamp": 1585578592.7497547, "_step": 316}
{"Episode reward": 47.663657882436645, "Episode length": 524, "Policy Loss": 0.9068283438682556, "Value Loss": 18.523941040039062, "_runtime": 8678.28023481369, "_timestamp": 1585578594.1248682, "_step": 317}
{"Episode reward": 12.60000000000069, "Episode length": 874, "Policy Loss": 0.21752676367759705, "Value Loss": 11.18493366241455, "_runtime": 8679.017191886902, "_timestamp": 1585578594.8618252, "_step": 318}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 0.9785038828849792, "Value Loss": 21.074846267700195, "_runtime": 8680.55719447136, "_timestamp": 1585578596.4018278, "_step": 319}
{"Episode reward": -99.7646094949902, "Episode length": 999, "Policy Loss": -0.6103123426437378, "Value Loss": 0.02335113100707531, "_runtime": 8681.599207162857, "_timestamp": 1585578597.4438405, "_step": 320}
{"Episode reward": 34.29999999999946, "Episode length": 657, "Policy Loss": 0.44079163670539856, "Value Loss": 14.866599082946777, "_runtime": 8683.121638774872, "_timestamp": 1585578598.966272, "_step": 321}
{"Episode reward": -99.80054002404073, "Episode length": 999, "Policy Loss": -0.6789668798446655, "Value Loss": 0.14857865869998932, "_runtime": 8684.68516588211, "_timestamp": 1585578600.5297992, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.670851469039917, "Value Loss": 0.05433579906821251, "_runtime": 8685.086288452148, "_timestamp": 1585578600.9309218, "_step": 323}
{"Episode reward": 76.79999999999995, "Episode length": 232, "Policy Loss": 2.646131992340088, "Value Loss": 41.52181625366211, "_runtime": 8686.64727807045, "_timestamp": 1585578602.4919114, "_step": 324}
{"Episode reward": -99.63055018409948, "Episode length": 999, "Policy Loss": -0.630488932132721, "Value Loss": 0.1362849771976471, "_runtime": 8687.389781475067, "_timestamp": 1585578603.2344148, "_step": 325}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": 0.969186007976532, "Value Loss": 21.137264251708984, "_runtime": 8688.892912864685, "_timestamp": 1585578604.7375462, "_step": 326}
{"Episode reward": -99.8000058207647, "Episode length": 999, "Policy Loss": -0.7293453216552734, "Value Loss": 0.094508096575737, "_runtime": 8689.70967388153, "_timestamp": 1585578605.5543072, "_step": 327}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 0.9167622923851013, "Value Loss": 19.253202438354492, "_runtime": 8691.241406440735, "_timestamp": 1585578607.0860398, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7416683435440063, "Value Loss": 0.09489727765321732, "_runtime": 8692.360660552979, "_timestamp": 1585578608.205294, "_step": 329}
{"Episode reward": 28.199999999999804, "Episode length": 718, "Policy Loss": 0.23430846631526947, "Value Loss": 13.441916465759277, "_runtime": 8693.888119220734, "_timestamp": 1585578609.7327526, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7565274834632874, "Value Loss": 0.0851779654622078, "_runtime": 8695.462033748627, "_timestamp": 1585578611.306667, "_step": 331}
{"Episode reward": -99.86826103934878, "Episode length": 999, "Policy Loss": -0.7575441598892212, "Value Loss": 0.22859536111354828, "_runtime": 8696.822390079498, "_timestamp": 1585578612.6670234, "_step": 332}
{"Episode reward": 11.918211741653053, "Episode length": 882, "Policy Loss": 0.23760893940925598, "Value Loss": 11.135151863098145, "_runtime": 8698.380208492279, "_timestamp": 1585578614.2248418, "_step": 333}
{"Episode reward": -99.83201940692821, "Episode length": 999, "Policy Loss": -0.7524420619010925, "Value Loss": 0.04202448949217796, "_runtime": 8699.952856302261, "_timestamp": 1585578615.7974896, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7958418726921082, "Value Loss": 0.13986250758171082, "_runtime": 8701.545875787735, "_timestamp": 1585578617.3905091, "_step": 335}
{"Episode reward": -99.81727390671008, "Episode length": 999, "Policy Loss": -0.7808848023414612, "Value Loss": 0.08544021099805832, "_runtime": 8702.563880681992, "_timestamp": 1585578618.408514, "_step": 336}
{"Episode reward": 36.24458458861273, "Episode length": 638, "Policy Loss": 0.4178205728530884, "Value Loss": 15.13004207611084, "_runtime": 8702.973095655441, "_timestamp": 1585578618.817729, "_step": 337}
{"Episode reward": 77.29999999999995, "Episode length": 227, "Policy Loss": 2.498995304107666, "Value Loss": 42.68305587768555, "_runtime": 8704.528617620468, "_timestamp": 1585578620.373251, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7397937774658203, "Value Loss": 0.03916747868061066, "_runtime": 8706.071876525879, "_timestamp": 1585578621.9165099, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7778787016868591, "Value Loss": 0.0348588228225708, "_runtime": 8707.576025247574, "_timestamp": 1585578623.4206586, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7727365493774414, "Value Loss": 0.02541465125977993, "_runtime": 8709.15935921669, "_timestamp": 1585578625.0039926, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7774102091789246, "Value Loss": 0.016628820449113846, "_runtime": 8710.600165367126, "_timestamp": 1585578626.4447987, "_step": 342}
{"Episode reward": 8.695034262166345, "Episode length": 914, "Policy Loss": 0.07478079944849014, "Value Loss": 10.553749084472656, "_runtime": 8711.304934740067, "_timestamp": 1585578627.149568, "_step": 343}
{"Episode reward": 55.329132664110155, "Episode length": 447, "Policy Loss": 1.1454148292541504, "Value Loss": 21.573999404907227, "_runtime": 8712.773854732513, "_timestamp": 1585578628.618488, "_step": 344}
{"Episode reward": 7.093889592588951, "Episode length": 930, "Policy Loss": 0.039161425083875656, "Value Loss": 10.474990844726562, "_runtime": 8714.331780910492, "_timestamp": 1585578630.1764143, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.832716703414917, "Value Loss": 0.1748138964176178, "_runtime": 8715.852647781372, "_timestamp": 1585578631.6972811, "_step": 346}
{"Episode reward": -99.85682826079288, "Episode length": 999, "Policy Loss": -0.8784233331680298, "Value Loss": 0.2160286158323288, "_runtime": 8716.811346769333, "_timestamp": 1585578632.65598, "_step": 347}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 0.3945007026195526, "Value Loss": 16.24725914001465, "_runtime": 8717.876135587692, "_timestamp": 1585578633.720769, "_step": 348}
{"Episode reward": 32.99999999999953, "Episode length": 670, "Policy Loss": 0.3028772175312042, "Value Loss": 14.431136131286621, "_runtime": 8719.436476707458, "_timestamp": 1585578635.28111, "_step": 349}
{"Episode reward": -99.64028274342279, "Episode length": 999, "Policy Loss": -0.8044241070747375, "Value Loss": 0.07652441412210464, "_runtime": 8720.807859420776, "_timestamp": 1585578636.6524928, "_step": 350}
{"Episode reward": 11.498239324987694, "Episode length": 886, "Policy Loss": -0.004418904893100262, "Value Loss": 10.990378379821777, "_runtime": 8722.34801363945, "_timestamp": 1585578638.192647, "_step": 351}
{"Episode reward": -99.78632618235285, "Episode length": 999, "Policy Loss": -0.7951401472091675, "Value Loss": 0.033672086894512177, "_runtime": 8723.890800476074, "_timestamp": 1585578639.7354338, "_step": 352}
{"Episode reward": 1.3391935110105493, "Episode length": 987, "Policy Loss": -0.03145136684179306, "Value Loss": 9.921067237854004, "_runtime": 8725.493318796158, "_timestamp": 1585578641.3379521, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7734324336051941, "Value Loss": 0.033657580614089966, "_runtime": 8726.819093704224, "_timestamp": 1585578642.663727, "_step": 354}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": 0.12777051329612732, "Value Loss": 11.436117172241211, "_runtime": 8728.385434627533, "_timestamp": 1585578644.230068, "_step": 355}
{"Episode reward": -99.8331341329948, "Episode length": 999, "Policy Loss": -0.7835926413536072, "Value Loss": 0.029661165550351143, "_runtime": 8729.87382030487, "_timestamp": 1585578645.7184536, "_step": 356}
{"Episode reward": 5.113306897507229, "Episode length": 949, "Policy Loss": 0.005746362265199423, "Value Loss": 10.268136978149414, "_runtime": 8731.432634830475, "_timestamp": 1585578647.2772682, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.775154173374176, "Value Loss": 0.06138774752616882, "_runtime": 8732.993976354599, "_timestamp": 1585578648.8386097, "_step": 358}
{"Episode reward": -99.80155183710018, "Episode length": 999, "Policy Loss": -0.736060619354248, "Value Loss": 0.032259657979011536, "_runtime": 8734.547564268112, "_timestamp": 1585578650.3921976, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7574338912963867, "Value Loss": 0.023799490183591843, "_runtime": 8735.7549700737, "_timestamp": 1585578651.5996034, "_step": 360}
{"Episode reward": 22.997951465100158, "Episode length": 771, "Policy Loss": 0.2763627767562866, "Value Loss": 12.531435012817383, "_runtime": 8737.316686630249, "_timestamp": 1585578653.16132, "_step": 361}
{"Episode reward": -99.80727129131417, "Episode length": 999, "Policy Loss": -0.7487779855728149, "Value Loss": 0.016518626362085342, "_runtime": 8738.465230941772, "_timestamp": 1585578654.3098643, "_step": 362}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.2587575912475586, "Value Loss": 13.333735466003418, "_runtime": 8738.969722032547, "_timestamp": 1585578654.8143554, "_step": 363}
{"Episode reward": 69.59999999999985, "Episode length": 304, "Policy Loss": 1.9413050413131714, "Value Loss": 31.781269073486328, "_runtime": 8740.516575574875, "_timestamp": 1585578656.361209, "_step": 364}
{"Episode reward": -99.80615121135348, "Episode length": 999, "Policy Loss": -0.7466349601745605, "Value Loss": 0.027594557031989098, "_runtime": 8742.065314292908, "_timestamp": 1585578657.9099476, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7796080708503723, "Value Loss": 0.12623563408851624, "_runtime": 8743.559032440186, "_timestamp": 1585578659.4036658, "_step": 366}
{"Episode reward": -99.88890058994153, "Episode length": 999, "Policy Loss": -0.7542744278907776, "Value Loss": 0.021453965455293655, "_runtime": 8745.132407665253, "_timestamp": 1585578660.977041, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7263226509094238, "Value Loss": 0.021096402779221535, "_runtime": 8745.988288402557, "_timestamp": 1585578661.8329217, "_step": 368}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 0.7230839133262634, "Value Loss": 17.889074325561523, "_runtime": 8747.416169166565, "_timestamp": 1585578663.2608025, "_step": 369}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": 0.03764345124363899, "Value Loss": 10.704272270202637, "_runtime": 8748.982007980347, "_timestamp": 1585578664.8266413, "_step": 370}
{"Episode reward": -99.82835900522629, "Episode length": 999, "Policy Loss": -0.7565567493438721, "Value Loss": 0.01939554139971733, "_runtime": 8750.501065969467, "_timestamp": 1585578666.3456993, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7680611610412598, "Value Loss": 0.024988124147057533, "_runtime": 8751.588853597641, "_timestamp": 1585578667.433487, "_step": 372}
{"Episode reward": 30.099999999999696, "Episode length": 699, "Policy Loss": 0.3931182622909546, "Value Loss": 13.75031852722168, "_runtime": 8752.506336927414, "_timestamp": 1585578668.3509703, "_step": 373}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.8643396496772766, "Value Loss": 16.62412452697754, "_runtime": 8754.06440782547, "_timestamp": 1585578669.9090412, "_step": 374}
{"Episode reward": -99.86985874324897, "Episode length": 999, "Policy Loss": -0.7955861687660217, "Value Loss": 0.17007707059383392, "_runtime": 8755.609012365341, "_timestamp": 1585578671.4536457, "_step": 375}
{"Episode reward": -99.77768764356011, "Episode length": 999, "Policy Loss": -0.8090835213661194, "Value Loss": 0.07465444505214691, "_runtime": 8757.134805202484, "_timestamp": 1585578672.9794385, "_step": 376}
{"Episode reward": -99.80011849999288, "Episode length": 999, "Policy Loss": -0.810428261756897, "Value Loss": 0.1809288114309311, "_runtime": 8758.355953216553, "_timestamp": 1585578674.2005866, "_step": 377}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 0.13931211829185486, "Value Loss": 12.509538650512695, "_runtime": 8759.912777423859, "_timestamp": 1585578675.7574108, "_step": 378}
{"Episode reward": -99.75789945013682, "Episode length": 999, "Policy Loss": -0.779627799987793, "Value Loss": 0.04581829160451889, "_runtime": 8761.475566625595, "_timestamp": 1585578677.3202, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7744069695472717, "Value Loss": 0.03648805990815163, "_runtime": 8761.84648156166, "_timestamp": 1585578677.691115, "_step": 380}
{"Episode reward": 79.09999999999998, "Episode length": 209, "Policy Loss": 2.8428869247436523, "Value Loss": 45.86916732788086, "_runtime": 8763.399372816086, "_timestamp": 1585578679.2440062, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7580417394638062, "Value Loss": 0.017544420436024666, "_runtime": 8764.930414915085, "_timestamp": 1585578680.7750483, "_step": 382}
{"Episode reward": 1.7000000000013102, "Episode length": 983, "Policy Loss": -0.02822108007967472, "Value Loss": 9.790699005126953, "_runtime": 8766.41844367981, "_timestamp": 1585578682.263077, "_step": 383}
{"Episode reward": -99.84287436008313, "Episode length": 999, "Policy Loss": -0.7905641794204712, "Value Loss": 0.07535760849714279, "_runtime": 8767.981617927551, "_timestamp": 1585578683.8262513, "_step": 384}
{"Episode reward": -99.89336343444744, "Episode length": 999, "Policy Loss": -0.7759972214698792, "Value Loss": 0.022519122809171677, "_runtime": 8769.546949148178, "_timestamp": 1585578685.3915825, "_step": 385}
{"Episode reward": -99.80019044615189, "Episode length": 999, "Policy Loss": -0.7847681641578674, "Value Loss": 0.024776913225650787, "_runtime": 8769.94616651535, "_timestamp": 1585578685.7907999, "_step": 386}
{"Episode reward": 77.09999999999995, "Episode length": 229, "Policy Loss": 2.551260471343994, "Value Loss": 42.14070129394531, "_runtime": 8771.540389060974, "_timestamp": 1585578687.3850224, "_step": 387}
{"Episode reward": -99.80061720097298, "Episode length": 999, "Policy Loss": -0.7616190314292908, "Value Loss": 0.03979251906275749, "_runtime": 8772.22288608551, "_timestamp": 1585578688.0675194, "_step": 388}
{"Episode reward": 58.09999999999968, "Episode length": 419, "Policy Loss": 0.8896641731262207, "Value Loss": 23.297245025634766, "_runtime": 8773.71686887741, "_timestamp": 1585578689.5615022, "_step": 389}
{"Episode reward": -99.80479317046563, "Episode length": 999, "Policy Loss": -0.8103082180023193, "Value Loss": 0.08983007073402405, "_runtime": 8775.274864912033, "_timestamp": 1585578691.1194983, "_step": 390}
{"Episode reward": -99.75317066646973, "Episode length": 999, "Policy Loss": -0.7849359512329102, "Value Loss": 0.06175152212381363, "_runtime": 8776.369650125504, "_timestamp": 1585578692.2142835, "_step": 391}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.3374808728694916, "Value Loss": 13.20042896270752, "_runtime": 8777.378794193268, "_timestamp": 1585578693.2234275, "_step": 392}
{"Episode reward": 35.74811147302327, "Episode length": 643, "Policy Loss": 0.3788108825683594, "Value Loss": 14.917914390563965, "_runtime": 8778.92191696167, "_timestamp": 1585578694.7665503, "_step": 393}
{"Episode reward": -99.87444117069104, "Episode length": 999, "Policy Loss": -0.804104208946228, "Value Loss": 0.04259919747710228, "_runtime": 8779.933374404907, "_timestamp": 1585578695.7780077, "_step": 394}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 0.3094373047351837, "Value Loss": 14.851454734802246, "_runtime": 8781.452051639557, "_timestamp": 1585578697.296685, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.829077959060669, "Value Loss": 0.02728618122637272, "_runtime": 8783.004375457764, "_timestamp": 1585578698.8490088, "_step": 396}
{"Episode reward": 0.6000000000013728, "Episode length": 994, "Policy Loss": -0.12336061149835587, "Value Loss": 9.676240921020508, "_runtime": 8784.529195070267, "_timestamp": 1585578700.3738284, "_step": 397}
{"Episode reward": -99.82730157412449, "Episode length": 999, "Policy Loss": -0.8208343386650085, "Value Loss": 0.03197984769940376, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502, 0.06874249875545502]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06860680878162384, 0.04644790291786194, 0.16150261461734772, 0.2765573263168335, 0.39161205291748047, 0.5066667795181274, 0.6217214465141296, 0.7367761731147766, 0.8518308997154236, 0.9668856263160706, 1.0819402933120728, 1.1969950199127197, 1.3120496273040771, 1.4271043539047241, 1.542159080505371, 1.657213807106018, 1.772268533706665, 1.887323260307312, 2.002377986907959, 2.1174325942993164, 2.232487440109253, 2.3475420475006104, 2.462596893310547, 2.5776515007019043, 2.6927061080932617, 2.8077609539031982, 2.9228155612945557, 3.037870407104492, 3.1529250144958496, 3.267979860305786, 3.3830344676971436, 3.49808931350708, 3.6131439208984375, 3.728198528289795, 3.8432533740997314, 3.958308219909668, 4.073362827301025, 4.188417434692383, 4.30347204208374, 4.418527126312256, 4.533581733703613, 4.648636341094971, 4.763690948486328, 4.8787455558776855, 4.993800640106201, 5.108855247497559, 5.223909854888916, 5.338964462280273, 5.454019069671631, 5.5690741539001465, 5.684128761291504, 5.799183368682861, 5.914237976074219, 6.029293060302734, 6.144347667694092, 6.259402275085449, 6.374456882476807, 6.489511489868164, 6.60456657409668, 6.719621181488037, 6.8346757888793945, 6.949730396270752, 7.064785480499268, 7.179840087890625, 7.294894695281982]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10207849740982056, -0.09734946489334106, -0.09262043237686157, -0.08789139986038208, -0.08316236734390259, -0.0784333348274231, -0.0737043023109436, -0.06897526979446411, -0.06424623727798462, -0.05951720476150513, -0.054788172245025635, -0.05005913972854614, -0.04533010721206665, -0.04060107469558716, -0.035872042179107666, -0.031143009662628174, -0.02641397714614868, -0.02168494462966919, -0.016955912113189697, -0.012226879596710205, -0.007497847080230713, -0.0027688145637512207, 0.0019602179527282715, 0.006689250469207764, 0.011418282985687256, 0.016147315502166748, 0.02087634801864624, 0.025605380535125732, 0.030334413051605225, 0.03506344556808472, 0.03979247808456421, 0.0445215106010437, 0.04925054311752319, 0.053979575634002686, 0.05870860815048218, 0.06343764066696167, 0.06816667318344116, 0.07289570569992065, 0.07762473821640015, 0.08235377073287964, 0.08708280324935913, 0.09181183576583862, 0.09654086828231812, 0.10126990079879761, 0.1059989333152771, 0.11072796583175659, 0.11545699834823608, 0.12018603086471558, 0.12491506338119507, 0.12964409589767456, 0.13437312841415405, 0.13910216093063354, 0.14383119344711304, 0.14856022596359253, 0.15328925848007202, 0.1580182909965515, 0.162747323513031, 0.1674763560295105, 0.17220538854599, 0.17693442106246948, 0.18166345357894897, 0.18639248609542847, 0.19112151861190796, 0.19585055112838745, 0.20057958364486694]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 1.0, 5.0, 3.0, 2.0, 0.0, 0.0, 5.0, 3.0, 9.0, 15.0, 31.0, 15.0, 15.0, 0.0, 0.0, 0.0, 7.0, 115.0, 165.0, 1.0, 3.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 11.0, 2.0, 6.0, 6.0, 1.0, 4.0, 0.0, 1.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 4.0], "bins": [-0.5205885171890259, -0.49320822954177856, -0.46582794189453125, -0.43844765424728394, -0.41106733679771423, -0.3836870491504669, -0.3563067615032196, -0.3289264440536499, -0.3015461564064026, -0.2741658687591553, -0.24678558111190796, -0.21940529346466064, -0.19202500581741333, -0.16464471817016602, -0.1372644007205963, -0.109884113073349, -0.08250382542610168, -0.05512353777885437, -0.027743250131607056, -0.0003629326820373535, 0.02701735496520996, 0.054397642612457275, 0.08177793025970459, 0.1091582179069519, 0.13653850555419922, 0.16391879320144653, 0.19129908084869385, 0.21867942810058594, 0.24605971574783325, 0.27344000339508057, 0.3008202910423279, 0.3282005786895752, 0.3555808663368225, 0.3829611539840698, 0.41034144163131714, 0.43772172927856445, 0.46510201692581177, 0.4924823045730591, 0.5198626518249512, 0.5472428798675537, 0.5746232271194458, 0.6020034551620483, 0.6293838024139404, 0.6567641496658325, 0.6841443777084351, 0.7115247249603271, 0.7389049530029297, 0.7662853002548218, 0.7936655282974243, 0.8210458755493164, 0.848426103591919, 0.875806450843811, 0.9031866788864136, 0.9305670261383057, 0.9579473733901978, 0.9853276014328003, 1.0127079486846924, 1.040088176727295, 1.067468523979187, 1.0948487520217896, 1.1222290992736816, 1.1496093273162842, 1.1769896745681763, 1.2043699026107788, 1.231750249862671]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10392702370882034, -0.08926219493150711, -0.07459736615419388, -0.059932537376880646, -0.04526770859956741, -0.03060287982225418, -0.01593805104494095, -0.001273222267627716, 0.013391606509685516, 0.02805643528699875, 0.04272126406431198, 0.057386092841625214, 0.07205092161893845, 0.08671575039625168, 0.10138057917356491, 0.11604540795087814, 0.13071024417877197, 0.1453750729560852, 0.16003990173339844, 0.17470473051071167, 0.1893695592880249, 0.20403438806533813, 0.21869921684265137, 0.2333640456199646, 0.24802887439727783, 0.26269370317459106, 0.2773585319519043, 0.29202336072921753, 0.30668818950653076, 0.321353018283844, 0.3360178470611572, 0.35068267583847046, 0.3653475046157837, 0.3800123333930969, 0.39467716217041016, 0.4093419909477234, 0.4240068197250366, 0.43867164850234985, 0.4533364772796631, 0.4680013060569763, 0.48266613483428955, 0.4973309636116028, 0.511995792388916, 0.5266606211662292, 0.5413254499435425, 0.5559902787208557, 0.570655107498169, 0.5853199362754822, 0.5999847650527954, 0.6146495938301086, 0.6293144226074219, 0.6439792513847351, 0.6586440801620483, 0.6733089089393616, 0.6879737377166748, 0.702638566493988, 0.7173033952713013, 0.7319682240486145, 0.7466330528259277, 0.761297881603241, 0.7759627103805542, 0.7906275391578674, 0.8052923679351807, 0.8199571967124939, 0.8346220254898071]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 6.0, 3.0, 0.0, 10.0, 2.0, 1.0, 2.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0], "bins": [-0.6665191650390625, -0.6498388648033142, -0.6331585049629211, -0.6164782047271729, -0.5997979044914246, -0.5831176042556763, -0.5664372444152832, -0.5497569441795349, -0.5330766439437866, -0.5163962841033936, -0.49971598386764526, -0.483035683631897, -0.4663553535938263, -0.4496750235557556, -0.4329947233200073, -0.41631442308425903, -0.39963409304618835, -0.3829537630081177, -0.3662734627723694, -0.3495931327342987, -0.3329128324985504, -0.31623250246047974, -0.29955220222473145, -0.28287187218666077, -0.2661915421485901, -0.2495112419128418, -0.23283091187477112, -0.21615061163902283, -0.19947028160095215, -0.18278998136520386, -0.16610968112945557, -0.1494293212890625, -0.1327490210533142, -0.11606872081756592, -0.09938836097717285, -0.08270806074142456, -0.06602776050567627, -0.04934746026992798, -0.03266710042953491, -0.01598680019378662, 0.0006935000419616699, 0.017373859882354736, 0.03405416011810303, 0.05073446035385132, 0.06741476058959961, 0.08409512042999268, 0.10077542066574097, 0.11745572090148926, 0.13413608074188232, 0.15081638097763062, 0.1674966812133789, 0.1841769814491272, 0.20085734128952026, 0.21753764152526855, 0.23421794176101685, 0.25089824199676514, 0.2675786018371582, 0.2842589020729065, 0.3009392023086548, 0.31761956214904785, 0.33429980278015137, 0.35098016262054443, 0.3676605224609375, 0.384340763092041, 0.4010211229324341]}, "_runtime": 8785.823366641998, "_timestamp": 1585578701.668, "_step": 398}
{"Episode reward": 17.300000000000423, "Episode length": 827, "Policy Loss": 0.03097335807979107, "Value Loss": 11.658312797546387, "_runtime": 8786.92733335495, "_timestamp": 1585578702.7719667, "_step": 399}
{"Episode reward": 30.39999999999968, "Episode length": 696, "Policy Loss": 0.536697268486023, "Value Loss": 13.899529457092285, "_runtime": 8787.941997766495, "_timestamp": 1585578703.786631, "_step": 400}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.6291561126708984, "Value Loss": 14.579537391662598, "_runtime": 8789.485345125198, "_timestamp": 1585578705.3299785, "_step": 401}
{"Episode reward": -99.80278660096089, "Episode length": 999, "Policy Loss": -0.8413560390472412, "Value Loss": 0.014704039320349693, "_runtime": 8791.023975849152, "_timestamp": 1585578706.8686092, "_step": 402}
{"Episode reward": -99.8008539095507, "Episode length": 999, "Policy Loss": -0.8460118770599365, "Value Loss": 0.024208277463912964, "_runtime": 8791.782609462738, "_timestamp": 1585578707.6272428, "_step": 403}
{"Episode reward": 51.39999999999959, "Episode length": 486, "Policy Loss": 0.6201677322387695, "Value Loss": 19.89158821105957, "_runtime": 8792.03581237793, "_timestamp": 1585578707.8804457, "_step": 404}
{"Episode reward": 87.6745524581522, "Episode length": 124, "Policy Loss": 5.124848365783691, "Value Loss": 76.63239288330078, "_runtime": 8793.49518418312, "_timestamp": 1585578709.3398175, "_step": 405}
{"Episode reward": 5.700000000001083, "Episode length": 943, "Policy Loss": -0.06797489523887634, "Value Loss": 10.097748756408691, "_runtime": 8795.046572446823, "_timestamp": 1585578710.8912058, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9085323810577393, "Value Loss": 0.076119564473629, "_runtime": 8796.526976108551, "_timestamp": 1585578712.3716094, "_step": 407}
{"Episode reward": -99.80007081627706, "Episode length": 999, "Policy Loss": -0.9288509488105774, "Value Loss": 0.12635111808776855, "_runtime": 8798.08417391777, "_timestamp": 1585578713.9288073, "_step": 408}
{"Episode reward": -99.88371847905078, "Episode length": 999, "Policy Loss": -0.9199360609054565, "Value Loss": 0.05116668716073036, "_runtime": 8799.249801397324, "_timestamp": 1585578715.0944347, "_step": 409}
{"Episode reward": 25.09999999999998, "Episode length": 749, "Policy Loss": -0.06311830878257751, "Value Loss": 13.712807655334473, "_runtime": 8799.748233318329, "_timestamp": 1585578715.5928667, "_step": 410}
{"Episode reward": 69.65354939363881, "Episode length": 305, "Policy Loss": 1.3868224620819092, "Value Loss": 31.25162696838379, "_runtime": 8801.300138235092, "_timestamp": 1585578717.1447716, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0020759105682373, "Value Loss": 0.0921422466635704, "_runtime": 8802.837554693222, "_timestamp": 1585578718.682188, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0051157474517822, "Value Loss": 0.38216620683670044, "_runtime": 8804.31811118126, "_timestamp": 1585578720.1627445, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9557539224624634, "Value Loss": 0.030857207253575325, "_runtime": 8805.858226776123, "_timestamp": 1585578721.70286, "_step": 414}
{"Episode reward": 1.6893156107528284, "Episode length": 985, "Policy Loss": -0.24624693393707275, "Value Loss": 9.99413776397705, "_runtime": 8807.41764831543, "_timestamp": 1585578723.2622817, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9634329080581665, "Value Loss": 0.04109417647123337, "_runtime": 8808.270681381226, "_timestamp": 1585578724.1153147, "_step": 416}
{"Episode reward": 45.92831660322796, "Episode length": 542, "Policy Loss": 0.4974658489227295, "Value Loss": 17.667524337768555, "_runtime": 8809.830887317657, "_timestamp": 1585578725.6755207, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9259164333343506, "Value Loss": 0.039680950343608856, "_runtime": 8811.393013954163, "_timestamp": 1585578727.2376473, "_step": 418}
{"Episode reward": -99.76097359545389, "Episode length": 999, "Policy Loss": -0.9371073246002197, "Value Loss": 0.02953607775270939, "_runtime": 8812.639845609665, "_timestamp": 1585578728.484479, "_step": 419}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": -0.06331219524145126, "Value Loss": 11.754100799560547, "_runtime": 8814.207525968552, "_timestamp": 1585578730.0521593, "_step": 420}
{"Episode reward": -99.86143635660271, "Episode length": 999, "Policy Loss": -0.9355427622795105, "Value Loss": 0.02045724354684353, "_runtime": 8815.754743814468, "_timestamp": 1585578731.5993772, "_step": 421}
{"Episode reward": -99.80462890602509, "Episode length": 999, "Policy Loss": -0.9164348244667053, "Value Loss": 0.02724928967654705, "_runtime": 8817.289932727814, "_timestamp": 1585578733.134566, "_step": 422}
{"Episode reward": -99.77479648664455, "Episode length": 999, "Policy Loss": -0.9156658053398132, "Value Loss": 0.020649150013923645, "_runtime": 8818.89213347435, "_timestamp": 1585578734.7367668, "_step": 423}
{"Episode reward": -99.77823872566084, "Episode length": 999, "Policy Loss": -0.9136586785316467, "Value Loss": 0.15087339282035828, "_runtime": 8819.807765722275, "_timestamp": 1585578735.652399, "_step": 424}
{"Episode reward": 41.62597426762749, "Episode length": 584, "Policy Loss": 0.35279878973960876, "Value Loss": 16.747251510620117, "_runtime": 8821.363080978394, "_timestamp": 1585578737.2077143, "_step": 425}
{"Episode reward": -99.70655029155175, "Episode length": 999, "Policy Loss": -0.8547949194908142, "Value Loss": 0.0708722323179245, "_runtime": 8822.939116954803, "_timestamp": 1585578738.7837503, "_step": 426}
{"Episode reward": -99.86100349537888, "Episode length": 999, "Policy Loss": -0.8437833786010742, "Value Loss": 0.016721386462450027, "_runtime": 8824.465538024902, "_timestamp": 1585578740.3101714, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8197979927062988, "Value Loss": 0.01763288490474224, "_runtime": 8826.020347833633, "_timestamp": 1585578741.8649812, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8034219145774841, "Value Loss": 0.05518702417612076, "_runtime": 8827.270864486694, "_timestamp": 1585578743.1154978, "_step": 429}
{"Episode reward": 20.705417726934186, "Episode length": 793, "Policy Loss": 0.019353816285729408, "Value Loss": 12.433948516845703, "_runtime": 8828.745733976364, "_timestamp": 1585578744.5903673, "_step": 430}
{"Episode reward": 6.016582816840284, "Episode length": 940, "Policy Loss": 0.03101152740418911, "Value Loss": 10.166321754455566, "_runtime": 8830.310059547424, "_timestamp": 1585578746.154693, "_step": 431}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7442930936813354, "Value Loss": 0.01220223493874073, "_runtime": 8831.869740247726, "_timestamp": 1585578747.7143736, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7640312314033508, "Value Loss": 0.2696501612663269, "_runtime": 8833.181859016418, "_timestamp": 1585578749.0264924, "_step": 433}
{"Episode reward": 16.296584361792085, "Episode length": 838, "Policy Loss": 0.20105546712875366, "Value Loss": 11.389775276184082, "_runtime": 8834.745768785477, "_timestamp": 1585578750.5904021, "_step": 434}
{"Episode reward": -99.80203285217145, "Episode length": 999, "Policy Loss": -0.7607650756835938, "Value Loss": 0.14088553190231323, "_runtime": 8835.545737028122, "_timestamp": 1585578751.3903704, "_step": 435}
{"Episode reward": 50.29999999999957, "Episode length": 497, "Policy Loss": 0.8039149641990662, "Value Loss": 19.075687408447266, "_runtime": 8836.296267271042, "_timestamp": 1585578752.1409006, "_step": 436}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 1.3281868696212769, "Value Loss": 20.24376106262207, "_runtime": 8837.464666843414, "_timestamp": 1585578753.3093002, "_step": 437}
{"Episode reward": 25.29999999999997, "Episode length": 747, "Policy Loss": 0.3964961767196655, "Value Loss": 12.703558921813965, "_runtime": 8838.978178739548, "_timestamp": 1585578754.822812, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6686155200004578, "Value Loss": 0.022533485665917397, "_runtime": 8840.493031740189, "_timestamp": 1585578756.337665, "_step": 439}
{"Episode reward": -99.80861886888603, "Episode length": 999, "Policy Loss": -0.8512240052223206, "Value Loss": 0.41629758477211, "_runtime": 8841.358057022095, "_timestamp": 1585578757.2026904, "_step": 440}
{"Episode reward": 44.899418854340404, "Episode length": 552, "Policy Loss": 0.5936765074729919, "Value Loss": 17.42966079711914, "_runtime": 8842.946649312973, "_timestamp": 1585578758.7912827, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6855695247650146, "Value Loss": 0.029105421155691147, "_runtime": 8843.755586862564, "_timestamp": 1585578759.6002202, "_step": 442}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 0.7223612070083618, "Value Loss": 18.925048828125, "_runtime": 8845.272817134857, "_timestamp": 1585578761.1174505, "_step": 443}
{"Episode reward": -99.86719116121391, "Episode length": 999, "Policy Loss": -0.7420583367347717, "Value Loss": 0.25880953669548035, "_runtime": 8846.838161706924, "_timestamp": 1585578762.682795, "_step": 444}
{"Episode reward": -99.83867624737182, "Episode length": 999, "Policy Loss": -0.6645703315734863, "Value Loss": 0.02211686596274376, "_runtime": 8847.66387963295, "_timestamp": 1585578763.508513, "_step": 445}
{"Episode reward": 46.56627300046336, "Episode length": 535, "Policy Loss": 0.7781194448471069, "Value Loss": 18.00458526611328, "_runtime": 8849.206524848938, "_timestamp": 1585578765.0511582, "_step": 446}
{"Episode reward": -99.80011557675758, "Episode length": 999, "Policy Loss": -0.6536378264427185, "Value Loss": 0.04114861786365509, "_runtime": 8850.761971950531, "_timestamp": 1585578766.6066053, "_step": 447}
{"Episode reward": -99.73944517494972, "Episode length": 999, "Policy Loss": -0.6329088807106018, "Value Loss": 0.04227694869041443, "_runtime": 8852.277599573135, "_timestamp": 1585578768.122233, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6386200785636902, "Value Loss": 0.02482827939093113, "_runtime": 8853.841587305069, "_timestamp": 1585578769.6862206, "_step": 449}
{"Episode reward": -99.81688295006612, "Episode length": 999, "Policy Loss": -0.6515353322029114, "Value Loss": 0.02537272684276104, "_runtime": 8855.41018295288, "_timestamp": 1585578771.2548163, "_step": 450}
{"Episode reward": -99.80389619022468, "Episode length": 999, "Policy Loss": -0.6540420055389404, "Value Loss": 0.05897177383303642, "_runtime": 8856.31729221344, "_timestamp": 1585578772.1619256, "_step": 451}
{"Episode reward": 42.99999999999947, "Episode length": 570, "Policy Loss": 0.6840299963951111, "Value Loss": 16.876617431640625, "_runtime": 8857.874895572662, "_timestamp": 1585578773.719529, "_step": 452}
{"Episode reward": -99.79533617235582, "Episode length": 999, "Policy Loss": -0.6411570310592651, "Value Loss": 0.013369102030992508, "_runtime": 8859.442955493927, "_timestamp": 1585578775.2875888, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.616104006767273, "Value Loss": 0.04505730792880058, "_runtime": 8860.95616698265, "_timestamp": 1585578776.8008003, "_step": 454}
{"Episode reward": -99.800487542151, "Episode length": 999, "Policy Loss": -0.7204933166503906, "Value Loss": 0.30424681305885315, "_runtime": 8862.512515544891, "_timestamp": 1585578778.357149, "_step": 455}
{"Episode reward": -99.8597356144325, "Episode length": 999, "Policy Loss": -0.6043941974639893, "Value Loss": 0.03833064064383507, "_runtime": 8864.083940982819, "_timestamp": 1585578779.9285743, "_step": 456}
{"Episode reward": -99.73457417944307, "Episode length": 999, "Policy Loss": -0.6000606417655945, "Value Loss": 0.007414947263896465, "_runtime": 8864.593131542206, "_timestamp": 1585578780.437765, "_step": 457}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 1.9471138715744019, "Value Loss": 32.07584762573242, "_runtime": 8866.184430837631, "_timestamp": 1585578782.0290642, "_step": 458}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5812906622886658, "Value Loss": 0.007886054925620556, "_runtime": 8867.629093408585, "_timestamp": 1585578783.4737267, "_step": 459}
{"Episode reward": 8.225874458254324, "Episode length": 918, "Policy Loss": 0.2080572098493576, "Value Loss": 10.46187686920166, "_runtime": 8869.126843214035, "_timestamp": 1585578784.9714766, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.583605945110321, "Value Loss": 0.01569068245589733, "_runtime": 8870.697340726852, "_timestamp": 1585578786.541974, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5758382678031921, "Value Loss": 0.02129637636244297, "_runtime": 8872.25953578949, "_timestamp": 1585578788.1041691, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5983695387840271, "Value Loss": 0.026923591271042824, "_runtime": 8873.493135929108, "_timestamp": 1585578789.3377693, "_step": 463}
{"Episode reward": 20.100000000000264, "Episode length": 799, "Policy Loss": 0.32564833760261536, "Value Loss": 12.152031898498535, "_runtime": 8875.063988685608, "_timestamp": 1585578790.908622, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5957098603248596, "Value Loss": 0.08807089179754257, "_runtime": 8876.638204574585, "_timestamp": 1585578792.482838, "_step": 465}
{"Episode reward": -99.81635546833137, "Episode length": 999, "Policy Loss": -0.5824500918388367, "Value Loss": 0.03281465545296669, "_runtime": 8878.03566980362, "_timestamp": 1585578793.8803031, "_step": 466}
{"Episode reward": 9.057383429446233, "Episode length": 911, "Policy Loss": 0.22304634749889374, "Value Loss": 10.483781814575195, "_runtime": 8879.314986228943, "_timestamp": 1585578795.1596196, "_step": 467}
{"Episode reward": 18.500000000000355, "Episode length": 815, "Policy Loss": 0.2853723466396332, "Value Loss": 11.733966827392578, "_runtime": 8880.883347034454, "_timestamp": 1585578796.7279804, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5405663847923279, "Value Loss": 0.04334396868944168, "_runtime": 8882.437847137451, "_timestamp": 1585578798.2824805, "_step": 469}
{"Episode reward": -99.8430503860102, "Episode length": 999, "Policy Loss": -0.5448969602584839, "Value Loss": 0.04272829368710518, "_runtime": 8883.98466682434, "_timestamp": 1585578799.8293002, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5846685171127319, "Value Loss": 0.03974968194961548, "_runtime": 8885.54516172409, "_timestamp": 1585578801.389795, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5552293062210083, "Value Loss": 0.02358296886086464, "_runtime": 8887.095896720886, "_timestamp": 1585578802.94053, "_step": 472}
{"Episode reward": -99.80359618998924, "Episode length": 999, "Policy Loss": -0.5610238909721375, "Value Loss": 0.02677609957754612, "_runtime": 8888.704586744308, "_timestamp": 1585578804.54922, "_step": 473}
{"Episode reward": -99.80698450952629, "Episode length": 999, "Policy Loss": -0.5258805155754089, "Value Loss": 0.06220807135105133, "_runtime": 8889.585782527924, "_timestamp": 1585578805.4304159, "_step": 474}
{"Episode reward": 44.999999999999496, "Episode length": 550, "Policy Loss": 0.768060564994812, "Value Loss": 17.510257720947266, "_runtime": 8891.147915124893, "_timestamp": 1585578806.9925485, "_step": 475}
{"Episode reward": -99.86083912560578, "Episode length": 999, "Policy Loss": -0.5229620933532715, "Value Loss": 0.014844357967376709, "_runtime": 8892.720173358917, "_timestamp": 1585578808.5648067, "_step": 476}
{"Episode reward": -99.84196800142387, "Episode length": 999, "Policy Loss": -0.4937448501586914, "Value Loss": 0.028796343132853508, "_runtime": 8894.242218255997, "_timestamp": 1585578810.0868516, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5029352903366089, "Value Loss": 0.01760636270046234, "_runtime": 8895.801101922989, "_timestamp": 1585578811.6457353, "_step": 478}
{"Episode reward": -99.83647101307147, "Episode length": 999, "Policy Loss": -0.5131343603134155, "Value Loss": 0.008524703793227673, "_runtime": 8897.37268280983, "_timestamp": 1585578813.2173162, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5110068321228027, "Value Loss": 0.011553783901035786, "_runtime": 8898.934579610825, "_timestamp": 1585578814.779213, "_step": 480}
{"Episode reward": -99.8186471734182, "Episode length": 999, "Policy Loss": -0.49954211711883545, "Value Loss": 0.034228209406137466, "_runtime": 8900.494953632355, "_timestamp": 1585578816.339587, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49788209795951843, "Value Loss": 0.010924478992819786, "_runtime": 8902.068143367767, "_timestamp": 1585578817.9127767, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.495670348405838, "Value Loss": 0.05200137197971344, "_runtime": 8903.625126600266, "_timestamp": 1585578819.46976, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4812299311161041, "Value Loss": 0.019135404378175735, "_runtime": 8904.65641951561, "_timestamp": 1585578820.5010529, "_step": 484}
{"Episode reward": 34.699999999999434, "Episode length": 653, "Policy Loss": 0.6468363404273987, "Value Loss": 14.620488166809082, "_runtime": 8906.049704313278, "_timestamp": 1585578821.8943377, "_step": 485}
{"Episode reward": 10.666229124554292, "Episode length": 895, "Policy Loss": 0.44232669472694397, "Value Loss": 10.720945358276367, "_runtime": 8907.612349748611, "_timestamp": 1585578823.456983, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4602873921394348, "Value Loss": 0.005209838505834341, "_runtime": 8909.144260406494, "_timestamp": 1585578824.9888937, "_step": 487}
{"Episode reward": -99.77902429075772, "Episode length": 999, "Policy Loss": -0.4466237425804138, "Value Loss": 0.00662651564925909, "_runtime": 8910.71003293991, "_timestamp": 1585578826.5546663, "_step": 488}
{"Episode reward": -99.80023871669407, "Episode length": 999, "Policy Loss": -0.4481559991836548, "Value Loss": 0.006766863167285919, "_runtime": 8911.551034212112, "_timestamp": 1585578827.3956676, "_step": 489}
{"Episode reward": 47.49999999999953, "Episode length": 525, "Policy Loss": 1.0408313274383545, "Value Loss": 18.377365112304688, "_runtime": 8912.698441028595, "_timestamp": 1585578828.5430744, "_step": 490}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.5233533978462219, "Value Loss": 13.61566162109375, "_runtime": 8913.826150417328, "_timestamp": 1585578829.6707838, "_step": 491}
{"Episode reward": 28.496917600836397, "Episode length": 716, "Policy Loss": 0.5897583365440369, "Value Loss": 13.206594467163086, "_runtime": 8915.355061531067, "_timestamp": 1585578831.1996949, "_step": 492}
{"Episode reward": -99.82289772033552, "Episode length": 999, "Policy Loss": -0.48703011870384216, "Value Loss": 0.18908636271953583, "_runtime": 8916.576377630234, "_timestamp": 1585578832.421011, "_step": 493}
{"Episode reward": 20.50000000000024, "Episode length": 795, "Policy Loss": 0.5392249822616577, "Value Loss": 11.865230560302734, "_runtime": 8918.108726739883, "_timestamp": 1585578833.95336, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5652652978897095, "Value Loss": 0.11966778337955475, "_runtime": 8918.939850330353, "_timestamp": 1585578834.7844837, "_step": 495}
{"Episode reward": 47.784947930182796, "Episode length": 523, "Policy Loss": 0.8589063286781311, "Value Loss": 18.381031036376953, "_runtime": 8919.989335775375, "_timestamp": 1585578835.833969, "_step": 496}
{"Episode reward": 32.26605354770976, "Episode length": 678, "Policy Loss": 0.6426340341567993, "Value Loss": 14.12973403930664, "_runtime": 8921.546466112137, "_timestamp": 1585578837.3910995, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4662506580352783, "Value Loss": 0.0574658066034317, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984, 0.141444593667984]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.14143900573253632, 0.08324320614337921, 0.30792540311813354, 0.5326076149940491, 0.7572898268699646, 0.9819720387458801, 1.2066543102264404, 1.431336522102356, 1.6560187339782715, 1.8807010650634766, 2.1053831577301025, 2.3300652503967285, 2.5547475814819336, 2.7794299125671387, 3.0041120052337646, 3.2287940979003906, 3.4534764289855957, 3.678158760070801, 3.902841091156006, 4.127522945404053, 4.352205276489258, 4.576887607574463, 4.80156946182251, 5.026251792907715, 5.25093412399292, 5.475616455078125, 5.70029878616333, 5.924980640411377, 6.149662971496582, 6.374345302581787, 6.599027156829834, 6.823709487915039, 7.048391819000244, 7.273074150085449, 7.497756481170654, 7.722438335418701, 7.9471211433410645, 8.171802520751953, 8.396484375, 8.621167182922363, 8.84584903717041, 9.070530891418457, 9.29521369934082, 9.519895553588867, 9.744577407836914, 9.969260215759277, 10.193942070007324, 10.418624877929688, 10.643306732177734, 10.867988586425781, 11.092671394348145, 11.317353248596191, 11.542036056518555, 11.766717910766602, 11.991399765014648, 12.216082572937012, 12.440764427185059, 12.665446281433105, 12.890129089355469, 13.114810943603516, 13.339492797851562, 13.564175605773926, 13.788857460021973, 14.013540267944336, 14.238222122192383]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.16333302855491638, -0.15427610278129578, -0.14521917700767517, -0.13616225123405457, -0.12710532546043396, -0.11804840713739395, -0.10899148881435394, -0.09993456304073334, -0.09087763726711273, -0.08182071149349213, -0.07276378571987152, -0.06370686739683151, -0.05464994162321091, -0.0455930158495903, -0.03653609752655029, -0.027479171752929688, -0.018422245979309082, -0.009365320205688477, -0.0003083944320678711, 0.008748531341552734, 0.01780545711517334, 0.02686236798763275, 0.03591929376125336, 0.04497621953487396, 0.05403314530849457, 0.06309007108211517, 0.07214699685573578, 0.08120392262935638, 0.0902608335018158, 0.0993177592754364, 0.108374685049057, 0.11743161082267761, 0.12648853659629822, 0.13554546236991882, 0.14460238814353943, 0.15365931391716003, 0.16271623969078064, 0.17177316546440125, 0.18083009123802185, 0.18988701701164246, 0.19894394278526306, 0.20800083875656128, 0.21705776453018188, 0.2261146903038025, 0.2351716160774231, 0.2442285418510437, 0.2532854676246643, 0.2623423933982849, 0.2713993191719055, 0.2804562449455261, 0.28951317071914673, 0.29857009649276733, 0.30762702226638794, 0.31668394804000854, 0.32574087381362915, 0.33479779958724976, 0.343854695558548, 0.3529116213321686, 0.3619685471057892, 0.3710254728794098, 0.3800823986530304, 0.389139324426651, 0.3981962502002716, 0.4072531759738922, 0.4163101017475128]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 1.0, 6.0, 2.0, 2.0, 0.0, 0.0, 5.0, 7.0, 11.0, 41.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 274.0, 14.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 4.0, 2.0, 6.0, 4.0, 4.0, 4.0, 6.0, 6.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0], "bins": [-0.8277232646942139, -0.7812824249267578, -0.7348416447639465, -0.6884008049964905, -0.6419600248336792, -0.5955191850662231, -0.5490783452987671, -0.5026375651359558, -0.45619675517082214, -0.4097559452056885, -0.3633151352405548, -0.31687432527542114, -0.2704334855079651, -0.2239927053451538, -0.17755186557769775, -0.13111108541488647, -0.08467024564743042, -0.038229405879974365, 0.008211374282836914, 0.05465221405029297, 0.10109299421310425, 0.1475338339805603, 0.19397461414337158, 0.24041545391082764, 0.2868562936782837, 0.33329713344573975, 0.37973785400390625, 0.4261786937713623, 0.47261953353881836, 0.5190603733062744, 0.5655010938644409, 0.611941933631897, 0.658382773399353, 0.7048236131668091, 0.7512644529342651, 0.7977051734924316, 0.8441460132598877, 0.8905868530273438, 0.9370276927947998, 0.9834684133529663, 1.0299092531204224, 1.0763500928878784, 1.1227909326553345, 1.1692317724227905, 1.215672492980957, 1.262113332748413, 1.3085541725158691, 1.3549950122833252, 1.4014358520507812, 1.4478766918182373, 1.4943175315856934, 1.5407581329345703, 1.5871989727020264, 1.6336398124694824, 1.6800806522369385, 1.7265214920043945, 1.7729623317718506, 1.8194031715393066, 1.8658440113067627, 1.9122848510742188, 1.9587254524230957, 2.0051662921905518, 2.051607131958008, 2.098047971725464, 2.14448881149292]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.2442442774772644, -0.21320849657058716, -0.18217270076274872, -0.15113690495491028, -0.12010112404823303, -0.08906534314155579, -0.058029547333717346, -0.026993751525878906, 0.00404202938079834, 0.035077810287475586, 0.06611359119415283, 0.09714940190315247, 0.1281851828098297, 0.15922096371650696, 0.1902567744255066, 0.22129255533218384, 0.2523283362388611, 0.28336411714553833, 0.3143998980522156, 0.3454356789588928, 0.37647145986557007, 0.4075073003768921, 0.43854308128356934, 0.4695788621902466, 0.5006146430969238, 0.5316504240036011, 0.5626862049102783, 0.5937219858169556, 0.6247578263282776, 0.6557936072349548, 0.6868293881416321, 0.7178651690483093, 0.7489009499549866, 0.7799367308616638, 0.8109725117683411, 0.8420082926750183, 0.8730440735816956, 0.9040798544883728, 0.93511563539505, 0.9661514163017273, 0.9971871972084045, 1.0282230377197266, 1.0592589378356934, 1.090294599533081, 1.1213304996490479, 1.1523661613464355, 1.1834020614624023, 1.21443772315979, 1.2454736232757568, 1.2765092849731445, 1.3075451850891113, 1.338580846786499, 1.3696167469024658, 1.4006524085998535, 1.4316883087158203, 1.462723970413208, 1.4937598705291748, 1.5247957706451416, 1.5558314323425293, 1.586867332458496, 1.6179029941558838, 1.6489388942718506, 1.6799745559692383, 1.711010456085205, 1.7420461177825928]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 5.0, 4.0, 1.0, 0.0, 3.0, 7.0, 3.0, 6.0, 1.0, 0.0, 1.0, 2.0, 5.0, 4.0], "bins": [-0.7353603839874268, -0.7224713563919067, -0.7095823287963867, -0.6966933608055115, -0.6838043332099915, -0.6709153056144714, -0.6580263376235962, -0.6451373100280762, -0.6322482824325562, -0.6193592548370361, -0.6064702272415161, -0.5935812592506409, -0.5806922316551208, -0.5678032040596008, -0.5549142360687256, -0.5420252084732056, -0.5291361808776855, -0.5162471532821655, -0.5033581256866455, -0.49046915769577026, -0.47758013010025024, -0.4646911025047302, -0.4518021047115326, -0.43891310691833496, -0.42602407932281494, -0.4131350517272949, -0.4002460539340973, -0.38735705614089966, -0.37446802854537964, -0.3615790009498596, -0.348690003156662, -0.33580100536346436, -0.32291197776794434, -0.3100229501724243, -0.2971339523792267, -0.28424495458602905, -0.27135592699050903, -0.258466899394989, -0.24557790160179138, -0.23268890380859375, -0.21979987621307373, -0.2069108486175537, -0.1940218210220337, -0.18113285303115845, -0.16824382543563843, -0.1553547978401184, -0.14246582984924316, -0.12957680225372314, -0.11668777465820312, -0.1037987470626831, -0.09090971946716309, -0.07802075147628784, -0.06513172388076782, -0.0522426962852478, -0.03935372829437256, -0.02646470069885254, -0.01357567310333252, -0.0006866455078125, 0.01220238208770752, 0.025091350078582764, 0.03798037767410278, 0.0508694052696228, 0.06375837326049805, 0.07664740085601807, 0.08953642845153809]}, "_runtime": 8922.59060549736, "_timestamp": 1585578838.4352388, "_step": 498}
{"Episode reward": 31.698044984042255, "Episode length": 684, "Policy Loss": 0.5933193564414978, "Value Loss": 13.834748268127441, "_runtime": 8922.59060549736, "_timestamp": 1585578838.4352388, "_step": 499}
