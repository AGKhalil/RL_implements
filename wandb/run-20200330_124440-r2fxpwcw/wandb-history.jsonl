{"Episode reward": -44.949925539489975, "Episode length": 999, "Policy Loss": -0.06396814435720444, "Value Loss": 0.007771438453346491, "_runtime": 2383.395838737488, "_timestamp": 1585572299.240472, "_step": 0}
{"Episode reward": -98.44386412521158, "Episode length": 999, "Policy Loss": 18.826807022094727, "Value Loss": 184.5789031982422, "_runtime": 2384.890403985977, "_timestamp": 1585572300.7350373, "_step": 1}
{"Episode reward": -57.28624412401221, "Episode length": 999, "Policy Loss": -0.09001646190881729, "Value Loss": 0.8426671028137207, "_runtime": 2386.447125196457, "_timestamp": 1585572302.2917585, "_step": 2}
{"Episode reward": -81.10373448621928, "Episode length": 999, "Policy Loss": 2.729290246963501, "Value Loss": 68.76154327392578, "_runtime": 2387.9877376556396, "_timestamp": 1585572303.832371, "_step": 3}
{"Episode reward": -96.73090759767676, "Episode length": 999, "Policy Loss": 5.865893363952637, "Value Loss": 611.2568969726562, "_runtime": 2389.505711078644, "_timestamp": 1585572305.3503444, "_step": 4}
{"Episode reward": -90.44510071585248, "Episode length": 999, "Policy Loss": -2.567314386367798, "Value Loss": 1.7798670530319214, "_runtime": 2391.1144256591797, "_timestamp": 1585572306.959059, "_step": 5}
{"Episode reward": -96.57247375183297, "Episode length": 999, "Policy Loss": -7.37215518951416, "Value Loss": 98.6728286743164, "_runtime": 2392.6688125133514, "_timestamp": 1585572308.5134459, "_step": 6}
{"Episode reward": -98.66234843761656, "Episode length": 999, "Policy Loss": 2.488010883331299, "Value Loss": 216.675537109375, "_runtime": 2394.1910061836243, "_timestamp": 1585572310.0356395, "_step": 7}
{"Episode reward": -98.11561524685851, "Episode length": 999, "Policy Loss": -0.6333900094032288, "Value Loss": 14.493010520935059, "_runtime": 2395.7559847831726, "_timestamp": 1585572311.6006181, "_step": 8}
{"Episode reward": -96.59430072680045, "Episode length": 999, "Policy Loss": -1.7676331996917725, "Value Loss": 5.944587230682373, "_runtime": 2397.3044714927673, "_timestamp": 1585572313.1491048, "_step": 9}
{"Episode reward": -98.08192711435943, "Episode length": 999, "Policy Loss": -5.041697025299072, "Value Loss": 44.52513885498047, "_runtime": 2398.842960357666, "_timestamp": 1585572314.6875937, "_step": 10}
{"Episode reward": -98.35482693218131, "Episode length": 999, "Policy Loss": -1.8487554788589478, "Value Loss": 25.54202651977539, "_runtime": 2400.395227909088, "_timestamp": 1585572316.2398612, "_step": 11}
{"Episode reward": -98.89464694539909, "Episode length": 999, "Policy Loss": 3.939831256866455, "Value Loss": 146.59799194335938, "_runtime": 2401.9424481391907, "_timestamp": 1585572317.7870815, "_step": 12}
{"Episode reward": -98.82171519074275, "Episode length": 999, "Policy Loss": 3.3661844730377197, "Value Loss": 41.78014373779297, "_runtime": 2403.477651119232, "_timestamp": 1585572319.3222845, "_step": 13}
{"Episode reward": -99.28003402083897, "Episode length": 999, "Policy Loss": 3.4234492778778076, "Value Loss": 85.28105926513672, "_runtime": 2404.4384722709656, "_timestamp": 1585572320.2831056, "_step": 14}
{"Episode reward": 39.36236027290797, "Episode length": 614, "Policy Loss": -91.28828430175781, "Value Loss": 1753.661865234375, "_runtime": 2405.9937405586243, "_timestamp": 1585572321.838374, "_step": 15}
{"Episode reward": -99.87996334494098, "Episode length": 999, "Policy Loss": -2.842104911804199, "Value Loss": 7.77193021774292, "_runtime": 2407.5371708869934, "_timestamp": 1585572323.3818042, "_step": 16}
{"Episode reward": -99.00071044361988, "Episode length": 999, "Policy Loss": 3.0753228664398193, "Value Loss": 518.011474609375, "_runtime": 2409.062031507492, "_timestamp": 1585572324.9066648, "_step": 17}
{"Episode reward": -99.34996335510294, "Episode length": 999, "Policy Loss": -20.311141967773438, "Value Loss": 450.4322814941406, "_runtime": 2410.6220347881317, "_timestamp": 1585572326.4666681, "_step": 18}
{"Episode reward": -99.00943763948824, "Episode length": 999, "Policy Loss": -33.7379035949707, "Value Loss": 1123.7135009765625, "_runtime": 2412.193797826767, "_timestamp": 1585572328.0384312, "_step": 19}
{"Episode reward": -99.41461685173263, "Episode length": 999, "Policy Loss": -15.9639892578125, "Value Loss": 100.83475494384766, "_runtime": 2413.7549834251404, "_timestamp": 1585572329.5996168, "_step": 20}
{"Episode reward": -99.79415313881333, "Episode length": 999, "Policy Loss": -3.550135612487793, "Value Loss": 57.853336334228516, "_runtime": 2415.375375032425, "_timestamp": 1585572331.2200084, "_step": 21}
{"Episode reward": -99.80219612717488, "Episode length": 999, "Policy Loss": -1.337167501449585, "Value Loss": 541.0304565429688, "_runtime": 2416.1492760181427, "_timestamp": 1585572331.9939094, "_step": 22}
{"Episode reward": 52.99475257982641, "Episode length": 471, "Policy Loss": 6.8510918617248535, "Value Loss": 122.95702362060547, "_runtime": 2417.7297315597534, "_timestamp": 1585572333.574365, "_step": 23}
{"Episode reward": -99.72176345977793, "Episode length": 999, "Policy Loss": 4.770198345184326, "Value Loss": 256.28155517578125, "_runtime": 2419.311388015747, "_timestamp": 1585572335.1560214, "_step": 24}
{"Episode reward": -99.54888700106973, "Episode length": 999, "Policy Loss": 3.9406943321228027, "Value Loss": 77.23976135253906, "_runtime": 2419.9122812747955, "_timestamp": 1585572335.7569146, "_step": 25}
{"Episode reward": 61.951424613222215, "Episode length": 381, "Policy Loss": 8.116140365600586, "Value Loss": 845.5370483398438, "_runtime": 2421.474888086319, "_timestamp": 1585572337.3195214, "_step": 26}
{"Episode reward": -99.82207577377417, "Episode length": 999, "Policy Loss": 5.517482757568359, "Value Loss": 121.1346206665039, "_runtime": 2423.0444729328156, "_timestamp": 1585572338.8891063, "_step": 27}
{"Episode reward": -99.88103186348313, "Episode length": 999, "Policy Loss": 6.728822231292725, "Value Loss": 1343.65185546875, "_runtime": 2424.4910814762115, "_timestamp": 1585572340.3357148, "_step": 28}
{"Episode reward": 3.4000000000012136, "Episode length": 966, "Policy Loss": 3.0378003120422363, "Value Loss": 2123.5146484375, "_runtime": 2425.8113164901733, "_timestamp": 1585572341.6559498, "_step": 29}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": -0.21850205957889557, "Value Loss": 57.486778259277344, "_runtime": 2427.3909165859222, "_timestamp": 1585572343.23555, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.236595630645752, "Value Loss": 94.73768615722656, "_runtime": 2428.429967403412, "_timestamp": 1585572344.2746007, "_step": 31}
{"Episode reward": 33.4999999999995, "Episode length": 665, "Policy Loss": -8.810641288757324, "Value Loss": 216.76670837402344, "_runtime": 2429.983869075775, "_timestamp": 1585572345.8285024, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -13.031414985656738, "Value Loss": 114.37274932861328, "_runtime": 2431.554677248001, "_timestamp": 1585572347.3993106, "_step": 33}
{"Episode reward": -99.78897474296251, "Episode length": 999, "Policy Loss": -14.827316284179688, "Value Loss": 297.0573425292969, "_runtime": 2433.0188398361206, "_timestamp": 1585572348.8634732, "_step": 34}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": -18.834774017333984, "Value Loss": 133.04502868652344, "_runtime": 2434.5953092575073, "_timestamp": 1585572350.4399426, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -23.937824249267578, "Value Loss": 582.4535522460938, "_runtime": 2436.176339149475, "_timestamp": 1585572352.0209725, "_step": 36}
{"Episode reward": -99.82496949173371, "Episode length": 999, "Policy Loss": -22.230222702026367, "Value Loss": 61.562347412109375, "_runtime": 2437.7644839286804, "_timestamp": 1585572353.6091173, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -21.544567108154297, "Value Loss": 174.0903778076172, "_runtime": 2438.6338498592377, "_timestamp": 1585572354.4784832, "_step": 38}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": -16.79183006286621, "Value Loss": 41.02556610107422, "_runtime": 2440.109349012375, "_timestamp": 1585572355.9539824, "_step": 39}
{"Episode reward": 6.2000000000010544, "Episode length": 938, "Policy Loss": -14.312848091125488, "Value Loss": 33.58561706542969, "_runtime": 2441.6820061206818, "_timestamp": 1585572357.5266395, "_step": 40}
{"Episode reward": -99.6241495881216, "Episode length": 999, "Policy Loss": -12.886223793029785, "Value Loss": 14.524470329284668, "_runtime": 2443.211792945862, "_timestamp": 1585572359.0564263, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.734536170959473, "Value Loss": 12.087896347045898, "_runtime": 2444.7811183929443, "_timestamp": 1585572360.6257517, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.097135543823242, "Value Loss": 30.848953247070312, "_runtime": 2446.012064218521, "_timestamp": 1585572361.8566976, "_step": 43}
{"Episode reward": 22.000000000000156, "Episode length": 780, "Policy Loss": -5.686065196990967, "Value Loss": 179.5547637939453, "_runtime": 2447.5807485580444, "_timestamp": 1585572363.425382, "_step": 44}
{"Episode reward": -99.8917194340364, "Episode length": 999, "Policy Loss": -6.562899589538574, "Value Loss": 48.94924545288086, "_runtime": 2448.593591451645, "_timestamp": 1585572364.4382248, "_step": 45}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": -5.000048637390137, "Value Loss": 25.09290885925293, "_runtime": 2450.1577241420746, "_timestamp": 1585572366.0023575, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.356326580047607, "Value Loss": 27.1113224029541, "_runtime": 2451.7195138931274, "_timestamp": 1585572367.5641472, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.70166540145874, "Value Loss": 104.39321899414062, "_runtime": 2453.2582714557648, "_timestamp": 1585572369.1029048, "_step": 48}
{"Episode reward": -99.85184457041183, "Episode length": 999, "Policy Loss": -6.836218357086182, "Value Loss": 3.226778507232666, "_runtime": 2454.828703403473, "_timestamp": 1585572370.6733367, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -8.165650367736816, "Value Loss": 22.670900344848633, "_runtime": 2456.395108938217, "_timestamp": 1585572372.2397423, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.512160301208496, "Value Loss": 86.60399627685547, "_runtime": 2457.9714543819427, "_timestamp": 1585572373.8160877, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.246772766113281, "Value Loss": 56.07914352416992, "_runtime": 2458.8532359600067, "_timestamp": 1585572374.6978693, "_step": 52}
{"Episode reward": 45.599607082828385, "Episode length": 545, "Policy Loss": -7.311913967132568, "Value Loss": 42.88003921508789, "_runtime": 2460.1477596759796, "_timestamp": 1585572375.992393, "_step": 53}
{"Episode reward": 17.90000000000039, "Episode length": 821, "Policy Loss": -6.274476528167725, "Value Loss": 16.282583236694336, "_runtime": 2461.7598135471344, "_timestamp": 1585572377.604447, "_step": 54}
{"Episode reward": -99.81502130180458, "Episode length": 999, "Policy Loss": -5.824866771697998, "Value Loss": 7.6224284172058105, "_runtime": 2462.6683440208435, "_timestamp": 1585572378.5129774, "_step": 55}
{"Episode reward": 41.09999999999944, "Episode length": 589, "Policy Loss": -3.3279576301574707, "Value Loss": 30.746402740478516, "_runtime": 2463.5596401691437, "_timestamp": 1585572379.4042735, "_step": 56}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": -2.7372543811798096, "Value Loss": 45.103912353515625, "_runtime": 2465.1103122234344, "_timestamp": 1585572380.9549456, "_step": 57}
{"Episode reward": -99.80583979636292, "Episode length": 999, "Policy Loss": -3.955350399017334, "Value Loss": 30.251922607421875, "_runtime": 2466.036864042282, "_timestamp": 1585572381.8814974, "_step": 58}
{"Episode reward": 40.21480070017221, "Episode length": 598, "Policy Loss": -3.50494122505188, "Value Loss": 26.146595001220703, "_runtime": 2467.559317111969, "_timestamp": 1585572383.4039505, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.292160511016846, "Value Loss": 5.464818477630615, "_runtime": 2468.2901039123535, "_timestamp": 1585572384.1347373, "_step": 60}
{"Episode reward": 55.09812578819656, "Episode length": 450, "Policy Loss": -3.011096477508545, "Value Loss": 37.41411209106445, "_runtime": 2469.825618982315, "_timestamp": 1585572385.6702523, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.70046854019165, "Value Loss": 2.38063907623291, "_runtime": 2471.3939361572266, "_timestamp": 1585572387.2385695, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -5.541287422180176, "Value Loss": 2.2353718280792236, "_runtime": 2472.910630941391, "_timestamp": 1585572388.7552643, "_step": 63}
{"Episode reward": -99.72364685311774, "Episode length": 999, "Policy Loss": -5.48270845413208, "Value Loss": 0.8674202561378479, "_runtime": 2474.487572669983, "_timestamp": 1585572390.332206, "_step": 64}
{"Episode reward": -99.86703115850547, "Episode length": 999, "Policy Loss": -5.327857971191406, "Value Loss": 0.697297215461731, "_runtime": 2475.7704260349274, "_timestamp": 1585572391.6150594, "_step": 65}
{"Episode reward": 18.700000000000344, "Episode length": 813, "Policy Loss": -4.120332717895508, "Value Loss": 13.343680381774902, "_runtime": 2476.853362083435, "_timestamp": 1585572392.6979954, "_step": 66}
{"Episode reward": 31.299999999999628, "Episode length": 687, "Policy Loss": -3.741166114807129, "Value Loss": 15.803743362426758, "_runtime": 2478.417326450348, "_timestamp": 1585572394.2619598, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.613561630249023, "Value Loss": 0.3936936557292938, "_runtime": 2479.9715785980225, "_timestamp": 1585572395.816212, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.299478054046631, "Value Loss": 0.34696778655052185, "_runtime": 2481.4975423812866, "_timestamp": 1585572397.3421757, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.945354461669922, "Value Loss": 0.29621750116348267, "_runtime": 2483.06405878067, "_timestamp": 1585572398.9086921, "_step": 70}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6621041297912598, "Value Loss": 0.5792703032493591, "_runtime": 2484.6337702274323, "_timestamp": 1585572400.4784036, "_step": 71}
{"Episode reward": -99.80041071325401, "Episode length": 999, "Policy Loss": -3.3624510765075684, "Value Loss": 0.5746914148330688, "_runtime": 2486.242194890976, "_timestamp": 1585572402.0868282, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.105998992919922, "Value Loss": 0.3734514117240906, "_runtime": 2487.812628507614, "_timestamp": 1585572403.6572618, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.857609272003174, "Value Loss": 0.40722811222076416, "_runtime": 2489.3821849823, "_timestamp": 1585572405.2268183, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.587477445602417, "Value Loss": 0.282802015542984, "_runtime": 2490.829692840576, "_timestamp": 1585572406.6743262, "_step": 75}
{"Episode reward": 7.7931375443945115, "Episode length": 923, "Policy Loss": -1.5936075448989868, "Value Loss": 11.739579200744629, "_runtime": 2492.4102873802185, "_timestamp": 1585572408.2549207, "_step": 76}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.3072614669799805, "Value Loss": 1.9067937135696411, "_runtime": 2492.8437356948853, "_timestamp": 1585572408.688369, "_step": 77}
{"Episode reward": 75.79999999999993, "Episode length": 242, "Policy Loss": 1.388706088066101, "Value Loss": 41.4311408996582, "_runtime": 2494.3991959095, "_timestamp": 1585572410.2438293, "_step": 78}
{"Episode reward": -99.84879684187332, "Episode length": 999, "Policy Loss": -1.8200856447219849, "Value Loss": 0.5827877521514893, "_runtime": 2495.9780864715576, "_timestamp": 1585572411.8227198, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.591008186340332, "Value Loss": 0.9571647644042969, "_runtime": 2496.867609977722, "_timestamp": 1585572412.7122433, "_step": 80}
{"Episode reward": 40.49999999999943, "Episode length": 595, "Policy Loss": 0.022167997434735298, "Value Loss": 16.958147048950195, "_runtime": 2498.4317412376404, "_timestamp": 1585572414.2763746, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2563550472259521, "Value Loss": 0.3097645044326782, "_runtime": 2500.0111582279205, "_timestamp": 1585572415.8557916, "_step": 82}
{"Episode reward": -99.83168543465295, "Episode length": 999, "Policy Loss": -1.142894983291626, "Value Loss": 0.4322830140590668, "_runtime": 2500.740253686905, "_timestamp": 1585572416.584887, "_step": 83}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.7330866456031799, "Value Loss": 21.474136352539062, "_runtime": 2502.3171093463898, "_timestamp": 1585572418.1617427, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.034392237663269, "Value Loss": 0.5853980779647827, "_runtime": 2503.883039712906, "_timestamp": 1585572419.727673, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9709229469299316, "Value Loss": 0.24587702751159668, "_runtime": 2504.720212459564, "_timestamp": 1585572420.5648458, "_step": 86}
{"Episode reward": 45.599999999999504, "Episode length": 544, "Policy Loss": 0.6887919306755066, "Value Loss": 18.86346435546875, "_runtime": 2506.284054994583, "_timestamp": 1585572422.1286883, "_step": 87}
{"Episode reward": -99.85710698850313, "Episode length": 999, "Policy Loss": -0.9150334596633911, "Value Loss": 0.12658041715621948, "_runtime": 2506.9228332042694, "_timestamp": 1585572422.7674665, "_step": 88}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 1.074376106262207, "Value Loss": 26.16461753845215, "_runtime": 2508.4511246681213, "_timestamp": 1585572424.295758, "_step": 89}
{"Episode reward": -99.82815136648574, "Episode length": 999, "Policy Loss": -0.7827935218811035, "Value Loss": 0.04707595333456993, "_runtime": 2509.1470308303833, "_timestamp": 1585572424.9916642, "_step": 90}
{"Episode reward": 57.49999999999967, "Episode length": 425, "Policy Loss": 1.0917234420776367, "Value Loss": 23.69448471069336, "_runtime": 2510.6163556575775, "_timestamp": 1585572426.460989, "_step": 91}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.19106942415237427, "Value Loss": 10.309200286865234, "_runtime": 2511.7547965049744, "_timestamp": 1585572427.5994298, "_step": 92}
{"Episode reward": 30.19999999999969, "Episode length": 698, "Policy Loss": 0.49167460203170776, "Value Loss": 14.333883285522461, "_runtime": 2513.042223215103, "_timestamp": 1585572428.8868566, "_step": 93}
{"Episode reward": 15.000000000000554, "Episode length": 850, "Policy Loss": 0.38137286901474, "Value Loss": 11.700364112854004, "_runtime": 2513.6714963912964, "_timestamp": 1585572429.5161297, "_step": 94}
{"Episode reward": 60.966365097462855, "Episode length": 391, "Policy Loss": 1.4379467964172363, "Value Loss": 25.421293258666992, "_runtime": 2514.1645300388336, "_timestamp": 1585572430.0091634, "_step": 95}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 2.040940761566162, "Value Loss": 31.838930130004883, "_runtime": 2515.7075090408325, "_timestamp": 1585572431.5521424, "_step": 96}
{"Episode reward": -99.87023675776878, "Episode length": 999, "Policy Loss": -0.47436287999153137, "Value Loss": 0.05786411464214325, "_runtime": 2516.969589471817, "_timestamp": 1585572432.8142228, "_step": 97}
{"Episode reward": 17.00000000000044, "Episode length": 830, "Policy Loss": 0.5936034917831421, "Value Loss": 12.10008430480957, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535, 0.09387363493442535]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09387363493442535, 0.1725936084985733, 0.43906086683273315, 0.7055281400680542, 0.9719953536987305, 1.2384625673294067, 1.5049299001693726, 1.7713971138000488, 2.0378642082214355, 2.3043315410614014, 2.570798635482788, 2.837265968322754, 3.1037333011627197, 3.3702003955841064, 3.6366677284240723, 3.903134822845459, 4.169602394104004, 4.436069488525391, 4.7025370597839355, 4.969004154205322, 5.235471248626709, 5.501938819885254, 5.768405914306641, 6.034873008728027, 6.301340579986572, 6.567807674407959, 6.834274768829346, 7.100741863250732, 7.367209434509277, 7.633676528930664, 7.900143623352051, 8.166610717773438, 8.433077812194824, 8.699544906616211, 8.966012001037598, 9.232479095458984, 9.498947143554688, 9.765414237976074, 10.031881332397461, 10.298348426818848, 10.564815521240234, 10.831282615661621, 11.097750663757324, 11.364217758178711, 11.630684852600098, 11.897151947021484, 12.163619041442871, 12.430086135864258, 12.696554183959961, 12.963021278381348, 13.229488372802734, 13.495955467224121, 13.762422561645508, 14.028889656066895, 14.295356750488281, 14.561824798583984, 14.828291893005371, 15.094758987426758, 15.361226081848145, 15.627693176269531, 15.894160270690918, 16.160627365112305, 16.427095413208008, 16.693561553955078, 16.96002960205078]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.21768827736377716, -0.20958860218524933, -0.2014889270067215, -0.19338923692703247, -0.18528956174850464, -0.1771898865699768, -0.16909021139144897, -0.16099053621292114, -0.1528908610343933, -0.14479118585586548, -0.13669149577617645, -0.12859182059764862, -0.12049214541912079, -0.11239246279001236, -0.10429278761148453, -0.0961931049823761, -0.08809342980384827, -0.07999375462532043, -0.0718940794467926, -0.06379438936710358, -0.055694714188575745, -0.04759503901004791, -0.03949536383152008, -0.03139568865299225, -0.023296013474464417, -0.01519632339477539, -0.007096648216247559, 0.0010030269622802734, 0.009102702140808105, 0.017202377319335938, 0.025302067399024963, 0.033401742577552795, 0.04150141775608063, 0.04960109293460846, 0.05770076811313629, 0.06580044329166412, 0.07390011847019196, 0.08199979364871979, 0.09009949862957001, 0.09819917380809784, 0.10629884898662567, 0.1143985241651535, 0.12249819934368134, 0.13059787452220917, 0.138697549700737, 0.14679722487926483, 0.15489690005779266, 0.1629965752363205, 0.17109625041484833, 0.17919595539569855, 0.18729563057422638, 0.1953953057527542, 0.20349498093128204, 0.21159465610980988, 0.2196943312883377, 0.22779400646686554, 0.23589368164539337, 0.2439933568239212, 0.25209301710128784, 0.26019275188446045, 0.2682924270629883, 0.2763921022415161, 0.28449177742004395, 0.2925914525985718, 0.3006911277770996]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 5.0, 0.0, 0.0, 0.0, 6.0, 11.0, 12.0, 2.0, 12.0, 20.0, 3.0, 6.0, 322.0, 4.0, 12.0, 11.0, 10.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 5.0, 3.0, 5.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 3.0, 2.0, 0.0, 5.0, 2.0, 1.0, 0.0, 4.0], "bins": [-1.0948036909103394, -1.054735779762268, -1.0146678686141968, -0.9746000170707703, -0.934532105922699, -0.8944641947746277, -0.8543963432312012, -0.8143284320831299, -0.7742605209350586, -0.7341926097869873, -0.694124698638916, -0.6540568470954895, -0.6139889359474182, -0.5739210247993469, -0.5338531732559204, -0.4937852621078491, -0.45371735095977783, -0.41364943981170654, -0.37358152866363525, -0.33351367712020874, -0.29344576597213745, -0.25337785482406616, -0.21331000328063965, -0.17324209213256836, -0.13317418098449707, -0.09310626983642578, -0.05303835868835449, -0.012970447540283203, 0.027097344398498535, 0.06716525554656982, 0.10723316669464111, 0.1473010778427124, 0.1873689889907837, 0.22743690013885498, 0.26750481128692627, 0.30757272243499756, 0.34764063358306885, 0.3877084255218506, 0.4277763366699219, 0.46784424781799316, 0.5079121589660645, 0.5479800701141357, 0.588047981262207, 0.6281158924102783, 0.6681836843490601, 0.7082515954971313, 0.7483195066452026, 0.7883874177932739, 0.8284553289413452, 0.8685232400894165, 0.9085911512374878, 0.9486590623855591, 0.9887269735336304, 1.0287948846817017, 1.068862795829773, 1.1089307069778442, 1.1489983797073364, 1.1890662908554077, 1.229134202003479, 1.2692021131515503, 1.3092700242996216, 1.3493379354476929, 1.3894058465957642, 1.4294737577438354, 1.4695416688919067]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 4.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-2.6433093547821045, -2.5405807495117188, -2.437852144241333, -2.3351235389709473, -2.2323949337005615, -2.129666328430176, -2.026937961578369, -1.9242092370986938, -1.821480631828308, -1.7187520265579224, -1.6160234212875366, -1.5132948160171509, -1.4105663299560547, -1.307837724685669, -1.2051091194152832, -1.1023805141448975, -0.9996519088745117, -0.896923303604126, -0.7941946983337402, -0.6914660930633545, -0.5887374877929688, -0.486008882522583, -0.38328027725219727, -0.2805516719818115, -0.17782330513000488, -0.07509469985961914, 0.0276339054107666, 0.13036251068115234, 0.23309111595153809, 0.33581972122192383, 0.43854832649230957, 0.5412769317626953, 0.644005537033081, 0.7467341423034668, 0.8494627475738525, 0.9521913528442383, 1.054919958114624, 1.1576485633850098, 1.2603771686553955, 1.3631055355072021, 1.465834379196167, 1.5685627460479736, 1.6712915897369385, 1.7740199565887451, 1.87674880027771, 1.9794771671295166, 2.0822060108184814, 2.184934377670288, 2.2876627445220947, 2.3903915882110596, 2.493119955062866, 2.595848798751831, 2.6985771656036377, 2.8013060092926025, 2.904034376144409, 3.006763219833374, 3.1094915866851807, 3.2122204303741455, 3.314948797225952, 3.417677640914917, 3.5204060077667236, 3.6231348514556885, 3.725863218307495, 3.82859206199646, 3.9313204288482666]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 5.0, 22.0, 11.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.1871998310089111, -1.154618263244629, -1.1220366954803467, -1.0894551277160645, -1.0568735599517822, -1.0242918729782104, -0.9917103052139282, -0.959128737449646, -0.9265471696853638, -0.8939656019210815, -0.8613840341567993, -0.8288024067878723, -0.7962208390235901, -0.7636392712593079, -0.7310576438903809, -0.6984760761260986, -0.6658945083618164, -0.6333129405975342, -0.600731372833252, -0.568149745464325, -0.5355681777000427, -0.5029866099357605, -0.4704049825668335, -0.43782341480255127, -0.40524184703826904, -0.3726602792739868, -0.3400787115097046, -0.3074970841407776, -0.27491551637649536, -0.24233394861221313, -0.20975232124328613, -0.1771707534790039, -0.14458918571472168, -0.11200761795043945, -0.07942605018615723, -0.046844482421875, -0.014262914657592773, 0.018318772315979004, 0.05090034008026123, 0.08348190784454346, 0.11606347560882568, 0.1486450433731079, 0.18122661113739014, 0.21380817890167236, 0.24638986587524414, 0.27897143363952637, 0.3115530014038086, 0.3441345691680908, 0.37671613693237305, 0.4092977046966553, 0.4418792724609375, 0.4744608402252197, 0.507042407989502, 0.5396240949630737, 0.572205662727356, 0.6047872304916382, 0.6373687982559204, 0.6699503660202026, 0.7025319337844849, 0.7351135015487671, 0.7676951885223389, 0.8002767562866211, 0.8328583240509033, 0.8654398918151855, 0.8980214595794678]}, "_runtime": 2518.4583008289337, "_timestamp": 1585572434.3029342, "_step": 98}
{"Episode reward": 0.4960989892496599, "Episode length": 996, "Policy Loss": 0.46549302339553833, "Value Loss": 10.087321281433105, "_runtime": 2519.336927652359, "_timestamp": 1585572435.181561, "_step": 99}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 0.9494176506996155, "Value Loss": 18.214784622192383, "_runtime": 2520.1457693576813, "_timestamp": 1585572435.9904027, "_step": 100}
{"Episode reward": 48.59999999999955, "Episode length": 514, "Policy Loss": 0.9996993541717529, "Value Loss": 19.195354461669922, "_runtime": 2520.783494949341, "_timestamp": 1585572436.6281283, "_step": 101}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 1.24888277053833, "Value Loss": 24.790559768676758, "_runtime": 2521.9731199741364, "_timestamp": 1585572437.8177533, "_step": 102}
{"Episode reward": 21.57008609734494, "Episode length": 785, "Policy Loss": 0.30952948331832886, "Value Loss": 12.568572998046875, "_runtime": 2523.5078976154327, "_timestamp": 1585572439.352531, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8038349151611328, "Value Loss": 0.07844420522451401, "_runtime": 2524.89785695076, "_timestamp": 1585572440.7424903, "_step": 104}
{"Episode reward": 7.5000000000009805, "Episode length": 925, "Policy Loss": 0.046627022325992584, "Value Loss": 10.879623413085938, "_runtime": 2526.4383924007416, "_timestamp": 1585572442.2830257, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0061267614364624, "Value Loss": 0.11791550368070602, "_runtime": 2527.669976234436, "_timestamp": 1585572443.5146096, "_step": 106}
{"Episode reward": 21.19814745038768, "Episode length": 789, "Policy Loss": -0.14494898915290833, "Value Loss": 12.645711898803711, "_runtime": 2529.219519138336, "_timestamp": 1585572445.0641525, "_step": 107}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2125046253204346, "Value Loss": 0.06822416931390762, "_runtime": 2530.503624200821, "_timestamp": 1585572446.3482575, "_step": 108}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": -0.3538660705089569, "Value Loss": 12.119447708129883, "_runtime": 2532.0512685775757, "_timestamp": 1585572447.895902, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3366745710372925, "Value Loss": 0.041883111000061035, "_runtime": 2533.603672981262, "_timestamp": 1585572449.4483063, "_step": 110}
{"Episode reward": -99.84660495556751, "Episode length": 999, "Policy Loss": -1.4169541597366333, "Value Loss": 0.07563010603189468, "_runtime": 2534.468589782715, "_timestamp": 1585572450.3132231, "_step": 111}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": -0.04262246564030647, "Value Loss": 18.219961166381836, "_runtime": 2535.795336484909, "_timestamp": 1585572451.6399698, "_step": 112}
{"Episode reward": 16.51679615005898, "Episode length": 836, "Policy Loss": -0.4913337826728821, "Value Loss": 11.881954193115234, "_runtime": 2536.9373528957367, "_timestamp": 1585572452.7819862, "_step": 113}
{"Episode reward": 27.099999999999866, "Episode length": 729, "Policy Loss": -0.027002787217497826, "Value Loss": 13.620640754699707, "_runtime": 2537.5595574378967, "_timestamp": 1585572453.4041908, "_step": 114}
{"Episode reward": 60.19999999999971, "Episode length": 398, "Policy Loss": 0.8880427479743958, "Value Loss": 24.79969596862793, "_runtime": 2539.1043384075165, "_timestamp": 1585572454.9489717, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2092996835708618, "Value Loss": 0.03788020834326744, "_runtime": 2540.5178990364075, "_timestamp": 1585572456.3625324, "_step": 116}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": -0.3071100413799286, "Value Loss": 10.720911026000977, "_runtime": 2541.5791070461273, "_timestamp": 1585572457.4237404, "_step": 117}
{"Episode reward": 29.599999999999724, "Episode length": 704, "Policy Loss": 0.03550004959106445, "Value Loss": 14.02407455444336, "_runtime": 2542.90096616745, "_timestamp": 1585572458.7455995, "_step": 118}
{"Episode reward": 15.123633391783187, "Episode length": 850, "Policy Loss": -0.10859167575836182, "Value Loss": 11.457401275634766, "_runtime": 2544.460895061493, "_timestamp": 1585572460.3055284, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9501991271972656, "Value Loss": 0.1142256036400795, "_runtime": 2545.9880516529083, "_timestamp": 1585572461.832685, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9068599343299866, "Value Loss": 0.34773001074790955, "_runtime": 2547.219361782074, "_timestamp": 1585572463.0639951, "_step": 121}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": 0.07461294531822205, "Value Loss": 12.543089866638184, "_runtime": 2548.5168104171753, "_timestamp": 1585572464.3614438, "_step": 122}
{"Episode reward": 16.099466237053775, "Episode length": 840, "Policy Loss": -0.037241380661726, "Value Loss": 11.574564933776855, "_runtime": 2550.0780251026154, "_timestamp": 1585572465.9226584, "_step": 123}
{"Episode reward": -99.81204408556083, "Episode length": 999, "Policy Loss": -1.1070163249969482, "Value Loss": 0.027920352295041084, "_runtime": 2550.699427843094, "_timestamp": 1585572466.5440612, "_step": 124}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.0376269817352295, "Value Loss": 24.70496368408203, "_runtime": 2551.715257167816, "_timestamp": 1585572467.5598905, "_step": 125}
{"Episode reward": 34.392810767515954, "Episode length": 657, "Policy Loss": -0.06266170740127563, "Value Loss": 14.774336814880371, "_runtime": 2552.4751257896423, "_timestamp": 1585572468.3197591, "_step": 126}
{"Episode reward": 52.5999999999996, "Episode length": 474, "Policy Loss": 0.7654375433921814, "Value Loss": 20.29627799987793, "_runtime": 2553.989258289337, "_timestamp": 1585572469.8338916, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3321961164474487, "Value Loss": 0.03551369905471802, "_runtime": 2554.505275964737, "_timestamp": 1585572470.3499093, "_step": 128}
{"Episode reward": 68.19999999999982, "Episode length": 318, "Policy Loss": 1.10955011844635, "Value Loss": 29.969097137451172, "_runtime": 2555.408801317215, "_timestamp": 1585572471.2534347, "_step": 129}
{"Episode reward": 40.43091451972666, "Episode length": 596, "Policy Loss": 0.16568085551261902, "Value Loss": 16.086505889892578, "_runtime": 2556.954619407654, "_timestamp": 1585572472.7992527, "_step": 130}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4065766334533691, "Value Loss": 0.04784197732806206, "_runtime": 2558.4461104869843, "_timestamp": 1585572474.2907438, "_step": 131}
{"Episode reward": -99.82078745514015, "Episode length": 999, "Policy Loss": -1.4236729145050049, "Value Loss": 0.1568516045808792, "_runtime": 2559.3708984851837, "_timestamp": 1585572475.2155318, "_step": 132}
{"Episode reward": 42.89954348467237, "Episode length": 572, "Policy Loss": -0.09020859003067017, "Value Loss": 16.6170654296875, "_runtime": 2560.921764612198, "_timestamp": 1585572476.766398, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4751001596450806, "Value Loss": 0.061900388449430466, "_runtime": 2561.6150448322296, "_timestamp": 1585572477.4596782, "_step": 134}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": 0.2801794707775116, "Value Loss": 21.571086883544922, "_runtime": 2562.369312763214, "_timestamp": 1585572478.213946, "_step": 135}
{"Episode reward": 51.59999999999959, "Episode length": 484, "Policy Loss": -0.025426233187317848, "Value Loss": 19.07843017578125, "_runtime": 2563.9308681488037, "_timestamp": 1585572479.7755015, "_step": 136}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5932284593582153, "Value Loss": 0.06627396494150162, "_runtime": 2565.4427201747894, "_timestamp": 1585572481.2873535, "_step": 137}
{"Episode reward": -99.84518261886993, "Episode length": 999, "Policy Loss": -1.6377533674240112, "Value Loss": 0.056842852383852005, "_runtime": 2566.661392688751, "_timestamp": 1585572482.506026, "_step": 138}
{"Episode reward": 19.5000000000003, "Episode length": 805, "Policy Loss": -0.7011297941207886, "Value Loss": 11.583578109741211, "_runtime": 2568.2313001155853, "_timestamp": 1585572484.0759335, "_step": 139}
{"Episode reward": -99.80126123428205, "Episode length": 999, "Policy Loss": -1.7092320919036865, "Value Loss": 0.06494171917438507, "_runtime": 2569.753242969513, "_timestamp": 1585572485.5978763, "_step": 140}
{"Episode reward": 1.9751832209540368, "Episode length": 983, "Policy Loss": -0.9996316432952881, "Value Loss": 9.454521179199219, "_runtime": 2571.295870780945, "_timestamp": 1585572487.1405041, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7585299015045166, "Value Loss": 0.06593883782625198, "_runtime": 2572.858834505081, "_timestamp": 1585572488.7034678, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7431726455688477, "Value Loss": 0.054029181599617004, "_runtime": 2574.0024633407593, "_timestamp": 1585572489.8470967, "_step": 143}
{"Episode reward": 27.39999999999985, "Episode length": 726, "Policy Loss": -0.6957735419273376, "Value Loss": 12.691324234008789, "_runtime": 2574.556921005249, "_timestamp": 1585572490.4015543, "_step": 144}
{"Episode reward": 66.6999999999998, "Episode length": 333, "Policy Loss": 1.450742483139038, "Value Loss": 28.123096466064453, "_runtime": 2575.8635835647583, "_timestamp": 1585572491.708217, "_step": 145}
{"Episode reward": 16.30000000000048, "Episode length": 837, "Policy Loss": -0.7670196294784546, "Value Loss": 10.653139114379883, "_runtime": 2577.4074051380157, "_timestamp": 1585572493.2520385, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.611060619354248, "Value Loss": 0.05124528706073761, "_runtime": 2577.871190071106, "_timestamp": 1585572493.7158234, "_step": 147}
{"Episode reward": 70.43771877139793, "Episode length": 296, "Policy Loss": 0.7142350077629089, "Value Loss": 30.26613998413086, "_runtime": 2579.4089727401733, "_timestamp": 1585572495.253606, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4952788352966309, "Value Loss": 0.09437540173530579, "_runtime": 2580.810586452484, "_timestamp": 1585572496.6552198, "_step": 149}
{"Episode reward": 10.69973714351734, "Episode length": 894, "Policy Loss": -0.6462330222129822, "Value Loss": 10.137884140014648, "_runtime": 2581.628170967102, "_timestamp": 1585572497.4728043, "_step": 150}
{"Episode reward": 45.599999999999504, "Episode length": 544, "Policy Loss": -0.004928364418447018, "Value Loss": 17.7947998046875, "_runtime": 2583.2191200256348, "_timestamp": 1585572499.0637534, "_step": 151}
{"Episode reward": -99.82823562770942, "Episode length": 999, "Policy Loss": -1.398622751235962, "Value Loss": 0.0656777173280716, "_runtime": 2584.7684354782104, "_timestamp": 1585572500.6130688, "_step": 152}
{"Episode reward": -99.80273185372212, "Episode length": 999, "Policy Loss": -1.3849085569381714, "Value Loss": 0.05314333736896515, "_runtime": 2586.28209900856, "_timestamp": 1585572502.1267323, "_step": 153}
{"Episode reward": -99.85946232229331, "Episode length": 999, "Policy Loss": -1.358246088027954, "Value Loss": 0.05544952675700188, "_runtime": 2587.253734588623, "_timestamp": 1585572503.098368, "_step": 154}
{"Episode reward": 39.00667194724024, "Episode length": 610, "Policy Loss": -0.13061761856079102, "Value Loss": 14.48624038696289, "_runtime": 2588.825034379959, "_timestamp": 1585572504.6696677, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2338871955871582, "Value Loss": 0.038766488432884216, "_runtime": 2590.2439258098602, "_timestamp": 1585572506.0885592, "_step": 156}
{"Episode reward": 9.500000000000867, "Episode length": 905, "Policy Loss": -0.33492758870124817, "Value Loss": 9.813148498535156, "_runtime": 2591.767107486725, "_timestamp": 1585572507.6117408, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0951602458953857, "Value Loss": 0.036241427063941956, "_runtime": 2593.3354001045227, "_timestamp": 1585572509.1800334, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0277628898620605, "Value Loss": 0.02715478464961052, "_runtime": 2594.8881204128265, "_timestamp": 1585572510.7327538, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9485576152801514, "Value Loss": 0.026942182332277298, "_runtime": 2595.7392830848694, "_timestamp": 1585572511.5839164, "_step": 160}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 0.46105265617370605, "Value Loss": 16.467870712280273, "_runtime": 2596.759243249893, "_timestamp": 1585572512.6038766, "_step": 161}
{"Episode reward": 34.9402926862234, "Episode length": 651, "Policy Loss": 0.4258614182472229, "Value Loss": 14.222189903259277, "_runtime": 2597.3207166194916, "_timestamp": 1585572513.16535, "_step": 162}
{"Episode reward": 66.0999999999998, "Episode length": 339, "Policy Loss": 1.5946041345596313, "Value Loss": 28.615907669067383, "_runtime": 2597.816437482834, "_timestamp": 1585572513.6610708, "_step": 163}
{"Episode reward": 68.27041234970075, "Episode length": 318, "Policy Loss": 1.7831401824951172, "Value Loss": 29.910484313964844, "_runtime": 2599.3501732349396, "_timestamp": 1585572515.1948066, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0068358182907104, "Value Loss": 0.04776651784777641, "_runtime": 2600.8547942638397, "_timestamp": 1585572516.6994276, "_step": 165}
{"Episode reward": -99.808120969309, "Episode length": 999, "Policy Loss": -1.1113905906677246, "Value Loss": 0.17107102274894714, "_runtime": 2601.494998693466, "_timestamp": 1585572517.339632, "_step": 166}
{"Episode reward": 57.29999999999967, "Episode length": 427, "Policy Loss": 0.6909251809120178, "Value Loss": 22.138336181640625, "_runtime": 2602.5236485004425, "_timestamp": 1585572518.3682818, "_step": 167}
{"Episode reward": 34.678966937958634, "Episode length": 654, "Policy Loss": -0.10200957953929901, "Value Loss": 14.120789527893066, "_runtime": 2604.0660893917084, "_timestamp": 1585572519.9107227, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2588697671890259, "Value Loss": 0.05408274382352829, "_runtime": 2605.5754125118256, "_timestamp": 1585572521.4200459, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2328323125839233, "Value Loss": 0.1093001738190651, "_runtime": 2606.505345106125, "_timestamp": 1585572522.3499784, "_step": 170}
{"Episode reward": 41.69999999999945, "Episode length": 583, "Policy Loss": 0.07757459580898285, "Value Loss": 16.52208137512207, "_runtime": 2607.5991837978363, "_timestamp": 1585572523.4438171, "_step": 171}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.11490140855312347, "Value Loss": 13.503251075744629, "_runtime": 2608.4267604351044, "_timestamp": 1585572524.2713938, "_step": 172}
{"Episode reward": 47.49751067720307, "Episode length": 526, "Policy Loss": 0.3571469783782959, "Value Loss": 17.433942794799805, "_runtime": 2609.9680182933807, "_timestamp": 1585572525.8126516, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.920727550983429, "Value Loss": 0.024937257170677185, "_runtime": 2611.5041637420654, "_timestamp": 1585572527.348797, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7963955998420715, "Value Loss": 0.1096261739730835, "_runtime": 2613.022989988327, "_timestamp": 1585572528.8676233, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7002402544021606, "Value Loss": 0.02072504535317421, "_runtime": 2614.100217819214, "_timestamp": 1585572529.9448512, "_step": 176}
{"Episode reward": 31.499999999999616, "Episode length": 685, "Policy Loss": 0.48455360531806946, "Value Loss": 13.27959156036377, "_runtime": 2615.669052362442, "_timestamp": 1585572531.5136857, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5448814630508423, "Value Loss": 0.0313219279050827, "_runtime": 2617.2350018024445, "_timestamp": 1585572533.0796351, "_step": 178}
{"Episode reward": -99.84664663225273, "Episode length": 999, "Policy Loss": -0.4866097569465637, "Value Loss": 0.02664768509566784, "_runtime": 2617.9676053524017, "_timestamp": 1585572533.8122387, "_step": 179}
{"Episode reward": 53.29999999999961, "Episode length": 467, "Policy Loss": 1.2858152389526367, "Value Loss": 18.604290008544922, "_runtime": 2619.3738029003143, "_timestamp": 1585572535.2184362, "_step": 180}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.5150247812271118, "Value Loss": 9.482017517089844, "_runtime": 2620.0151028633118, "_timestamp": 1585572535.8597362, "_step": 181}
{"Episode reward": 60.79999999999972, "Episode length": 392, "Policy Loss": 1.2662006616592407, "Value Loss": 23.603002548217773, "_runtime": 2620.8869485855103, "_timestamp": 1585572536.731582, "_step": 182}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 0.5573509931564331, "Value Loss": 15.827253341674805, "_runtime": 2622.450412273407, "_timestamp": 1585572538.2950456, "_step": 183}
{"Episode reward": -99.86725725866714, "Episode length": 999, "Policy Loss": -0.8891334533691406, "Value Loss": 0.021376468241214752, "_runtime": 2623.95095205307, "_timestamp": 1585572539.7955854, "_step": 184}
{"Episode reward": -99.85046513713756, "Episode length": 999, "Policy Loss": -1.0356550216674805, "Value Loss": 0.13374409079551697, "_runtime": 2625.4775013923645, "_timestamp": 1585572541.3221347, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1761395931243896, "Value Loss": 0.11153293401002884, "_runtime": 2627.0451469421387, "_timestamp": 1585572542.8897803, "_step": 186}
{"Episode reward": -99.80511923767486, "Episode length": 999, "Policy Loss": -1.2836288213729858, "Value Loss": 0.11279771476984024, "_runtime": 2628.604950904846, "_timestamp": 1585572544.4495842, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2962409257888794, "Value Loss": 0.08869796246290207, "_runtime": 2630.1660187244415, "_timestamp": 1585572546.010652, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3186746835708618, "Value Loss": 0.19955679774284363, "_runtime": 2630.846842288971, "_timestamp": 1585572546.6914756, "_step": 189}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 0.661510169506073, "Value Loss": 22.966794967651367, "_runtime": 2632.0813200473785, "_timestamp": 1585572547.9259534, "_step": 190}
{"Episode reward": 21.60000000000018, "Episode length": 784, "Policy Loss": -0.08963195979595184, "Value Loss": 11.77082633972168, "_runtime": 2633.368011713028, "_timestamp": 1585572549.212645, "_step": 191}
{"Episode reward": 18.17949571721293, "Episode length": 820, "Policy Loss": 0.015998048707842827, "Value Loss": 11.588887214660645, "_runtime": 2633.897126197815, "_timestamp": 1585572549.7417595, "_step": 192}
{"Episode reward": 65.39999999999978, "Episode length": 346, "Policy Loss": 1.2847459316253662, "Value Loss": 26.089336395263672, "_runtime": 2635.4415900707245, "_timestamp": 1585572551.2862234, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7546964287757874, "Value Loss": 0.017559843137860298, "_runtime": 2636.9892551898956, "_timestamp": 1585572552.8338885, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6781432628631592, "Value Loss": 0.0309788566082716, "_runtime": 2638.4908530712128, "_timestamp": 1585572554.3354864, "_step": 195}
{"Episode reward": -99.74211481697718, "Episode length": 999, "Policy Loss": -0.6074638366699219, "Value Loss": 0.009348968975245953, "_runtime": 2640.05233502388, "_timestamp": 1585572555.8969684, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5249137282371521, "Value Loss": 0.09355039149522781, "_runtime": 2641.6264584064484, "_timestamp": 1585572557.4710917, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5084132552146912, "Value Loss": 0.006813642103224993, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375, -0.0020636755507439375]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.34228965640068054, -0.33690914511680603, -0.33152860403060913, -0.3261480927467346, -0.3207675814628601, -0.3153870403766632, -0.3100065290927887, -0.3046260178089142, -0.2992454767227173, -0.2938649654388428, -0.28848445415496826, -0.28310394287109375, -0.27772340178489685, -0.27234289050102234, -0.26696234941482544, -0.2615818381309509, -0.2562013268470764, -0.2508208155632019, -0.2454402893781662, -0.2400597631931305, -0.23467925190925598, -0.22929872572422028, -0.22391819953918457, -0.21853768825531006, -0.21315716207027435, -0.20777663588523865, -0.20239612460136414, -0.19701559841632843, -0.19163507223129272, -0.1862545609474182, -0.1808740347623825, -0.175493523478508, -0.1701129972934723, -0.16473247110843658, -0.15935195982456207, -0.15397143363952637, -0.14859092235565186, -0.14321039617061615, -0.13782986998558044, -0.13244935870170593, -0.12706883251667023, -0.12168830633163452, -0.11630779504776001, -0.1109272688627243, -0.1055467426776886, -0.10016623139381409, -0.09478570520877838, -0.08940517902374268, -0.08402466773986816, -0.07864415645599365, -0.07326361536979675, -0.06788310408592224, -0.06250259280204773, -0.05712205171585083, -0.05174154043197632, -0.04636102914810181, -0.04098048806190491, -0.035599976778030396, -0.030219465494155884, -0.024838954210281372, -0.019458413124084473, -0.014077901840209961, -0.00869739055633545, -0.00331684947013855, 0.002063661813735962]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0066122799180448055, -0.006437314674258232, -0.006262349896132946, -0.006087384652346373, -0.005912419408559799, -0.005737454164773226, -0.005562488920986652, -0.005387524142861366, -0.005212558899074793, -0.0050375936552882195, -0.004862628877162933, -0.00468766363337636, -0.0045126983895897865, -0.004337733145803213, -0.00416276790201664, -0.003987803123891354, -0.00381283788010478, -0.003637872636318207, -0.003462907625362277, -0.0032879426144063473, -0.003112977370619774, -0.0029380121268332005, -0.0027630471158772707, -0.002588082104921341, -0.0024131168611347675, -0.002238151617348194, -0.0020631863735616207, -0.0018882215954363346, -0.0017132563516497612, -0.0015382911078631878, -0.0013633263297379017, -0.0011883610859513283, -0.0010133958421647549, -0.0008384305983781815, -0.000663465354591608, -0.0004885005764663219, -0.00031353533267974854, -0.00013857008889317513, 3.639468923211098e-05, 0.0002113599330186844, 0.0003863251768052578, 0.0005612904205918312, 0.0007362556643784046, 0.0009112204425036907, 0.0010861856862902641, 0.0012611509300768375, 0.0014361157082021236, 0.0016110814176499844, 0.0017860461957752705, 0.0019610109739005566, 0.0021359766833484173, 0.0023109414614737034, 0.002485907170921564, 0.00266087194904685, 0.0028358367271721363, 0.003010802436619997, 0.003185767214745283, 0.0033607319928705692, 0.00353569770231843, 0.003710662480443716, 0.003885627258569002, 0.004060592968016863, 0.004235557746142149, 0.00441052345559001, 0.004585488233715296]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 4.0, 2.0, 0.0, 0.0, 1.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 4.0, 2.0, 9.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 7.0, 7.0, 11.0, 7.0, 0.0, 329.0, 3.0, 3.0, 15.0, 14.0, 4.0, 10.0, 6.0, 13.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 2.0], "bins": [-0.031070280820131302, -0.03024602308869362, -0.029421765357255936, -0.028597507625818253, -0.02777324989438057, -0.026948992162942886, -0.026124736294150352, -0.02530047856271267, -0.024476220831274986, -0.023651963099837303, -0.02282770536839962, -0.022003449499607086, -0.021179191768169403, -0.02035493403673172, -0.019530676305294037, -0.018706418573856354, -0.01788216084241867, -0.017057903110980988, -0.016233645379543304, -0.015409387648105621, -0.014585129916667938, -0.013760874047875404, -0.012936616316437721, -0.012112358585000038, -0.011288100853562355, -0.010463843122124672, -0.009639585390686989, -0.008815327659249306, -0.007991071790456772, -0.007166814059019089, -0.006342556327581406, -0.0055182985961437225, -0.004694040864706039, -0.0038697831332683563, -0.0030455254018306732, -0.00222126767039299, -0.001397009938955307, -0.0005727540701627731, 0.0002515055239200592, 0.0010757632553577423, 0.0019000209867954254, 0.00272427499294281, 0.003548532724380493, 0.004372790455818176, 0.005197048187255859, 0.0060213059186935425, 0.006845563650131226, 0.007669821381568909, 0.008494079113006592, 0.009318336844444275, 0.010142594575881958, 0.010966852307319641, 0.011791110038757324, 0.012615367770195007, 0.01343962550163269, 0.014263883233070374, 0.015088137239217758, 0.01591239497065544, 0.016736652702093124, 0.017560910433530807, 0.01838516816496849, 0.019209425896406174, 0.020033683627843857, 0.02085794135928154, 0.021682199090719223]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 1.0, 6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08637767285108566, -0.08356141299009323, -0.0807451531291008, -0.07792890071868896, -0.07511264085769653, -0.0722963809967041, -0.06948012113571167, -0.06666386127471924, -0.0638476088643074, -0.06103134900331497, -0.05821508914232254, -0.05539883300662041, -0.052582573145627975, -0.04976631700992584, -0.04695005714893341, -0.04413380101323128, -0.041317541152238846, -0.038501281291246414, -0.03568502515554428, -0.03286876529455185, -0.030052509158849716, -0.027236249297857285, -0.02441999316215515, -0.02160373330116272, -0.018787473440170288, -0.015971213579177856, -0.013154961168766022, -0.01033870130777359, -0.0075224414467811584, -0.004706181585788727, -0.001889929175376892, 0.0009263306856155396, 0.003742590546607971, 0.006558850407600403, 0.009375110268592834, 0.01219136267900467, 0.0150076225399971, 0.017823882400989532, 0.020640142261981964, 0.0234563946723938, 0.02627265453338623, 0.029088914394378662, 0.031905174255371094, 0.034721434116363525, 0.03753768652677536, 0.04035394638776779, 0.04317020624876022, 0.045986466109752655, 0.04880272597074509, 0.05161898583173752, 0.05443524569272995, 0.05725149065256119, 0.06006775051355362, 0.06288401037454605, 0.06570027023553848, 0.06851653009653091, 0.07133278995752335, 0.07414904981851578, 0.07696530967950821, 0.07978156954050064, 0.08259781450033188, 0.08541407436132431, 0.08823033422231674, 0.09104659408330917, 0.0938628539443016]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 5.0, 14.0, 6.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02669847384095192, -0.026062732562422752, -0.025426991283893585, -0.024791251868009567, -0.0241555105894804, -0.023519769310951233, -0.022884028032422066, -0.0222482867538929, -0.02161254547536373, -0.020976804196834564, -0.020341064780950546, -0.01970532350242138, -0.019069582223892212, -0.018433840945363045, -0.017798099666833878, -0.01716236025094986, -0.016526617109775543, -0.015890877693891525, -0.015255136415362358, -0.014619395136833191, -0.013983653858304024, -0.013347913511097431, -0.012712172232568264, -0.012076430954039097, -0.011440690606832504, -0.010804949328303337, -0.01016920804977417, -0.009533466771245003, -0.008897725492715836, -0.008261986076831818, -0.0076262447983026505, -0.006990503519773483, -0.006354762241244316, -0.005719020962715149, -0.005083279684185982, -0.004447538405656815, -0.0038117989897727966, -0.0031760577112436295, -0.0025403164327144623, -0.001904575154185295, -0.001268833875656128, -0.0006330925971269608, 2.64681875705719e-06, 0.0006383880972862244, 0.0012741293758153915, 0.0019098706543445587, 0.002545611932873726, 0.003181353211402893, 0.003817092627286911, 0.004452833905816078, 0.005088575184345245, 0.005724318325519562, 0.00636005774140358, 0.006995797157287598, 0.007631540298461914, 0.008267279714345932, 0.008903022855520248, 0.009538762271404266, 0.010174501687288284, 0.0108102448284626, 0.011445984244346619, 0.012081727385520935, 0.012717466801404953, 0.01335320994257927, 0.013988949358463287]}, "_runtime": 2643.171408176422, "_timestamp": 1585572559.0160415, "_step": 198}
{"Episode reward": -99.80458520427206, "Episode length": 999, "Policy Loss": -0.46601516008377075, "Value Loss": 0.009329224936664104, "_runtime": 2644.742463350296, "_timestamp": 1585572560.5870967, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4339255094528198, "Value Loss": 0.004107608459889889, "_runtime": 2645.273462295532, "_timestamp": 1585572561.1180956, "_step": 200}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 1.8597211837768555, "Value Loss": 27.906530380249023, "_runtime": 2646.220990419388, "_timestamp": 1585572562.0656238, "_step": 201}
{"Episode reward": 39.49999999999942, "Episode length": 605, "Policy Loss": 0.734420895576477, "Value Loss": 14.931193351745605, "_runtime": 2647.251307249069, "_timestamp": 1585572563.0959406, "_step": 202}
{"Episode reward": 35.19922547452093, "Episode length": 649, "Policy Loss": 0.5906159281730652, "Value Loss": 13.768207550048828, "_runtime": 2648.7690846920013, "_timestamp": 1585572564.613718, "_step": 203}
{"Episode reward": -99.80300255454937, "Episode length": 999, "Policy Loss": -0.633253276348114, "Value Loss": 0.013272726908326149, "_runtime": 2650.1360244750977, "_timestamp": 1585572565.9806578, "_step": 204}
{"Episode reward": 10.700000000000799, "Episode length": 893, "Policy Loss": 0.13354343175888062, "Value Loss": 9.250513076782227, "_runtime": 2650.963145494461, "_timestamp": 1585572566.8077788, "_step": 205}
{"Episode reward": 47.261990788205985, "Episode length": 528, "Policy Loss": 0.7115200757980347, "Value Loss": 16.56519889831543, "_runtime": 2652.5190320014954, "_timestamp": 1585572568.3636653, "_step": 206}
{"Episode reward": -99.83975985981384, "Episode length": 999, "Policy Loss": -0.8843142986297607, "Value Loss": 0.04844556376338005, "_runtime": 2654.0705976486206, "_timestamp": 1585572569.915231, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.939356803894043, "Value Loss": 0.04296790808439255, "_runtime": 2655.629863500595, "_timestamp": 1585572571.4744968, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9897252321243286, "Value Loss": 0.048285648226737976, "_runtime": 2657.1876616477966, "_timestamp": 1585572573.032295, "_step": 209}
{"Episode reward": -99.80029309429088, "Episode length": 999, "Policy Loss": -1.017342209815979, "Value Loss": 0.08725465089082718, "_runtime": 2658.1528408527374, "_timestamp": 1585572573.9974742, "_step": 210}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 0.2794732451438904, "Value Loss": 15.226301193237305, "_runtime": 2659.7065217494965, "_timestamp": 1585572575.551155, "_step": 211}
{"Episode reward": -99.87502156533161, "Episode length": 999, "Policy Loss": -0.9608227014541626, "Value Loss": 0.07165436446666718, "_runtime": 2661.268844127655, "_timestamp": 1585572577.1134775, "_step": 212}
{"Episode reward": -99.7354609258459, "Episode length": 999, "Policy Loss": -0.8882256150245667, "Value Loss": 0.06295795738697052, "_runtime": 2662.8079028129578, "_timestamp": 1585572578.6525362, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7988511323928833, "Value Loss": 0.022382615134119987, "_runtime": 2664.374727010727, "_timestamp": 1585572580.2193604, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6948076486587524, "Value Loss": 0.02998920902609825, "_runtime": 2665.574517726898, "_timestamp": 1585572581.419151, "_step": 215}
{"Episode reward": 23.694295996055075, "Episode length": 764, "Policy Loss": 0.4497980773448944, "Value Loss": 11.070801734924316, "_runtime": 2667.026895046234, "_timestamp": 1585572582.8715284, "_step": 216}
{"Episode reward": 7.698142462597261, "Episode length": 924, "Policy Loss": 0.2868383824825287, "Value Loss": 9.791626930236816, "_runtime": 2668.593790769577, "_timestamp": 1585572584.438424, "_step": 217}
{"Episode reward": -99.62344916760782, "Episode length": 999, "Policy Loss": -0.415637731552124, "Value Loss": 0.004319181200116873, "_runtime": 2669.1557998657227, "_timestamp": 1585572585.0004332, "_step": 218}
{"Episode reward": 65.69999999999979, "Episode length": 343, "Policy Loss": 1.7193117141723633, "Value Loss": 24.553958892822266, "_runtime": 2669.677852869034, "_timestamp": 1585572585.5224862, "_step": 219}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 1.927839994430542, "Value Loss": 26.608142852783203, "_runtime": 2670.3505487442017, "_timestamp": 1585572586.195182, "_step": 220}
{"Episode reward": 57.89999999999968, "Episode length": 421, "Policy Loss": 1.2357544898986816, "Value Loss": 21.649808883666992, "_runtime": 2671.5962283611298, "_timestamp": 1585572587.4408617, "_step": 221}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": 0.2459704726934433, "Value Loss": 11.107583045959473, "_runtime": 2673.0975403785706, "_timestamp": 1585572588.9421737, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8428599238395691, "Value Loss": 0.06925848871469498, "_runtime": 2673.8611929416656, "_timestamp": 1585572589.7058263, "_step": 223}
{"Episode reward": 49.99999999999957, "Episode length": 500, "Policy Loss": 0.5104913711547852, "Value Loss": 18.38258171081543, "_runtime": 2675.3901166915894, "_timestamp": 1585572591.23475, "_step": 224}
{"Episode reward": -99.81198484897473, "Episode length": 999, "Policy Loss": -1.0945969820022583, "Value Loss": 0.22904546558856964, "_runtime": 2676.9260618686676, "_timestamp": 1585572592.7706952, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1363716125488281, "Value Loss": 0.05192333087325096, "_runtime": 2678.0167360305786, "_timestamp": 1585572593.8613694, "_step": 226}
{"Episode reward": 30.499999999999673, "Episode length": 695, "Policy Loss": -0.15892955660820007, "Value Loss": 12.668437004089355, "_runtime": 2678.9479377269745, "_timestamp": 1585572594.792571, "_step": 227}
{"Episode reward": 40.39809390157404, "Episode length": 597, "Policy Loss": 0.4134718179702759, "Value Loss": 15.031953811645508, "_runtime": 2680.4895873069763, "_timestamp": 1585572596.3342206, "_step": 228}
{"Episode reward": -99.83297271728377, "Episode length": 999, "Policy Loss": -0.9529191255569458, "Value Loss": 0.05736452341079712, "_runtime": 2681.3378567695618, "_timestamp": 1585572597.18249, "_step": 229}
{"Episode reward": 45.1999999999995, "Episode length": 548, "Policy Loss": 0.6062297224998474, "Value Loss": 17.868064880371094, "_runtime": 2682.646874666214, "_timestamp": 1585572598.491508, "_step": 230}
{"Episode reward": 12.60565659515629, "Episode length": 875, "Policy Loss": 0.1481594741344452, "Value Loss": 9.896332740783691, "_runtime": 2684.182779788971, "_timestamp": 1585572600.0274131, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6458919644355774, "Value Loss": 0.007788566406816244, "_runtime": 2684.8452520370483, "_timestamp": 1585572600.6898854, "_step": 232}
{"Episode reward": 57.214428466558125, "Episode length": 428, "Policy Loss": 1.1012332439422607, "Value Loss": 19.873973846435547, "_runtime": 2686.3871569633484, "_timestamp": 1585572602.2317903, "_step": 233}
{"Episode reward": -99.72427276708048, "Episode length": 999, "Policy Loss": -0.5547626614570618, "Value Loss": 0.012109782546758652, "_runtime": 2687.317944049835, "_timestamp": 1585572603.1625774, "_step": 234}
{"Episode reward": 39.89999999999942, "Episode length": 601, "Policy Loss": 0.8168108463287354, "Value Loss": 15.193751335144043, "_runtime": 2687.769726037979, "_timestamp": 1585572603.6143594, "_step": 235}
{"Episode reward": 71.19999999999987, "Episode length": 288, "Policy Loss": 2.1559605598449707, "Value Loss": 28.415035247802734, "_runtime": 2689.307741880417, "_timestamp": 1585572605.1523752, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6561367511749268, "Value Loss": 0.011809872463345528, "_runtime": 2690.4953920841217, "_timestamp": 1585572606.3400254, "_step": 237}
{"Episode reward": 21.60000000000018, "Episode length": 784, "Policy Loss": 0.22774632275104523, "Value Loss": 11.489688873291016, "_runtime": 2691.070801258087, "_timestamp": 1585572606.9154346, "_step": 238}
{"Episode reward": 61.99999999999974, "Episode length": 380, "Policy Loss": 1.005156397819519, "Value Loss": 21.875076293945312, "_runtime": 2692.4772169589996, "_timestamp": 1585572608.3218503, "_step": 239}
{"Episode reward": 8.600000000000918, "Episode length": 914, "Policy Loss": -0.13277022540569305, "Value Loss": 9.702595710754395, "_runtime": 2693.9993329048157, "_timestamp": 1585572609.8439662, "_step": 240}
{"Episode reward": -99.82606082558492, "Episode length": 999, "Policy Loss": -1.0487867593765259, "Value Loss": 0.023079581558704376, "_runtime": 2694.979757785797, "_timestamp": 1585572610.8243911, "_step": 241}
{"Episode reward": 34.19999999999946, "Episode length": 658, "Policy Loss": 0.04150145500898361, "Value Loss": 15.535435676574707, "_runtime": 2696.5058867931366, "_timestamp": 1585572612.3505201, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3658692836761475, "Value Loss": 0.4744783639907837, "_runtime": 2697.211130142212, "_timestamp": 1585572613.0557635, "_step": 243}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": 0.3233558237552643, "Value Loss": 18.768844604492188, "_runtime": 2698.227813720703, "_timestamp": 1585572614.072447, "_step": 244}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": -0.31316670775413513, "Value Loss": 13.41968059539795, "_runtime": 2698.8158524036407, "_timestamp": 1585572614.6604857, "_step": 245}
{"Episode reward": 63.79999999999976, "Episode length": 362, "Policy Loss": 0.8241811394691467, "Value Loss": 24.399988174438477, "_runtime": 2700.319513320923, "_timestamp": 1585572616.1641467, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1911907196044922, "Value Loss": 0.05752331018447876, "_runtime": 2701.358234167099, "_timestamp": 1585572617.2028675, "_step": 247}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": 0.04721083864569664, "Value Loss": 12.154974937438965, "_runtime": 2702.865041255951, "_timestamp": 1585572618.7096746, "_step": 248}
{"Episode reward": -99.8833280146108, "Episode length": 999, "Policy Loss": -0.9698542356491089, "Value Loss": 0.02393273636698723, "_runtime": 2704.084662437439, "_timestamp": 1585572619.9292958, "_step": 249}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": -0.005966476164758205, "Value Loss": 11.44301986694336, "_runtime": 2705.1949536800385, "_timestamp": 1585572621.039587, "_step": 250}
{"Episode reward": 27.999999999999815, "Episode length": 720, "Policy Loss": 0.14950871467590332, "Value Loss": 11.45232105255127, "_runtime": 2706.7290568351746, "_timestamp": 1585572622.5736902, "_step": 251}
{"Episode reward": -99.83660013675551, "Episode length": 999, "Policy Loss": -0.7929790616035461, "Value Loss": 0.022697946056723595, "_runtime": 2708.2746016979218, "_timestamp": 1585572624.119235, "_step": 252}
{"Episode reward": -99.76845888085523, "Episode length": 999, "Policy Loss": -0.8010964393615723, "Value Loss": 0.01916256919503212, "_runtime": 2709.801332950592, "_timestamp": 1585572625.6459663, "_step": 253}
{"Episode reward": -99.86186882033805, "Episode length": 999, "Policy Loss": -0.8132361173629761, "Value Loss": 0.055863332003355026, "_runtime": 2710.8611583709717, "_timestamp": 1585572626.7057917, "_step": 254}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.46355706453323364, "Value Loss": 12.693074226379395, "_runtime": 2712.4281537532806, "_timestamp": 1585572628.272787, "_step": 255}
{"Episode reward": -99.79657550006965, "Episode length": 999, "Policy Loss": -0.9221599102020264, "Value Loss": 0.020067531615495682, "_runtime": 2713.9926431179047, "_timestamp": 1585572629.8372765, "_step": 256}
{"Episode reward": -99.8233497057096, "Episode length": 999, "Policy Loss": -1.06358003616333, "Value Loss": 0.09283024817705154, "_runtime": 2715.5184268951416, "_timestamp": 1585572631.3630602, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.054603934288025, "Value Loss": 0.10945279896259308, "_runtime": 2717.076084136963, "_timestamp": 1585572632.9207175, "_step": 258}
{"Episode reward": -99.80767503715911, "Episode length": 999, "Policy Loss": -1.0323832035064697, "Value Loss": 0.09123381972312927, "_runtime": 2718.6204736232758, "_timestamp": 1585572634.465107, "_step": 259}
{"Episode reward": 1.2927648719413583, "Episode length": 988, "Policy Loss": -0.29148101806640625, "Value Loss": 8.75615119934082, "_runtime": 2719.2721383571625, "_timestamp": 1585572635.1167717, "_step": 260}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.0758471488952637, "Value Loss": 23.544818878173828, "_runtime": 2720.8308115005493, "_timestamp": 1585572636.6754448, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7269821763038635, "Value Loss": 0.054805342108011246, "_runtime": 2722.0019381046295, "_timestamp": 1585572637.8465714, "_step": 262}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": 0.46289166808128357, "Value Loss": 12.46117115020752, "_runtime": 2723.464765071869, "_timestamp": 1585572639.3093984, "_step": 263}
{"Episode reward": 3.200000000001225, "Episode length": 968, "Policy Loss": 0.28952643275260925, "Value Loss": 8.995511054992676, "_runtime": 2724.5610361099243, "_timestamp": 1585572640.4056695, "_step": 264}
{"Episode reward": 30.769434975087307, "Episode length": 693, "Policy Loss": 0.7428932189941406, "Value Loss": 12.101573944091797, "_runtime": 2725.86229801178, "_timestamp": 1585572641.7069314, "_step": 265}
{"Episode reward": 17.84400605559388, "Episode length": 822, "Policy Loss": 0.4920315742492676, "Value Loss": 10.25913143157959, "_runtime": 2727.4231457710266, "_timestamp": 1585572643.267779, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4680980443954468, "Value Loss": 0.01494450494647026, "_runtime": 2728.9685208797455, "_timestamp": 1585572644.8131542, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5378962159156799, "Value Loss": 0.018210627138614655, "_runtime": 2730.5196540355682, "_timestamp": 1585572646.3642874, "_step": 268}
{"Episode reward": -99.80350419022004, "Episode length": 999, "Policy Loss": -0.593114972114563, "Value Loss": 0.024255694821476936, "_runtime": 2731.702160358429, "_timestamp": 1585572647.5467937, "_step": 269}
{"Episode reward": 24.300000000000026, "Episode length": 757, "Policy Loss": 0.17649996280670166, "Value Loss": 10.689966201782227, "_runtime": 2733.0120844841003, "_timestamp": 1585572648.8567178, "_step": 270}
{"Episode reward": 16.000000000000497, "Episode length": 840, "Policy Loss": 0.049480512738227844, "Value Loss": 9.931458473205566, "_runtime": 2734.447893857956, "_timestamp": 1585572650.2925272, "_step": 271}
{"Episode reward": 8.962193714083142, "Episode length": 911, "Policy Loss": -0.044515859335660934, "Value Loss": 9.264528274536133, "_runtime": 2735.495864868164, "_timestamp": 1585572651.3404982, "_step": 272}
{"Episode reward": 32.577711504324824, "Episode length": 675, "Policy Loss": 0.1303999423980713, "Value Loss": 12.5647554397583, "_runtime": 2737.035026073456, "_timestamp": 1585572652.8796594, "_step": 273}
{"Episode reward": -99.70660136043885, "Episode length": 999, "Policy Loss": -0.9358572363853455, "Value Loss": 0.035062242299318314, "_runtime": 2738.5932400226593, "_timestamp": 1585572654.4378734, "_step": 274}
{"Episode reward": -99.88012784868339, "Episode length": 999, "Policy Loss": -0.9632037281990051, "Value Loss": 0.17202390730381012, "_runtime": 2739.147307872772, "_timestamp": 1585572654.9919412, "_step": 275}
{"Episode reward": 65.5999999999998, "Episode length": 344, "Policy Loss": 1.0373098850250244, "Value Loss": 23.166000366210938, "_runtime": 2740.023429632187, "_timestamp": 1585572655.868063, "_step": 276}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.6120164394378662, "Value Loss": 14.336244583129883, "_runtime": 2740.5472898483276, "_timestamp": 1585572656.3919232, "_step": 277}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 1.5296645164489746, "Value Loss": 29.400999069213867, "_runtime": 2742.0503635406494, "_timestamp": 1585572657.894997, "_step": 278}
{"Episode reward": -99.8581890359507, "Episode length": 999, "Policy Loss": -0.7533465623855591, "Value Loss": 0.04114651307463646, "_runtime": 2743.577120780945, "_timestamp": 1585572659.4217541, "_step": 279}
{"Episode reward": -99.86810480393329, "Episode length": 999, "Policy Loss": -0.7077828049659729, "Value Loss": 0.037111394107341766, "_runtime": 2744.42809343338, "_timestamp": 1585572660.2727268, "_step": 280}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 1.1075046062469482, "Value Loss": 16.142147064208984, "_runtime": 2745.6553745269775, "_timestamp": 1585572661.5000079, "_step": 281}
{"Episode reward": 21.505587105080664, "Episode length": 786, "Policy Loss": 0.2729952037334442, "Value Loss": 10.40691089630127, "_runtime": 2746.128173828125, "_timestamp": 1585572661.9728072, "_step": 282}
{"Episode reward": 71.39999999999986, "Episode length": 286, "Policy Loss": 1.7273495197296143, "Value Loss": 27.748144149780273, "_runtime": 2747.652105808258, "_timestamp": 1585572663.4967391, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.635503351688385, "Value Loss": 0.01138342171907425, "_runtime": 2748.668071269989, "_timestamp": 1585572664.5127046, "_step": 284}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 0.28432297706604004, "Value Loss": 11.969987869262695, "_runtime": 2749.7654688358307, "_timestamp": 1585572665.6101022, "_step": 285}
{"Episode reward": 28.97350741587556, "Episode length": 711, "Policy Loss": 0.14176088571548462, "Value Loss": 11.427589416503906, "_runtime": 2750.602389574051, "_timestamp": 1585572666.447023, "_step": 286}
{"Episode reward": 47.09475012868595, "Episode length": 530, "Policy Loss": 0.5942051410675049, "Value Loss": 15.535786628723145, "_runtime": 2751.65722322464, "_timestamp": 1585572667.5018566, "_step": 287}
{"Episode reward": 31.499999999999616, "Episode length": 685, "Policy Loss": 0.14193180203437805, "Value Loss": 12.724040985107422, "_runtime": 2753.1223928928375, "_timestamp": 1585572668.9670262, "_step": 288}
{"Episode reward": 3.800000000001191, "Episode length": 962, "Policy Loss": -0.31892871856689453, "Value Loss": 8.843005180358887, "_runtime": 2754.643721103668, "_timestamp": 1585572670.4883544, "_step": 289}
{"Episode reward": -99.80013411044935, "Episode length": 999, "Policy Loss": -1.1723629236221313, "Value Loss": 0.21747079491615295, "_runtime": 2755.2687697410583, "_timestamp": 1585572671.113403, "_step": 290}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 0.9253884553909302, "Value Loss": 20.536073684692383, "_runtime": 2756.8054411411285, "_timestamp": 1585572672.6500745, "_step": 291}
{"Episode reward": -99.8000410616384, "Episode length": 999, "Policy Loss": -1.1334573030471802, "Value Loss": 0.03831694647669792, "_runtime": 2758.3653111457825, "_timestamp": 1585572674.2099445, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.051284909248352, "Value Loss": 0.08589989691972733, "_runtime": 2759.678533554077, "_timestamp": 1585572675.523167, "_step": 293}
{"Episode reward": 12.964176576957783, "Episode length": 872, "Policy Loss": 0.003150913631543517, "Value Loss": 10.756056785583496, "_runtime": 2761.251339197159, "_timestamp": 1585572677.0959725, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8768196702003479, "Value Loss": 0.023586783558130264, "_runtime": 2762.8212280273438, "_timestamp": 1585572678.6658614, "_step": 295}
{"Episode reward": -99.74715152568976, "Episode length": 999, "Policy Loss": -0.8071024417877197, "Value Loss": 0.023583604022860527, "_runtime": 2764.3645195961, "_timestamp": 1585572680.209153, "_step": 296}
{"Episode reward": -99.83683683872083, "Episode length": 999, "Policy Loss": -0.7409371137619019, "Value Loss": 0.023397104814648628, "_runtime": 2765.930244445801, "_timestamp": 1585572681.7748778, "_step": 297}
{"Episode reward": -99.83101206421712, "Episode length": 999, "Policy Loss": -0.6844340562820435, "Value Loss": 0.04792744666337967, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394, 0.32333534955978394]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.32333534955978394, 0.6448463797569275, 1.6130280494689941, 2.581209897994995, 3.549391508102417, 4.517573356628418, 5.485755443572998, 6.45393705368042, 7.422118663787842, 8.390299797058105, 9.358481407165527, 10.32666301727295, 11.294845581054688, 12.26302719116211, 13.231208801269531, 14.199390411376953, 15.167572021484375, 16.135753631591797, 17.10393524169922, 18.07211685180664, 19.040298461914062, 20.008480072021484, 20.976661682128906, 21.944843292236328, 22.913026809692383, 23.881208419799805, 24.849390029907227, 25.81757164001465, 26.78575325012207, 27.753934860229492, 28.722116470336914, 29.690298080444336, 30.658479690551758, 31.62666130065918, 32.594844818115234, 33.563026428222656, 34.53120803833008, 35.4993896484375, 36.46757125854492, 37.435752868652344, 38.403934478759766, 39.37211608886719, 40.34029769897461, 41.30847930908203, 42.27666091918945, 43.244842529296875, 44.2130241394043, 45.18120574951172, 46.149391174316406, 47.11757278442383, 48.08575439453125, 49.05393600463867, 50.022117614746094, 50.990299224853516, 51.95848083496094, 52.92666244506836, 53.89484405517578, 54.8630256652832, 55.831207275390625, 56.79938888549805, 57.76757049560547, 58.73575210571289, 59.70393371582031, 60.672115325927734, 61.640296936035156]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.6971662044525146, -0.6700853705406189, -0.6430044770240784, -0.6159236431121826, -0.5888428092002869, -0.5617619752883911, -0.5346810817718506, -0.5076002478599548, -0.4805193841457367, -0.45343852043151855, -0.4263576865196228, -0.39927682280540466, -0.3721959590911865, -0.34511512517929077, -0.31803426146507263, -0.2909534275531769, -0.26387256383895874, -0.2367917001247406, -0.20971086621284485, -0.1826300024986267, -0.15554916858673096, -0.12846827507019043, -0.10138744115829468, -0.07430660724639893, -0.0472257137298584, -0.020144879817962646, 0.0069359540939331055, 0.03401678800582886, 0.061097681522369385, 0.08817851543426514, 0.11525934934616089, 0.14234024286270142, 0.16942107677459717, 0.19650191068649292, 0.22358280420303345, 0.2506636381149292, 0.27774447202682495, 0.3048253059387207, 0.33190619945526123, 0.35898709297180176, 0.38606786727905273, 0.41314876079559326, 0.4402296543121338, 0.46731042861938477, 0.4943913221359253, 0.5214722156524658, 0.5485529899597168, 0.5756338834762573, 0.6027147769927979, 0.6297955513000488, 0.6568764448165894, 0.6839572191238403, 0.7110381126403809, 0.7381190061569214, 0.7651997804641724, 0.7922806739807129, 0.8193615674972534, 0.8464423418045044, 0.8735232353210449, 0.9006041288375854, 0.9276849031448364, 0.954765796661377, 0.9818466901779175, 1.0089274644851685, 1.036008358001709]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 4.0, 1.0, 0.0, 10.0, 3.0, 3.0, 12.0, 3.0, 3.0, 19.0, 16.0, 5.0, 0.0, 320.0, 0.0, 2.0, 11.0, 7.0, 11.0, 6.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 6.0, 7.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 1.0, 5.0, 2.0, 2.0, 1.0, 3.0], "bins": [-3.373927593231201, -3.243049383163452, -3.112171173095703, -2.981292724609375, -2.850414514541626, -2.719536304473877, -2.588657855987549, -2.4577796459198, -2.326901435852051, -2.1960232257843018, -2.0651450157165527, -1.9342665672302246, -1.8033883571624756, -1.6725101470947266, -1.541631817817688, -1.4107534885406494, -1.2798752784729004, -1.1489970684051514, -1.0181188583374023, -0.8872404098510742, -0.7563621997833252, -0.6254839897155762, -0.49460554122924805, -0.363727331161499, -0.23284912109375, -0.10197091102600098, 0.028907299041748047, 0.15978574752807617, 0.2906639575958252, 0.4215421676635742, 0.5524206161499023, 0.6832985877990723, 0.8141770362854004, 0.9450554847717285, 1.0759334564208984, 1.2068119049072266, 1.3376898765563965, 1.4685683250427246, 1.5994467735290527, 1.7303247451782227, 1.8612031936645508, 1.992081642150879, 2.122959613800049, 2.253838062286377, 2.384716510772705, 2.515594482421875, 2.646472930908203, 2.777350902557373, 2.908229351043701, 3.0391077995300293, 3.169985771179199, 3.3008642196655273, 3.4317421913146973, 3.5626206398010254, 3.6934990882873535, 3.8243770599365234, 3.9552555084228516, 4.08613395690918, 4.21701192855835, 4.347890377044678, 4.478768825531006, 4.609646797180176, 4.740524768829346, 4.871403217315674, 5.002281665802002]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-5.994789123535156, -5.689795970916748, -5.384802341461182, -5.079809188842773, -4.774815559387207, -4.469822406768799, -4.164829254150391, -3.859835624694824, -3.554842233657837, -3.2498488426208496, -2.9448554515838623, -2.639862060546875, -2.334868907928467, -2.0298755168914795, -1.7248821258544922, -1.4198884963989258, -1.1148953437805176, -0.8099021911621094, -0.504908561706543, -0.19991540908813477, 0.10507822036743164, 0.41007137298583984, 0.7150650024414062, 1.0200581550598145, 1.3250513076782227, 1.630044937133789, 1.9350380897521973, 2.2400312423706055, 2.545024871826172, 2.8500185012817383, 3.1550121307373047, 3.4600048065185547, 3.764998435974121, 4.0699920654296875, 4.3749847412109375, 4.679978370666504, 4.98497200012207, 5.289965629577637, 5.594958305358887, 5.899951934814453, 6.2049455642700195, 6.5099382400512695, 6.814931869506836, 7.119925498962402, 7.424919128417969, 7.729911804199219, 8.034905433654785, 8.339899063110352, 8.644891738891602, 8.949885368347168, 9.254878997802734, 9.5598726272583, 9.86486530303955, 10.169858932495117, 10.474851608276367, 10.77984619140625, 11.0848388671875, 11.38983154296875, 11.694826126098633, 11.999818801879883, 12.304813385009766, 12.609806060791016, 12.914798736572266, 13.219793319702148, 13.524785995483398]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 7.0, 25.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-6.979045867919922, -6.815158843994141, -6.651271343231201, -6.487383842468262, -6.3234968185424805, -6.159609794616699, -5.99572229385376, -5.83183479309082, -5.667947769165039, -5.504060745239258, -5.340173244476318, -5.176285743713379, -5.012398719787598, -4.848511695861816, -4.684624195098877, -4.5207366943359375, -4.356849670410156, -4.192962646484375, -4.0290751457214355, -3.865187883377075, -3.701300621032715, -3.5374133586883545, -3.373526096343994, -3.209638833999634, -3.0457515716552734, -2.881864547729492, -2.7179770469665527, -2.5540895462036133, -2.390202522277832, -2.226315498352051, -2.0624279975891113, -1.8985404968261719, -1.7346534729003906, -1.5707664489746094, -1.40687894821167, -1.2429914474487305, -1.0791044235229492, -0.915217399597168, -0.7513298988342285, -0.5874423980712891, -0.4235553741455078, -0.25966835021972656, -0.09578084945678711, 0.06810665130615234, 0.2319936752319336, 0.39588069915771484, 0.5597681999206543, 0.7236557006835938, 0.887542724609375, 1.0514297485351562, 1.2153167724609375, 1.3792047500610352, 1.5430917739868164, 1.7069787979125977, 1.8708667755126953, 2.0347537994384766, 2.198640823364258, 2.362527847290039, 2.5264148712158203, 2.690302848815918, 2.854189872741699, 3.0180768966674805, 3.181964874267578, 3.3458518981933594, 3.5097389221191406]}, "_runtime": 2767.1651813983917, "_timestamp": 1585572683.0098147, "_step": 298}
{"Episode reward": 21.988628796860738, "Episode length": 782, "Policy Loss": 0.14727333188056946, "Value Loss": 10.130619049072266, "_runtime": 2768.126478910446, "_timestamp": 1585572683.9711123, "_step": 299}
{"Episode reward": 39.399999999999416, "Episode length": 606, "Policy Loss": 0.5572945475578308, "Value Loss": 14.856683731079102, "_runtime": 2769.6953015327454, "_timestamp": 1585572685.5399349, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6811651587486267, "Value Loss": 0.03115958347916603, "_runtime": 2771.257882118225, "_timestamp": 1585572687.1025155, "_step": 301}
{"Episode reward": -99.85148482918599, "Episode length": 999, "Policy Loss": -0.7186304926872253, "Value Loss": 0.009504892863333225, "_runtime": 2772.8226478099823, "_timestamp": 1585572688.6672812, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7579888105392456, "Value Loss": 0.03473779559135437, "_runtime": 2774.3776440620422, "_timestamp": 1585572690.2222774, "_step": 303}
{"Episode reward": -99.82032431289413, "Episode length": 999, "Policy Loss": -0.7599562406539917, "Value Loss": 0.01490973774343729, "_runtime": 2775.9439544677734, "_timestamp": 1585572691.7885878, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7422838807106018, "Value Loss": 0.10236197710037231, "_runtime": 2776.967312812805, "_timestamp": 1585572692.8119462, "_step": 305}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 0.3789488673210144, "Value Loss": 12.672131538391113, "_runtime": 2777.781914949417, "_timestamp": 1585572693.6265483, "_step": 306}
{"Episode reward": 49.199999999999555, "Episode length": 508, "Policy Loss": 0.6983768939971924, "Value Loss": 15.818785667419434, "_runtime": 2779.357673883438, "_timestamp": 1585572695.2023072, "_step": 307}
{"Episode reward": -99.65822851993005, "Episode length": 999, "Policy Loss": -0.5833592414855957, "Value Loss": 0.009753445163369179, "_runtime": 2780.903072118759, "_timestamp": 1585572696.7477055, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5230745673179626, "Value Loss": 0.01256583258509636, "_runtime": 2781.2746727466583, "_timestamp": 1585572697.119306, "_step": 309}
{"Episode reward": 77.59999999999997, "Episode length": 224, "Policy Loss": 3.2607269287109375, "Value Loss": 44.670162200927734, "_runtime": 2782.8392584323883, "_timestamp": 1585572698.6838918, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7558197379112244, "Value Loss": 0.06854092329740524, "_runtime": 2783.880019903183, "_timestamp": 1585572699.7246532, "_step": 311}
{"Episode reward": 33.799999999999486, "Episode length": 662, "Policy Loss": 0.3493693768978119, "Value Loss": 14.179770469665527, "_runtime": 2784.359300136566, "_timestamp": 1585572700.2039335, "_step": 312}
{"Episode reward": 67.89999999999982, "Episode length": 321, "Policy Loss": 1.0524969100952148, "Value Loss": 28.6061954498291, "_runtime": 2785.363901615143, "_timestamp": 1585572701.208535, "_step": 313}
{"Episode reward": 35.9935500618064, "Episode length": 641, "Policy Loss": 0.2581903636455536, "Value Loss": 14.447120666503906, "_runtime": 2786.8972070217133, "_timestamp": 1585572702.7418404, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7110111713409424, "Value Loss": 0.13633406162261963, "_runtime": 2787.8724772930145, "_timestamp": 1585572703.7171106, "_step": 315}
{"Episode reward": 34.71725041866246, "Episode length": 653, "Policy Loss": 0.6960678696632385, "Value Loss": 14.011574745178223, "_runtime": 2788.4833455085754, "_timestamp": 1585572704.3279788, "_step": 316}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": 1.5268304347991943, "Value Loss": 21.07785415649414, "_runtime": 2789.4754343032837, "_timestamp": 1585572705.3200676, "_step": 317}
{"Episode reward": 35.99999999999937, "Episode length": 640, "Policy Loss": 1.0768412351608276, "Value Loss": 14.816503524780273, "_runtime": 2790.9986197948456, "_timestamp": 1585572706.8432531, "_step": 318}
{"Episode reward": -99.82892737984518, "Episode length": 999, "Policy Loss": -0.12205943465232849, "Value Loss": 0.04583101347088814, "_runtime": 2792.063297510147, "_timestamp": 1585572707.9079309, "_step": 319}
{"Episode reward": 29.492120712622736, "Episode length": 706, "Policy Loss": 0.7834692001342773, "Value Loss": 12.212323188781738, "_runtime": 2793.1772162914276, "_timestamp": 1585572709.0218496, "_step": 320}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 0.6509186625480652, "Value Loss": 12.154050827026367, "_runtime": 2794.720278978348, "_timestamp": 1585572710.5649123, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4546853005886078, "Value Loss": 0.04887070879340172, "_runtime": 2795.8527586460114, "_timestamp": 1585572711.697392, "_step": 322}
{"Episode reward": 25.99865233749145, "Episode length": 741, "Policy Loss": 0.2667953073978424, "Value Loss": 12.092911720275879, "_runtime": 2797.2658219337463, "_timestamp": 1585572713.1104553, "_step": 323}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": -0.12488356977701187, "Value Loss": 8.790984153747559, "_runtime": 2798.8048689365387, "_timestamp": 1585572714.6495023, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1418052911758423, "Value Loss": 0.09119965881109238, "_runtime": 2800.3400962352753, "_timestamp": 1585572716.1847296, "_step": 325}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3014545440673828, "Value Loss": 0.20468619465827942, "_runtime": 2801.0262825489044, "_timestamp": 1585572716.870916, "_step": 326}
{"Episode reward": 57.29999999999967, "Episode length": 427, "Policy Loss": 0.27494674921035767, "Value Loss": 18.98590660095215, "_runtime": 2802.0714635849, "_timestamp": 1585572717.916097, "_step": 327}
{"Episode reward": 33.299999999999514, "Episode length": 667, "Policy Loss": -0.19134649634361267, "Value Loss": 13.66204833984375, "_runtime": 2803.497125864029, "_timestamp": 1585572719.3417592, "_step": 328}
{"Episode reward": 9.200000000000884, "Episode length": 908, "Policy Loss": -0.411959707736969, "Value Loss": 9.998997688293457, "_runtime": 2805.0114085674286, "_timestamp": 1585572720.856042, "_step": 329}
{"Episode reward": -99.80153969563403, "Episode length": 999, "Policy Loss": -0.9689591526985168, "Value Loss": 0.02312464639544487, "_runtime": 2806.0052037239075, "_timestamp": 1585572721.849837, "_step": 330}
{"Episode reward": 35.94563817977842, "Episode length": 641, "Policy Loss": 0.24317167699337006, "Value Loss": 13.146594047546387, "_runtime": 2806.729427099228, "_timestamp": 1585572722.5740604, "_step": 331}
{"Episode reward": 54.69999999999963, "Episode length": 453, "Policy Loss": 0.7007122039794922, "Value Loss": 18.71858787536621, "_runtime": 2807.8411300182343, "_timestamp": 1585572723.6857634, "_step": 332}
{"Episode reward": 28.999804189428446, "Episode length": 711, "Policy Loss": 0.08464121073484421, "Value Loss": 11.04157543182373, "_runtime": 2809.3842368125916, "_timestamp": 1585572725.2288702, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7250387668609619, "Value Loss": 0.01744200475513935, "_runtime": 2810.8213226795197, "_timestamp": 1585572726.665956, "_step": 334}
{"Episode reward": 5.379638886080286, "Episode length": 947, "Policy Loss": -0.15417620539665222, "Value Loss": 7.613062858581543, "_runtime": 2812.3563919067383, "_timestamp": 1585572728.2010252, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8108468651771545, "Value Loss": 0.0971824899315834, "_runtime": 2812.8925862312317, "_timestamp": 1585572728.7372196, "_step": 336}
{"Episode reward": 67.99999999999983, "Episode length": 320, "Policy Loss": 1.381824016571045, "Value Loss": 25.822031021118164, "_runtime": 2814.445660829544, "_timestamp": 1585572730.2902942, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8361365795135498, "Value Loss": 0.025035947561264038, "_runtime": 2815.2432763576508, "_timestamp": 1585572731.0879097, "_step": 338}
{"Episode reward": 50.39999999999957, "Episode length": 496, "Policy Loss": 0.6337698698043823, "Value Loss": 17.709392547607422, "_runtime": 2816.7619268894196, "_timestamp": 1585572732.6065602, "_step": 339}
{"Episode reward": -99.89394228458265, "Episode length": 999, "Policy Loss": -0.818459153175354, "Value Loss": 0.08607659488916397, "_runtime": 2817.8920073509216, "_timestamp": 1585572733.7366407, "_step": 340}
{"Episode reward": 27.89999999999982, "Episode length": 721, "Policy Loss": 0.2332724779844284, "Value Loss": 11.198911666870117, "_runtime": 2819.037540435791, "_timestamp": 1585572734.8821738, "_step": 341}
{"Episode reward": 25.4887162558734, "Episode length": 747, "Policy Loss": 0.06520243734121323, "Value Loss": 10.439922332763672, "_runtime": 2820.0531482696533, "_timestamp": 1585572735.8977816, "_step": 342}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.257917195558548, "Value Loss": 11.72183609008789, "_runtime": 2821.626795053482, "_timestamp": 1585572737.4714284, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8589194416999817, "Value Loss": 0.02553328312933445, "_runtime": 2823.1641759872437, "_timestamp": 1585572739.0088093, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8885257244110107, "Value Loss": 0.01727788895368576, "_runtime": 2824.479617834091, "_timestamp": 1585572740.3242512, "_step": 345}
{"Episode reward": 13.938257084787509, "Episode length": 861, "Policy Loss": -0.07392348349094391, "Value Loss": 9.538314819335938, "_runtime": 2826.0461790561676, "_timestamp": 1585572741.8908124, "_step": 346}
{"Episode reward": -99.80619518905738, "Episode length": 999, "Policy Loss": -0.9198039770126343, "Value Loss": 0.06335388869047165, "_runtime": 2826.8401987552643, "_timestamp": 1585572742.684832, "_step": 347}
{"Episode reward": 50.300499862059525, "Episode length": 497, "Policy Loss": 0.2741882801055908, "Value Loss": 15.038382530212402, "_runtime": 2828.3958070278168, "_timestamp": 1585572744.2404404, "_step": 348}
{"Episode reward": -99.82143242396275, "Episode length": 999, "Policy Loss": -0.9128350615501404, "Value Loss": 0.030404236167669296, "_runtime": 2829.3567311763763, "_timestamp": 1585572745.2013645, "_step": 349}
{"Episode reward": 39.63605077117624, "Episode length": 604, "Policy Loss": 0.0049137091264128685, "Value Loss": 12.657045364379883, "_runtime": 2830.874504804611, "_timestamp": 1585572746.7191381, "_step": 350}
{"Episode reward": -99.80529190935054, "Episode length": 999, "Policy Loss": -0.8714266419410706, "Value Loss": 0.10395505279302597, "_runtime": 2832.4513866901398, "_timestamp": 1585572748.29602, "_step": 351}
{"Episode reward": -99.7668723538504, "Episode length": 999, "Policy Loss": -0.8413101434707642, "Value Loss": 0.04839891567826271, "_runtime": 2833.971094608307, "_timestamp": 1585572749.815728, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7979776263237, "Value Loss": 0.03970378264784813, "_runtime": 2835.5307626724243, "_timestamp": 1585572751.375396, "_step": 353}
{"Episode reward": -99.80009313225607, "Episode length": 999, "Policy Loss": -0.7291684150695801, "Value Loss": 0.0837266594171524, "_runtime": 2836.859141588211, "_timestamp": 1585572752.703775, "_step": 354}
{"Episode reward": 15.287788336724589, "Episode length": 848, "Policy Loss": 0.10309046506881714, "Value Loss": 8.82319164276123, "_runtime": 2838.4305136203766, "_timestamp": 1585572754.275147, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.527825653553009, "Value Loss": 0.012599126435816288, "_runtime": 2840.0039088726044, "_timestamp": 1585572755.8485422, "_step": 356}
{"Episode reward": -99.88063127994397, "Episode length": 999, "Policy Loss": -0.44399845600128174, "Value Loss": 0.022856537252664566, "_runtime": 2841.5576570034027, "_timestamp": 1585572757.4022903, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35447436571121216, "Value Loss": 0.07001538574695587, "_runtime": 2843.131672859192, "_timestamp": 1585572758.9763062, "_step": 358}
{"Episode reward": -99.80001706033805, "Episode length": 999, "Policy Loss": -0.3138519525527954, "Value Loss": 0.02472173608839512, "_runtime": 2843.727484226227, "_timestamp": 1585572759.5721176, "_step": 359}
{"Episode reward": 63.69999999999976, "Episode length": 363, "Policy Loss": 1.6693544387817383, "Value Loss": 22.009923934936523, "_runtime": 2844.8453183174133, "_timestamp": 1585572760.6899517, "_step": 360}
{"Episode reward": 30.699999999999662, "Episode length": 693, "Policy Loss": 0.8015336394309998, "Value Loss": 12.468746185302734, "_runtime": 2845.260066509247, "_timestamp": 1585572761.1046999, "_step": 361}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": 2.7954840660095215, "Value Loss": 37.326560974121094, "_runtime": 2846.7755398750305, "_timestamp": 1585572762.6201732, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6792364716529846, "Value Loss": 0.020705819129943848, "_runtime": 2848.3268167972565, "_timestamp": 1585572764.1714501, "_step": 363}
{"Episode reward": -99.7659678913639, "Episode length": 999, "Policy Loss": -0.8824558258056641, "Value Loss": 0.028229594230651855, "_runtime": 2849.813606262207, "_timestamp": 1585572765.6582396, "_step": 364}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0756256580352783, "Value Loss": 0.16144990921020508, "_runtime": 2850.866918563843, "_timestamp": 1585572766.711552, "_step": 365}
{"Episode reward": 33.457146439700836, "Episode length": 667, "Policy Loss": -0.20266465842723846, "Value Loss": 13.633330345153809, "_runtime": 2851.650286436081, "_timestamp": 1585572767.4949198, "_step": 366}
{"Episode reward": 51.39221295714337, "Episode length": 487, "Policy Loss": 0.12215005606412888, "Value Loss": 18.27888298034668, "_runtime": 2853.198630332947, "_timestamp": 1585572769.0432637, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1327095031738281, "Value Loss": 0.13771529495716095, "_runtime": 2854.740772008896, "_timestamp": 1585572770.5854053, "_step": 368}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0002096891403198, "Value Loss": 0.1675969362258911, "_runtime": 2855.1294374465942, "_timestamp": 1585572770.9740708, "_step": 369}
{"Episode reward": 76.59999999999994, "Episode length": 234, "Policy Loss": 2.4045569896698, "Value Loss": 39.31641387939453, "_runtime": 2856.6775534152985, "_timestamp": 1585572772.5221868, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6514719128608704, "Value Loss": 0.020766938105225563, "_runtime": 2858.2515745162964, "_timestamp": 1585572774.0962079, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48193150758743286, "Value Loss": 0.026506716385483742, "_runtime": 2859.7444615364075, "_timestamp": 1585572775.5890949, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2890135943889618, "Value Loss": 0.015085178427398205, "_runtime": 2860.433554172516, "_timestamp": 1585572776.2781875, "_step": 373}
{"Episode reward": 57.699999999999676, "Episode length": 423, "Policy Loss": 1.6689659357070923, "Value Loss": 21.82906723022461, "_runtime": 2861.994788169861, "_timestamp": 1585572777.8394215, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.02048000879585743, "Value Loss": 0.029368266463279724, "_runtime": 2863.5387744903564, "_timestamp": 1585572779.3834078, "_step": 375}
{"Episode reward": -99.8173628065721, "Episode length": 999, "Policy Loss": 0.09712281823158264, "Value Loss": 0.08018225431442261, "_runtime": 2864.608499288559, "_timestamp": 1585572780.4531326, "_step": 376}
{"Episode reward": 29.54556615352604, "Episode length": 705, "Policy Loss": 1.2432243824005127, "Value Loss": 12.272626876831055, "_runtime": 2866.174252271652, "_timestamp": 1585572782.0188856, "_step": 377}
{"Episode reward": -99.8277126673595, "Episode length": 999, "Policy Loss": 0.08863098919391632, "Value Loss": 0.17370149493217468, "_runtime": 2867.73734331131, "_timestamp": 1585572783.5819767, "_step": 378}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.047101862728595734, "Value Loss": 0.08564426749944687, "_runtime": 2869.3045818805695, "_timestamp": 1585572785.1492152, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2096896916627884, "Value Loss": 0.007211954798549414, "_runtime": 2870.8776202201843, "_timestamp": 1585572786.7222536, "_step": 380}
{"Episode reward": -99.80041306353966, "Episode length": 999, "Policy Loss": -0.3670838475227356, "Value Loss": 0.04083635285496712, "_runtime": 2872.4402618408203, "_timestamp": 1585572788.2848952, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4850369095802307, "Value Loss": 0.030357105657458305, "_runtime": 2874.004109144211, "_timestamp": 1585572789.8487425, "_step": 382}
{"Episode reward": -99.81516832448402, "Episode length": 999, "Policy Loss": -0.6023871302604675, "Value Loss": 0.05002028867602348, "_runtime": 2875.588278055191, "_timestamp": 1585572791.4329114, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6411780714988708, "Value Loss": 0.03677000850439072, "_runtime": 2876.477600812912, "_timestamp": 1585572792.3222342, "_step": 384}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.7706156373023987, "Value Loss": 16.371658325195312, "_runtime": 2878.037415742874, "_timestamp": 1585572793.882049, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7739996910095215, "Value Loss": 0.11571958661079407, "_runtime": 2879.616827726364, "_timestamp": 1585572795.461461, "_step": 386}
{"Episode reward": -99.84575881697097, "Episode length": 999, "Policy Loss": -0.7593203186988831, "Value Loss": 0.07112613320350647, "_runtime": 2880.2289547920227, "_timestamp": 1585572796.0735881, "_step": 387}
{"Episode reward": 61.46049374192926, "Episode length": 386, "Policy Loss": 1.337830662727356, "Value Loss": 19.418256759643555, "_runtime": 2881.7959368228912, "_timestamp": 1585572797.6405702, "_step": 388}
{"Episode reward": -99.83585805035987, "Episode length": 999, "Policy Loss": -0.696523904800415, "Value Loss": 0.09311039745807648, "_runtime": 2883.37584066391, "_timestamp": 1585572799.220474, "_step": 389}
{"Episode reward": -99.64792490787666, "Episode length": 999, "Policy Loss": -0.5707209706306458, "Value Loss": 0.0383184552192688, "_runtime": 2884.8862047195435, "_timestamp": 1585572800.730838, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4512024223804474, "Value Loss": 0.03808875381946564, "_runtime": 2886.450270652771, "_timestamp": 1585572802.294904, "_step": 391}
{"Episode reward": -99.80905795432487, "Episode length": 999, "Policy Loss": -0.33097022771835327, "Value Loss": 0.015065312385559082, "_runtime": 2887.3543512821198, "_timestamp": 1585572803.1989846, "_step": 392}
{"Episode reward": 42.99193806052155, "Episode length": 571, "Policy Loss": 0.8000980019569397, "Value Loss": 14.207210540771484, "_runtime": 2888.917192220688, "_timestamp": 1585572804.7618256, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.26268360018730164, "Value Loss": 0.01792634092271328, "_runtime": 2890.4931206703186, "_timestamp": 1585572806.337754, "_step": 394}
{"Episode reward": -99.83648207187512, "Episode length": 999, "Policy Loss": -0.28628990054130554, "Value Loss": 0.0033915420062839985, "_runtime": 2891.3029181957245, "_timestamp": 1585572807.1475515, "_step": 395}
{"Episode reward": 48.09999999999954, "Episode length": 519, "Policy Loss": 0.7373675107955933, "Value Loss": 13.759764671325684, "_runtime": 2892.8965137004852, "_timestamp": 1585572808.741147, "_step": 396}
{"Episode reward": -99.86251264959434, "Episode length": 999, "Policy Loss": -0.3736869990825653, "Value Loss": 0.004830677527934313, "_runtime": 2894.469264268875, "_timestamp": 1585572810.3138976, "_step": 397}
{"Episode reward": -99.81371071971815, "Episode length": 999, "Policy Loss": -0.4347003996372223, "Value Loss": 0.03583037480711937, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429, -0.014325268566608429]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-2.3133633136749268, -2.2769932746887207, -2.2406229972839355, -2.2042529582977295, -2.1678826808929443, -2.1315126419067383, -2.0951426029205322, -2.058772325515747, -2.022402286529541, -1.9860321283340454, -1.9496619701385498, -1.9132918119430542, -1.8769216537475586, -1.8405516147613525, -1.8041813373565674, -1.7678112983703613, -1.7314411401748657, -1.6950709819793701, -1.658700942993164, -1.622330665588379, -1.5859606266021729, -1.5495904684066772, -1.5132203102111816, -1.4768502712249756, -1.4404799938201904, -1.4041099548339844, -1.3677397966384888, -1.3313696384429932, -1.2949994802474976, -1.258629322052002, -1.222259283065796, -1.1858891248703003, -1.1495189666748047, -1.113148808479309, -1.0767786502838135, -1.0404086112976074, -1.0040384531021118, -0.9676682949066162, -0.9312981367111206, -0.894927978515625, -0.858557939529419, -0.8221877813339233, -0.7858176231384277, -0.7494474649429321, -0.7130773067474365, -0.6767071485519409, -0.6403371095657349, -0.6039669513702393, -0.5675967931747437, -0.531226634979248, -0.49485647678375244, -0.4584864377975464, -0.4221162796020508, -0.3857461214065552, -0.34937596321105957, -0.3130059242248535, -0.27663564682006836, -0.2402656078338623, -0.20389533042907715, -0.1675252914428711, -0.13115525245666504, -0.09478497505187988, -0.05841493606567383, -0.022044658660888672, 0.014325380325317383]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.045899998396635056, -0.044704869389534, -0.043509744107723236, -0.04231461510062218, -0.04111948981881142, -0.03992436081171036, -0.0387292355298996, -0.03753410652279854, -0.03633897751569748, -0.03514385223388672, -0.03394872695207596, -0.0327535979449749, -0.03155846893787384, -0.03036334365606308, -0.02916821464896202, -0.02797308750450611, -0.0267779603600502, -0.02558283321559429, -0.024387706071138382, -0.023192578926682472, -0.021997451782226562, -0.020802322775125504, -0.019607195630669594, -0.018412068486213684, -0.017216941341757774, -0.016021814197301865, -0.014826687052845955, -0.013631559908390045, -0.012436430901288986, -0.011241305619478226, -0.010046176612377167, -0.008851051330566406, -0.007655922323465347, -0.006460793316364288, -0.005265668034553528, -0.004070539027452469, -0.0028754137456417084, -0.0016802847385406494, -0.0004851594567298889, 0.00070996955037117, 0.0019050948321819305, 0.0031002238392829895, 0.0042953528463840485, 0.005490478128194809, 0.006685607135295868, 0.007880732417106628, 0.009075861424207687, 0.010270986706018448, 0.011466115713119507, 0.012661244720220566, 0.013856370002031326, 0.015051499009132385, 0.016246624290943146, 0.017441753298044205, 0.018636878579854965, 0.019832003861665726, 0.021027136594057083, 0.022222261875867844, 0.023417387157678604, 0.02461251989006996, 0.025807645171880722, 0.027002770453691483, 0.028197895735502243, 0.0293930284678936, 0.03058815374970436]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 2.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 3.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 4.0, 0.0, 2.0, 7.0, 6.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 3.0, 10.0, 4.0, 8.0, 338.0, 8.0, 9.0, 17.0, 4.0, 3.0, 3.0, 3.0, 12.0, 0.0, 1.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0], "bins": [-0.22287732362747192, -0.21707533299922943, -0.21127332746982574, -0.20547133684158325, -0.19966934621334076, -0.19386735558509827, -0.18806535005569458, -0.1822633594274521, -0.1764613687992096, -0.1706593632698059, -0.16485737264156342, -0.15905538201332092, -0.15325337648391724, -0.14745138585567474, -0.14164939522743225, -0.13584738969802856, -0.13004539906978607, -0.12424340099096298, -0.11844141036272049, -0.1126394122838974, -0.10683742165565491, -0.10103542357683182, -0.09523342549800873, -0.08943143486976624, -0.08362942934036255, -0.07782743871212006, -0.07202544808387756, -0.06622345745563507, -0.060421451926231384, -0.05461946129798889, -0.0488174706697464, -0.04301546514034271, -0.03721347451210022, -0.03141148388385773, -0.02560947835445404, -0.019807487726211548, -0.014005497097969055, -0.008203491568565369, -0.002401500940322876, 0.0034004896879196167, 0.00920248031616211, 0.015004485845565796, 0.02080647647380829, 0.02660846710205078, 0.03241047263145447, 0.038212478160858154, 0.04401445388793945, 0.04981645941734314, 0.055618464946746826, 0.061420440673828125, 0.06722244620323181, 0.07302442193031311, 0.0788264274597168, 0.08462843298912048, 0.09043040871620178, 0.09623241424560547, 0.10203441977500916, 0.10783639550209045, 0.11363840103149414, 0.11944040656089783, 0.12524238228797913, 0.1310443878173828, 0.1368463933467865, 0.1426483690738678, 0.14845037460327148]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.599075198173523, -0.5830305814743042, -0.5669859051704407, -0.5509412884712219, -0.5348966121673584, -0.5188519954681396, -0.5028073787689209, -0.48676273226737976, -0.4707180857658386, -0.4546734392642975, -0.43862879276275635, -0.4225841760635376, -0.40653952956199646, -0.3904948830604553, -0.3744502663612366, -0.35840561985969543, -0.3423609733581543, -0.32631632685661316, -0.310271680355072, -0.29422706365585327, -0.27818241715431213, -0.262137770652771, -0.24609315395355225, -0.2300485074520111, -0.21400386095046997, -0.19795921444892883, -0.1819145679473877, -0.16586995124816895, -0.1498253047466278, -0.13378065824508667, -0.11773604154586792, -0.10169139504432678, -0.08564674854278564, -0.0696021318435669, -0.05355745553970337, -0.03751283884048462, -0.021468162536621094, -0.005423545837402344, 0.010621070861816406, 0.02666574716567993, 0.04271036386489868, 0.05875498056411743, 0.07479965686798096, 0.09084427356719971, 0.10688889026641846, 0.12293356657028198, 0.13897818326950073, 0.15502285957336426, 0.171067476272583, 0.18711209297180176, 0.20315676927566528, 0.21920138597488403, 0.23524606227874756, 0.2512906789779663, 0.26733529567718506, 0.2833799719810486, 0.29942458868026733, 0.3154692053794861, 0.3315138816833496, 0.34755849838256836, 0.3636031150817871, 0.37964779138565063, 0.3956924080848694, 0.4117370843887329, 0.42778170108795166]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 6.0, 7.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.11782350391149521, -0.11476195603609085, -0.11170040816068649, -0.10863886028528214, -0.10557731240987778, -0.10251576453447342, -0.09945421665906906, -0.0963926687836647, -0.09333112090826035, -0.09026957303285599, -0.08720802515745163, -0.08414647728204727, -0.08108492940664291, -0.07802338153123856, -0.0749618336558342, -0.07190028578042984, -0.06883873790502548, -0.06577719002962112, -0.06271564215421677, -0.05965409427881241, -0.05659254640340805, -0.05353099852800369, -0.050469450652599335, -0.04740790277719498, -0.04434635490179062, -0.04128480702638626, -0.0382232591509819, -0.035161711275577545, -0.03210016340017319, -0.02903861552476883, -0.02597706764936447, -0.022915519773960114, -0.019853971898555756, -0.016792424023151398, -0.01373087614774704, -0.010669328272342682, -0.007607780396938324, -0.004546232521533966, -0.0014846846461296082, 0.0015768632292747498, 0.004638411104679108, 0.007699958980083466, 0.010761506855487823, 0.013823054730892181, 0.01688460260629654, 0.019946150481700897, 0.023007698357105255, 0.026069246232509613, 0.02913079410791397, 0.03219234198331833, 0.03525388985872269, 0.038315437734127045, 0.0413769856095314, 0.04443853348493576, 0.04750008136034012, 0.050561629235744476, 0.053623177111148834, 0.05668472498655319, 0.05974627286195755, 0.06280782073736191, 0.06586936861276627, 0.06893091648817062, 0.07199246436357498, 0.07505401223897934, 0.0781155601143837]}, "_runtime": 2895.995274782181, "_timestamp": 1585572811.8399081, "_step": 398}
{"Episode reward": -99.82217913269857, "Episode length": 999, "Policy Loss": -0.4417837858200073, "Value Loss": 0.022234797477722168, "_runtime": 2896.8063559532166, "_timestamp": 1585572812.6509893, "_step": 399}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 0.925868034362793, "Value Loss": 15.891195297241211, "_runtime": 2898.3780460357666, "_timestamp": 1585572814.2226794, "_step": 400}
{"Episode reward": -99.82322011627117, "Episode length": 999, "Policy Loss": -0.43861931562423706, "Value Loss": 0.007505623623728752, "_runtime": 2899.944299221039, "_timestamp": 1585572815.7889326, "_step": 401}
{"Episode reward": -99.87193491458753, "Episode length": 999, "Policy Loss": -0.41899311542510986, "Value Loss": 0.02771857939660549, "_runtime": 2901.467470407486, "_timestamp": 1585572817.3121037, "_step": 402}
{"Episode reward": -99.80593069940666, "Episode length": 999, "Policy Loss": -0.375273734331131, "Value Loss": 0.048620566725730896, "_runtime": 2903.0343816280365, "_timestamp": 1585572818.879015, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31092163920402527, "Value Loss": 0.0338759645819664, "_runtime": 2904.27969455719, "_timestamp": 1585572820.124328, "_step": 404}
{"Episode reward": 21.40000000000019, "Episode length": 786, "Policy Loss": 0.6380010843276978, "Value Loss": 10.161771774291992, "_runtime": 2905.8432941436768, "_timestamp": 1585572821.6879275, "_step": 405}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22046403586864471, "Value Loss": 0.003982897847890854, "_runtime": 2907.153059244156, "_timestamp": 1585572822.9976926, "_step": 406}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": 0.5743422508239746, "Value Loss": 9.297260284423828, "_runtime": 2908.7037029266357, "_timestamp": 1585572824.5483363, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19131571054458618, "Value Loss": 0.00567416287958622, "_runtime": 2909.974291563034, "_timestamp": 1585572825.818925, "_step": 408}
{"Episode reward": 18.200000000000372, "Episode length": 818, "Policy Loss": 0.5379328727722168, "Value Loss": 9.259480476379395, "_runtime": 2911.52730345726, "_timestamp": 1585572827.3719368, "_step": 409}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2557620704174042, "Value Loss": 0.012877578847110271, "_runtime": 2912.05809879303, "_timestamp": 1585572827.9027321, "_step": 410}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": 2.0395705699920654, "Value Loss": 31.630170822143555, "_runtime": 2913.472494840622, "_timestamp": 1585572829.3171282, "_step": 411}
{"Episode reward": 8.99707519859166, "Episode length": 911, "Policy Loss": 0.25938838720321655, "Value Loss": 9.112727165222168, "_runtime": 2915.0801994800568, "_timestamp": 1585572830.9248328, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8020404577255249, "Value Loss": 0.1444743424654007, "_runtime": 2916.5846157073975, "_timestamp": 1585572832.429249, "_step": 413}
{"Episode reward": -99.81810818314412, "Episode length": 999, "Policy Loss": -1.033778190612793, "Value Loss": 1.0643048286437988, "_runtime": 2917.0913059711456, "_timestamp": 1585572832.9359393, "_step": 414}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 1.6471855640411377, "Value Loss": 31.660083770751953, "_runtime": 2918.037500858307, "_timestamp": 1585572833.8821342, "_step": 415}
{"Episode reward": 39.89999999999942, "Episode length": 601, "Policy Loss": 0.6463203430175781, "Value Loss": 15.615523338317871, "_runtime": 2918.870787858963, "_timestamp": 1585572834.7154212, "_step": 416}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 1.2060961723327637, "Value Loss": 17.298831939697266, "_runtime": 2920.387843847275, "_timestamp": 1585572836.2324772, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06531072407960892, "Value Loss": 0.06514272838830948, "_runtime": 2921.9204964637756, "_timestamp": 1585572837.7651298, "_step": 418}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25785812735557556, "Value Loss": 0.10261396318674088, "_runtime": 2923.4369838237762, "_timestamp": 1585572839.2816172, "_step": 419}
{"Episode reward": -99.80391307510295, "Episode length": 999, "Policy Loss": 0.45510074496269226, "Value Loss": 0.09685512632131577, "_runtime": 2925.0043864250183, "_timestamp": 1585572840.8490198, "_step": 420}
{"Episode reward": -99.89979258812824, "Episode length": 999, "Policy Loss": 0.698144257068634, "Value Loss": 0.8321045637130737, "_runtime": 2926.5699605941772, "_timestamp": 1585572842.414594, "_step": 421}
{"Episode reward": 0.5000000000013785, "Episode length": 995, "Policy Loss": 1.6699585914611816, "Value Loss": 9.883014678955078, "_runtime": 2928.121819972992, "_timestamp": 1585572843.9664533, "_step": 422}
{"Episode reward": -99.8114293847219, "Episode length": 999, "Policy Loss": 0.31072545051574707, "Value Loss": 0.3114126920700073, "_runtime": 2929.14577126503, "_timestamp": 1585572844.9904046, "_step": 423}
{"Episode reward": 34.89999999999942, "Episode length": 651, "Policy Loss": 1.430275321006775, "Value Loss": 14.571649551391602, "_runtime": 2930.071832895279, "_timestamp": 1585572845.9164662, "_step": 424}
{"Episode reward": 42.099999999999454, "Episode length": 579, "Policy Loss": 0.8846973180770874, "Value Loss": 14.3973970413208, "_runtime": 2931.6326949596405, "_timestamp": 1585572847.4773283, "_step": 425}
{"Episode reward": -99.62643075920504, "Episode length": 999, "Policy Loss": -0.7498553991317749, "Value Loss": 0.059049803763628006, "_runtime": 2932.5581085681915, "_timestamp": 1585572848.402742, "_step": 426}
{"Episode reward": 39.89999999999942, "Episode length": 601, "Policy Loss": 0.4058952033519745, "Value Loss": 14.31280517578125, "_runtime": 2934.0860624313354, "_timestamp": 1585572849.9306958, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3137162923812866, "Value Loss": 0.10292282700538635, "_runtime": 2935.657773256302, "_timestamp": 1585572851.5024066, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4866182804107666, "Value Loss": 0.11683820188045502, "_runtime": 2937.1121904850006, "_timestamp": 1585572852.9568238, "_step": 429}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": -1.0108875036239624, "Value Loss": 8.582334518432617, "_runtime": 2938.1966977119446, "_timestamp": 1585572854.041331, "_step": 430}
{"Episode reward": 30.29764741621881, "Episode length": 698, "Policy Loss": -0.7159813046455383, "Value Loss": 10.95499324798584, "_runtime": 2939.079393386841, "_timestamp": 1585572854.9240267, "_step": 431}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": -0.016711562871932983, "Value Loss": 16.437509536743164, "_runtime": 2940.3502039909363, "_timestamp": 1585572856.1948373, "_step": 432}
{"Episode reward": 18.65280306041275, "Episode length": 815, "Policy Loss": -0.08268190920352936, "Value Loss": 9.361998558044434, "_runtime": 2941.710718393326, "_timestamp": 1585572857.5553517, "_step": 433}
{"Episode reward": 11.500000000000753, "Episode length": 885, "Policy Loss": 0.03380373492836952, "Value Loss": 8.278868675231934, "_runtime": 2943.2161960601807, "_timestamp": 1585572859.0608294, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6968260407447815, "Value Loss": 0.033776164054870605, "_runtime": 2944.755784511566, "_timestamp": 1585572860.6004179, "_step": 435}
{"Episode reward": -99.76615462042253, "Episode length": 999, "Policy Loss": -0.5220465064048767, "Value Loss": 0.019867055118083954, "_runtime": 2945.415006160736, "_timestamp": 1585572861.2596395, "_step": 436}
{"Episode reward": 59.1999999999997, "Episode length": 408, "Policy Loss": 1.2320947647094727, "Value Loss": 18.061370849609375, "_runtime": 2946.975117921829, "_timestamp": 1585572862.8197513, "_step": 437}
{"Episode reward": -99.81434774547675, "Episode length": 999, "Policy Loss": -0.30879780650138855, "Value Loss": 0.04737020283937454, "_runtime": 2948.5409364700317, "_timestamp": 1585572864.3855698, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.27941176295280457, "Value Loss": 0.01803162321448326, "_runtime": 2950.048687696457, "_timestamp": 1585572865.893321, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.25578540563583374, "Value Loss": 0.08215449750423431, "_runtime": 2951.6130108833313, "_timestamp": 1585572867.4576442, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.27386224269866943, "Value Loss": 0.047682151198387146, "_runtime": 2953.171948194504, "_timestamp": 1585572869.0165815, "_step": 441}
{"Episode reward": -99.85167770534613, "Episode length": 999, "Policy Loss": -0.30517837405204773, "Value Loss": 0.05961187556385994, "_runtime": 2954.2702436447144, "_timestamp": 1585572870.114877, "_step": 442}
{"Episode reward": 28.79515771716811, "Episode length": 713, "Policy Loss": 0.7744235396385193, "Value Loss": 12.53296184539795, "_runtime": 2955.840577363968, "_timestamp": 1585572871.6852107, "_step": 443}
{"Episode reward": -99.85670869499305, "Episode length": 999, "Policy Loss": -0.4781116247177124, "Value Loss": 0.016465282067656517, "_runtime": 2957.4114100933075, "_timestamp": 1585572873.2560434, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5743532776832581, "Value Loss": 0.017586106434464455, "_runtime": 2958.574840784073, "_timestamp": 1585572874.4194741, "_step": 445}
{"Episode reward": 23.300000000000082, "Episode length": 767, "Policy Loss": 0.21427634358406067, "Value Loss": 9.541956901550293, "_runtime": 2960.1176812648773, "_timestamp": 1585572875.9623146, "_step": 446}
{"Episode reward": -99.87467305809119, "Episode length": 999, "Policy Loss": -0.7628706097602844, "Value Loss": 0.06559386104345322, "_runtime": 2961.6643965244293, "_timestamp": 1585572877.5090299, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7751624584197998, "Value Loss": 0.03664746880531311, "_runtime": 2963.2294166088104, "_timestamp": 1585572879.07405, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7935599684715271, "Value Loss": 0.05579282343387604, "_runtime": 2964.781875371933, "_timestamp": 1585572880.6265087, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7647051215171814, "Value Loss": 0.021826917305588722, "_runtime": 2966.33381152153, "_timestamp": 1585572882.1784449, "_step": 450}
{"Episode reward": -99.8011020898805, "Episode length": 999, "Policy Loss": -0.7332096099853516, "Value Loss": 0.0673752874135971, "_runtime": 2967.424234390259, "_timestamp": 1585572883.2688677, "_step": 451}
{"Episode reward": 30.39999999999968, "Episode length": 696, "Policy Loss": 0.5445257425308228, "Value Loss": 12.690290451049805, "_runtime": 2968.7163412570953, "_timestamp": 1585572884.5609746, "_step": 452}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.1285317838191986, "Value Loss": 8.127652168273926, "_runtime": 2970.275326728821, "_timestamp": 1585572886.11996, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5585615038871765, "Value Loss": 0.05907196179032326, "_runtime": 2971.8038918972015, "_timestamp": 1585572887.6485252, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44858404994010925, "Value Loss": 0.017852449789643288, "_runtime": 2972.527230501175, "_timestamp": 1585572888.3718638, "_step": 455}
{"Episode reward": 54.39373167604171, "Episode length": 457, "Policy Loss": 1.2729099988937378, "Value Loss": 20.46345329284668, "_runtime": 2974.0873308181763, "_timestamp": 1585572889.9319642, "_step": 456}
{"Episode reward": -99.71602811701456, "Episode length": 999, "Policy Loss": -0.3608351945877075, "Value Loss": 0.010272648185491562, "_runtime": 2974.854413986206, "_timestamp": 1585572890.6990473, "_step": 457}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": 1.110422134399414, "Value Loss": 17.47263526916504, "_runtime": 2976.0521681308746, "_timestamp": 1585572891.8968015, "_step": 458}
{"Episode reward": 20.389316275343546, "Episode length": 798, "Policy Loss": 0.5536535382270813, "Value Loss": 11.750617027282715, "_runtime": 2977.609974384308, "_timestamp": 1585572893.4546077, "_step": 459}
{"Episode reward": -99.80000288486342, "Episode length": 999, "Policy Loss": -0.36469563841819763, "Value Loss": 0.07485359907150269, "_runtime": 2979.1159448623657, "_timestamp": 1585572894.9605782, "_step": 460}
{"Episode reward": -99.7624050129191, "Episode length": 999, "Policy Loss": -0.33661168813705444, "Value Loss": 0.02240181341767311, "_runtime": 2980.6459686756134, "_timestamp": 1585572896.490602, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.29006731510162354, "Value Loss": 0.019932229071855545, "_runtime": 2982.198140144348, "_timestamp": 1585572898.0427735, "_step": 462}
{"Episode reward": -99.80396637953679, "Episode length": 999, "Policy Loss": -0.24028226733207703, "Value Loss": 0.00537750031799078, "_runtime": 2983.6752059459686, "_timestamp": 1585572899.5198393, "_step": 463}
{"Episode reward": 4.200000000001168, "Episode length": 958, "Policy Loss": 0.6360507607460022, "Value Loss": 8.587141036987305, "_runtime": 2985.2716295719147, "_timestamp": 1585572901.116263, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15556567907333374, "Value Loss": 0.02432609163224697, "_runtime": 2986.621704339981, "_timestamp": 1585572902.4663377, "_step": 465}
{"Episode reward": 13.343667572364865, "Episode length": 867, "Policy Loss": 0.608721911907196, "Value Loss": 7.834295749664307, "_runtime": 2987.8820872306824, "_timestamp": 1585572903.7267206, "_step": 466}
{"Episode reward": 19.030605569109653, "Episode length": 811, "Policy Loss": 0.6858295202255249, "Value Loss": 9.539790153503418, "_runtime": 2988.9612572193146, "_timestamp": 1585572904.8058906, "_step": 467}
{"Episode reward": 31.196658405288687, "Episode length": 689, "Policy Loss": 0.6045320630073547, "Value Loss": 10.640593528747559, "_runtime": 2990.51277923584, "_timestamp": 1585572906.3574126, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3643215000629425, "Value Loss": 0.009056824259459972, "_runtime": 2992.0476467609406, "_timestamp": 1585572907.89228, "_step": 469}
{"Episode reward": -99.82949402630189, "Episode length": 999, "Policy Loss": -0.4690800905227661, "Value Loss": 0.01002857182174921, "_runtime": 2992.5362951755524, "_timestamp": 1585572908.3809285, "_step": 470}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 1.4146971702575684, "Value Loss": 22.957128524780273, "_runtime": 2994.088624715805, "_timestamp": 1585572909.933258, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6311886310577393, "Value Loss": 0.014844140969216824, "_runtime": 2995.0797669887543, "_timestamp": 1585572910.9244003, "_step": 472}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 0.35540321469306946, "Value Loss": 12.780284881591797, "_runtime": 2996.5696272850037, "_timestamp": 1585572912.4142606, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7536605000495911, "Value Loss": 0.031578179448843, "_runtime": 2997.973275899887, "_timestamp": 1585572913.8179092, "_step": 474}
{"Episode reward": 9.708782577515493, "Episode length": 903, "Policy Loss": -0.2426781952381134, "Value Loss": 7.585567474365234, "_runtime": 2999.4949412345886, "_timestamp": 1585572915.3395746, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6453232169151306, "Value Loss": 0.0853896513581276, "_runtime": 3000.963449239731, "_timestamp": 1585572916.8080826, "_step": 476}
{"Episode reward": 5.300000000001106, "Episode length": 947, "Policy Loss": 0.24067120254039764, "Value Loss": 8.677324295043945, "_runtime": 3001.8404319286346, "_timestamp": 1585572917.6850653, "_step": 477}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.8906523585319519, "Value Loss": 14.620551109313965, "_runtime": 3002.955879688263, "_timestamp": 1585572918.800513, "_step": 478}
{"Episode reward": 27.599415126070227, "Episode length": 725, "Policy Loss": 0.826884925365448, "Value Loss": 11.520350456237793, "_runtime": 3004.359482526779, "_timestamp": 1585572920.2041159, "_step": 479}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": 0.672671377658844, "Value Loss": 10.812695503234863, "_runtime": 3005.8772888183594, "_timestamp": 1585572921.7219222, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.28658828139305115, "Value Loss": 0.16794827580451965, "_runtime": 3007.3965260982513, "_timestamp": 1585572923.2411594, "_step": 481}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41184762120246887, "Value Loss": 0.013011462986469269, "_runtime": 3008.9580471515656, "_timestamp": 1585572924.8026805, "_step": 482}
{"Episode reward": -99.84605656899372, "Episode length": 999, "Policy Loss": -0.4966432750225067, "Value Loss": 0.019306665286421776, "_runtime": 3010.510016679764, "_timestamp": 1585572926.35465, "_step": 483}
{"Episode reward": -99.85239978432516, "Episode length": 999, "Policy Loss": -0.5689403414726257, "Value Loss": 0.01905760169029236, "_runtime": 3012.0708680152893, "_timestamp": 1585572927.9155014, "_step": 484}
{"Episode reward": -99.86666188277164, "Episode length": 999, "Policy Loss": -0.6229715943336487, "Value Loss": 0.010810939595103264, "_runtime": 3013.6255791187286, "_timestamp": 1585572929.4702125, "_step": 485}
{"Episode reward": -99.80730424523215, "Episode length": 999, "Policy Loss": -0.6479693055152893, "Value Loss": 0.008791807107627392, "_runtime": 3015.043808221817, "_timestamp": 1585572930.8884416, "_step": 486}
{"Episode reward": 8.704023632035572, "Episode length": 913, "Policy Loss": 0.22775442898273468, "Value Loss": 10.009774208068848, "_runtime": 3016.6051177978516, "_timestamp": 1585572932.4497511, "_step": 487}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6744272708892822, "Value Loss": 0.12200762331485748, "_runtime": 3017.544088602066, "_timestamp": 1585572933.388722, "_step": 488}
{"Episode reward": 40.36420040391329, "Episode length": 597, "Policy Loss": 0.5825740694999695, "Value Loss": 11.773588180541992, "_runtime": 3019.1035187244415, "_timestamp": 1585572934.948152, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5394614338874817, "Value Loss": 0.13258573412895203, "_runtime": 3020.664179801941, "_timestamp": 1585572936.5088131, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4228869676589966, "Value Loss": 0.1078466922044754, "_runtime": 3022.1830916404724, "_timestamp": 1585572938.027725, "_step": 491}
{"Episode reward": -99.67703679054837, "Episode length": 999, "Policy Loss": -0.2579598128795624, "Value Loss": 0.02247750572860241, "_runtime": 3023.605832338333, "_timestamp": 1585572939.4504657, "_step": 492}
{"Episode reward": 8.878989325464673, "Episode length": 912, "Policy Loss": 0.6335761547088623, "Value Loss": 8.163010597229004, "_runtime": 3025.1512920856476, "_timestamp": 1585572940.9959254, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.03147972375154495, "Value Loss": 0.008878752589225769, "_runtime": 3026.698487520218, "_timestamp": 1585572942.5431209, "_step": 494}
{"Episode reward": 0.5000000000013785, "Episode length": 995, "Policy Loss": 0.653706431388855, "Value Loss": 7.951719760894775, "_runtime": 3027.4429960250854, "_timestamp": 1585572943.2876294, "_step": 495}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 1.4247218370437622, "Value Loss": 15.448052406311035, "_runtime": 3029.006592273712, "_timestamp": 1585572944.8512256, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1790507286787033, "Value Loss": 0.02636917494237423, "_runtime": 3029.746868133545, "_timestamp": 1585572945.5915015, "_step": 497}
{"Episode reward": 52.89999999999961, "Episode length": 471, "Policy Loss": 1.2325817346572876, "Value Loss": 19.111873626708984, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674, -0.27184879779815674]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0], "bins": [-49.09820556640625, -48.32679748535156, -47.555389404296875, -46.78398513793945, -46.012577056884766, -45.24116897583008, -44.469764709472656, -43.69835662841797, -42.92694854736328, -42.155540466308594, -41.384132385253906, -40.612728118896484, -39.8413200378418, -39.06991195678711, -38.29850769042969, -37.527099609375, -36.75569152832031, -35.984283447265625, -35.21287536621094, -34.441471099853516, -33.67006301879883, -32.89865493774414, -32.12725067138672, -31.35584259033203, -30.584434509277344, -29.813026428222656, -29.0416202545166, -28.270214080810547, -27.49880599975586, -26.727397918701172, -25.955991744995117, -25.184585571289062, -24.413177490234375, -23.641769409179688, -22.870363235473633, -22.098957061767578, -21.32754898071289, -20.556140899658203, -19.78473472595215, -19.013328552246094, -18.241920471191406, -17.47051239013672, -16.69910430908203, -15.92770004272461, -15.156291961669922, -14.384883880615234, -13.613479614257812, -12.842071533203125, -12.070663452148438, -11.29925537109375, -10.527847290039062, -9.75644302368164, -8.985034942626953, -8.213626861572266, -7.442222595214844, -6.670814514160156, -5.899406433105469, -5.127998352050781, -4.356590270996094, -3.585186004638672, -2.8137779235839844, -2.042369842529297, -1.270965576171875, -0.4995574951171875, 0.2718505859375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8710393905639648, -0.8483294248580933, -0.8256194591522217, -0.8029094934463501, -0.7801995277404785, -0.7574895620346069, -0.7347795963287354, -0.7120696306228638, -0.6893596649169922, -0.6666496992111206, -0.643939733505249, -0.6212297677993774, -0.5985198020935059, -0.5758098363876343, -0.5530998706817627, -0.5303899049758911, -0.5076799392700195, -0.48497000336647034, -0.46226003766059875, -0.4395500719547272, -0.4168401062488556, -0.394130140542984, -0.3714201748371124, -0.34871023893356323, -0.32600027322769165, -0.30329030752182007, -0.2805803418159485, -0.2578703761100769, -0.23516041040420532, -0.21245044469833374, -0.18974047899246216, -0.16703051328659058, -0.144320547580719, -0.12161058187484741, -0.09890061616897583, -0.07619065046310425, -0.053480684757232666, -0.030770719051361084, -0.008060753345489502, 0.01464921236038208, 0.03735917806625366, 0.060069143772125244, 0.08277910947799683, 0.10548907518386841, 0.12819904088974, 0.1509089469909668, 0.17361891269683838, 0.19632887840270996, 0.21903884410858154, 0.24174880981445312, 0.2644587755203247, 0.2871687412261963, 0.30987870693206787, 0.33258867263793945, 0.35529863834381104, 0.3780086040496826, 0.4007185697555542, 0.4234285354614258, 0.44613850116729736, 0.46884846687316895, 0.4915584325790405, 0.5142683982849121, 0.5369783639907837, 0.5596883296966553, 0.5823982954025269]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [4.0, 0.0, 0.0, 2.0, 2.0, 4.0, 0.0, 1.0, 3.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 4.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 8.0, 6.0, 18.0, 10.0, 0.0, 326.0, 1.0, 16.0, 19.0, 7.0, 6.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 0.0, 3.0, 1.0, 0.0, 2.0], "bins": [-4.3625874519348145, -4.248856067657471, -4.135124683380127, -4.021393299102783, -3.9076621532440186, -3.793930768966675, -3.68019962310791, -3.5664682388305664, -3.4527368545532227, -3.339005470275879, -3.225274085998535, -3.1115429401397705, -2.9978115558624268, -2.884080171585083, -2.7703490257263184, -2.6566176414489746, -2.542886257171631, -2.429154872894287, -2.3154234886169434, -2.2016923427581787, -2.087960958480835, -1.9742295742034912, -1.8604984283447266, -1.7467670440673828, -1.633035659790039, -1.5193042755126953, -1.4055728912353516, -1.291841745376587, -1.1781103610992432, -1.0643789768218994, -0.9506478309631348, -0.836916446685791, -0.7231850624084473, -0.6094536781311035, -0.49572229385375977, -0.3819911479949951, -0.26825952529907227, -0.15452861785888672, -0.04079723358154297, 0.07293415069580078, 0.18666553497314453, 0.3003969192504883, 0.41412830352783203, 0.5278596878051758, 0.6415905952453613, 0.7553219795227051, 0.8690533638000488, 0.9827847480773926, 1.0965161323547363, 1.21024751663208, 1.3239789009094238, 1.4377102851867676, 1.5514416694641113, 1.6651725769042969, 1.7789039611816406, 1.8926353454589844, 2.006366729736328, 2.120098114013672, 2.2338294982910156, 2.3475608825683594, 2.461291790008545, 2.5750231742858887, 2.6887545585632324, 2.802485942840576, 2.91621732711792]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0], "bins": [-11.369571685791016, -11.115609169006348, -10.861645698547363, -10.607683181762695, -10.353719711303711, -10.099757194519043, -9.845794677734375, -9.59183120727539, -9.337868690490723, -9.083905220031738, -8.82994270324707, -8.575979232788086, -8.322016716003418, -8.06805419921875, -7.814090728759766, -7.560128211975098, -7.3061652183532715, -7.052202224731445, -6.798239231109619, -6.544276714324951, -6.290313720703125, -6.036350727081299, -5.782387733459473, -5.5284247398376465, -5.27446174621582, -5.020499229431152, -4.766536235809326, -4.5125732421875, -4.258610248565674, -4.004647254943848, -3.7506847381591797, -3.4967217445373535, -3.2427587509155273, -2.9887962341308594, -2.734832763671875, -2.480870246887207, -2.2269067764282227, -1.9729442596435547, -1.7189817428588867, -1.4650182723999023, -1.2110557556152344, -0.95709228515625, -0.703129768371582, -0.44916725158691406, -0.1952037811279297, 0.05875873565673828, 0.31272220611572266, 0.5666847229003906, 0.820648193359375, 1.074610710144043, 1.328573226928711, 1.5825366973876953, 1.8364992141723633, 2.0904626846313477, 2.3444252014160156, 2.5983877182006836, 2.852351188659668, 3.106313705444336, 3.3602771759033203, 3.6142396926879883, 3.8682022094726562, 4.122165679931641, 4.376128196716309, 4.630091667175293, 4.884054183959961]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 8.0, 1.0, 5.0, 8.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-1.5404777526855469, -1.4603803157806396, -1.3802828788757324, -1.3001854419708252, -1.220088005065918, -1.1399905681610107, -1.059893250465393, -0.9797958135604858, -0.8996983766555786, -0.8196009397506714, -0.7395035028457642, -0.6594061255455017, -0.5793086886405945, -0.49921131134033203, -0.4191138744354248, -0.3390164375305176, -0.25891900062561035, -0.17882156372070312, -0.0987241268157959, -0.018626689910888672, 0.061470746994018555, 0.14156806468963623, 0.22166550159454346, 0.3017629384994507, 0.3818603754043579, 0.4619576930999756, 0.5420551300048828, 0.62215256690979, 0.7022500038146973, 0.7823474407196045, 0.8624448776245117, 0.942542314529419, 1.0226397514343262, 1.1027371883392334, 1.1828346252441406, 1.2629320621490479, 1.343029499053955, 1.4231269359588623, 1.5032243728637695, 1.5833218097686768, 1.663419246673584, 1.743516445159912, 1.8236138820648193, 1.9037113189697266, 1.9838087558746338, 2.063906192779541, 2.1440036296844482, 2.2241010665893555, 2.3041985034942627, 2.38429594039917, 2.464393138885498, 2.5444908142089844, 2.6245880126953125, 2.704685688018799, 2.784782886505127, 2.8648805618286133, 2.9449777603149414, 3.0250754356384277, 3.105172634124756, 3.185270309448242, 3.2653675079345703, 3.3454651832580566, 3.4255623817443848, 3.505660057067871, 3.585757255554199]}, "_runtime": 3030.849334716797, "_timestamp": 1585572946.693968, "_step": 498}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": 0.5130408406257629, "Value Loss": 11.724879264831543, "_runtime": 3030.849334716797, "_timestamp": 1585572946.693968, "_step": 499}
