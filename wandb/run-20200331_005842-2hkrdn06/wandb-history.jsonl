{"Episode reward": -63.872716770875556, "Episode length": 999, "Policy Loss": 0.03142975643277168, "Value Loss": 0.07211674749851227, "_runtime": 18971.93988966942, "_timestamp": 1585616341.5727592, "_step": 0}
{"Episode reward": 16.486245012525558, "Episode length": 941, "Policy Loss": 0.46386024355888367, "Value Loss": 17.326404571533203, "_runtime": 18973.47039246559, "_timestamp": 1585616343.103262, "_step": 1}
{"Episode reward": -94.92914902178859, "Episode length": 999, "Policy Loss": -3.3753905296325684, "Value Loss": 4880.83251953125, "_runtime": 18975.058107852936, "_timestamp": 1585616344.6909773, "_step": 2}
{"Episode reward": -96.90579018620417, "Episode length": 999, "Policy Loss": -2.9122579097747803, "Value Loss": 62.78770446777344, "_runtime": 18976.60249567032, "_timestamp": 1585616346.2353652, "_step": 3}
{"Episode reward": -97.17748864702904, "Episode length": 999, "Policy Loss": -1.3197897672653198, "Value Loss": 316.1250915527344, "_runtime": 18977.68772625923, "_timestamp": 1585616347.3205957, "_step": 4}
{"Episode reward": 30.999490243315833, "Episode length": 701, "Policy Loss": 5.055929183959961, "Value Loss": 207.72267150878906, "_runtime": 18979.26703596115, "_timestamp": 1585616348.8999054, "_step": 5}
{"Episode reward": -98.72594625633515, "Episode length": 999, "Policy Loss": 6.743793487548828, "Value Loss": 2466.697021484375, "_runtime": 18980.817339658737, "_timestamp": 1585616350.4502091, "_step": 6}
{"Episode reward": -98.57215305388429, "Episode length": 999, "Policy Loss": 11.934728622436523, "Value Loss": 1414.845458984375, "_runtime": 18982.345947742462, "_timestamp": 1585616351.9788172, "_step": 7}
{"Episode reward": -98.88942445632394, "Episode length": 999, "Policy Loss": 6.562117099761963, "Value Loss": 322.08544921875, "_runtime": 18983.93244123459, "_timestamp": 1585616353.5653107, "_step": 8}
{"Episode reward": -99.04640354990161, "Episode length": 999, "Policy Loss": 4.868621349334717, "Value Loss": 15.144685745239258, "_runtime": 18985.505454301834, "_timestamp": 1585616355.1383238, "_step": 9}
{"Episode reward": -98.66906733391417, "Episode length": 999, "Policy Loss": 2.1934006214141846, "Value Loss": 30.883167266845703, "_runtime": 18986.855860233307, "_timestamp": 1585616356.4887297, "_step": 10}
{"Episode reward": 13.194326616000595, "Episode length": 878, "Policy Loss": 1.3649091720581055, "Value Loss": 70.98886108398438, "_runtime": 18988.49164414406, "_timestamp": 1585616358.1245136, "_step": 11}
{"Episode reward": -98.35344113013367, "Episode length": 999, "Policy Loss": -1.0113648176193237, "Value Loss": 22.429466247558594, "_runtime": 18990.070166826248, "_timestamp": 1585616359.7030363, "_step": 12}
{"Episode reward": -98.60304875989955, "Episode length": 999, "Policy Loss": -3.215740442276001, "Value Loss": 43.42143249511719, "_runtime": 18991.620198726654, "_timestamp": 1585616361.2530682, "_step": 13}
{"Episode reward": -97.95955882314696, "Episode length": 999, "Policy Loss": -0.785053551197052, "Value Loss": 366.3820495605469, "_runtime": 18993.207778930664, "_timestamp": 1585616362.8406484, "_step": 14}
{"Episode reward": -99.14499657470888, "Episode length": 999, "Policy Loss": -2.509561538696289, "Value Loss": 87.33738708496094, "_runtime": 18994.782179117203, "_timestamp": 1585616364.4150486, "_step": 15}
{"Episode reward": -99.00821455363344, "Episode length": 999, "Policy Loss": -5.607452392578125, "Value Loss": 152.005859375, "_runtime": 18995.53555703163, "_timestamp": 1585616365.1684265, "_step": 16}
{"Episode reward": 54.290316355839366, "Episode length": 465, "Policy Loss": -3.0577776432037354, "Value Loss": 169.51573181152344, "_runtime": 18996.36842250824, "_timestamp": 1585616366.001292, "_step": 17}
{"Episode reward": 49.14713284692317, "Episode length": 514, "Policy Loss": -2.728400945663452, "Value Loss": 41.33074188232422, "_runtime": 18997.143912792206, "_timestamp": 1585616366.7767823, "_step": 18}
{"Episode reward": 53.3293339423886, "Episode length": 473, "Policy Loss": -1.6080141067504883, "Value Loss": 209.17564392089844, "_runtime": 18998.677478551865, "_timestamp": 1585616368.310348, "_step": 19}
{"Episode reward": -98.07944944959931, "Episode length": 999, "Policy Loss": -3.7019221782684326, "Value Loss": 26.558185577392578, "_runtime": 19000.183685541153, "_timestamp": 1585616369.816555, "_step": 20}
{"Episode reward": 3.6919423358967265, "Episode length": 982, "Policy Loss": -3.5029096603393555, "Value Loss": 61.0988883972168, "_runtime": 19001.71942138672, "_timestamp": 1585616371.3522909, "_step": 21}
{"Episode reward": -98.86651936703551, "Episode length": 999, "Policy Loss": -2.5132415294647217, "Value Loss": 19.096588134765625, "_runtime": 19002.75822854042, "_timestamp": 1585616372.391098, "_step": 22}
{"Episode reward": 34.73086078391144, "Episode length": 664, "Policy Loss": -1.678836464881897, "Value Loss": 37.823123931884766, "_runtime": 19004.327268838882, "_timestamp": 1585616373.9601383, "_step": 23}
{"Episode reward": -98.83346841898049, "Episode length": 999, "Policy Loss": -1.0389493703842163, "Value Loss": 3.7519960403442383, "_runtime": 19005.89311861992, "_timestamp": 1585616375.525988, "_step": 24}
{"Episode reward": -98.29312046724931, "Episode length": 999, "Policy Loss": 0.12434893101453781, "Value Loss": 7.971615791320801, "_runtime": 19007.433076381683, "_timestamp": 1585616377.0659459, "_step": 25}
{"Episode reward": -98.06831962755184, "Episode length": 999, "Policy Loss": 0.5054304599761963, "Value Loss": 10.441183090209961, "_runtime": 19009.00661087036, "_timestamp": 1585616378.6394804, "_step": 26}
{"Episode reward": -98.49779984246804, "Episode length": 999, "Policy Loss": 1.973434567451477, "Value Loss": 25.83839988708496, "_runtime": 19010.589664936066, "_timestamp": 1585616380.2225344, "_step": 27}
{"Episode reward": -98.23931886429213, "Episode length": 999, "Policy Loss": 2.6880910396575928, "Value Loss": 20.831987380981445, "_runtime": 19012.202527046204, "_timestamp": 1585616381.8353965, "_step": 28}
{"Episode reward": -98.672188496222, "Episode length": 999, "Policy Loss": 2.9781908988952637, "Value Loss": 15.890596389770508, "_runtime": 19013.791883945465, "_timestamp": 1585616383.4247534, "_step": 29}
{"Episode reward": -99.16744764095522, "Episode length": 999, "Policy Loss": 3.911015510559082, "Value Loss": 12.588225364685059, "_runtime": 19015.377481222153, "_timestamp": 1585616385.0103507, "_step": 30}
{"Episode reward": -98.455955345744, "Episode length": 999, "Policy Loss": 0.6625183820724487, "Value Loss": 215.8462371826172, "_runtime": 19016.954412698746, "_timestamp": 1585616386.5872822, "_step": 31}
{"Episode reward": -97.56468508885028, "Episode length": 999, "Policy Loss": 1.827805519104004, "Value Loss": 20.18535041809082, "_runtime": 19017.900790452957, "_timestamp": 1585616387.53366, "_step": 32}
{"Episode reward": 42.46019252517834, "Episode length": 589, "Policy Loss": 1.1433770656585693, "Value Loss": 23.537914276123047, "_runtime": 19019.484981298447, "_timestamp": 1585616389.1178508, "_step": 33}
{"Episode reward": -98.11908917427381, "Episode length": 999, "Policy Loss": -1.294913649559021, "Value Loss": 11.42531967163086, "_runtime": 19021.066951990128, "_timestamp": 1585616390.6998215, "_step": 34}
{"Episode reward": -97.9941595110233, "Episode length": 999, "Policy Loss": -0.9811066389083862, "Value Loss": 85.31682586669922, "_runtime": 19022.6083650589, "_timestamp": 1585616392.2412345, "_step": 35}
{"Episode reward": -96.8288384428971, "Episode length": 999, "Policy Loss": -2.6853280067443848, "Value Loss": 38.86088943481445, "_runtime": 19023.82791543007, "_timestamp": 1585616393.460785, "_step": 36}
{"Episode reward": 25.363762758627516, "Episode length": 768, "Policy Loss": -0.3641626536846161, "Value Loss": 84.86375427246094, "_runtime": 19024.80744934082, "_timestamp": 1585616394.4403188, "_step": 37}
{"Episode reward": 39.85327565715739, "Episode length": 618, "Policy Loss": -1.2450499534606934, "Value Loss": 36.14435577392578, "_runtime": 19026.384746551514, "_timestamp": 1585616396.017616, "_step": 38}
{"Episode reward": -96.85014195836479, "Episode length": 999, "Policy Loss": -2.3114631175994873, "Value Loss": 0.7995728850364685, "_runtime": 19027.945955753326, "_timestamp": 1585616397.5788252, "_step": 39}
{"Episode reward": -97.04923258043357, "Episode length": 999, "Policy Loss": -2.685669183731079, "Value Loss": 11.251519203186035, "_runtime": 19029.3354074955, "_timestamp": 1585616398.968277, "_step": 40}
{"Episode reward": 11.64265948655445, "Episode length": 902, "Policy Loss": -1.6051851511001587, "Value Loss": 28.564577102661133, "_runtime": 19030.915455579758, "_timestamp": 1585616400.548325, "_step": 41}
{"Episode reward": -96.33409451242461, "Episode length": 999, "Policy Loss": -2.8417954444885254, "Value Loss": 37.40816116333008, "_runtime": 19032.491859912872, "_timestamp": 1585616402.1247294, "_step": 42}
{"Episode reward": -95.49632342754246, "Episode length": 999, "Policy Loss": -1.032157301902771, "Value Loss": 2.8533554077148438, "_runtime": 19033.270869493484, "_timestamp": 1585616402.903739, "_step": 43}
{"Episode reward": 53.661219486001464, "Episode length": 481, "Policy Loss": -0.5423246026039124, "Value Loss": 33.40403747558594, "_runtime": 19034.83692574501, "_timestamp": 1585616404.4697952, "_step": 44}
{"Episode reward": -95.86584616804065, "Episode length": 999, "Policy Loss": -0.5830144286155701, "Value Loss": 0.6308985948562622, "_runtime": 19036.007041454315, "_timestamp": 1585616405.639911, "_step": 45}
{"Episode reward": 31.963748329854837, "Episode length": 710, "Policy Loss": -0.15839150547981262, "Value Loss": 16.067211151123047, "_runtime": 19037.53687286377, "_timestamp": 1585616407.1697423, "_step": 46}
{"Episode reward": -94.93077151135854, "Episode length": 999, "Policy Loss": -0.25475895404815674, "Value Loss": 0.031641636043787, "_runtime": 19039.12135243416, "_timestamp": 1585616408.754222, "_step": 47}
{"Episode reward": -94.56828016217911, "Episode length": 999, "Policy Loss": -0.11464670300483704, "Value Loss": 0.6463160514831543, "_runtime": 19040.582298517227, "_timestamp": 1585616410.215168, "_step": 48}
{"Episode reward": 10.063746835376989, "Episode length": 934, "Policy Loss": 0.599896252155304, "Value Loss": 16.072736740112305, "_runtime": 19041.635391950607, "_timestamp": 1585616411.2682614, "_step": 49}
{"Episode reward": 36.543323863263566, "Episode length": 667, "Policy Loss": 0.8829877376556396, "Value Loss": 20.655038833618164, "_runtime": 19042.32443523407, "_timestamp": 1585616411.9573047, "_step": 50}
{"Episode reward": 60.67975413139578, "Episode length": 419, "Policy Loss": 1.1128777265548706, "Value Loss": 29.82972526550293, "_runtime": 19043.891063690186, "_timestamp": 1585616413.5239332, "_step": 51}
{"Episode reward": -94.51036592516897, "Episode length": 999, "Policy Loss": 0.3239959180355072, "Value Loss": 4.738987445831299, "_runtime": 19045.43673825264, "_timestamp": 1585616415.0696077, "_step": 52}
{"Episode reward": -94.66756785066849, "Episode length": 999, "Policy Loss": 0.26029494404792786, "Value Loss": 1.045459508895874, "_runtime": 19046.958683252335, "_timestamp": 1585616416.5915527, "_step": 53}
{"Episode reward": -94.07058221656976, "Episode length": 999, "Policy Loss": 0.3319166302680969, "Value Loss": 3.219149589538574, "_runtime": 19048.550054073334, "_timestamp": 1585616418.1829236, "_step": 54}
{"Episode reward": -94.80733423705256, "Episode length": 999, "Policy Loss": 0.5032185316085815, "Value Loss": 2.5273892879486084, "_runtime": 19049.498420476913, "_timestamp": 1585616419.13129, "_step": 55}
{"Episode reward": 42.795765552311444, "Episode length": 594, "Policy Loss": 1.2012790441513062, "Value Loss": 18.352672576904297, "_runtime": 19051.03949522972, "_timestamp": 1585616420.6723647, "_step": 56}
{"Episode reward": -94.2700386259138, "Episode length": 999, "Policy Loss": 0.4107140898704529, "Value Loss": 0.2821594476699829, "_runtime": 19051.710441589355, "_timestamp": 1585616421.343311, "_step": 57}
{"Episode reward": 61.01895589835081, "Episode length": 403, "Policy Loss": 1.1245918273925781, "Value Loss": 24.800546646118164, "_runtime": 19052.429874181747, "_timestamp": 1585616422.0627437, "_step": 58}
{"Episode reward": 57.14874113551893, "Episode length": 454, "Policy Loss": 1.0318784713745117, "Value Loss": 22.005403518676758, "_runtime": 19053.419450759888, "_timestamp": 1585616423.0523202, "_step": 59}
{"Episode reward": 39.95691198298694, "Episode length": 630, "Policy Loss": 0.8947769403457642, "Value Loss": 16.00004768371582, "_runtime": 19054.695784807205, "_timestamp": 1585616424.3286543, "_step": 60}
{"Episode reward": 18.616012339048112, "Episode length": 843, "Policy Loss": 0.7454290390014648, "Value Loss": 11.973758697509766, "_runtime": 19055.532860517502, "_timestamp": 1585616425.16573, "_step": 61}
{"Episode reward": 49.55477273015758, "Episode length": 543, "Policy Loss": 0.9904208779335022, "Value Loss": 18.770606994628906, "_runtime": 19056.395755052567, "_timestamp": 1585616426.0286245, "_step": 62}
{"Episode reward": 46.70589777772044, "Episode length": 554, "Policy Loss": 0.7386784553527832, "Value Loss": 18.17275047302246, "_runtime": 19057.8684258461, "_timestamp": 1585616427.5012953, "_step": 63}
{"Episode reward": 9.584879886182492, "Episode length": 954, "Policy Loss": 0.48761504888534546, "Value Loss": 10.577676773071289, "_runtime": 19058.915157318115, "_timestamp": 1585616428.5480268, "_step": 64}
{"Episode reward": 34.89112912766406, "Episode length": 681, "Policy Loss": 0.5465824604034424, "Value Loss": 14.846015930175781, "_runtime": 19060.473873376846, "_timestamp": 1585616430.1067429, "_step": 65}
{"Episode reward": -94.5063807462581, "Episode length": 999, "Policy Loss": 0.008681630715727806, "Value Loss": 0.0027435868978500366, "_runtime": 19062.04096341133, "_timestamp": 1585616431.673833, "_step": 66}
{"Episode reward": -94.41680036492318, "Episode length": 999, "Policy Loss": -0.06666506826877594, "Value Loss": 0.0046959975734353065, "_runtime": 19063.58198261261, "_timestamp": 1585616433.214852, "_step": 67}
{"Episode reward": -94.49326717673739, "Episode length": 999, "Policy Loss": -0.13308483362197876, "Value Loss": 0.009100114926695824, "_runtime": 19065.153795957565, "_timestamp": 1585616434.7866654, "_step": 68}
{"Episode reward": -94.59170737808466, "Episode length": 999, "Policy Loss": -0.19175343215465546, "Value Loss": 0.022428737953305244, "_runtime": 19065.945246219635, "_timestamp": 1585616435.5781157, "_step": 69}
{"Episode reward": 53.70326165797668, "Episode length": 485, "Policy Loss": 0.44808831810951233, "Value Loss": 20.772689819335938, "_runtime": 19067.51741695404, "_timestamp": 1585616437.1502864, "_step": 70}
{"Episode reward": -94.94042866300106, "Episode length": 999, "Policy Loss": -0.2960130572319031, "Value Loss": 0.02564311772584915, "_runtime": 19069.100219011307, "_timestamp": 1585616438.7330885, "_step": 71}
{"Episode reward": -93.90560801362395, "Episode length": 999, "Policy Loss": -0.33617258071899414, "Value Loss": 0.04926092550158501, "_runtime": 19070.628400564194, "_timestamp": 1585616440.26127, "_step": 72}
{"Episode reward": -92.82174504645153, "Episode length": 999, "Policy Loss": -0.36436665058135986, "Value Loss": 0.07534398138523102, "_runtime": 19072.204631090164, "_timestamp": 1585616441.8375006, "_step": 73}
{"Episode reward": -93.21342604838743, "Episode length": 999, "Policy Loss": -0.39560702443122864, "Value Loss": 0.020182767882943153, "_runtime": 19073.77954006195, "_timestamp": 1585616443.4124095, "_step": 74}
{"Episode reward": -93.72928602124118, "Episode length": 999, "Policy Loss": -0.435215026140213, "Value Loss": 0.0676628053188324, "_runtime": 19075.35297703743, "_timestamp": 1585616444.9858465, "_step": 75}
{"Episode reward": -93.92342249574206, "Episode length": 999, "Policy Loss": -0.43731826543807983, "Value Loss": 0.04220523312687874, "_runtime": 19076.938296556473, "_timestamp": 1585616446.571166, "_step": 76}
{"Episode reward": -94.60484273067422, "Episode length": 999, "Policy Loss": -0.4569701552391052, "Value Loss": 0.14013776183128357, "_runtime": 19078.34025478363, "_timestamp": 1585616447.9731243, "_step": 77}
{"Episode reward": 18.38477599125021, "Episode length": 884, "Policy Loss": -0.049435101449489594, "Value Loss": 11.287882804870605, "_runtime": 19079.192516326904, "_timestamp": 1585616448.8253858, "_step": 78}
{"Episode reward": 50.45611054154346, "Episode length": 528, "Policy Loss": 0.00344333634711802, "Value Loss": 18.71072769165039, "_runtime": 19079.718863487244, "_timestamp": 1585616449.351733, "_step": 79}
{"Episode reward": 72.29051745762195, "Episode length": 306, "Policy Loss": 0.31988874077796936, "Value Loss": 32.40299987792969, "_runtime": 19080.533524274826, "_timestamp": 1585616450.1663938, "_step": 80}
{"Episode reward": 51.877577781927904, "Episode length": 512, "Policy Loss": -0.06795638054609299, "Value Loss": 19.049528121948242, "_runtime": 19081.72747373581, "_timestamp": 1585616451.3603432, "_step": 81}
{"Episode reward": 27.843916017407054, "Episode length": 776, "Policy Loss": -0.30214449763298035, "Value Loss": 12.730375289916992, "_runtime": 19083.22068476677, "_timestamp": 1585616452.8535542, "_step": 82}
{"Episode reward": -91.50806889833724, "Episode length": 999, "Policy Loss": -0.6830872893333435, "Value Loss": 0.10089278221130371, "_runtime": 19084.571393966675, "_timestamp": 1585616454.2042634, "_step": 83}
{"Episode reward": 20.11097060320273, "Episode length": 867, "Policy Loss": -0.42076852917671204, "Value Loss": 11.378761291503906, "_runtime": 19086.113806009293, "_timestamp": 1585616455.7466755, "_step": 84}
{"Episode reward": -90.98669555447114, "Episode length": 999, "Policy Loss": -0.7853218913078308, "Value Loss": 0.10758458822965622, "_runtime": 19087.6675055027, "_timestamp": 1585616457.300375, "_step": 85}
{"Episode reward": -91.38162114669538, "Episode length": 999, "Policy Loss": -0.7868012189865112, "Value Loss": 0.15449535846710205, "_runtime": 19089.22465825081, "_timestamp": 1585616458.8575277, "_step": 86}
{"Episode reward": -92.22895524936398, "Episode length": 999, "Policy Loss": -0.8176369071006775, "Value Loss": 0.12062682211399078, "_runtime": 19090.805292844772, "_timestamp": 1585616460.4381623, "_step": 87}
{"Episode reward": -90.81067164343088, "Episode length": 999, "Policy Loss": -0.8331242203712463, "Value Loss": 0.08991510421037674, "_runtime": 19092.3799803257, "_timestamp": 1585616462.0128498, "_step": 88}
{"Episode reward": -90.77381437530725, "Episode length": 999, "Policy Loss": -0.8275769352912903, "Value Loss": 0.09176169335842133, "_runtime": 19093.95726132393, "_timestamp": 1585616463.5901308, "_step": 89}
{"Episode reward": -91.21282583588162, "Episode length": 999, "Policy Loss": -0.814682126045227, "Value Loss": 0.12891890108585358, "_runtime": 19095.532966852188, "_timestamp": 1585616465.1658363, "_step": 90}
{"Episode reward": -91.77995567719157, "Episode length": 999, "Policy Loss": -0.7879888415336609, "Value Loss": 0.09156151115894318, "_runtime": 19097.109384298325, "_timestamp": 1585616466.7422538, "_step": 91}
{"Episode reward": -91.31092532422547, "Episode length": 999, "Policy Loss": -0.7610979080200195, "Value Loss": 0.08409101516008377, "_runtime": 19098.69642353058, "_timestamp": 1585616468.329293, "_step": 92}
{"Episode reward": -91.22157903573441, "Episode length": 999, "Policy Loss": -0.7287799119949341, "Value Loss": 0.10253793001174927, "_runtime": 19100.260612487793, "_timestamp": 1585616469.893482, "_step": 93}
{"Episode reward": -90.90926374086729, "Episode length": 999, "Policy Loss": -0.7089957594871521, "Value Loss": 0.0734613835811615, "_runtime": 19101.83108639717, "_timestamp": 1585616471.4639559, "_step": 94}
{"Episode reward": -89.22527417974274, "Episode length": 999, "Policy Loss": -0.6692534685134888, "Value Loss": 0.1625269204378128, "_runtime": 19103.4191904068, "_timestamp": 1585616473.05206, "_step": 95}
{"Episode reward": -90.02302142157484, "Episode length": 999, "Policy Loss": -0.6133806705474854, "Value Loss": 0.07166291028261185, "_runtime": 19105.007132053375, "_timestamp": 1585616474.6400015, "_step": 96}
{"Episode reward": -89.16906474490635, "Episode length": 999, "Policy Loss": -0.5697622299194336, "Value Loss": 0.05129736661911011, "_runtime": 19106.59383416176, "_timestamp": 1585616476.2267036, "_step": 97}
{"Episode reward": -87.70255405137172, "Episode length": 999, "Policy Loss": -0.5232920050621033, "Value Loss": 0.05514697730541229, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742, -18.453947067260742]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 9.0], "bins": [-26.39934730529785, -25.698354721069336, -24.997364044189453, -24.296371459960938, -23.595378875732422, -22.894386291503906, -22.193395614624023, -21.492403030395508, -20.791412353515625, -20.09041976928711, -19.389427185058594, -18.688434600830078, -17.987443923950195, -17.28645133972168, -16.585460662841797, -15.884467124938965, -15.183475494384766, -14.482483863830566, -13.78149127960205, -13.080499649047852, -12.379507064819336, -11.678515434265137, -10.977523803710938, -10.276531219482422, -9.575540542602539, -8.874547958374023, -8.173555374145508, -7.472562789916992, -6.771572113037109, -6.070579528808594, -5.369586944580078, -4.668596267700195, -3.9676036834716797, -3.266611099243164, -2.5656204223632812, -1.8646278381347656, -1.16363525390625, -0.4626445770263672, 0.23834800720214844, 0.9393405914306641, 1.6403331756591797, 2.3413238525390625, 3.042316436767578, 3.7433090209960938, 4.444299697875977, 5.145292282104492, 5.846284866333008, 6.547277450561523, 7.248266220092773, 7.949258804321289, 8.650251388549805, 9.35124397277832, 10.052236557006836, 10.753229141235352, 11.454221725463867, 12.155210494995117, 12.856203079223633, 13.557195663452148, 14.258188247680664, 14.95918083190918, 15.660173416137695, 16.361162185668945, 17.06215476989746, 17.763147354125977, 18.464139938354492]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5.25560188293457, -5.1356072425842285, -5.0156121253967285, -4.895617485046387, -4.775622844696045, -4.655628204345703, -4.535633087158203, -4.415638446807861, -4.2956438064575195, -4.1756486892700195, -4.055654048919678, -3.935659408569336, -3.815664529800415, -3.695669651031494, -3.5756750106811523, -3.4556803703308105, -3.3356854915618896, -3.2156906127929688, -3.095695972442627, -2.975701093673706, -2.8557064533233643, -2.7357115745544434, -2.6157169342041016, -2.4957220554351807, -2.3757271766662598, -2.255732536315918, -2.135737657546997, -2.0157430171966553, -1.8957481384277344, -1.7757534980773926, -1.6557586193084717, -1.5357639789581299, -1.415769100189209, -1.295774221420288, -1.1757793426513672, -1.0557847023010254, -0.9357900619506836, -0.8157954216003418, -0.6958003044128418, -0.5758056640625, -0.4558110237121582, -0.3358159065246582, -0.2158212661743164, -0.09582662582397461, 0.024168014526367188, 0.1441631317138672, 0.264157772064209, 0.3841524124145508, 0.5041475296020508, 0.6241421699523926, 0.7441368103027344, 0.8641314506530762, 0.9841265678405762, 1.104121208190918, 1.2241158485412598, 1.3441104888916016, 1.4641056060791016, 1.5841002464294434, 1.7040948867797852, 1.8240900039672852, 1.944084644317627, 2.0640792846679688, 2.1840739250183105, 2.3040690422058105, 2.4240636825561523]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 6.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 15.0, 24.0, 26.0, 314.0, 25.0, 15.0, 8.0, 2.0, 0.0, 3.0, 4.0, 3.0, 6.0, 4.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 3.0], "bins": [-4.172451019287109, -4.053765296936035, -3.935079336166382, -3.8163933753967285, -3.6977076530456543, -3.579021692276001, -3.4603357315063477, -3.3416500091552734, -3.222964286804199, -3.104278326034546, -2.9855923652648926, -2.8669066429138184, -2.748220682144165, -2.6295347213745117, -2.5108489990234375, -2.3921632766723633, -2.27347731590271, -2.1547913551330566, -2.0361056327819824, -1.917419672012329, -1.7987339496612549, -1.6800479888916016, -1.5613622665405273, -1.442676305770874, -1.3239903450012207, -1.2053046226501465, -1.0866186618804932, -0.967932939529419, -0.8492469787597656, -0.7305612564086914, -0.6118752956390381, -0.49318957328796387, -0.37450361251831055, -0.2558176517486572, -0.1371316909790039, -0.018445968627929688, 0.10023975372314453, 0.21892547607421875, 0.33761167526245117, 0.4562973976135254, 0.5749831199645996, 0.693669319152832, 0.8123550415039062, 0.9310407638549805, 1.0497264862060547, 1.168412685394287, 1.2870984077453613, 1.4057841300964355, 1.524470329284668, 1.6431560516357422, 1.7618417739868164, 1.8805274963378906, 1.999213695526123, 2.1178994178771973, 2.2365851402282715, 2.3552708625793457, 2.473957061767578, 2.5926427841186523, 2.7113285064697266, 2.830014705657959, 2.948700428009033, 3.0673861503601074, 3.1860718727111816, 3.304758071899414, 3.4234437942504883]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-2.201674461364746, -2.132173538208008, -2.0626723766326904, -1.9931713342666626, -1.9236702919006348, -1.854169249534607, -1.784668207168579, -1.7151671648025513, -1.6456661224365234, -1.5761650800704956, -1.5066640377044678, -1.43716299533844, -1.367661952972412, -1.2981609106063843, -1.2286598682403564, -1.1591588258743286, -1.0896577835083008, -1.020156741142273, -0.9506556987762451, -0.8811546564102173, -0.8116536140441895, -0.7421525716781616, -0.6726515293121338, -0.603150486946106, -0.5336494445800781, -0.4641484022140503, -0.39464735984802246, -0.32514631748199463, -0.2556452751159668, -0.18614435195922852, -0.11664319038391113, -0.04714202880859375, 0.02235889434814453, 0.09185981750488281, 0.1613609790802002, 0.23086214065551758, 0.30036306381225586, 0.36986398696899414, 0.4393651485443115, 0.5088663101196289, 0.5783672332763672, 0.6478681564331055, 0.7173693180084229, 0.7868704795837402, 0.8563714027404785, 0.9258723258972168, 0.9953734874725342, 1.0648746490478516, 1.1343755722045898, 1.2038764953613281, 1.2733776569366455, 1.342878818511963, 1.4123797416687012, 1.4818806648254395, 1.5513818264007568, 1.6208829879760742, 1.6903839111328125, 1.7598848342895508, 1.829385757446289, 1.8988871574401855, 1.9683880805969238, 2.037889003753662, 2.1073904037475586, 2.176891326904297, 2.246392250061035]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 5.0, 1.0, 0.0, 3.0, 3.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8240219354629517, -0.7973442077636719, -0.7706664800643921, -0.7439888119697571, -0.7173110842704773, -0.6906333565711975, -0.6639556288719177, -0.6372779607772827, -0.6106002330780029, -0.5839225053787231, -0.5572447776794434, -0.5305670499801636, -0.5038893222808838, -0.4772116541862488, -0.450533926486969, -0.4238562285900116, -0.3971785008907318, -0.370500773191452, -0.34382307529449463, -0.31714534759521484, -0.29046761989593506, -0.26378995180130005, -0.23711222410202026, -0.21043449640274048, -0.1837567687034607, -0.1570790410041809, -0.1304013729095459, -0.10372364521026611, -0.07704591751098633, -0.05036818981170654, -0.023690521717071533, 0.002987205982208252, 0.029664933681488037, 0.05634266138076782, 0.08302038908004761, 0.10969805717468262, 0.1363757848739624, 0.1630535125732422, 0.18973124027252197, 0.21640896797180176, 0.24308669567108154, 0.26976442337036133, 0.29644203186035156, 0.32311975955963135, 0.34979748725891113, 0.3764752149581909, 0.4031529426574707, 0.4298306703567505, 0.4565083980560303, 0.48318612575531006, 0.5098638534545898, 0.5365414619445801, 0.5632191896438599, 0.5898969173431396, 0.6165746450424194, 0.6432523727416992, 0.669930100440979, 0.6966078281402588, 0.7232855558395386, 0.7499632835388184, 0.7766408920288086, 0.8033186197280884, 0.8299963474273682, 0.856674075126648, 0.8833518028259277]}, "_runtime": 19107.018471717834, "_timestamp": 1585616476.6513412, "_step": 98}
{"Episode reward": 79.66303389033199, "Episode length": 233, "Policy Loss": 0.5666589736938477, "Value Loss": 41.88089370727539, "_runtime": 19108.619540452957, "_timestamp": 1585616478.25241, "_step": 99}
{"Episode reward": -89.21117074772748, "Episode length": 999, "Policy Loss": -0.4550190269947052, "Value Loss": 0.08741037547588348, "_runtime": 19110.18675661087, "_timestamp": 1585616479.819626, "_step": 100}
{"Episode reward": -91.05044028091322, "Episode length": 999, "Policy Loss": -0.4326167702674866, "Value Loss": 0.09100505709648132, "_runtime": 19111.50815820694, "_timestamp": 1585616481.1410277, "_step": 101}
{"Episode reward": 20.937904169574324, "Episode length": 882, "Policy Loss": -0.13386403024196625, "Value Loss": 11.152552604675293, "_runtime": 19112.500317811966, "_timestamp": 1585616482.1331873, "_step": 102}
{"Episode reward": 44.13206204550126, "Episode length": 621, "Policy Loss": 0.18884405493736267, "Value Loss": 15.879923820495605, "_runtime": 19114.07909679413, "_timestamp": 1585616483.7119663, "_step": 103}
{"Episode reward": -90.20123670035447, "Episode length": 999, "Policy Loss": -0.33935415744781494, "Value Loss": 0.029351089149713516, "_runtime": 19115.624993801117, "_timestamp": 1585616485.2578633, "_step": 104}
{"Episode reward": -93.33527542915635, "Episode length": 999, "Policy Loss": -0.3144102394580841, "Value Loss": 0.04275035485625267, "_runtime": 19117.172221660614, "_timestamp": 1585616486.8050911, "_step": 105}
{"Episode reward": -91.52406194040395, "Episode length": 999, "Policy Loss": -0.28823721408843994, "Value Loss": 0.021899795159697533, "_runtime": 19118.749042510986, "_timestamp": 1585616488.381912, "_step": 106}
{"Episode reward": -91.98748476098794, "Episode length": 999, "Policy Loss": -0.26141446828842163, "Value Loss": 0.018104644492268562, "_runtime": 19120.310725450516, "_timestamp": 1585616489.943595, "_step": 107}
{"Episode reward": -91.7519505660795, "Episode length": 999, "Policy Loss": -0.23146797716617584, "Value Loss": 0.011381801217794418, "_runtime": 19121.887118577957, "_timestamp": 1585616491.519988, "_step": 108}
{"Episode reward": -92.71318522908578, "Episode length": 999, "Policy Loss": -0.21020840108394623, "Value Loss": 0.03909999504685402, "_runtime": 19123.475915670395, "_timestamp": 1585616493.1087852, "_step": 109}
{"Episode reward": -92.31504759725637, "Episode length": 999, "Policy Loss": -0.1795988380908966, "Value Loss": 0.010746654123067856, "_runtime": 19125.04910349846, "_timestamp": 1585616494.681973, "_step": 110}
{"Episode reward": -91.98640136964934, "Episode length": 999, "Policy Loss": -0.1473233550786972, "Value Loss": 0.005641611758619547, "_runtime": 19126.63299036026, "_timestamp": 1585616496.2658598, "_step": 111}
{"Episode reward": -92.98475431789616, "Episode length": 999, "Policy Loss": -0.1260477751493454, "Value Loss": 0.021646108478307724, "_runtime": 19128.070463895798, "_timestamp": 1585616497.7033334, "_step": 112}
{"Episode reward": 16.929894715586826, "Episode length": 904, "Policy Loss": 0.34139251708984375, "Value Loss": 10.833423614501953, "_runtime": 19129.657856225967, "_timestamp": 1585616499.2907257, "_step": 113}
{"Episode reward": -92.53923495410966, "Episode length": 999, "Policy Loss": -0.07294290512800217, "Value Loss": 0.01472842413932085, "_runtime": 19131.28086090088, "_timestamp": 1585616500.9137304, "_step": 114}
{"Episode reward": -93.97557790025887, "Episode length": 999, "Policy Loss": -0.06030764803290367, "Value Loss": 0.004361995495855808, "_runtime": 19132.84648013115, "_timestamp": 1585616502.4793496, "_step": 115}
{"Episode reward": -92.99490216969714, "Episode length": 999, "Policy Loss": -0.034422919154167175, "Value Loss": 0.025220027193427086, "_runtime": 19134.398585796356, "_timestamp": 1585616504.0314553, "_step": 116}
{"Episode reward": -94.16480439433269, "Episode length": 999, "Policy Loss": -0.027469584718346596, "Value Loss": 0.04468691721558571, "_runtime": 19135.64443397522, "_timestamp": 1585616505.2773035, "_step": 117}
{"Episode reward": 25.674671733168026, "Episode length": 790, "Policy Loss": 0.34449249505996704, "Value Loss": 12.382272720336914, "_runtime": 19137.214575767517, "_timestamp": 1585616506.8474452, "_step": 118}
{"Episode reward": -93.59009782056809, "Episode length": 999, "Policy Loss": -0.007924254052340984, "Value Loss": 0.009128829464316368, "_runtime": 19138.79054069519, "_timestamp": 1585616508.4234102, "_step": 119}
{"Episode reward": -94.04118948851269, "Episode length": 999, "Policy Loss": -0.004101810976862907, "Value Loss": 0.007609887979924679, "_runtime": 19140.346752405167, "_timestamp": 1585616509.979622, "_step": 120}
{"Episode reward": -95.47675555732764, "Episode length": 999, "Policy Loss": -0.008036918938159943, "Value Loss": 0.010936571285128593, "_runtime": 19141.90415906906, "_timestamp": 1585616511.5370286, "_step": 121}
{"Episode reward": -94.2589702386132, "Episode length": 999, "Policy Loss": -0.0026330044493079185, "Value Loss": 0.014598195441067219, "_runtime": 19143.460190296173, "_timestamp": 1585616513.0930598, "_step": 122}
{"Episode reward": -94.22209887665267, "Episode length": 999, "Policy Loss": 0.0009741184185259044, "Value Loss": 0.06254396587610245, "_runtime": 19145.02014708519, "_timestamp": 1585616514.6530166, "_step": 123}
{"Episode reward": -93.42533313322866, "Episode length": 999, "Policy Loss": 0.0031434036791324615, "Value Loss": 0.007319701835513115, "_runtime": 19146.592707633972, "_timestamp": 1585616516.225577, "_step": 124}
{"Episode reward": -94.57881560558151, "Episode length": 999, "Policy Loss": 0.008487088605761528, "Value Loss": 0.048001401126384735, "_runtime": 19147.594017505646, "_timestamp": 1585616517.226887, "_step": 125}
{"Episode reward": 39.968144021296276, "Episode length": 635, "Policy Loss": 0.5363864302635193, "Value Loss": 15.408198356628418, "_runtime": 19149.067457437515, "_timestamp": 1585616518.700327, "_step": 126}
{"Episode reward": 10.558240590846395, "Episode length": 945, "Policy Loss": 0.26985877752304077, "Value Loss": 10.125068664550781, "_runtime": 19150.228322029114, "_timestamp": 1585616519.8611915, "_step": 127}
{"Episode reward": 30.420953128954707, "Episode length": 737, "Policy Loss": 0.3306187391281128, "Value Loss": 13.064122200012207, "_runtime": 19150.98152947426, "_timestamp": 1585616520.614399, "_step": 128}
{"Episode reward": 54.43358665132667, "Episode length": 484, "Policy Loss": 1.1406196355819702, "Value Loss": 19.946674346923828, "_runtime": 19152.541021823883, "_timestamp": 1585616522.1738913, "_step": 129}
{"Episode reward": -94.75439295463474, "Episode length": 999, "Policy Loss": -0.13971467316150665, "Value Loss": 0.02304329164326191, "_runtime": 19154.130464076996, "_timestamp": 1585616523.7633336, "_step": 130}
{"Episode reward": -95.3188200346474, "Episode length": 999, "Policy Loss": -0.18792133033275604, "Value Loss": 0.027766287326812744, "_runtime": 19155.645833730698, "_timestamp": 1585616525.2787032, "_step": 131}
{"Episode reward": -96.26174427187416, "Episode length": 999, "Policy Loss": -0.24142146110534668, "Value Loss": 0.04494144022464752, "_runtime": 19156.78136754036, "_timestamp": 1585616526.414237, "_step": 132}
{"Episode reward": 31.007036144387257, "Episode length": 721, "Policy Loss": 0.21417437493801117, "Value Loss": 13.192129135131836, "_runtime": 19158.048872709274, "_timestamp": 1585616527.6817422, "_step": 133}
{"Episode reward": 21.87162378746055, "Episode length": 812, "Policy Loss": 0.057424332946538925, "Value Loss": 11.92749309539795, "_runtime": 19159.557045698166, "_timestamp": 1585616529.1899152, "_step": 134}
{"Episode reward": 5.800129919417898, "Episode length": 971, "Policy Loss": -0.07072068750858307, "Value Loss": 10.184844017028809, "_runtime": 19161.0960252285, "_timestamp": 1585616530.7288947, "_step": 135}
{"Episode reward": -95.74708219017485, "Episode length": 999, "Policy Loss": -0.44764769077301025, "Value Loss": 0.019254326820373535, "_runtime": 19162.647080659866, "_timestamp": 1585616532.2799501, "_step": 136}
{"Episode reward": -96.03693491137649, "Episode length": 999, "Policy Loss": -0.47119587659835815, "Value Loss": 0.1015285849571228, "_runtime": 19164.200632810593, "_timestamp": 1585616533.8335023, "_step": 137}
{"Episode reward": -96.73387015354508, "Episode length": 999, "Policy Loss": -0.5230961441993713, "Value Loss": 0.022662242874503136, "_runtime": 19165.05350470543, "_timestamp": 1585616534.6863742, "_step": 138}
{"Episode reward": 48.79821999206016, "Episode length": 530, "Policy Loss": 0.15825407207012177, "Value Loss": 17.877309799194336, "_runtime": 19166.193712472916, "_timestamp": 1585616535.826582, "_step": 139}
{"Episode reward": 29.62598120273161, "Episode length": 727, "Policy Loss": 0.06643474847078323, "Value Loss": 13.464719772338867, "_runtime": 19167.751397371292, "_timestamp": 1585616537.3842669, "_step": 140}
{"Episode reward": -96.49969473924082, "Episode length": 999, "Policy Loss": -0.6125590205192566, "Value Loss": 0.06865398585796356, "_runtime": 19169.273039340973, "_timestamp": 1585616538.9059088, "_step": 141}
{"Episode reward": -96.27612470249156, "Episode length": 999, "Policy Loss": -0.636506974697113, "Value Loss": 0.029765082523226738, "_runtime": 19170.825949430466, "_timestamp": 1585616540.458819, "_step": 142}
{"Episode reward": -97.95262358532126, "Episode length": 999, "Policy Loss": -0.6555123925209045, "Value Loss": 0.056492261588573456, "_runtime": 19171.817331314087, "_timestamp": 1585616541.4502008, "_step": 143}
{"Episode reward": 39.11530983512354, "Episode length": 627, "Policy Loss": -0.09813819080591202, "Value Loss": 14.871273040771484, "_runtime": 19173.34972667694, "_timestamp": 1585616542.9825962, "_step": 144}
{"Episode reward": 4.10875747848884, "Episode length": 987, "Policy Loss": -0.17660489678382874, "Value Loss": 9.866631507873535, "_runtime": 19174.917502641678, "_timestamp": 1585616544.5503721, "_step": 145}
{"Episode reward": -97.02494247529164, "Episode length": 999, "Policy Loss": -0.6896668076515198, "Value Loss": 0.03605896234512329, "_runtime": 19176.4460003376, "_timestamp": 1585616546.0788698, "_step": 146}
{"Episode reward": -97.2761882069376, "Episode length": 999, "Policy Loss": -0.6878089308738708, "Value Loss": 0.05041582137346268, "_runtime": 19178.040760040283, "_timestamp": 1585616547.6736295, "_step": 147}
{"Episode reward": -97.01415215280154, "Episode length": 999, "Policy Loss": -0.6663001775741577, "Value Loss": 0.10476863384246826, "_runtime": 19179.603733301163, "_timestamp": 1585616549.2366028, "_step": 148}
{"Episode reward": -97.60920122786857, "Episode length": 999, "Policy Loss": -0.6543020009994507, "Value Loss": 0.052568838000297546, "_runtime": 19179.98356938362, "_timestamp": 1585616549.6164389, "_step": 149}
{"Episode reward": 78.92284920155187, "Episode length": 214, "Policy Loss": 1.0544034242630005, "Value Loss": 43.83088684082031, "_runtime": 19181.553457975388, "_timestamp": 1585616551.1863275, "_step": 150}
{"Episode reward": -97.19751865111184, "Episode length": 999, "Policy Loss": -0.673829972743988, "Value Loss": 0.04864111170172691, "_runtime": 19183.123224258423, "_timestamp": 1585616552.7560937, "_step": 151}
{"Episode reward": -97.27059714364258, "Episode length": 999, "Policy Loss": -0.7183753252029419, "Value Loss": 0.1038842499256134, "_runtime": 19184.61137366295, "_timestamp": 1585616554.2442431, "_step": 152}
{"Episode reward": -98.29992454924219, "Episode length": 999, "Policy Loss": -0.7381415963172913, "Value Loss": 0.045966289937496185, "_runtime": 19185.019632339478, "_timestamp": 1585616554.6525018, "_step": 153}
{"Episode reward": 77.64147655485581, "Episode length": 229, "Policy Loss": 1.3652689456939697, "Value Loss": 42.53018569946289, "_runtime": 19186.076348781586, "_timestamp": 1585616555.7092183, "_step": 154}
{"Episode reward": 34.750292425317085, "Episode length": 673, "Policy Loss": -0.1456436961889267, "Value Loss": 14.522302627563477, "_runtime": 19187.46566271782, "_timestamp": 1585616557.0985322, "_step": 155}
{"Episode reward": 11.722573291767375, "Episode length": 903, "Policy Loss": -0.3654320538043976, "Value Loss": 10.656702041625977, "_runtime": 19188.95567893982, "_timestamp": 1585616558.5885484, "_step": 156}
{"Episode reward": -97.89947490812945, "Episode length": 999, "Policy Loss": -0.7898884415626526, "Value Loss": 0.07554063946008682, "_runtime": 19190.495096683502, "_timestamp": 1585616560.1279662, "_step": 157}
{"Episode reward": -97.45814708586083, "Episode length": 999, "Policy Loss": -0.8011766672134399, "Value Loss": 0.147615447640419, "_runtime": 19192.03526711464, "_timestamp": 1585616561.6681366, "_step": 158}
{"Episode reward": -97.50452656244516, "Episode length": 999, "Policy Loss": -0.7832045555114746, "Value Loss": 0.03788786754012108, "_runtime": 19193.58104634285, "_timestamp": 1585616563.2139158, "_step": 159}
{"Episode reward": -97.52985303637585, "Episode length": 999, "Policy Loss": -0.7639865875244141, "Value Loss": 0.03943508490920067, "_runtime": 19195.155848503113, "_timestamp": 1585616564.788718, "_step": 160}
{"Episode reward": -97.98396690886737, "Episode length": 999, "Policy Loss": -0.7420707941055298, "Value Loss": 0.09458273649215698, "_runtime": 19196.353269577026, "_timestamp": 1585616565.986139, "_step": 161}
{"Episode reward": 25.260722279600742, "Episode length": 770, "Policy Loss": -0.16674111783504486, "Value Loss": 12.559216499328613, "_runtime": 19197.903556585312, "_timestamp": 1585616567.536426, "_step": 162}
{"Episode reward": -97.46736489621806, "Episode length": 999, "Policy Loss": -0.6742327809333801, "Value Loss": 0.048763662576675415, "_runtime": 19199.480241537094, "_timestamp": 1585616569.113111, "_step": 163}
{"Episode reward": -97.70644009900816, "Episode length": 999, "Policy Loss": -0.6475335955619812, "Value Loss": 0.027767134830355644, "_runtime": 19201.056433916092, "_timestamp": 1585616570.6893034, "_step": 164}
{"Episode reward": -97.52175578612892, "Episode length": 999, "Policy Loss": -0.592196524143219, "Value Loss": 0.08911248296499252, "_runtime": 19202.614547014236, "_timestamp": 1585616572.2474165, "_step": 165}
{"Episode reward": -97.97022755191344, "Episode length": 999, "Policy Loss": -0.5608032941818237, "Value Loss": 0.02262216806411743, "_runtime": 19203.469750642776, "_timestamp": 1585616573.1026201, "_step": 166}
{"Episode reward": 48.09615150278823, "Episode length": 534, "Policy Loss": 0.1805281788110733, "Value Loss": 18.21637535095215, "_runtime": 19204.657697677612, "_timestamp": 1585616574.2905672, "_step": 167}
{"Episode reward": 24.93609474989543, "Episode length": 765, "Policy Loss": -0.02649616077542305, "Value Loss": 12.388641357421875, "_runtime": 19206.211948871613, "_timestamp": 1585616575.8448184, "_step": 168}
{"Episode reward": -97.45344510115915, "Episode length": 999, "Policy Loss": -0.4463607966899872, "Value Loss": 0.10625508427619934, "_runtime": 19207.64611506462, "_timestamp": 1585616577.2789845, "_step": 169}
{"Episode reward": 8.427046300059672, "Episode length": 939, "Policy Loss": -0.03837414085865021, "Value Loss": 10.072921752929688, "_runtime": 19209.190670967102, "_timestamp": 1585616578.8235404, "_step": 170}
{"Episode reward": -97.34639510127455, "Episode length": 999, "Policy Loss": -0.41392433643341064, "Value Loss": 0.0259093064814806, "_runtime": 19210.344529390335, "_timestamp": 1585616579.9773989, "_step": 171}
{"Episode reward": 27.035965767688268, "Episode length": 743, "Policy Loss": 0.16473565995693207, "Value Loss": 12.961536407470703, "_runtime": 19211.901089191437, "_timestamp": 1585616581.5339587, "_step": 172}
{"Episode reward": -98.42765231952981, "Episode length": 999, "Policy Loss": -0.38507112860679626, "Value Loss": 0.025310741737484932, "_runtime": 19213.471075296402, "_timestamp": 1585616583.1039448, "_step": 173}
{"Episode reward": -96.98743625070355, "Episode length": 999, "Policy Loss": -0.3627691864967346, "Value Loss": 0.014244120568037033, "_runtime": 19215.004287719727, "_timestamp": 1585616584.6371572, "_step": 174}
{"Episode reward": -98.32731235532877, "Episode length": 999, "Policy Loss": -0.35326647758483887, "Value Loss": 0.08198761940002441, "_runtime": 19216.55794429779, "_timestamp": 1585616586.1908138, "_step": 175}
{"Episode reward": -97.37452344243408, "Episode length": 999, "Policy Loss": -0.3236536681652069, "Value Loss": 0.028264058753848076, "_runtime": 19217.76111316681, "_timestamp": 1585616587.3939826, "_step": 176}
{"Episode reward": 25.426115087561683, "Episode length": 768, "Policy Loss": 0.22741329669952393, "Value Loss": 12.594646453857422, "_runtime": 19219.316759586334, "_timestamp": 1585616588.949629, "_step": 177}
{"Episode reward": -97.85897107660594, "Episode length": 999, "Policy Loss": -0.28917738795280457, "Value Loss": 0.018777357414364815, "_runtime": 19220.89117193222, "_timestamp": 1585616590.5240414, "_step": 178}
{"Episode reward": -97.73290795029443, "Episode length": 999, "Policy Loss": -0.2800803780555725, "Value Loss": 0.019240891560912132, "_runtime": 19222.32619380951, "_timestamp": 1585616591.9590633, "_step": 179}
{"Episode reward": 10.332231768803936, "Episode length": 922, "Policy Loss": 0.10632850229740143, "Value Loss": 10.160239219665527, "_runtime": 19222.933646202087, "_timestamp": 1585616592.5665157, "_step": 180}
{"Episode reward": 63.3656577255217, "Episode length": 372, "Policy Loss": 1.127580165863037, "Value Loss": 25.767471313476562, "_runtime": 19224.53496694565, "_timestamp": 1585616594.1678364, "_step": 181}
{"Episode reward": -97.25617170257452, "Episode length": 999, "Policy Loss": -0.28739920258522034, "Value Loss": 0.05701897293329239, "_runtime": 19226.099064588547, "_timestamp": 1585616595.731934, "_step": 182}
{"Episode reward": -97.25185887880501, "Episode length": 999, "Policy Loss": -0.30817678570747375, "Value Loss": 0.060896411538124084, "_runtime": 19227.605160713196, "_timestamp": 1585616597.2380302, "_step": 183}
{"Episode reward": -98.23025581898126, "Episode length": 999, "Policy Loss": -0.32024186849594116, "Value Loss": 0.051005586981773376, "_runtime": 19229.172475099564, "_timestamp": 1585616598.8053446, "_step": 184}
{"Episode reward": -97.25735337847621, "Episode length": 999, "Policy Loss": -0.3278469145298004, "Value Loss": 0.015390269458293915, "_runtime": 19230.74277472496, "_timestamp": 1585616600.3756442, "_step": 185}
{"Episode reward": -97.7195013726405, "Episode length": 999, "Policy Loss": -0.32868269085884094, "Value Loss": 0.019313247874379158, "_runtime": 19232.281106472015, "_timestamp": 1585616601.913976, "_step": 186}
{"Episode reward": -97.74314169003968, "Episode length": 999, "Policy Loss": -0.3295217454433441, "Value Loss": 0.011139169335365295, "_runtime": 19233.849531173706, "_timestamp": 1585616603.4824007, "_step": 187}
{"Episode reward": -98.02030977897964, "Episode length": 999, "Policy Loss": -0.32159096002578735, "Value Loss": 0.016116352751851082, "_runtime": 19234.82980298996, "_timestamp": 1585616604.4626725, "_step": 188}
{"Episode reward": 39.478174183513026, "Episode length": 618, "Policy Loss": 0.40440866351127625, "Value Loss": 14.900768280029297, "_runtime": 19235.9919962883, "_timestamp": 1585616605.6248658, "_step": 189}
{"Episode reward": 26.901185201967607, "Episode length": 747, "Policy Loss": 0.1558510959148407, "Value Loss": 12.410927772521973, "_runtime": 19237.558443069458, "_timestamp": 1585616607.1913126, "_step": 190}
{"Episode reward": -97.47638350588767, "Episode length": 999, "Policy Loss": -0.3055519759654999, "Value Loss": 0.027226485311985016, "_runtime": 19239.10496520996, "_timestamp": 1585616608.7378347, "_step": 191}
{"Episode reward": -97.82725589476735, "Episode length": 999, "Policy Loss": -0.3106943368911743, "Value Loss": 0.025731343775987625, "_runtime": 19240.01680445671, "_timestamp": 1585616609.649674, "_step": 192}
{"Episode reward": 42.816968317262145, "Episode length": 586, "Policy Loss": 0.3585125803947449, "Value Loss": 15.809407234191895, "_runtime": 19241.583334445953, "_timestamp": 1585616611.216204, "_step": 193}
{"Episode reward": -97.86889132081994, "Episode length": 999, "Policy Loss": -0.3238743841648102, "Value Loss": 0.06843551248311996, "_runtime": 19242.861185073853, "_timestamp": 1585616612.4940546, "_step": 194}
{"Episode reward": 19.710043752451213, "Episode length": 817, "Policy Loss": 0.12360244989395142, "Value Loss": 11.995396614074707, "_runtime": 19244.381007909775, "_timestamp": 1585616614.0138774, "_step": 195}
{"Episode reward": -98.21035043268762, "Episode length": 999, "Policy Loss": -0.3549204468727112, "Value Loss": 0.011109372600913048, "_runtime": 19245.953539848328, "_timestamp": 1585616615.5864093, "_step": 196}
{"Episode reward": -97.68142037437637, "Episode length": 999, "Policy Loss": -0.35838088393211365, "Value Loss": 0.06402156502008438, "_runtime": 19246.663140535355, "_timestamp": 1585616616.29601, "_step": 197}
{"Episode reward": 56.29452212424797, "Episode length": 440, "Policy Loss": 0.7011546492576599, "Value Loss": 21.200176239013672, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414, 9.226877212524414]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-9.226019859313965, -8.036614418029785, -6.8472089767456055, -5.657803058624268, -4.468397617340088, -3.278992176055908, -2.0895862579345703, -0.9001808166503906, 0.28922462463378906, 1.4786300659179688, 2.6680355072021484, 3.857440948486328, 5.046847343444824, 6.236252784729004, 7.425658226013184, 8.615063667297363, 9.804469108581543, 10.993874549865723, 12.183279991149902, 13.372685432434082, 14.562090873718262, 15.751496315002441, 16.940902709960938, 18.130306243896484, 19.319713592529297, 20.50912094116211, 21.698524475097656, 22.887928009033203, 24.077335357666016, 25.266738891601562, 26.456146240234375, 27.645549774169922, 28.834957122802734, 30.024364471435547, 31.213768005371094, 32.403175354003906, 33.59257888793945, 34.781986236572266, 35.97138977050781, 37.160797119140625, 38.35020065307617, 39.539608001708984, 40.72901153564453, 41.918418884277344, 43.10782241821289, 44.2972297668457, 45.48663330078125, 46.67604064941406, 47.865447998046875, 49.05485153198242, 50.244258880615234, 51.43366241455078, 52.623069763183594, 53.81247329711914, 55.00187683105469, 56.1912841796875, 57.38069152832031, 58.570098876953125, 59.759498596191406, 60.94890594482422, 62.13831329345703, 63.327720642089844, 64.51712036132812, 65.70652770996094, 66.89593505859375]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4718509316444397, -0.35872429609298706, -0.24559767544269562, -0.13247105479240417, -0.019344419240951538, 0.09378218650817871, 0.20690882205963135, 0.320035457611084, 0.4331620931625366, 0.5462886691093445, 0.6594153046607971, 0.7725419402122498, 0.8856685757637024, 0.998795211315155, 1.111921787261963, 1.225048542022705, 1.3381750583648682, 1.4513018131256104, 1.5644283294677734, 1.6775550842285156, 1.7906816005706787, 1.903808355331421, 2.016934871673584, 2.130061626434326, 2.2431881427764893, 2.3563148975372314, 2.4694414138793945, 2.5825681686401367, 2.6956946849823, 2.808821439743042, 2.921947956085205, 3.0350747108459473, 3.1482012271881104, 3.2613277435302734, 3.3744544982910156, 3.4875810146331787, 3.600707530975342, 3.713834285736084, 3.826961040496826, 3.9400877952575684, 4.053214073181152, 4.1663408279418945, 4.279467582702637, 4.392594337463379, 4.505720615386963, 4.618847370147705, 4.731974124908447, 4.8451008796691895, 4.958227157592773, 5.071353912353516, 5.184480667114258, 5.297606945037842, 5.410733699798584, 5.523860454559326, 5.636987209320068, 5.750113487243652, 5.8632402420043945, 5.976366996765137, 6.089493751525879, 6.202620029449463, 6.315746784210205, 6.428873538970947, 6.5420002937316895, 6.655126571655273, 6.768253326416016]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 3.0, 0.0, 2.0, 1.0, 5.0, 29.0, 53.0, 338.0, 27.0, 5.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-4.491536617279053, -4.326513290405273, -4.161489963531494, -3.996466875076294, -3.8314435482025146, -3.6664204597473145, -3.501397132873535, -3.336373805999756, -3.1713504791259766, -3.0063273906707764, -2.841304063796997, -2.676280975341797, -2.5112576484680176, -2.3462343215942383, -2.181210994720459, -2.016187906265259, -1.8511645793914795, -1.6861412525177002, -1.5211181640625, -1.3560948371887207, -1.1910715103149414, -1.0260484218597412, -0.8610250949859619, -0.6960017681121826, -0.5309786796569824, -0.3659553527832031, -0.20093202590942383, -0.03590869903564453, 0.12911462783813477, 0.29413747787475586, 0.45916080474853516, 0.6241841316223145, 0.7892074584960938, 0.954230785369873, 1.1192541122436523, 1.2842774391174316, 1.4493002891540527, 1.614323616027832, 1.7793469429016113, 1.9443702697753906, 2.10939359664917, 2.274416923522949, 2.4394397735595703, 2.6044631004333496, 2.769486427307129, 2.934509754180908, 3.0995330810546875, 3.264556407928467, 3.429579257965088, 3.5946030616760254, 3.7596259117126465, 3.924649715423584, 4.089672565460205, 4.254695415496826, 4.419719219207764, 4.584742069244385, 4.749765872955322, 4.914788722991943, 5.0798115730285645, 5.244835376739502, 5.409858226776123, 5.5748820304870605, 5.739904880523682, 5.904928684234619, 6.06995153427124]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-2.5545828342437744, -2.431731700897217, -2.3088808059692383, -2.1860296726226807, -2.063178539276123, -1.9403276443481445, -1.817476511001587, -1.6946254968643188, -1.5717744827270508, -1.4489234685897827, -1.3260724544525146, -1.203221321105957, -1.080370306968689, -0.9575192928314209, -0.8346681594848633, -0.7118171453475952, -0.5889661312103271, -0.46611499786376953, -0.343264102935791, -0.2204129695892334, -0.09756207466125488, 0.025289058685302734, 0.14814019203186035, 0.27099108695983887, 0.3938422203063965, 0.5166933536529541, 0.6395442485809326, 0.7623953819274902, 0.8852465152740479, 1.0080974102020264, 1.130948543548584, 1.2537994384765625, 1.3766505718231201, 1.4995014667510986, 1.6223528385162354, 1.7452037334442139, 1.8680546283721924, 1.990906000137329, 2.1137568950653076, 2.236607789993286, 2.3594586849212646, 2.4823100566864014, 2.60516095161438, 2.7280118465423584, 2.850863218307495, 2.9737141132354736, 3.096565008163452, 3.219416379928589, 3.3422672748565674, 3.465118169784546, 3.5879695415496826, 3.710820436477661, 3.8336713314056396, 3.9565227031707764, 4.079373359680176, 4.2022247314453125, 4.325076103210449, 4.4479265213012695, 4.570777893066406, 4.693628311157227, 4.816479682922363, 4.9393310546875, 5.06218147277832, 5.185032844543457, 5.307884216308594]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 0.0, 0.0, 1.0, 4.0, 2.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0], "bins": [-0.8240619897842407, -0.8033726215362549, -0.782683253288269, -0.7619938850402832, -0.7413045167922974, -0.7206151485443115, -0.6999257802963257, -0.6792364120483398, -0.658547043800354, -0.6378576755523682, -0.6171683073043823, -0.5964789390563965, -0.5757895708084106, -0.5551002025604248, -0.534410834312439, -0.5137214660644531, -0.4930320680141449, -0.47234269976615906, -0.4516533315181732, -0.4309639632701874, -0.41027459502220154, -0.3895852267742157, -0.36889585852622986, -0.348206490278244, -0.3275170922279358, -0.30682772397994995, -0.2861383557319641, -0.26544898748397827, -0.24475961923599243, -0.2240702509880066, -0.20338088274002075, -0.1826915144920349, -0.16200214624404907, -0.14131277799606323, -0.12062340974807739, -0.09993404150009155, -0.07924467325210571, -0.05855530500411987, -0.03786593675613403, -0.017176568508148193, 0.0035127997398376465, 0.024202167987823486, 0.044891536235809326, 0.06558090448379517, 0.086270272731781, 0.10695964097976685, 0.12764900922775269, 0.14833837747573853, 0.16902780532836914, 0.18971717357635498, 0.21040654182434082, 0.23109591007232666, 0.2517852783203125, 0.27247464656829834, 0.2931640148162842, 0.31385338306427, 0.33454275131225586, 0.3552321195602417, 0.37592148780822754, 0.3966108560562134, 0.4173002243041992, 0.43798959255218506, 0.4586789608001709, 0.47936832904815674, 0.5000576972961426]}, "_runtime": 19247.960448741913, "_timestamp": 1585616617.5933182, "_step": 198}
{"Episode reward": 20.131559508937684, "Episode length": 812, "Policy Loss": 0.08257371932268143, "Value Loss": 11.851848602294922, "_runtime": 19249.54259109497, "_timestamp": 1585616619.1754606, "_step": 199}
{"Episode reward": -98.23296784472605, "Episode length": 999, "Policy Loss": -0.4353739023208618, "Value Loss": 0.01206409465521574, "_runtime": 19251.066467523575, "_timestamp": 1585616620.699337, "_step": 200}
{"Episode reward": -98.30929810416126, "Episode length": 999, "Policy Loss": -0.46035054326057434, "Value Loss": 0.07474881410598755, "_runtime": 19252.626621484756, "_timestamp": 1585616622.259491, "_step": 201}
{"Episode reward": -97.89548340267349, "Episode length": 999, "Policy Loss": -0.47823724150657654, "Value Loss": 0.05148573964834213, "_runtime": 19254.2025039196, "_timestamp": 1585616623.8353734, "_step": 202}
{"Episode reward": -98.52258821923655, "Episode length": 999, "Policy Loss": -0.5060847997665405, "Value Loss": 0.027219632640480995, "_runtime": 19255.62519645691, "_timestamp": 1585616625.258066, "_step": 203}
{"Episode reward": 10.756841939449046, "Episode length": 911, "Policy Loss": -0.05250835791230202, "Value Loss": 9.99663257598877, "_runtime": 19257.205286979675, "_timestamp": 1585616626.8381565, "_step": 204}
{"Episode reward": -98.09567025988024, "Episode length": 999, "Policy Loss": -0.505929708480835, "Value Loss": 0.02066701278090477, "_runtime": 19258.383791208267, "_timestamp": 1585616628.0166607, "_step": 205}
{"Episode reward": 26.669963035955035, "Episode length": 746, "Policy Loss": -0.01683553121984005, "Value Loss": 12.777081489562988, "_runtime": 19259.954446554184, "_timestamp": 1585616629.587316, "_step": 206}
{"Episode reward": -97.14318463840274, "Episode length": 999, "Policy Loss": -0.511656641960144, "Value Loss": 0.05203623324632645, "_runtime": 19261.53672003746, "_timestamp": 1585616631.1695895, "_step": 207}
{"Episode reward": -97.96505790149341, "Episode length": 999, "Policy Loss": -0.5306328535079956, "Value Loss": 0.02185969240963459, "_runtime": 19263.097454547882, "_timestamp": 1585616632.730324, "_step": 208}
{"Episode reward": -98.23296314635326, "Episode length": 999, "Policy Loss": -0.5299197435379028, "Value Loss": 0.021383939310908318, "_runtime": 19264.668160676956, "_timestamp": 1585616634.3010302, "_step": 209}
{"Episode reward": -97.78438222549295, "Episode length": 999, "Policy Loss": -0.5065726637840271, "Value Loss": 0.036052681505680084, "_runtime": 19266.24509716034, "_timestamp": 1585616635.8779666, "_step": 210}
{"Episode reward": -97.5403292041063, "Episode length": 999, "Policy Loss": -0.49716392159461975, "Value Loss": 0.019309571012854576, "_runtime": 19267.365384101868, "_timestamp": 1585616636.9982536, "_step": 211}
{"Episode reward": 31.085422081554782, "Episode length": 705, "Policy Loss": 0.23374317586421967, "Value Loss": 13.685279846191406, "_runtime": 19268.945376873016, "_timestamp": 1585616638.5782464, "_step": 212}
{"Episode reward": -98.12143154635794, "Episode length": 999, "Policy Loss": -0.46546536684036255, "Value Loss": 0.019697587937116623, "_runtime": 19269.591903209686, "_timestamp": 1585616639.2247727, "_step": 213}
{"Episode reward": 61.76487674619503, "Episode length": 389, "Policy Loss": 0.48778101801872253, "Value Loss": 23.61687660217285, "_runtime": 19270.3088183403, "_timestamp": 1585616639.9416878, "_step": 214}
{"Episode reward": 55.20103612886579, "Episode length": 459, "Policy Loss": 0.32656407356262207, "Value Loss": 19.756486892700195, "_runtime": 19271.667392730713, "_timestamp": 1585616641.3002622, "_step": 215}
{"Episode reward": 18.26704038853859, "Episode length": 838, "Policy Loss": 0.07759898900985718, "Value Loss": 11.269147872924805, "_runtime": 19273.05048918724, "_timestamp": 1585616642.6833587, "_step": 216}
{"Episode reward": 9.98021374220734, "Episode length": 913, "Policy Loss": -0.08677339553833008, "Value Loss": 10.19735050201416, "_runtime": 19274.06505060196, "_timestamp": 1585616643.69792, "_step": 217}
{"Episode reward": 34.9086347037686, "Episode length": 662, "Policy Loss": 0.02657085657119751, "Value Loss": 13.91125202178955, "_runtime": 19275.61570763588, "_timestamp": 1585616645.248577, "_step": 218}
{"Episode reward": -97.80177015571526, "Episode length": 999, "Policy Loss": -0.5288079380989075, "Value Loss": 0.21900954842567444, "_runtime": 19277.141022205353, "_timestamp": 1585616646.7738917, "_step": 219}
{"Episode reward": 3.2244889761327613, "Episode length": 986, "Policy Loss": -0.19319799542427063, "Value Loss": 9.677350044250488, "_runtime": 19278.67673945427, "_timestamp": 1585616648.309609, "_step": 220}
{"Episode reward": -97.68521339105838, "Episode length": 999, "Policy Loss": -0.5837754011154175, "Value Loss": 0.0378766693174839, "_runtime": 19279.53797197342, "_timestamp": 1585616649.1708415, "_step": 221}
{"Episode reward": 47.72434774882575, "Episode length": 533, "Policy Loss": 0.1612616926431656, "Value Loss": 18.050554275512695, "_runtime": 19281.10636138916, "_timestamp": 1585616650.7392309, "_step": 222}
{"Episode reward": -98.60576117054866, "Episode length": 999, "Policy Loss": -0.5959147214889526, "Value Loss": 0.04487302899360657, "_runtime": 19281.822012662888, "_timestamp": 1585616651.4548821, "_step": 223}
{"Episode reward": 56.92803355702512, "Episode length": 442, "Policy Loss": 0.3130962550640106, "Value Loss": 21.735824584960938, "_runtime": 19282.585469961166, "_timestamp": 1585616652.2183394, "_step": 224}
{"Episode reward": 52.5381689994723, "Episode length": 490, "Policy Loss": 0.4668898284435272, "Value Loss": 18.968868255615234, "_runtime": 19284.14086651802, "_timestamp": 1585616653.773736, "_step": 225}
{"Episode reward": -98.14988801162198, "Episode length": 999, "Policy Loss": -0.6237290501594543, "Value Loss": 0.03696165233850479, "_runtime": 19285.673495292664, "_timestamp": 1585616655.3063648, "_step": 226}
{"Episode reward": -97.72606831147598, "Episode length": 999, "Policy Loss": -0.6240113377571106, "Value Loss": 0.06290428340435028, "_runtime": 19287.211414575577, "_timestamp": 1585616656.844284, "_step": 227}
{"Episode reward": -97.8416095633366, "Episode length": 999, "Policy Loss": -0.6052082777023315, "Value Loss": 0.05991288647055626, "_runtime": 19288.7832968235, "_timestamp": 1585616658.4161663, "_step": 228}
{"Episode reward": -96.71503037430553, "Episode length": 999, "Policy Loss": -0.5819599628448486, "Value Loss": 0.07944187521934509, "_runtime": 19289.547435045242, "_timestamp": 1585616659.1803045, "_step": 229}
{"Episode reward": 53.95071423147437, "Episode length": 468, "Policy Loss": 0.16152796149253845, "Value Loss": 19.9910945892334, "_runtime": 19290.136538028717, "_timestamp": 1585616659.7694075, "_step": 230}
{"Episode reward": 64.13834153920357, "Episode length": 364, "Policy Loss": 0.48037347197532654, "Value Loss": 26.767210006713867, "_runtime": 19291.69101500511, "_timestamp": 1585616661.3238845, "_step": 231}
{"Episode reward": -97.47384013693839, "Episode length": 999, "Policy Loss": -0.55172199010849, "Value Loss": 0.07345013320446014, "_runtime": 19292.840463876724, "_timestamp": 1585616662.4733334, "_step": 232}
{"Episode reward": 27.30872732796537, "Episode length": 746, "Policy Loss": -0.07286319136619568, "Value Loss": 12.10576343536377, "_runtime": 19294.35906291008, "_timestamp": 1585616663.9919324, "_step": 233}
{"Episode reward": -98.16969369438301, "Episode length": 999, "Policy Loss": -0.5540557503700256, "Value Loss": 0.04925191402435303, "_runtime": 19295.743862867355, "_timestamp": 1585616665.3767323, "_step": 234}
{"Episode reward": 13.879656362929182, "Episode length": 878, "Policy Loss": -0.0942574292421341, "Value Loss": 11.238646507263184, "_runtime": 19297.335803747177, "_timestamp": 1585616666.9686732, "_step": 235}
{"Episode reward": -98.01096143410167, "Episode length": 999, "Policy Loss": -0.5120723247528076, "Value Loss": 0.03452157601714134, "_runtime": 19298.899730682373, "_timestamp": 1585616668.5326002, "_step": 236}
{"Episode reward": -97.36884843165123, "Episode length": 999, "Policy Loss": -0.5014036297798157, "Value Loss": 0.03528079017996788, "_runtime": 19299.9087972641, "_timestamp": 1585616669.5416667, "_step": 237}
{"Episode reward": 38.98036157509591, "Episode length": 631, "Policy Loss": 0.01349642314016819, "Value Loss": 13.965838432312012, "_runtime": 19301.491233825684, "_timestamp": 1585616671.1241033, "_step": 238}
{"Episode reward": -97.93287408557663, "Episode length": 999, "Policy Loss": -0.445122092962265, "Value Loss": 0.05350236967206001, "_runtime": 19302.69999575615, "_timestamp": 1585616672.3328652, "_step": 239}
{"Episode reward": 25.78545628248635, "Episode length": 764, "Policy Loss": 0.06861452758312225, "Value Loss": 12.507121086120605, "_runtime": 19304.25791978836, "_timestamp": 1585616673.8907893, "_step": 240}
{"Episode reward": -97.83315137902446, "Episode length": 999, "Policy Loss": -0.40839385986328125, "Value Loss": 0.01630851998925209, "_runtime": 19305.85216999054, "_timestamp": 1585616675.4850395, "_step": 241}
{"Episode reward": -97.76458613159832, "Episode length": 999, "Policy Loss": -0.382954865694046, "Value Loss": 0.043758492916822433, "_runtime": 19307.397563695908, "_timestamp": 1585616677.0304332, "_step": 242}
{"Episode reward": -97.44541494692515, "Episode length": 999, "Policy Loss": -0.3551099896430969, "Value Loss": 0.0702899917960167, "_runtime": 19308.980494260788, "_timestamp": 1585616678.6133637, "_step": 243}
{"Episode reward": -97.80075661575319, "Episode length": 999, "Policy Loss": -0.34065762162208557, "Value Loss": 0.04609902948141098, "_runtime": 19310.5717356205, "_timestamp": 1585616680.204605, "_step": 244}
{"Episode reward": -97.22895823346927, "Episode length": 999, "Policy Loss": -0.2970235049724579, "Value Loss": 0.01040819101035595, "_runtime": 19312.148686408997, "_timestamp": 1585616681.781556, "_step": 245}
{"Episode reward": -97.73481190264994, "Episode length": 999, "Policy Loss": -0.2672419548034668, "Value Loss": 0.08115292340517044, "_runtime": 19313.727482318878, "_timestamp": 1585616683.3603518, "_step": 246}
{"Episode reward": -97.68694954317645, "Episode length": 999, "Policy Loss": -0.2220681607723236, "Value Loss": 0.01759476400911808, "_runtime": 19315.31274819374, "_timestamp": 1585616684.9456177, "_step": 247}
{"Episode reward": -97.9718344523717, "Episode length": 999, "Policy Loss": -0.20176559686660767, "Value Loss": 0.039224155247211456, "_runtime": 19316.45154595375, "_timestamp": 1585616686.0844154, "_step": 248}
{"Episode reward": 30.45092647022952, "Episode length": 712, "Policy Loss": 0.3033912479877472, "Value Loss": 12.851089477539062, "_runtime": 19317.457259893417, "_timestamp": 1585616687.0901294, "_step": 249}
{"Episode reward": 38.278489822226895, "Episode length": 626, "Policy Loss": 0.38792380690574646, "Value Loss": 15.013333320617676, "_runtime": 19318.088616609573, "_timestamp": 1585616687.721486, "_step": 250}
{"Episode reward": 62.88760181515674, "Episode length": 380, "Policy Loss": 0.7676169872283936, "Value Loss": 24.42106819152832, "_runtime": 19319.431803703308, "_timestamp": 1585616689.0646732, "_step": 251}
{"Episode reward": 14.729237631422095, "Episode length": 872, "Policy Loss": 0.24313147366046906, "Value Loss": 11.30331039428711, "_runtime": 19321.00738453865, "_timestamp": 1585616690.640254, "_step": 252}
{"Episode reward": -97.09855622388739, "Episode length": 999, "Policy Loss": -0.22486650943756104, "Value Loss": 0.0059287273325026035, "_runtime": 19322.52633690834, "_timestamp": 1585616692.1592064, "_step": 253}
{"Episode reward": -97.45327508434623, "Episode length": 999, "Policy Loss": -0.25503185391426086, "Value Loss": 0.016464341431856155, "_runtime": 19324.088017702103, "_timestamp": 1585616693.7208872, "_step": 254}
{"Episode reward": -96.52251190075457, "Episode length": 999, "Policy Loss": -0.26858142018318176, "Value Loss": 0.012114387936890125, "_runtime": 19325.663482666016, "_timestamp": 1585616695.2963521, "_step": 255}
{"Episode reward": -96.31892315439106, "Episode length": 999, "Policy Loss": -0.2823256254196167, "Value Loss": 0.01990518346428871, "_runtime": 19327.22661280632, "_timestamp": 1585616696.8594823, "_step": 256}
{"Episode reward": -96.25643515569398, "Episode length": 999, "Policy Loss": -0.28634801506996155, "Value Loss": 0.012300691567361355, "_runtime": 19328.434061527252, "_timestamp": 1585616698.066931, "_step": 257}
{"Episode reward": 25.73967712906564, "Episode length": 762, "Policy Loss": 0.2512144446372986, "Value Loss": 12.51689338684082, "_runtime": 19330.009737730026, "_timestamp": 1585616699.6426072, "_step": 258}
{"Episode reward": -96.73700099801779, "Episode length": 999, "Policy Loss": -0.29939210414886475, "Value Loss": 0.008692490868270397, "_runtime": 19330.538474321365, "_timestamp": 1585616700.1713438, "_step": 259}
{"Episode reward": 69.75331571971385, "Episode length": 310, "Policy Loss": 0.8046191334724426, "Value Loss": 30.254453659057617, "_runtime": 19332.08253145218, "_timestamp": 1585616701.715401, "_step": 260}
{"Episode reward": -96.70165299048857, "Episode length": 999, "Policy Loss": -0.3377028703689575, "Value Loss": 0.011023513041436672, "_runtime": 19333.661817073822, "_timestamp": 1585616703.2946866, "_step": 261}
{"Episode reward": -97.52559410038165, "Episode length": 999, "Policy Loss": -0.3751835823059082, "Value Loss": 0.03805701807141304, "_runtime": 19334.666038751602, "_timestamp": 1585616704.2989082, "_step": 262}
{"Episode reward": 35.69600078262495, "Episode length": 665, "Policy Loss": 0.23889626562595367, "Value Loss": 14.776611328125, "_runtime": 19336.243889570236, "_timestamp": 1585616705.876759, "_step": 263}
{"Episode reward": -97.09013306671288, "Episode length": 999, "Policy Loss": -0.4018855094909668, "Value Loss": 0.013305331580340862, "_runtime": 19337.213319778442, "_timestamp": 1585616706.8461893, "_step": 264}
{"Episode reward": 40.811034830446886, "Episode length": 606, "Policy Loss": 0.17562426626682281, "Value Loss": 15.284385681152344, "_runtime": 19338.154410362244, "_timestamp": 1585616707.7872798, "_step": 265}
{"Episode reward": 41.45745876687179, "Episode length": 609, "Policy Loss": 0.13351725041866302, "Value Loss": 15.876996040344238, "_runtime": 19339.71937394142, "_timestamp": 1585616709.3522434, "_step": 266}
{"Episode reward": -97.25724894146461, "Episode length": 999, "Policy Loss": -0.4386969804763794, "Value Loss": 0.023767048493027687, "_runtime": 19341.12721133232, "_timestamp": 1585616710.7600808, "_step": 267}
{"Episode reward": 10.348868383671345, "Episode length": 922, "Policy Loss": -0.06633070856332779, "Value Loss": 10.10707950592041, "_runtime": 19342.196325063705, "_timestamp": 1585616711.8291945, "_step": 268}
{"Episode reward": 31.941777741136008, "Episode length": 703, "Policy Loss": -0.01033883634954691, "Value Loss": 13.191461563110352, "_runtime": 19343.75766468048, "_timestamp": 1585616713.3905342, "_step": 269}
{"Episode reward": -97.0103047751389, "Episode length": 999, "Policy Loss": -0.44737720489501953, "Value Loss": 0.09080120176076889, "_runtime": 19345.345264673233, "_timestamp": 1585616714.9781342, "_step": 270}
{"Episode reward": -95.47314514869153, "Episode length": 999, "Policy Loss": -0.4559476375579834, "Value Loss": 0.1718979775905609, "_runtime": 19346.87461090088, "_timestamp": 1585616716.5074804, "_step": 271}
{"Episode reward": -96.33554088285658, "Episode length": 999, "Policy Loss": -0.43419378995895386, "Value Loss": 0.09257393330335617, "_runtime": 19348.436795949936, "_timestamp": 1585616718.0696654, "_step": 272}
{"Episode reward": -96.6574371128831, "Episode length": 999, "Policy Loss": -0.41925153136253357, "Value Loss": 0.03421071544289589, "_runtime": 19349.21669435501, "_timestamp": 1585616718.8495638, "_step": 273}
{"Episode reward": 52.814310915896954, "Episode length": 489, "Policy Loss": 0.23189377784729004, "Value Loss": 18.84334945678711, "_runtime": 19350.18025827408, "_timestamp": 1585616719.8131278, "_step": 274}
{"Episode reward": 41.06545759595732, "Episode length": 617, "Policy Loss": 0.16189874708652496, "Value Loss": 15.246736526489258, "_runtime": 19351.743453025818, "_timestamp": 1585616721.3763225, "_step": 275}
{"Episode reward": -95.6463524492434, "Episode length": 999, "Policy Loss": -0.38251784443855286, "Value Loss": 0.06291531771421432, "_runtime": 19352.516681194305, "_timestamp": 1585616722.1495507, "_step": 276}
{"Episode reward": 51.428898906560036, "Episode length": 505, "Policy Loss": 0.3585129380226135, "Value Loss": 19.339433670043945, "_runtime": 19353.865769147873, "_timestamp": 1585616723.4986386, "_step": 277}
{"Episode reward": 15.065997992556376, "Episode length": 891, "Policy Loss": -0.07867832481861115, "Value Loss": 10.233393669128418, "_runtime": 19355.43344783783, "_timestamp": 1585616725.0663173, "_step": 278}
{"Episode reward": -96.03137097786826, "Episode length": 999, "Policy Loss": -0.39261770248413086, "Value Loss": 0.024462180212140083, "_runtime": 19356.59047293663, "_timestamp": 1585616726.2233424, "_step": 279}
{"Episode reward": 27.52539737178219, "Episode length": 762, "Policy Loss": -0.05362345650792122, "Value Loss": 11.966033935546875, "_runtime": 19358.125598669052, "_timestamp": 1585616727.7584682, "_step": 280}
{"Episode reward": -95.11951980256903, "Episode length": 999, "Policy Loss": -0.4209524095058441, "Value Loss": 0.024438932538032532, "_runtime": 19359.53528237343, "_timestamp": 1585616729.1681519, "_step": 281}
{"Episode reward": 13.397063131266648, "Episode length": 900, "Policy Loss": -0.12390001118183136, "Value Loss": 10.022531509399414, "_runtime": 19361.070419549942, "_timestamp": 1585616730.703289, "_step": 282}
{"Episode reward": -95.13793492107067, "Episode length": 999, "Policy Loss": -0.4270786941051483, "Value Loss": 0.02977084554731846, "_runtime": 19362.633178710938, "_timestamp": 1585616732.2660482, "_step": 283}
{"Episode reward": -95.18334476123977, "Episode length": 999, "Policy Loss": -0.4111533463001251, "Value Loss": 0.04852927848696709, "_runtime": 19364.19308400154, "_timestamp": 1585616733.8259535, "_step": 284}
{"Episode reward": -94.04589767682802, "Episode length": 999, "Policy Loss": -0.39762553572654724, "Value Loss": 0.028011709451675415, "_runtime": 19365.75495147705, "_timestamp": 1585616735.387821, "_step": 285}
{"Episode reward": -95.36704091495098, "Episode length": 999, "Policy Loss": -0.380229651927948, "Value Loss": 0.02198854275047779, "_runtime": 19367.350051879883, "_timestamp": 1585616736.9829214, "_step": 286}
{"Episode reward": -94.49665849503037, "Episode length": 999, "Policy Loss": -0.35412800312042236, "Value Loss": 0.03941744565963745, "_runtime": 19368.25153017044, "_timestamp": 1585616737.8843997, "_step": 287}
{"Episode reward": 46.22488661726255, "Episode length": 568, "Policy Loss": 0.10983528196811676, "Value Loss": 16.001201629638672, "_runtime": 19369.820482492447, "_timestamp": 1585616739.453352, "_step": 288}
{"Episode reward": -94.7200517606208, "Episode length": 999, "Policy Loss": -0.31014302372932434, "Value Loss": 0.013343405909836292, "_runtime": 19371.3868124485, "_timestamp": 1585616741.019682, "_step": 289}
{"Episode reward": -93.95163132562942, "Episode length": 999, "Policy Loss": -0.2927282452583313, "Value Loss": 0.011403878219425678, "_runtime": 19371.896340608597, "_timestamp": 1585616741.52921, "_step": 290}
{"Episode reward": 69.53786299693121, "Episode length": 320, "Policy Loss": 0.8675212860107422, "Value Loss": 29.780385971069336, "_runtime": 19373.46917462349, "_timestamp": 1585616743.102044, "_step": 291}
{"Episode reward": -94.23265787363736, "Episode length": 999, "Policy Loss": -0.2698875069618225, "Value Loss": 0.010400598868727684, "_runtime": 19375.036241531372, "_timestamp": 1585616744.669111, "_step": 292}
{"Episode reward": -94.10308497917818, "Episode length": 999, "Policy Loss": -0.26629215478897095, "Value Loss": 0.0646216943860054, "_runtime": 19376.536094903946, "_timestamp": 1585616746.1689644, "_step": 293}
{"Episode reward": -94.87758592381277, "Episode length": 999, "Policy Loss": -0.25271305441856384, "Value Loss": 0.01791314408183098, "_runtime": 19378.021847486496, "_timestamp": 1585616747.654717, "_step": 294}
{"Episode reward": 9.526344923957751, "Episode length": 944, "Policy Loss": 0.011496600694954395, "Value Loss": 9.712801933288574, "_runtime": 19378.95969891548, "_timestamp": 1585616748.5925684, "_step": 295}
{"Episode reward": 43.616633240008575, "Episode length": 595, "Policy Loss": 0.19780009984970093, "Value Loss": 15.198649406433105, "_runtime": 19380.499406576157, "_timestamp": 1585616750.132276, "_step": 296}
{"Episode reward": -94.72602373517904, "Episode length": 999, "Policy Loss": -0.21674996614456177, "Value Loss": 0.048099614679813385, "_runtime": 19382.077367544174, "_timestamp": 1585616751.710237, "_step": 297}
{"Episode reward": -93.68853291556793, "Episode length": 999, "Policy Loss": -0.23724232614040375, "Value Loss": 0.09703794866800308, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344, -26.205039978027344]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0], "bins": [-28.185026168823242, -27.335390090942383, -26.48575210571289, -25.63611602783203, -24.78647804260254, -23.93684196472168, -23.087203979492188, -22.237567901611328, -21.38793182373047, -20.538293838500977, -19.688655853271484, -18.839019775390625, -17.989383697509766, -17.139747619628906, -16.290109634399414, -15.440472602844238, -14.590835571289062, -13.741198539733887, -12.891561508178711, -12.041925430297852, -11.19228744506836, -10.3426513671875, -9.493013381958008, -8.643377304077148, -7.793741226196289, -6.944103240966797, -6.0944671630859375, -5.244829177856445, -4.395193099975586, -3.5455551147460938, -2.6959190368652344, -1.8462810516357422, -0.9966449737548828, -0.14700889587402344, 0.7026290893554688, 1.5522651672363281, 2.4019031524658203, 3.2515392303466797, 4.101175308227539, 4.950815200805664, 5.800451278686523, 6.650087356567383, 7.499723434448242, 8.349359512329102, 9.198999404907227, 10.048635482788086, 10.898271560668945, 11.747907638549805, 12.597543716430664, 13.447183609008789, 14.296819686889648, 15.146455764770508, 15.996091842651367, 16.845731735229492, 17.69536781311035, 18.54500389099121, 19.39463996887207, 20.24427604675293, 21.093915939331055, 21.943552017211914, 22.793188095092773, 23.642824172973633, 24.492464065551758, 25.342100143432617, 26.191736221313477]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2.300507068634033, -2.22930908203125, -2.158111095428467, -2.0869128704071045, -2.0157148838043213, -1.944516897201538, -1.8733189105987549, -1.8021209239959717, -1.730922818183899, -1.6597247123718262, -1.588526725769043, -1.5173287391662598, -1.4461307525634766, -1.3749326467514038, -1.3037346601486206, -1.2325365543365479, -1.1613385677337646, -1.0901405811309814, -1.0189424753189087, -0.9477444887161255, -0.8765463829040527, -0.8053483963012695, -0.7341504096984863, -0.6629523038864136, -0.5917543172836304, -0.5205563306808472, -0.4493582248687744, -0.3781602382659912, -0.306962251663208, -0.2357642650604248, -0.1645660400390625, -0.0933680534362793, -0.022170066833496094, 0.04902791976928711, 0.12022590637207031, 0.19142413139343262, 0.2626221179962158, 0.333820104598999, 0.4050180912017822, 0.47621607780456543, 0.5474143028259277, 0.6186122894287109, 0.6898102760314941, 0.7610082626342773, 0.8322062492370605, 0.9034042358398438, 0.974602460861206, 1.0458004474639893, 1.1169984340667725, 1.1881964206695557, 1.2593944072723389, 1.3305926322937012, 1.4017906188964844, 1.4729886054992676, 1.5441865921020508, 1.615384578704834, 1.6865825653076172, 1.7577805519104004, 1.8289785385131836, 1.900177001953125, 1.9713749885559082, 2.0425729751586914, 2.1137709617614746, 2.184968948364258, 2.256166934967041]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 6.0, 5.0, 6.0, 6.0, 5.0, 5.0, 7.0, 11.0, 7.0, 4.0, 8.0, 12.0, 292.0, 9.0, 10.0, 9.0, 5.0, 19.0, 13.0, 7.0, 8.0, 5.0, 6.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0], "bins": [-1.3831984996795654, -1.340284824371338, -1.2973711490631104, -1.2544574737548828, -1.2115437984466553, -1.1686301231384277, -1.1257164478302002, -1.0828028917312622, -1.0398892164230347, -0.9969755411148071, -0.9540618658065796, -0.911148190498352, -0.8682345151901245, -0.825320839881897, -0.7824072241783142, -0.7394935488700867, -0.6965798735618591, -0.6536661982536316, -0.610752522945404, -0.5678389072418213, -0.5249252319335938, -0.4820115566253662, -0.43909788131713867, -0.39618420600891113, -0.3532705307006836, -0.31035685539245605, -0.2674431800842285, -0.22452962398529053, -0.181615948677063, -0.13870227336883545, -0.09578859806060791, -0.05287492275238037, -0.009961247444152832, 0.03295242786407471, 0.07586610317230225, 0.11877977848052979, 0.16169345378875732, 0.20460712909698486, 0.24752068519592285, 0.2904343605041504, 0.33334803581237793, 0.37626171112060547, 0.419175386428833, 0.46208906173706055, 0.5050027370452881, 0.5479164123535156, 0.5908300876617432, 0.6337437629699707, 0.6766574382781982, 0.7195711135864258, 0.7624847888946533, 0.8053984642028809, 0.8483121395111084, 0.8912258148193359, 0.9341392517089844, 0.9770529270172119, 1.0199666023254395, 1.062880277633667, 1.1057939529418945, 1.148707628250122, 1.1916213035583496, 1.2345349788665771, 1.2774486541748047, 1.3203623294830322, 1.3632760047912598]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.3236042261123657, -1.2645800113677979, -1.20555579662323, -1.146531581878662, -1.0875073671340942, -1.0284831523895264, -0.9694588780403137, -0.9104346632957458, -0.851410448551178, -0.7923862338066101, -0.7333620190620422, -0.6743378043174744, -0.6153135299682617, -0.5562893152236938, -0.497265100479126, -0.4382408857345581, -0.37921667098999023, -0.32019245624542236, -0.2611682415008545, -0.20214402675628662, -0.14311981201171875, -0.08409559726715088, -0.025071382522583008, 0.03395283222198486, 0.09297716617584229, 0.15200138092041016, 0.21102559566497803, 0.2700498104095459, 0.32907402515411377, 0.38809823989868164, 0.4471224546432495, 0.5061466693878174, 0.5651708841323853, 0.6241950988769531, 0.683219313621521, 0.7422436475753784, 0.8012677431106567, 0.8602920770645142, 0.9193161725997925, 0.9783405065536499, 1.0373646020889282, 1.0963889360427856, 1.155413031578064, 1.2144373655319214, 1.2734614610671997, 1.3324857950210571, 1.3915098905563354, 1.4505342245101929, 1.5095585584640503, 1.5685826539993286, 1.627606987953186, 1.6866310834884644, 1.7456554174423218, 1.8046795129776, 1.8637038469314575, 1.9227279424667358, 1.9817522764205933, 2.040776252746582, 2.0998005867004395, 2.158824920654297, 2.2178492546081543, 2.2768731117248535, 2.335897445678711, 2.3949217796325684, 2.453946113586426]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 7.0, 11.0, 10.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.2795772552490234, -1.242722511291504, -1.2058677673339844, -1.1690130233764648, -1.1321582794189453, -1.0953035354614258, -1.0584487915039062, -1.0215941667556763, -0.9847394227981567, -0.9478846788406372, -0.9110299348831177, -0.8741751909255981, -0.8373204469680786, -0.8004657030105591, -0.7636110186576843, -0.7267562747001648, -0.6899015307426453, -0.6530467867851257, -0.6161920428276062, -0.5793373584747314, -0.5424826145172119, -0.5056278705596924, -0.46877312660217285, -0.4319183826446533, -0.3950636386871338, -0.35820895433425903, -0.3213542103767395, -0.28449946641921997, -0.24764478206634521, -0.21079003810882568, -0.17393529415130615, -0.13708055019378662, -0.10022580623626709, -0.06337106227874756, -0.026516318321228027, 0.010338425636291504, 0.047193169593811035, 0.08404791355133057, 0.12090253829956055, 0.15775728225708008, 0.1946120262145996, 0.23146677017211914, 0.26832151412963867, 0.3051762580871582, 0.34203100204467773, 0.37888574600219727, 0.4157404899597168, 0.45259523391723633, 0.48944997787475586, 0.5263046026229858, 0.5631593465805054, 0.6000140905380249, 0.6368688344955444, 0.673723578453064, 0.7105783224105835, 0.7474329471588135, 0.784287691116333, 0.8211424350738525, 0.8579971790313721, 0.8948519229888916, 0.9317066669464111, 0.9685614109039307, 1.0054161548614502, 1.0422708988189697, 1.0791256427764893]}, "_runtime": 19382.565810918808, "_timestamp": 1585616752.1986804, "_step": 298}
{"Episode reward": 71.04758438716331, "Episode length": 303, "Policy Loss": 0.8038561940193176, "Value Loss": 29.649208068847656, "_runtime": 19384.117126226425, "_timestamp": 1585616753.7499957, "_step": 299}
{"Episode reward": -93.80740298762451, "Episode length": 999, "Policy Loss": -0.22911383211612701, "Value Loss": 0.016505537554621696, "_runtime": 19385.69177341461, "_timestamp": 1585616755.324643, "_step": 300}
{"Episode reward": -95.47005555994244, "Episode length": 999, "Policy Loss": -0.2461247593164444, "Value Loss": 0.036064498126506805, "_runtime": 19387.189188957214, "_timestamp": 1585616756.8220584, "_step": 301}
{"Episode reward": -94.01727739926355, "Episode length": 999, "Policy Loss": -0.2657950818538666, "Value Loss": 0.027079937979578972, "_runtime": 19388.241786003113, "_timestamp": 1585616757.8746555, "_step": 302}
{"Episode reward": 36.86683856365476, "Episode length": 670, "Policy Loss": 0.07939944416284561, "Value Loss": 13.560905456542969, "_runtime": 19389.800374507904, "_timestamp": 1585616759.433244, "_step": 303}
{"Episode reward": -93.29736284260268, "Episode length": 999, "Policy Loss": -0.29085573554039, "Value Loss": 0.08911719173192978, "_runtime": 19391.380075454712, "_timestamp": 1585616761.012945, "_step": 304}
{"Episode reward": -94.69332600548536, "Episode length": 999, "Policy Loss": -0.3060937523841858, "Value Loss": 0.03138252720236778, "_runtime": 19392.927965164185, "_timestamp": 1585616762.5608346, "_step": 305}
{"Episode reward": -93.14662228971791, "Episode length": 999, "Policy Loss": -0.30977195501327515, "Value Loss": 0.044570907950401306, "_runtime": 19393.493745088577, "_timestamp": 1585616763.1266146, "_step": 306}
{"Episode reward": 68.09854508356305, "Episode length": 341, "Policy Loss": 0.33774176239967346, "Value Loss": 26.121875762939453, "_runtime": 19393.96710920334, "_timestamp": 1585616763.5999787, "_step": 307}
{"Episode reward": 73.16113171563282, "Episode length": 282, "Policy Loss": 0.4414864778518677, "Value Loss": 30.923124313354492, "_runtime": 19395.52713561058, "_timestamp": 1585616765.160005, "_step": 308}
{"Episode reward": -92.73755462615922, "Episode length": 999, "Policy Loss": -0.3748134672641754, "Value Loss": 0.03514573723077774, "_runtime": 19397.029668807983, "_timestamp": 1585616766.6625383, "_step": 309}
{"Episode reward": -93.3534092211155, "Episode length": 999, "Policy Loss": -0.41137266159057617, "Value Loss": 0.08388849347829819, "_runtime": 19398.526210308075, "_timestamp": 1585616768.1590798, "_step": 310}
{"Episode reward": -92.27369623294133, "Episode length": 999, "Policy Loss": -0.4312251806259155, "Value Loss": 0.14381705224514008, "_runtime": 19400.097478866577, "_timestamp": 1585616769.7303483, "_step": 311}
{"Episode reward": -92.79258757181282, "Episode length": 999, "Policy Loss": -0.4460240602493286, "Value Loss": 0.04364541172981262, "_runtime": 19401.093564987183, "_timestamp": 1585616770.7264345, "_step": 312}
{"Episode reward": 41.20952779851447, "Episode length": 637, "Policy Loss": -0.16486264765262604, "Value Loss": 13.915122985839844, "_runtime": 19402.637035369873, "_timestamp": 1585616772.2699049, "_step": 313}
{"Episode reward": -90.2188561041692, "Episode length": 999, "Policy Loss": -0.4236699044704437, "Value Loss": 0.06111162528395653, "_runtime": 19404.20253753662, "_timestamp": 1585616773.835407, "_step": 314}
{"Episode reward": -88.6225571494267, "Episode length": 999, "Policy Loss": -0.39799654483795166, "Value Loss": 0.03317955508828163, "_runtime": 19405.727278470993, "_timestamp": 1585616775.360148, "_step": 315}
{"Episode reward": -87.52984563598096, "Episode length": 999, "Policy Loss": -0.3713957667350769, "Value Loss": 0.041139062494039536, "_runtime": 19407.300796985626, "_timestamp": 1585616776.9336665, "_step": 316}
{"Episode reward": -84.34924909473271, "Episode length": 999, "Policy Loss": -0.32212984561920166, "Value Loss": 0.03678249195218086, "_runtime": 19408.89184308052, "_timestamp": 1585616778.5247126, "_step": 317}
{"Episode reward": -83.80774524248653, "Episode length": 999, "Policy Loss": -0.2964729964733124, "Value Loss": 0.03165864944458008, "_runtime": 19410.452010154724, "_timestamp": 1585616780.0848796, "_step": 318}
{"Episode reward": -77.95264560280576, "Episode length": 999, "Policy Loss": -0.23875637352466583, "Value Loss": 0.025640403851866722, "_runtime": 19412.02645421028, "_timestamp": 1585616781.6593237, "_step": 319}
{"Episode reward": -72.88090458463415, "Episode length": 999, "Policy Loss": -0.19440913200378418, "Value Loss": 0.019083460792899132, "_runtime": 19413.61419057846, "_timestamp": 1585616783.24706, "_step": 320}
{"Episode reward": -67.27289457246077, "Episode length": 999, "Policy Loss": -0.15243376791477203, "Value Loss": 0.011683082208037376, "_runtime": 19415.229162454605, "_timestamp": 1585616784.862032, "_step": 321}
{"Episode reward": -60.519890342242206, "Episode length": 999, "Policy Loss": -0.11493244767189026, "Value Loss": 0.008188745006918907, "_runtime": 19416.805248260498, "_timestamp": 1585616786.4381177, "_step": 322}
{"Episode reward": -57.89372875301099, "Episode length": 999, "Policy Loss": -0.09021807461977005, "Value Loss": 0.006460242904722691, "_runtime": 19418.394967079163, "_timestamp": 1585616788.0278366, "_step": 323}
{"Episode reward": -52.52044366020628, "Episode length": 999, "Policy Loss": -0.06585269421339035, "Value Loss": 0.0049536763690412045, "_runtime": 19419.97371482849, "_timestamp": 1585616789.6065843, "_step": 324}
{"Episode reward": -47.647268839435675, "Episode length": 999, "Policy Loss": -0.04208743944764137, "Value Loss": 0.0038371244445443153, "_runtime": 19421.549124717712, "_timestamp": 1585616791.1819942, "_step": 325}
{"Episode reward": -44.574465841018295, "Episode length": 999, "Policy Loss": -0.024407001212239265, "Value Loss": 0.0034622796811163425, "_runtime": 19423.13819384575, "_timestamp": 1585616792.7710633, "_step": 326}
{"Episode reward": -42.979257821400715, "Episode length": 999, "Policy Loss": -0.008954481221735477, "Value Loss": 0.002541900845244527, "_runtime": 19424.708993196487, "_timestamp": 1585616794.3418627, "_step": 327}
{"Episode reward": -38.9678175608584, "Episode length": 999, "Policy Loss": 0.005640196613967419, "Value Loss": 0.0023105053696781397, "_runtime": 19426.278717279434, "_timestamp": 1585616795.9115868, "_step": 328}
{"Episode reward": -40.1698403659633, "Episode length": 999, "Policy Loss": 0.012639516033232212, "Value Loss": 0.0025138272903859615, "_runtime": 19427.85782265663, "_timestamp": 1585616797.4906921, "_step": 329}
{"Episode reward": -37.30731431319869, "Episode length": 999, "Policy Loss": 0.02346429042518139, "Value Loss": 0.0031859197188168764, "_runtime": 19429.43453192711, "_timestamp": 1585616799.0674014, "_step": 330}
{"Episode reward": -37.370168846153724, "Episode length": 999, "Policy Loss": 0.027197031304240227, "Value Loss": 0.004214441869407892, "_runtime": 19431.0280315876, "_timestamp": 1585616800.660901, "_step": 331}
{"Episode reward": -34.759133679108196, "Episode length": 999, "Policy Loss": 0.03435114026069641, "Value Loss": 0.0037834898103028536, "_runtime": 19432.613933324814, "_timestamp": 1585616802.2468028, "_step": 332}
{"Episode reward": -36.5971150443113, "Episode length": 999, "Policy Loss": 0.03767970949411392, "Value Loss": 0.0035239788703620434, "_runtime": 19434.1898291111, "_timestamp": 1585616803.8226986, "_step": 333}
{"Episode reward": -33.62200038511983, "Episode length": 999, "Policy Loss": 0.042047202587127686, "Value Loss": 0.003969467710703611, "_runtime": 19435.749843597412, "_timestamp": 1585616805.382713, "_step": 334}
{"Episode reward": -33.96536894886306, "Episode length": 999, "Policy Loss": 0.04383473843336105, "Value Loss": 0.004972601309418678, "_runtime": 19437.315953969955, "_timestamp": 1585616806.9488235, "_step": 335}
{"Episode reward": -32.965950467883836, "Episode length": 999, "Policy Loss": 0.042365074157714844, "Value Loss": 0.0054798368364572525, "_runtime": 19438.92936897278, "_timestamp": 1585616808.5622385, "_step": 336}
{"Episode reward": -33.02364284725592, "Episode length": 999, "Policy Loss": 0.04562551900744438, "Value Loss": 0.004719320684671402, "_runtime": 19440.499162197113, "_timestamp": 1585616810.1320317, "_step": 337}
{"Episode reward": -32.92944860757084, "Episode length": 999, "Policy Loss": 0.04155224189162254, "Value Loss": 0.005486596841365099, "_runtime": 19442.07675385475, "_timestamp": 1585616811.7096233, "_step": 338}
{"Episode reward": -33.793274806293574, "Episode length": 999, "Policy Loss": 0.04444147273898125, "Value Loss": 0.0049466341733932495, "_runtime": 19443.6496925354, "_timestamp": 1585616813.282562, "_step": 339}
{"Episode reward": -34.36552977950837, "Episode length": 999, "Policy Loss": 0.0427209846675396, "Value Loss": 0.0036927040200680494, "_runtime": 19445.21212363243, "_timestamp": 1585616814.844993, "_step": 340}
{"Episode reward": -33.65804708635347, "Episode length": 999, "Policy Loss": 0.040761251002550125, "Value Loss": 0.0044047636911273, "_runtime": 19446.7922911644, "_timestamp": 1585616816.4251606, "_step": 341}
{"Episode reward": -34.279425501367236, "Episode length": 999, "Policy Loss": 0.03768756240606308, "Value Loss": 0.004343443550169468, "_runtime": 19448.356498003006, "_timestamp": 1585616817.9893675, "_step": 342}
{"Episode reward": -35.23834651446527, "Episode length": 999, "Policy Loss": 0.03281746804714203, "Value Loss": 0.004249699879437685, "_runtime": 19449.92830967903, "_timestamp": 1585616819.5611792, "_step": 343}
{"Episode reward": -38.50560546884555, "Episode length": 999, "Policy Loss": 0.030016537755727768, "Value Loss": 0.0030502432491630316, "_runtime": 19451.50501894951, "_timestamp": 1585616821.1378884, "_step": 344}
{"Episode reward": -42.341063802584394, "Episode length": 999, "Policy Loss": 0.022765515372157097, "Value Loss": 0.003684606170281768, "_runtime": 19453.07097697258, "_timestamp": 1585616822.7038465, "_step": 345}
{"Episode reward": -47.37418939721853, "Episode length": 999, "Policy Loss": 0.01396607793867588, "Value Loss": 0.005930487997829914, "_runtime": 19454.64408516884, "_timestamp": 1585616824.2769547, "_step": 346}
{"Episode reward": -51.04568233127183, "Episode length": 999, "Policy Loss": 0.0036067464388906956, "Value Loss": 0.004115849267691374, "_runtime": 19456.221518039703, "_timestamp": 1585616825.8543875, "_step": 347}
{"Episode reward": -58.4064242714954, "Episode length": 999, "Policy Loss": -0.007441741414368153, "Value Loss": 0.0033508697524666786, "_runtime": 19457.793827295303, "_timestamp": 1585616827.4266968, "_step": 348}
{"Episode reward": -63.657114923649885, "Episode length": 999, "Policy Loss": -0.01831916533410549, "Value Loss": 0.003561988938599825, "_runtime": 19459.366763591766, "_timestamp": 1585616828.999633, "_step": 349}
{"Episode reward": -62.92651685364049, "Episode length": 999, "Policy Loss": -0.021601740270853043, "Value Loss": 0.003566896542906761, "_runtime": 19460.947326898575, "_timestamp": 1585616830.5801964, "_step": 350}
{"Episode reward": -63.66698710206433, "Episode length": 999, "Policy Loss": -0.022046701982617378, "Value Loss": 0.0032057969365268946, "_runtime": 19462.566715955734, "_timestamp": 1585616832.1995854, "_step": 351}
{"Episode reward": -68.13945010798822, "Episode length": 999, "Policy Loss": -0.03458700329065323, "Value Loss": 0.0068449778482317924, "_runtime": 19464.13906931877, "_timestamp": 1585616833.7719388, "_step": 352}
{"Episode reward": -69.89665051890401, "Episode length": 999, "Policy Loss": -0.035521820187568665, "Value Loss": 0.0036139385774731636, "_runtime": 19465.73397922516, "_timestamp": 1585616835.3668487, "_step": 353}
{"Episode reward": -72.47136366043364, "Episode length": 999, "Policy Loss": -0.04159926995635033, "Value Loss": 0.0056563010439276695, "_runtime": 19467.315754413605, "_timestamp": 1585616836.948624, "_step": 354}
{"Episode reward": -73.56299365903328, "Episode length": 999, "Policy Loss": -0.04192795604467392, "Value Loss": 0.006709259934723377, "_runtime": 19468.905993938446, "_timestamp": 1585616838.5388634, "_step": 355}
{"Episode reward": -76.07340779269916, "Episode length": 999, "Policy Loss": -0.04780524969100952, "Value Loss": 0.005813928786665201, "_runtime": 19470.4982213974, "_timestamp": 1585616840.1310909, "_step": 356}
{"Episode reward": -74.25778894090601, "Episode length": 999, "Policy Loss": -0.034996502101421356, "Value Loss": 0.002010370371863246, "_runtime": 19472.090146541595, "_timestamp": 1585616841.723016, "_step": 357}
{"Episode reward": -78.9388589102766, "Episode length": 999, "Policy Loss": -0.03817607834935188, "Value Loss": 0.0021721136290580034, "_runtime": 19473.677610874176, "_timestamp": 1585616843.3104804, "_step": 358}
{"Episode reward": -78.05711723394766, "Episode length": 999, "Policy Loss": -0.033013347536325455, "Value Loss": 0.003880026051774621, "_runtime": 19475.271328926086, "_timestamp": 1585616844.9041984, "_step": 359}
{"Episode reward": -80.17215594500439, "Episode length": 999, "Policy Loss": -0.02963537909090519, "Value Loss": 0.005287833046168089, "_runtime": 19476.86212849617, "_timestamp": 1585616846.494998, "_step": 360}
{"Episode reward": -79.69562498760467, "Episode length": 999, "Policy Loss": -0.021650584414601326, "Value Loss": 0.00338329141959548, "_runtime": 19478.4538025856, "_timestamp": 1585616848.086672, "_step": 361}
{"Episode reward": -80.27091652547114, "Episode length": 999, "Policy Loss": -0.020057784393429756, "Value Loss": 0.0016729893395677209, "_runtime": 19480.049133062363, "_timestamp": 1585616849.6820025, "_step": 362}
{"Episode reward": -79.2822892895164, "Episode length": 999, "Policy Loss": -0.009102722629904747, "Value Loss": 0.002787098754197359, "_runtime": 19481.639523744583, "_timestamp": 1585616851.2723932, "_step": 363}
{"Episode reward": -81.83258690685456, "Episode length": 999, "Policy Loss": -0.012189059518277645, "Value Loss": 0.002679613186046481, "_runtime": 19483.22061443329, "_timestamp": 1585616852.853484, "_step": 364}
{"Episode reward": -81.19800760840492, "Episode length": 999, "Policy Loss": -0.008665383793413639, "Value Loss": 0.0027476949617266655, "_runtime": 19484.842886447906, "_timestamp": 1585616854.475756, "_step": 365}
{"Episode reward": -82.13335114688246, "Episode length": 999, "Policy Loss": -0.0027846330776810646, "Value Loss": 0.004573398735374212, "_runtime": 19486.424308776855, "_timestamp": 1585616856.0571783, "_step": 366}
{"Episode reward": -83.99970976674513, "Episode length": 999, "Policy Loss": -0.003603125922381878, "Value Loss": 0.0020412104204297066, "_runtime": 19488.0132689476, "_timestamp": 1585616857.6461384, "_step": 367}
{"Episode reward": -81.42258764615158, "Episode length": 999, "Policy Loss": 0.005589961539953947, "Value Loss": 0.003845776664093137, "_runtime": 19489.60647058487, "_timestamp": 1585616859.23934, "_step": 368}
{"Episode reward": -80.28923508890358, "Episode length": 999, "Policy Loss": 0.007496785372495651, "Value Loss": 0.0027622797060757875, "_runtime": 19491.19699692726, "_timestamp": 1585616860.8298664, "_step": 369}
{"Episode reward": -81.36190505050143, "Episode length": 999, "Policy Loss": 0.01302995067089796, "Value Loss": 0.004736666101962328, "_runtime": 19492.778398752213, "_timestamp": 1585616862.4112682, "_step": 370}
{"Episode reward": -81.757099836766, "Episode length": 999, "Policy Loss": -0.005214978009462357, "Value Loss": 0.06690176576375961, "_runtime": 19494.359486103058, "_timestamp": 1585616863.9923556, "_step": 371}
{"Episode reward": -82.23792955355707, "Episode length": 999, "Policy Loss": 0.013375133275985718, "Value Loss": 0.004698638338595629, "_runtime": 19495.950403690338, "_timestamp": 1585616865.5832732, "_step": 372}
{"Episode reward": -81.68773593276377, "Episode length": 999, "Policy Loss": 0.022269047796726227, "Value Loss": 0.004773913882672787, "_runtime": 19497.540934324265, "_timestamp": 1585616867.1738038, "_step": 373}
{"Episode reward": -81.33891631886061, "Episode length": 999, "Policy Loss": 0.021870089694857597, "Value Loss": 0.0034432257525622845, "_runtime": 19499.13306903839, "_timestamp": 1585616868.7659385, "_step": 374}
{"Episode reward": -79.94298895588386, "Episode length": 999, "Policy Loss": 0.029763219878077507, "Value Loss": 0.008510899730026722, "_runtime": 19500.722493886948, "_timestamp": 1585616870.3553634, "_step": 375}
{"Episode reward": -80.67143805427163, "Episode length": 999, "Policy Loss": 0.02978482097387314, "Value Loss": 0.003331148764118552, "_runtime": 19502.31491470337, "_timestamp": 1585616871.9477842, "_step": 376}
{"Episode reward": -82.15357105008408, "Episode length": 999, "Policy Loss": 0.031071335077285767, "Value Loss": 0.006372062489390373, "_runtime": 19503.91117477417, "_timestamp": 1585616873.5440443, "_step": 377}
{"Episode reward": -80.52061758464998, "Episode length": 999, "Policy Loss": 0.008195825852453709, "Value Loss": 0.14892122149467468, "_runtime": 19505.502776622772, "_timestamp": 1585616875.135646, "_step": 378}
{"Episode reward": -80.09447330876965, "Episode length": 999, "Policy Loss": 0.03631507232785225, "Value Loss": 0.007418094668537378, "_runtime": 19507.091747045517, "_timestamp": 1585616876.7246165, "_step": 379}
{"Episode reward": -80.9087375437621, "Episode length": 999, "Policy Loss": 0.0368647426366806, "Value Loss": 0.005326847545802593, "_runtime": 19508.736748933792, "_timestamp": 1585616878.3696184, "_step": 380}
{"Episode reward": -79.21918794728735, "Episode length": 999, "Policy Loss": 0.036973267793655396, "Value Loss": 0.003818198572844267, "_runtime": 19510.33102631569, "_timestamp": 1585616879.9638958, "_step": 381}
{"Episode reward": -78.7840320661182, "Episode length": 999, "Policy Loss": 0.03604628145694733, "Value Loss": 0.004481118638068438, "_runtime": 19511.923687934875, "_timestamp": 1585616881.5565574, "_step": 382}
{"Episode reward": -78.03782613891268, "Episode length": 999, "Policy Loss": 0.04667447507381439, "Value Loss": 0.009525724686682224, "_runtime": 19513.51682138443, "_timestamp": 1585616883.1496909, "_step": 383}
{"Episode reward": -76.37936602712918, "Episode length": 999, "Policy Loss": 0.03657319024205208, "Value Loss": 0.005487492308020592, "_runtime": 19515.11522626877, "_timestamp": 1585616884.7480958, "_step": 384}
{"Episode reward": -78.8353343317817, "Episode length": 999, "Policy Loss": 0.027826741337776184, "Value Loss": 0.003044195706024766, "_runtime": 19516.710802793503, "_timestamp": 1585616886.3436723, "_step": 385}
{"Episode reward": -76.43857010372176, "Episode length": 999, "Policy Loss": 0.029068181291222572, "Value Loss": 0.004182641394436359, "_runtime": 19518.31571674347, "_timestamp": 1585616887.9485862, "_step": 386}
{"Episode reward": -75.54240564030354, "Episode length": 999, "Policy Loss": 0.028356127440929413, "Value Loss": 0.0030935348477214575, "_runtime": 19519.917110681534, "_timestamp": 1585616889.5499802, "_step": 387}
{"Episode reward": -72.76802306332353, "Episode length": 999, "Policy Loss": 0.026904234662652016, "Value Loss": 0.0028275151271373034, "_runtime": 19521.51172375679, "_timestamp": 1585616891.1445932, "_step": 388}
{"Episode reward": -73.05284864569101, "Episode length": 999, "Policy Loss": 0.025514323264360428, "Value Loss": 0.002079479629173875, "_runtime": 19523.113360643387, "_timestamp": 1585616892.7462301, "_step": 389}
{"Episode reward": -73.21769720208975, "Episode length": 999, "Policy Loss": 0.019140470772981644, "Value Loss": 0.002863060450181365, "_runtime": 19524.716237306595, "_timestamp": 1585616894.3491068, "_step": 390}
{"Episode reward": -72.90013776271205, "Episode length": 999, "Policy Loss": 0.015304109081625938, "Value Loss": 0.0022804741747677326, "_runtime": 19526.300099134445, "_timestamp": 1585616895.9329686, "_step": 391}
{"Episode reward": -69.49211764575497, "Episode length": 999, "Policy Loss": 0.01212816871702671, "Value Loss": 0.005609448067843914, "_runtime": 19527.89050102234, "_timestamp": 1585616897.5233705, "_step": 392}
{"Episode reward": -70.70727471157038, "Episode length": 999, "Policy Loss": 0.011530846357345581, "Value Loss": 0.002091762376949191, "_runtime": 19529.49492239952, "_timestamp": 1585616899.127792, "_step": 393}
{"Episode reward": -68.55868209677055, "Episode length": 999, "Policy Loss": 0.015293656848371029, "Value Loss": 0.0021914842072874308, "_runtime": 19531.100301027298, "_timestamp": 1585616900.7331705, "_step": 394}
{"Episode reward": -66.49305225268192, "Episode length": 999, "Policy Loss": 0.01328357681632042, "Value Loss": 0.0023252968676388264, "_runtime": 19532.728501796722, "_timestamp": 1585616902.3613713, "_step": 395}
{"Episode reward": -65.67576377810857, "Episode length": 999, "Policy Loss": 0.011818384751677513, "Value Loss": 0.0029005641117691994, "_runtime": 19534.331924438477, "_timestamp": 1585616903.964794, "_step": 396}
{"Episode reward": -67.8090806376242, "Episode length": 999, "Policy Loss": 0.00641688471660018, "Value Loss": 0.0025357194244861603, "_runtime": 19535.93464422226, "_timestamp": 1585616905.5675137, "_step": 397}
{"Episode reward": -66.83582935094796, "Episode length": 999, "Policy Loss": 0.006205462384968996, "Value Loss": 0.002402143320068717, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961, -0.8722637295722961]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-1.8128927946090698, -1.770941972732544, -1.7289912700653076, -1.6870405673980713, -1.6450897455215454, -1.6031389236450195, -1.5611882209777832, -1.5192375183105469, -1.477286696434021, -1.4353358745574951, -1.3933851718902588, -1.3514344692230225, -1.3094836473464966, -1.2675328254699707, -1.2255821228027344, -1.183631420135498, -1.1416805982589722, -1.0997297763824463, -1.05777907371521, -1.0158283710479736, -0.9738775491714478, -0.9319267868995667, -0.8899760246276855, -0.8480252623558044, -0.8060745000839233, -0.764123797416687, -0.7221729755401611, -0.6802221536636353, -0.6382714509963989, -0.5963207483291626, -0.5543699264526367, -0.5124191045761108, -0.4704684019088745, -0.4285176992416382, -0.3865668773651123, -0.3446160554885864, -0.3026653528213501, -0.26071465015411377, -0.2187638282775879, -0.176813006401062, -0.13486230373382568, -0.09291160106658936, -0.05096077919006348, -0.009009957313537598, 0.03294074535369873, 0.07489144802093506, 0.11684226989746094, 0.15879309177398682, 0.20074379444122314, 0.24269449710845947, 0.2846451997756958, 0.32659614086151123, 0.36854684352874756, 0.4104975461959839, 0.4524484872817993, 0.49439918994903564, 0.536349892616272, 0.5783005952835083, 0.6202512979507446, 0.6622022390365601, 0.7041529417037964, 0.7461036443710327, 0.7880545854568481, 0.8300052881240845, 0.8719559907913208]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03928526118397713, -0.035168182104825974, -0.03105110488831997, -0.026934027671813965, -0.02281694859266281, -0.018699869513511658, -0.014582792297005653, -0.010465715080499649, -0.0063486360013484955, -0.002231556922197342, 0.0018855221569538116, 0.006002597510814667, 0.01011967658996582, 0.014236755669116974, 0.01835383102297783, 0.022470910102128983, 0.026587989181280136, 0.03070506826043129, 0.03482214733958244, 0.0389392264187336, 0.04305630549788475, 0.04717337712645531, 0.05129045620560646, 0.055407535284757614, 0.05952461436390877, 0.06364169716835022, 0.06775876879692078, 0.07187585532665253, 0.07599292695522308, 0.08010999858379364, 0.08422708511352539, 0.08834417164325714, 0.0924612432718277, 0.09657831490039825, 0.10069540143013, 0.10481247305870056, 0.10892955958843231, 0.11304663121700287, 0.11716371774673462, 0.12128078937530518, 0.12539787590503693, 0.12951494753360748, 0.13363201916217804, 0.1377491056919098, 0.14186617732048035, 0.1459832638502121, 0.15010033547878265, 0.1542174220085144, 0.15833449363708496, 0.16245156526565552, 0.16656865179538727, 0.17068572342395782, 0.17480280995368958, 0.17891988158226013, 0.18303696811199188, 0.18715403974056244, 0.191271111369133, 0.19538819789886475, 0.1995052695274353, 0.20362235605716705, 0.2077394276857376, 0.21185649931430817, 0.2159736007452011, 0.22009067237377167, 0.22420774400234222]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 4.0, 0.0, 5.0, 3.0, 3.0, 5.0, 4.0, 3.0, 8.0, 8.0, 14.0, 19.0, 11.0, 302.0, 4.0, 10.0, 4.0, 13.0, 16.0, 10.0, 9.0, 4.0, 8.0, 4.0, 5.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.1305861920118332, -0.12605737149715424, -0.12152855843305588, -0.11699974536895752, -0.11247092485427856, -0.1079421117901802, -0.10341329872608185, -0.0988844782114029, -0.09435566514730453, -0.08982685208320618, -0.08529803156852722, -0.08076921850442886, -0.0762404054403305, -0.07171158492565155, -0.06718277186155319, -0.06265395134687424, -0.05812513828277588, -0.05359632521867752, -0.049067504703998566, -0.04453869163990021, -0.04000987112522125, -0.035481058061122894, -0.030952244997024536, -0.02642342448234558, -0.021894611418247223, -0.017365798354148865, -0.01283697783946991, -0.008308164775371552, -0.0037793517112731934, 0.0007494688034057617, 0.005278289318084717, 0.009807094931602478, 0.014335915446281433, 0.018864735960960388, 0.02339354157447815, 0.027922362089157104, 0.03245118260383606, 0.03697998821735382, 0.041508808732032776, 0.04603762924671173, 0.050566449761390686, 0.05509525537490845, 0.0596240758895874, 0.06415289640426636, 0.06868170201778412, 0.07321052253246307, 0.07773934304714203, 0.08226814866065979, 0.08679696917533875, 0.0913257896900177, 0.09585459530353546, 0.10038341581821442, 0.10491223633289337, 0.10944104194641113, 0.11396986246109009, 0.11849868297576904, 0.1230274885892868, 0.12755630910396576, 0.13208512961864471, 0.13661395013332367, 0.14114277064800262, 0.1456715613603592, 0.15020038187503815, 0.1547292023897171, 0.15925802290439606]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.26920560002326965, -0.2597053647041321, -0.2502051293849945, -0.24070489406585693, -0.23120465874671936, -0.2217044234275818, -0.21220417320728302, -0.20270393788814545, -0.19320370256900787, -0.1837034672498703, -0.17420323193073273, -0.16470298171043396, -0.1552027463912964, -0.1457025110721588, -0.13620227575302124, -0.12670204043388367, -0.1172018051147461, -0.10770156979560852, -0.09820133447647095, -0.08870109915733337, -0.0792008638381958, -0.06970061361789703, -0.06020037829875946, -0.05070014297962189, -0.041199907660484314, -0.03169967234134674, -0.022199437022209167, -0.0126991868019104, -0.003198951482772827, 0.006301283836364746, 0.01580151915550232, 0.025301754474639893, 0.034801989793777466, 0.04430222511291504, 0.05380246043205261, 0.06330269575119019, 0.07280293107032776, 0.08230316638946533, 0.0918034017086029, 0.10130363702774048, 0.11080387234687805, 0.12030413746833801, 0.12980437278747559, 0.13930460810661316, 0.14880484342575073, 0.1583050787448883, 0.16780531406402588, 0.17730554938316345, 0.18680578470230103, 0.1963060200214386, 0.20580625534057617, 0.21530649065971375, 0.22480672597885132, 0.2343069612979889, 0.24380722641944885, 0.25330743193626404, 0.262807697057724, 0.2723079025745392, 0.28180816769599915, 0.29130837321281433, 0.3008086383342743, 0.3103088438510895, 0.31980910897254944, 0.3293093144893646, 0.3388095796108246]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-0.02736104652285576, -0.026599012315273285, -0.02583697810769081, -0.025074943900108337, -0.024312907829880714, -0.02355087362229824, -0.022788839414715767, -0.022026805207133293, -0.02126476913690567, -0.020502734929323196, -0.019740700721740723, -0.01897866651415825, -0.018216632306575775, -0.0174545980989933, -0.016692563891410828, -0.015930527821183205, -0.015168493613600731, -0.014406459406018257, -0.013644424267113209, -0.012882390059530735, -0.012120354920625687, -0.011358320713043213, -0.01059628650546074, -0.009834252297878265, -0.009072218090295792, -0.008310182020068169, -0.007548147812485695, -0.006786113604903221, -0.006024079397320747, -0.005262045189738274, -0.004500009119510651, -0.003737974911928177, -0.002975940704345703, -0.0022139064967632294, -0.0014518722891807556, -0.0006898362189531326, 7.219798862934113e-05, 0.0008342321962118149, 0.0015962664037942886, 0.0023583006113767624, 0.0031203366816043854, 0.003882370889186859, 0.004644405096769333, 0.005406439304351807, 0.00616847351193428, 0.006930507719516754, 0.007692541927099228, 0.008454576134681702, 0.009216610342264175, 0.009978648275136948, 0.010740682482719421, 0.011502716690301895, 0.012264750897884369, 0.013026785105466843, 0.013788819313049316, 0.01455085352063179, 0.015312887728214264, 0.016074921935796738, 0.01683695614337921, 0.017598994076251984, 0.018361028283834457, 0.01912306249141693, 0.019885096698999405, 0.02064713090658188, 0.021409165114164352]}, "_runtime": 19537.54172563553, "_timestamp": 1585616907.174595, "_step": 398}
{"Episode reward": -67.42512124955077, "Episode length": 999, "Policy Loss": 0.003561305347830057, "Value Loss": 0.001992701319977641, "_runtime": 19539.14718079567, "_timestamp": 1585616908.7800503, "_step": 399}
{"Episode reward": -66.28632054450182, "Episode length": 999, "Policy Loss": 0.0012974434066563845, "Value Loss": 0.0026640587020665407, "_runtime": 19540.750610351562, "_timestamp": 1585616910.3834798, "_step": 400}
{"Episode reward": -69.7672733589192, "Episode length": 999, "Policy Loss": -0.0041309441439807415, "Value Loss": 0.0022038682363927364, "_runtime": 19542.34438586235, "_timestamp": 1585616911.9772553, "_step": 401}
{"Episode reward": -66.60690231931594, "Episode length": 999, "Policy Loss": 0.0005508053000085056, "Value Loss": 0.0018689509015530348, "_runtime": 19543.938144683838, "_timestamp": 1585616913.5710142, "_step": 402}
{"Episode reward": -66.27928284244271, "Episode length": 999, "Policy Loss": 0.0013328035129234195, "Value Loss": 0.0022072470746934414, "_runtime": 19545.532222509384, "_timestamp": 1585616915.165092, "_step": 403}
{"Episode reward": -65.38516966291743, "Episode length": 999, "Policy Loss": -0.0007472001598216593, "Value Loss": 0.002876179525628686, "_runtime": 19547.127316236496, "_timestamp": 1585616916.7601857, "_step": 404}
{"Episode reward": -65.74521189939871, "Episode length": 999, "Policy Loss": -0.0019840297754853964, "Value Loss": 0.002630002796649933, "_runtime": 19548.732806921005, "_timestamp": 1585616918.3656764, "_step": 405}
{"Episode reward": -68.54504950860566, "Episode length": 999, "Policy Loss": -0.0070939441211521626, "Value Loss": 0.003125944407656789, "_runtime": 19550.325157165527, "_timestamp": 1585616919.9580266, "_step": 406}
{"Episode reward": -67.42657731731238, "Episode length": 999, "Policy Loss": -0.003526552813127637, "Value Loss": 0.0019118248019367456, "_runtime": 19551.93236875534, "_timestamp": 1585616921.5652382, "_step": 407}
{"Episode reward": -68.75966031242262, "Episode length": 999, "Policy Loss": -0.00754097243770957, "Value Loss": 0.0037259026430547237, "_runtime": 19553.53181362152, "_timestamp": 1585616923.164683, "_step": 408}
{"Episode reward": -70.73598132024243, "Episode length": 999, "Policy Loss": -0.007360957097262144, "Value Loss": 0.0018263778183609247, "_runtime": 19555.13511776924, "_timestamp": 1585616924.7679873, "_step": 409}
{"Episode reward": -68.72277369870828, "Episode length": 999, "Policy Loss": -0.0068728248588740826, "Value Loss": 0.007279647514224052, "_runtime": 19556.769926548004, "_timestamp": 1585616926.402796, "_step": 410}
{"Episode reward": -71.30986060907674, "Episode length": 999, "Policy Loss": -0.005308835301548243, "Value Loss": 0.0020002303645014763, "_runtime": 19558.362479686737, "_timestamp": 1585616927.9953492, "_step": 411}
{"Episode reward": -72.55908255836673, "Episode length": 999, "Policy Loss": -0.009475934319198132, "Value Loss": 0.002685735234990716, "_runtime": 19559.965719223022, "_timestamp": 1585616929.5985887, "_step": 412}
{"Episode reward": -71.66901609010057, "Episode length": 999, "Policy Loss": -0.004807004239410162, "Value Loss": 0.0028315940871834755, "_runtime": 19561.56871843338, "_timestamp": 1585616931.201588, "_step": 413}
{"Episode reward": -74.656705642059, "Episode length": 999, "Policy Loss": -0.00697398791089654, "Value Loss": 0.0017935322830453515, "_runtime": 19563.161771059036, "_timestamp": 1585616932.7946405, "_step": 414}
{"Episode reward": -79.5170769779579, "Episode length": 999, "Policy Loss": -0.013470358215272427, "Value Loss": 0.001639490481466055, "_runtime": 19564.76429438591, "_timestamp": 1585616934.3971639, "_step": 415}
{"Episode reward": -75.27403143183966, "Episode length": 999, "Policy Loss": -0.0031115510500967503, "Value Loss": 0.001850524335168302, "_runtime": 19566.367396354675, "_timestamp": 1585616936.0002658, "_step": 416}
{"Episode reward": -76.85993639240522, "Episode length": 999, "Policy Loss": -0.004780802875757217, "Value Loss": 0.0016883466159924865, "_runtime": 19567.97057199478, "_timestamp": 1585616937.6034415, "_step": 417}
{"Episode reward": -77.56383929058264, "Episode length": 999, "Policy Loss": -0.004381118807941675, "Value Loss": 0.0018943718168884516, "_runtime": 19569.57252931595, "_timestamp": 1585616939.2053988, "_step": 418}
{"Episode reward": -78.28756305136682, "Episode length": 999, "Policy Loss": -0.0010592519538477063, "Value Loss": 0.0019874852150678635, "_runtime": 19571.17705655098, "_timestamp": 1585616940.809926, "_step": 419}
{"Episode reward": -80.03102610156931, "Episode length": 999, "Policy Loss": -0.002340136794373393, "Value Loss": 0.0016055450541898608, "_runtime": 19572.772316217422, "_timestamp": 1585616942.4051857, "_step": 420}
{"Episode reward": -77.36978085245292, "Episode length": 999, "Policy Loss": 0.0032855954486876726, "Value Loss": 0.0026678089052438736, "_runtime": 19574.367137670517, "_timestamp": 1585616944.0000072, "_step": 421}
{"Episode reward": -78.22431060314781, "Episode length": 999, "Policy Loss": 0.0014514131471514702, "Value Loss": 0.0037400100845843554, "_runtime": 19575.960240840912, "_timestamp": 1585616945.5931103, "_step": 422}
{"Episode reward": -78.37897007227878, "Episode length": 999, "Policy Loss": 0.003015040885657072, "Value Loss": 0.0016277204267680645, "_runtime": 19577.56535410881, "_timestamp": 1585616947.1982236, "_step": 423}
{"Episode reward": -77.29602609843715, "Episode length": 999, "Policy Loss": 0.00724180368706584, "Value Loss": 0.0019432652043178678, "_runtime": 19579.202564239502, "_timestamp": 1585616948.8354337, "_step": 424}
{"Episode reward": -76.55618266754367, "Episode length": 999, "Policy Loss": 0.010517314076423645, "Value Loss": 0.002378618810325861, "_runtime": 19580.79761314392, "_timestamp": 1585616950.4304826, "_step": 425}
{"Episode reward": -78.2685269053755, "Episode length": 999, "Policy Loss": 0.006966582499444485, "Value Loss": 0.0021195420995354652, "_runtime": 19582.39301609993, "_timestamp": 1585616952.0258856, "_step": 426}
{"Episode reward": -79.46779293800452, "Episode length": 999, "Policy Loss": 0.00391740957275033, "Value Loss": 0.0017474128399044275, "_runtime": 19583.993604421616, "_timestamp": 1585616953.626474, "_step": 427}
{"Episode reward": -78.58879792590523, "Episode length": 999, "Policy Loss": 0.006160305347293615, "Value Loss": 0.0015110011445358396, "_runtime": 19585.599417209625, "_timestamp": 1585616955.2322867, "_step": 428}
{"Episode reward": -79.57734596418388, "Episode length": 999, "Policy Loss": 0.0032873668242245913, "Value Loss": 0.0014653797261416912, "_runtime": 19587.193808317184, "_timestamp": 1585616956.8266778, "_step": 429}
{"Episode reward": -77.74138404345172, "Episode length": 999, "Policy Loss": 0.006963400635868311, "Value Loss": 0.0022386449854820967, "_runtime": 19588.795929908752, "_timestamp": 1585616958.4287994, "_step": 430}
{"Episode reward": -78.29927201160041, "Episode length": 999, "Policy Loss": 0.004604100249707699, "Value Loss": 0.0029722186736762524, "_runtime": 19590.39078116417, "_timestamp": 1585616960.0236506, "_step": 431}
{"Episode reward": -79.62171370250978, "Episode length": 999, "Policy Loss": 0.002887635724619031, "Value Loss": 0.002388915978372097, "_runtime": 19591.994278907776, "_timestamp": 1585616961.6271484, "_step": 432}
{"Episode reward": -78.12489633061112, "Episode length": 999, "Policy Loss": 0.006069230381399393, "Value Loss": 0.0015587243251502514, "_runtime": 19593.600049495697, "_timestamp": 1585616963.232919, "_step": 433}
{"Episode reward": -79.56361570143595, "Episode length": 999, "Policy Loss": 0.0017410328146070242, "Value Loss": 0.0014694785932078958, "_runtime": 19595.205668449402, "_timestamp": 1585616964.838538, "_step": 434}
{"Episode reward": -82.82054591869763, "Episode length": 999, "Policy Loss": -0.008988418616354465, "Value Loss": 0.005580579861998558, "_runtime": 19596.808545827866, "_timestamp": 1585616966.4414153, "_step": 435}
{"Episode reward": -81.27176311238338, "Episode length": 999, "Policy Loss": -0.0015870756469666958, "Value Loss": 0.001625753939151764, "_runtime": 19598.412271022797, "_timestamp": 1585616968.0451405, "_step": 436}
{"Episode reward": -82.33264483409215, "Episode length": 999, "Policy Loss": -0.0031863446347415447, "Value Loss": 0.001886351383291185, "_runtime": 19600.005600214005, "_timestamp": 1585616969.6384697, "_step": 437}
{"Episode reward": -79.5186693984866, "Episode length": 999, "Policy Loss": -0.03344057872891426, "Value Loss": 0.07486950606107712, "_runtime": 19601.610708475113, "_timestamp": 1585616971.243578, "_step": 438}
{"Episode reward": -82.37468474538652, "Episode length": 999, "Policy Loss": 0.00790497288107872, "Value Loss": 0.006018423940986395, "_runtime": 19603.25466275215, "_timestamp": 1585616972.8875322, "_step": 439}
{"Episode reward": -82.6467973794534, "Episode length": 999, "Policy Loss": 0.020490525290369987, "Value Loss": 0.002614486264064908, "_runtime": 19604.848711252213, "_timestamp": 1585616974.4815807, "_step": 440}
{"Episode reward": -80.5507850572124, "Episode length": 999, "Policy Loss": -0.027175186201930046, "Value Loss": 0.3819546401500702, "_runtime": 19606.439081192017, "_timestamp": 1585616976.0719507, "_step": 441}
{"Episode reward": -81.05405474689205, "Episode length": 999, "Policy Loss": 0.05821961537003517, "Value Loss": 0.016185443848371506, "_runtime": 19608.041992902756, "_timestamp": 1585616977.6748624, "_step": 442}
{"Episode reward": -82.02538459988136, "Episode length": 999, "Policy Loss": 0.07904580980539322, "Value Loss": 0.021770432591438293, "_runtime": 19609.646401643753, "_timestamp": 1585616979.2792711, "_step": 443}
{"Episode reward": -81.84810713057992, "Episode length": 999, "Policy Loss": 0.08189074695110321, "Value Loss": 0.010524637065827847, "_runtime": 19611.239404201508, "_timestamp": 1585616980.8722737, "_step": 444}
{"Episode reward": -82.64352204378743, "Episode length": 999, "Policy Loss": 0.09859298169612885, "Value Loss": 0.02298893593251705, "_runtime": 19612.84281015396, "_timestamp": 1585616982.4756796, "_step": 445}
{"Episode reward": -79.98344664181413, "Episode length": 999, "Policy Loss": 0.10818450152873993, "Value Loss": 0.025107581168413162, "_runtime": 19614.4368391037, "_timestamp": 1585616984.0697086, "_step": 446}
{"Episode reward": -75.96802848063548, "Episode length": 999, "Policy Loss": 0.1247965469956398, "Value Loss": 0.04972387105226517, "_runtime": 19616.030126571655, "_timestamp": 1585616985.662996, "_step": 447}
{"Episode reward": -77.48733012931602, "Episode length": 999, "Policy Loss": 0.12415797263383865, "Value Loss": 0.035450536757707596, "_runtime": 19617.6262216568, "_timestamp": 1585616987.2590911, "_step": 448}
{"Episode reward": -79.08594463760028, "Episode length": 999, "Policy Loss": 0.12382935732603073, "Value Loss": 0.05030782148241997, "_runtime": 19619.219982385635, "_timestamp": 1585616988.8528519, "_step": 449}
{"Episode reward": -74.9392488883815, "Episode length": 999, "Policy Loss": 0.125883549451828, "Value Loss": 0.02692626602947712, "_runtime": 19620.824849128723, "_timestamp": 1585616990.4577186, "_step": 450}
{"Episode reward": -74.35740103402794, "Episode length": 999, "Policy Loss": 0.09431314468383789, "Value Loss": 0.010664110071957111, "_runtime": 19622.43429851532, "_timestamp": 1585616992.067168, "_step": 451}
{"Episode reward": -74.73966086194135, "Episode length": 999, "Policy Loss": 0.09950141608715057, "Value Loss": 0.01584145985543728, "_runtime": 19624.04011273384, "_timestamp": 1585616993.6729822, "_step": 452}
{"Episode reward": -72.56132794485461, "Episode length": 999, "Policy Loss": 0.08912838995456696, "Value Loss": 0.012252178974449635, "_runtime": 19625.64294910431, "_timestamp": 1585616995.2758186, "_step": 453}
{"Episode reward": -72.79225521583238, "Episode length": 999, "Policy Loss": 0.06408049166202545, "Value Loss": 0.004622079897671938, "_runtime": 19627.28673863411, "_timestamp": 1585616996.919608, "_step": 454}
{"Episode reward": -73.21921364578992, "Episode length": 999, "Policy Loss": 0.056126270443201065, "Value Loss": 0.006352017633616924, "_runtime": 19628.8923971653, "_timestamp": 1585616998.5252666, "_step": 455}
{"Episode reward": -72.42381283321252, "Episode length": 999, "Policy Loss": 0.04243183881044388, "Value Loss": 0.003356573171913624, "_runtime": 19630.475069522858, "_timestamp": 1585617000.107939, "_step": 456}
{"Episode reward": -74.21029742208191, "Episode length": 999, "Policy Loss": 0.025930609554052353, "Value Loss": 0.0019840411841869354, "_runtime": 19632.07092690468, "_timestamp": 1585617001.7037964, "_step": 457}
{"Episode reward": -74.62151942928134, "Episode length": 999, "Policy Loss": 0.010265873745083809, "Value Loss": 0.0018196769524365664, "_runtime": 19633.66457748413, "_timestamp": 1585617003.297447, "_step": 458}
{"Episode reward": -73.01948768850991, "Episode length": 999, "Policy Loss": 0.005809677764773369, "Value Loss": 0.004491620697081089, "_runtime": 19635.24916958809, "_timestamp": 1585617004.882039, "_step": 459}
{"Episode reward": -76.81490715863005, "Episode length": 999, "Policy Loss": -0.011132007464766502, "Value Loss": 0.002017716644331813, "_runtime": 19636.85144162178, "_timestamp": 1585617006.484311, "_step": 460}
{"Episode reward": -75.59786770531088, "Episode length": 999, "Policy Loss": -0.027499686926603317, "Value Loss": 0.007137737702578306, "_runtime": 19638.455327272415, "_timestamp": 1585617008.0881968, "_step": 461}
{"Episode reward": -77.59316774581015, "Episode length": 999, "Policy Loss": -0.032119691371917725, "Value Loss": 0.004911912139505148, "_runtime": 19640.058161258698, "_timestamp": 1585617009.6910307, "_step": 462}
{"Episode reward": -77.88460326789391, "Episode length": 999, "Policy Loss": -0.03232143446803093, "Value Loss": 0.00415966147556901, "_runtime": 19641.665525197983, "_timestamp": 1585617011.2983947, "_step": 463}
{"Episode reward": -78.909814712262, "Episode length": 999, "Policy Loss": -0.03759642317891121, "Value Loss": 0.003015740541741252, "_runtime": 19643.258905410767, "_timestamp": 1585617012.891775, "_step": 464}
{"Episode reward": -76.86507116700844, "Episode length": 999, "Policy Loss": -0.04020790383219719, "Value Loss": 0.005106666125357151, "_runtime": 19644.86051750183, "_timestamp": 1585617014.493387, "_step": 465}
{"Episode reward": -79.79717385749588, "Episode length": 999, "Policy Loss": -0.042447756975889206, "Value Loss": 0.0046824305318295956, "_runtime": 19646.46244740486, "_timestamp": 1585617016.095317, "_step": 466}
{"Episode reward": -78.19909153767125, "Episode length": 999, "Policy Loss": -0.04501287639141083, "Value Loss": 0.010349921882152557, "_runtime": 19648.06746983528, "_timestamp": 1585617017.7003393, "_step": 467}
{"Episode reward": -75.81272248079033, "Episode length": 999, "Policy Loss": -0.07504425942897797, "Value Loss": 0.06881356984376907, "_runtime": 19649.670099020004, "_timestamp": 1585617019.3029685, "_step": 468}
{"Episode reward": -79.2636630388194, "Episode length": 999, "Policy Loss": -0.0209830142557621, "Value Loss": 0.003140097949653864, "_runtime": 19651.317959547043, "_timestamp": 1585617020.950829, "_step": 469}
{"Episode reward": -80.48911692352627, "Episode length": 999, "Policy Loss": -0.010687480680644512, "Value Loss": 0.0016113159945234656, "_runtime": 19652.919399023056, "_timestamp": 1585617022.5522685, "_step": 470}
{"Episode reward": -79.25809667510222, "Episode length": 999, "Policy Loss": 0.005425760988146067, "Value Loss": 0.0013496594037860632, "_runtime": 19654.52347111702, "_timestamp": 1585617024.1563406, "_step": 471}
{"Episode reward": -76.59390499444675, "Episode length": 999, "Policy Loss": 0.018523361533880234, "Value Loss": 0.005488356109708548, "_runtime": 19656.12516760826, "_timestamp": 1585617025.758037, "_step": 472}
{"Episode reward": -78.927409689571, "Episode length": 999, "Policy Loss": 0.03112516924738884, "Value Loss": 0.004296683240681887, "_runtime": 19657.7283744812, "_timestamp": 1585617027.361244, "_step": 473}
{"Episode reward": -79.46579053047301, "Episode length": 999, "Policy Loss": 0.04185491427779198, "Value Loss": 0.007370056584477425, "_runtime": 19659.316417455673, "_timestamp": 1585617028.949287, "_step": 474}
{"Episode reward": -79.72762912704508, "Episode length": 999, "Policy Loss": 0.04413938149809837, "Value Loss": 0.006910644005984068, "_runtime": 19660.911923646927, "_timestamp": 1585617030.5447931, "_step": 475}
{"Episode reward": -81.3728864693601, "Episode length": 999, "Policy Loss": 0.03902216628193855, "Value Loss": 0.0039467113092541695, "_runtime": 19662.508455514908, "_timestamp": 1585617032.141325, "_step": 476}
{"Episode reward": -77.22320247259367, "Episode length": 999, "Policy Loss": 0.05825052410364151, "Value Loss": 0.008318006992340088, "_runtime": 19664.10689020157, "_timestamp": 1585617033.7397597, "_step": 477}
{"Episode reward": -79.05656604179637, "Episode length": 999, "Policy Loss": 0.04812035709619522, "Value Loss": 0.004346854519098997, "_runtime": 19665.696432590485, "_timestamp": 1585617035.329302, "_step": 478}
{"Episode reward": -80.39080773140695, "Episode length": 999, "Policy Loss": 0.04612933471798897, "Value Loss": 0.005818468052893877, "_runtime": 19667.29260277748, "_timestamp": 1585617036.9254723, "_step": 479}
{"Episode reward": -77.81528275724872, "Episode length": 999, "Policy Loss": 0.04488980025053024, "Value Loss": 0.010145630687475204, "_runtime": 19668.890486955643, "_timestamp": 1585617038.5233564, "_step": 480}
{"Episode reward": -80.72481318032416, "Episode length": 999, "Policy Loss": 0.028075160458683968, "Value Loss": 0.0025556774344295263, "_runtime": 19670.48106765747, "_timestamp": 1585617040.1139371, "_step": 481}
{"Episode reward": -80.14126317883196, "Episode length": 999, "Policy Loss": 0.024049054831266403, "Value Loss": 0.003177745034918189, "_runtime": 19672.06900548935, "_timestamp": 1585617041.701875, "_step": 482}
{"Episode reward": -83.43302197750589, "Episode length": 999, "Policy Loss": 0.013281737454235554, "Value Loss": 0.0020534915383905172, "_runtime": 19673.6553273201, "_timestamp": 1585617043.2881968, "_step": 483}
{"Episode reward": -83.33353431661865, "Episode length": 999, "Policy Loss": 0.00485521974042058, "Value Loss": 0.0030768706928938627, "_runtime": 19675.292467832565, "_timestamp": 1585617044.9253373, "_step": 484}
{"Episode reward": -80.35836750956175, "Episode length": 999, "Policy Loss": -0.005819051992148161, "Value Loss": 0.012866751290857792, "_runtime": 19676.881651878357, "_timestamp": 1585617046.5145214, "_step": 485}
{"Episode reward": -83.34056540318512, "Episode length": 999, "Policy Loss": -0.0034948636312037706, "Value Loss": 0.0011488425079733133, "_runtime": 19678.468776226044, "_timestamp": 1585617048.1016457, "_step": 486}
{"Episode reward": -83.01095900574028, "Episode length": 999, "Policy Loss": -0.011514016427099705, "Value Loss": 0.002159194555133581, "_runtime": 19680.066356420517, "_timestamp": 1585617049.699226, "_step": 487}
{"Episode reward": -81.1962060624308, "Episode length": 999, "Policy Loss": -0.003858790034428239, "Value Loss": 0.0017584740417078137, "_runtime": 19681.664249658585, "_timestamp": 1585617051.2971191, "_step": 488}
{"Episode reward": -81.6530589939943, "Episode length": 999, "Policy Loss": -0.006332774180918932, "Value Loss": 0.0013864368665963411, "_runtime": 19683.259805440903, "_timestamp": 1585617052.892675, "_step": 489}
{"Episode reward": -81.81476523312818, "Episode length": 999, "Policy Loss": -0.007423283066600561, "Value Loss": 0.0021316048223525286, "_runtime": 19684.856555700302, "_timestamp": 1585617054.4894252, "_step": 490}
{"Episode reward": -80.66439012377647, "Episode length": 999, "Policy Loss": -0.005857487674802542, "Value Loss": 0.0020181024447083473, "_runtime": 19686.465809583664, "_timestamp": 1585617056.098679, "_step": 491}
{"Episode reward": -81.43978394607505, "Episode length": 999, "Policy Loss": -0.00771162798628211, "Value Loss": 0.001239990466274321, "_runtime": 19688.067773342133, "_timestamp": 1585617057.7006428, "_step": 492}
{"Episode reward": -80.6214222785141, "Episode length": 999, "Policy Loss": -0.031208807602524757, "Value Loss": 0.017260057851672173, "_runtime": 19689.676578998566, "_timestamp": 1585617059.3094485, "_step": 493}
{"Episode reward": -81.19037947700677, "Episode length": 999, "Policy Loss": -0.003637259593233466, "Value Loss": 0.004336223937571049, "_runtime": 19691.27011489868, "_timestamp": 1585617060.9029844, "_step": 494}
{"Episode reward": -82.80493516838327, "Episode length": 999, "Policy Loss": -0.005034997593611479, "Value Loss": 0.0013388373190537095, "_runtime": 19692.872732400894, "_timestamp": 1585617062.505602, "_step": 495}
{"Episode reward": -83.15801011629802, "Episode length": 999, "Policy Loss": -0.0008522343705408275, "Value Loss": 0.0014217370189726353, "_runtime": 19694.47718310356, "_timestamp": 1585617064.1100526, "_step": 496}
{"Episode reward": -82.32826718078017, "Episode length": 999, "Policy Loss": 0.002437177812680602, "Value Loss": 0.001384790288284421, "_runtime": 19696.081522464752, "_timestamp": 1585617065.714392, "_step": 497}
{"Episode reward": -78.81650572904958, "Episode length": 999, "Policy Loss": 0.010977234691381454, "Value Loss": 0.0033162201289087534, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246, -0.8683485984802246]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.6822770833969116, -0.6580922603607178, -0.6339073777198792, -0.6097224950790405, -0.5855376720428467, -0.5613528490066528, -0.5371679663658142, -0.5129830837249756, -0.48879826068878174, -0.4646134078502655, -0.44042855501174927, -0.41624370217323303, -0.3920588493347168, -0.36787399649620056, -0.3436891436576843, -0.3195042908191681, -0.29531943798065186, -0.2711345851421356, -0.24694973230361938, -0.22276487946510315, -0.19858002662658691, -0.17439520359039307, -0.15021032094955444, -0.12602543830871582, -0.10184061527252197, -0.07765579223632812, -0.0534709095954895, -0.02928602695465088, -0.005101203918457031, 0.019083619117736816, 0.04326850175857544, 0.06745338439941406, 0.09163820743560791, 0.11582303047180176, 0.14000791311264038, 0.164192795753479, 0.18837761878967285, 0.2125624418258667, 0.23674732446670532, 0.26093220710754395, 0.2851170301437378, 0.30930185317993164, 0.3334866762161255, 0.3576716184616089, 0.38185644149780273, 0.4060412645339966, 0.43022620677948, 0.45441102981567383, 0.4785958528518677, 0.5027806758880615, 0.5269654989242554, 0.5511504411697388, 0.5753352642059326, 0.5995200872421265, 0.6237050294876099, 0.6478898525238037, 0.6720746755599976, 0.6962594985961914, 0.7204443216323853, 0.7446292638778687, 0.7688140869140625, 0.7929989099502563, 0.8171838521957397, 0.8413686752319336, 0.8655534982681274]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03332965821027756, -0.02983318455517292, -0.026336710900068283, -0.022840237244963646, -0.01934376358985901, -0.01584728993475437, -0.012350816279649734, -0.008854342624545097, -0.00535786896944046, -0.0018613934516906738, 0.001635078340768814, 0.005131550133228302, 0.008628025650978088, 0.012124501168727875, 0.015620972961187363, 0.01911744475364685, 0.022613920271396637, 0.026110395789146423, 0.02960687130689621, 0.0331033393740654, 0.036599814891815186, 0.04009629040956497, 0.04359275847673416, 0.04708923399448395, 0.050585709512233734, 0.05408218502998352, 0.05757866054773331, 0.061075128614902496, 0.06457160413265228, 0.06806807965040207, 0.07156454771757126, 0.07506102323532104, 0.07855749875307083, 0.08205397427082062, 0.0855504497885704, 0.0890469178557396, 0.09254340082406998, 0.09603986889123917, 0.09953633695840836, 0.10303281992673874, 0.10652928799390793, 0.11002575606107712, 0.1135222390294075, 0.11701870709657669, 0.12051517516374588, 0.12401165813207626, 0.12750813364982605, 0.13100460171699524, 0.13450106978416443, 0.13799753785133362, 0.1414940357208252, 0.14499050378799438, 0.14848697185516357, 0.15198343992233276, 0.15547990798950195, 0.15897640585899353, 0.16247287392616272, 0.1659693419933319, 0.1694658100605011, 0.1729622781276703, 0.17645874619483948, 0.17995524406433105, 0.18345171213150024, 0.18694818019866943, 0.19044464826583862]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 6.0, 11.0, 13.0, 67.0, 280.0, 9.0, 9.0, 14.0, 8.0, 11.0, 9.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.1094488650560379, -0.10581888258457184, -0.10218890011310577, -0.09855891764163971, -0.09492894262075424, -0.09129896014928818, -0.08766897767782211, -0.08403899520635605, -0.08040902018547058, -0.07677903771400452, -0.07314905524253845, -0.06951907277107239, -0.06588909029960632, -0.06225911155343056, -0.05862912908196449, -0.05499915033578873, -0.05136916786432266, -0.0477391853928566, -0.04410920292139053, -0.040479227900505066, -0.036849245429039, -0.03321926295757294, -0.029589280486106873, -0.025959298014640808, -0.022329315543174744, -0.018699340522289276, -0.015069358050823212, -0.011439375579357147, -0.007809393107891083, -0.004179410636425018, -0.0005494356155395508, 0.0030805468559265137, 0.006710529327392578, 0.010340511798858643, 0.013970494270324707, 0.01760047674179077, 0.021230459213256836, 0.0248604416847229, 0.02849040925502777, 0.032120391726493835, 0.0357503741979599, 0.039380356669425964, 0.04301033914089203, 0.04664032161235809, 0.05027030408382416, 0.05390028655529022, 0.05753026902675629, 0.06116025149822235, 0.06479023396968842, 0.06842020153999329, 0.07205018401145935, 0.07568016648292542, 0.07931014895439148, 0.08294013142585754, 0.08657011389732361, 0.09020009636878967, 0.09383007884025574, 0.0974600613117218, 0.10109004378318787, 0.10472001135349274, 0.1083499938249588, 0.11197997629642487, 0.11560995876789093, 0.119239941239357, 0.12286992371082306]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.20214945077896118, -0.19588255882263184, -0.18961568176746368, -0.18334878981113434, -0.177081897854805, -0.17081502079963684, -0.1645481288433075, -0.15828123688697815, -0.1520143449306488, -0.14574746787548065, -0.1394805759191513, -0.13321369886398315, -0.1269468069076538, -0.12067991495132446, -0.11441303044557571, -0.10814613848924637, -0.10187925398349762, -0.09561236947774887, -0.08934547752141953, -0.08307859301567078, -0.07681170105934143, -0.07054482400417328, -0.06427793204784393, -0.05801104009151459, -0.051744163036346436, -0.04547727108001709, -0.039210379123687744, -0.0329434871673584, -0.026676610112190247, -0.0204097181558609, -0.014142826199531555, -0.007875949144363403, -0.0016090571880340576, 0.004657834768295288, 0.01092471182346344, 0.017191603779792786, 0.02345849573612213, 0.029725372791290283, 0.03599226474761963, 0.042259156703948975, 0.04852604866027832, 0.054792940616607666, 0.061059802770614624, 0.06732669472694397, 0.07359358668327332, 0.07986047863960266, 0.086127370595932, 0.09239426255226135, 0.09866112470626831, 0.10492801666259766, 0.111194908618927, 0.11746180057525635, 0.1237286925315857, 0.12999558448791504, 0.13626247644424438, 0.14252933859825134, 0.1487962305545807, 0.15506312251091003, 0.16133001446723938, 0.16759690642356873, 0.17386379837989807, 0.18013066053390503, 0.18639755249023438, 0.19266444444656372, 0.19893133640289307]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 9.0, 9.0, 7.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11149724572896957, -0.10824351012706757, -0.10498977452516556, -0.10173603892326355, -0.09848230332136154, -0.09522856771945953, -0.09197483211755753, -0.08872109651565552, -0.08546736091375351, -0.0822136253118515, -0.0789598897099495, -0.07570615410804749, -0.07245241850614548, -0.06919868290424347, -0.06594494730234146, -0.06269121170043945, -0.059437476098537445, -0.05618374049663544, -0.05293000489473343, -0.04967626929283142, -0.04642253369092941, -0.043168798089027405, -0.0399150624871254, -0.03666132688522339, -0.03340759128332138, -0.030153855681419373, -0.026900120079517365, -0.023646384477615356, -0.02039264887571335, -0.01713891327381134, -0.013885177671909332, -0.010631442070007324, -0.007377706468105316, -0.004123970866203308, -0.0008702352643013, 0.002383500337600708, 0.005637235939502716, 0.008890971541404724, 0.012144707143306732, 0.015398450195789337, 0.01865217834711075, 0.02190590649843216, 0.025159649550914764, 0.02841339260339737, 0.03166712075471878, 0.03492084890604019, 0.0381745919585228, 0.0414283350110054, 0.04468206316232681, 0.047935791313648224, 0.05118953436613083, 0.054443277418613434, 0.057697005569934845, 0.060950733721256256, 0.06420447677373886, 0.06745821982622147, 0.07071194797754288, 0.07396567612886429, 0.0772194191813469, 0.0804731622338295, 0.08372689038515091, 0.08698061853647232, 0.09023436158895493, 0.09348810464143753, 0.09674183279275894]}, "_runtime": 19697.72562289238, "_timestamp": 1585617067.3584924, "_step": 498}
{"Episode reward": -80.28304990391835, "Episode length": 999, "Policy Loss": 0.011342099867761135, "Value Loss": 0.0017396449111402035, "_runtime": 19697.72562289238, "_timestamp": 1585617067.3584924, "_step": 499}
