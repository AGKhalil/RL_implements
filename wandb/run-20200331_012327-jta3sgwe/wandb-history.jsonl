{"Episode reward": 87.32975568372825, "Episode length": 331, "Policy Loss": 0.4609195291996002, "Value Loss": 31.017894744873047, "_runtime": 20445.28585743904, "_timestamp": 1585617814.918727, "_step": 0}
{"Episode reward": 78.73767865478764, "Episode length": 221, "Policy Loss": 0.32685479521751404, "Value Loss": 273.478515625, "_runtime": 20445.783632278442, "_timestamp": 1585617815.4165018, "_step": 1}
{"Episode reward": 68.8140955716433, "Episode length": 326, "Policy Loss": 7.531103134155273, "Value Loss": 49311.62109375, "_runtime": 20446.026660203934, "_timestamp": 1585617815.6595297, "_step": 2}
{"Episode reward": 86.93658982661503, "Episode length": 144, "Policy Loss": -235.7373046875, "Value Loss": 15929.57421875, "_runtime": 20446.49568939209, "_timestamp": 1585617816.1285589, "_step": 3}
{"Episode reward": 72.54743915243314, "Episode length": 310, "Policy Loss": -68.07282257080078, "Value Loss": 52147.0703125, "_runtime": 20447.915423631668, "_timestamp": 1585617817.548293, "_step": 4}
{"Episode reward": 17.080229005017344, "Episode length": 916, "Policy Loss": -25.647287368774414, "Value Loss": 4054.68701171875, "_runtime": 20449.44774413109, "_timestamp": 1585617819.0806136, "_step": 5}
{"Episode reward": -80.52639793713611, "Episode length": 999, "Policy Loss": -12.246292114257812, "Value Loss": 757.0374755859375, "_runtime": 20451.01234483719, "_timestamp": 1585617820.6452143, "_step": 6}
{"Episode reward": -42.70716561644854, "Episode length": 999, "Policy Loss": -1.7086564302444458, "Value Loss": 13.136978149414062, "_runtime": 20452.60212135315, "_timestamp": 1585617822.2349908, "_step": 7}
{"Episode reward": -99.74125967487883, "Episode length": 999, "Policy Loss": 0.38242459297180176, "Value Loss": 5.358822822570801, "_runtime": 20454.156522274017, "_timestamp": 1585617823.7893918, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 9.40999698638916, "Value Loss": 54.54410171508789, "_runtime": 20455.72253513336, "_timestamp": 1585617825.3554046, "_step": 9}
{"Episode reward": -98.8990763420425, "Episode length": 999, "Policy Loss": 5.100139141082764, "Value Loss": 63.848960876464844, "_runtime": 20457.32396006584, "_timestamp": 1585617826.9568295, "_step": 10}
{"Episode reward": -59.61412652221894, "Episode length": 999, "Policy Loss": 3.2382872104644775, "Value Loss": 60.177040100097656, "_runtime": 20458.89187169075, "_timestamp": 1585617828.5247412, "_step": 11}
{"Episode reward": -78.97960874557693, "Episode length": 999, "Policy Loss": -39.461822509765625, "Value Loss": 2141.419677734375, "_runtime": 20460.466243982315, "_timestamp": 1585617830.0991135, "_step": 12}
{"Episode reward": -75.50098983296988, "Episode length": 999, "Policy Loss": -16.209672927856445, "Value Loss": 329.96246337890625, "_runtime": 20462.0612885952, "_timestamp": 1585617831.694158, "_step": 13}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -10.152132034301758, "Value Loss": 77.33106231689453, "_runtime": 20463.647243261337, "_timestamp": 1585617833.2801127, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -62.10572052001953, "Value Loss": 3158.392333984375, "_runtime": 20465.223407506943, "_timestamp": 1585617834.856277, "_step": 15}
{"Episode reward": -98.752668150976, "Episode length": 999, "Policy Loss": -20.272199630737305, "Value Loss": 2759.517822265625, "_runtime": 20466.865881443024, "_timestamp": 1585617836.498751, "_step": 16}
{"Episode reward": -59.90355549912015, "Episode length": 999, "Policy Loss": 6.909268856048584, "Value Loss": 184.65234375, "_runtime": 20468.462025165558, "_timestamp": 1585617838.0948946, "_step": 17}
{"Episode reward": -85.76296317889384, "Episode length": 999, "Policy Loss": 2.628976583480835, "Value Loss": 807.2483520507812, "_runtime": 20470.054213523865, "_timestamp": 1585617839.687083, "_step": 18}
{"Episode reward": -93.43967842291822, "Episode length": 999, "Policy Loss": 14.001869201660156, "Value Loss": 188.13861083984375, "_runtime": 20471.651012659073, "_timestamp": 1585617841.2838821, "_step": 19}
{"Episode reward": -93.95432256298025, "Episode length": 999, "Policy Loss": 17.656173706054688, "Value Loss": 429.4318542480469, "_runtime": 20473.246080636978, "_timestamp": 1585617842.87895, "_step": 20}
{"Episode reward": -93.50816314171641, "Episode length": 999, "Policy Loss": 17.69320297241211, "Value Loss": 1119.3677978515625, "_runtime": 20474.83928179741, "_timestamp": 1585617844.4721513, "_step": 21}
{"Episode reward": -93.35175246416789, "Episode length": 999, "Policy Loss": -8.627070426940918, "Value Loss": 1266.86669921875, "_runtime": 20476.443256616592, "_timestamp": 1585617846.076126, "_step": 22}
{"Episode reward": -94.86063823572724, "Episode length": 999, "Policy Loss": -1.2159265279769897, "Value Loss": 1873.223876953125, "_runtime": 20478.03047800064, "_timestamp": 1585617847.6633475, "_step": 23}
{"Episode reward": -97.23658634678134, "Episode length": 999, "Policy Loss": 13.937356948852539, "Value Loss": 260.04986572265625, "_runtime": 20479.614595651627, "_timestamp": 1585617849.2474651, "_step": 24}
{"Episode reward": -97.60299469160702, "Episode length": 999, "Policy Loss": 20.447282791137695, "Value Loss": 380.8096008300781, "_runtime": 20481.213178157806, "_timestamp": 1585617850.8460476, "_step": 25}
{"Episode reward": -97.81937649794168, "Episode length": 999, "Policy Loss": 23.24056053161621, "Value Loss": 991.2455444335938, "_runtime": 20482.801028490067, "_timestamp": 1585617852.433898, "_step": 26}
{"Episode reward": -97.56207432900162, "Episode length": 999, "Policy Loss": 17.95299530029297, "Value Loss": 473.5992431640625, "_runtime": 20484.387020111084, "_timestamp": 1585617854.0198896, "_step": 27}
{"Episode reward": -96.96999962464493, "Episode length": 999, "Policy Loss": 14.948763847351074, "Value Loss": 61.04409408569336, "_runtime": 20485.995675325394, "_timestamp": 1585617855.6285448, "_step": 28}
{"Episode reward": -97.77783933812697, "Episode length": 999, "Policy Loss": 10.402005195617676, "Value Loss": 63.60211944580078, "_runtime": 20487.58612370491, "_timestamp": 1585617857.2189932, "_step": 29}
{"Episode reward": -96.04619706941503, "Episode length": 999, "Policy Loss": 21.68718719482422, "Value Loss": 476.73828125, "_runtime": 20489.176409721375, "_timestamp": 1585617858.8092792, "_step": 30}
{"Episode reward": -98.93515094319092, "Episode length": 999, "Policy Loss": 9.137736320495605, "Value Loss": 90.26473236083984, "_runtime": 20490.82063794136, "_timestamp": 1585617860.4535074, "_step": 31}
{"Episode reward": -97.5662981251107, "Episode length": 999, "Policy Loss": 19.14022445678711, "Value Loss": 203.77821350097656, "_runtime": 20492.40834093094, "_timestamp": 1585617862.0412104, "_step": 32}
{"Episode reward": -99.04263487487707, "Episode length": 999, "Policy Loss": 7.924326419830322, "Value Loss": 21.273279190063477, "_runtime": 20494.000299692154, "_timestamp": 1585617863.6331692, "_step": 33}
{"Episode reward": -99.28904869682931, "Episode length": 999, "Policy Loss": 6.8160295486450195, "Value Loss": 9.563538551330566, "_runtime": 20495.5943069458, "_timestamp": 1585617865.2271764, "_step": 34}
{"Episode reward": -97.88055691961164, "Episode length": 999, "Policy Loss": 7.195974826812744, "Value Loss": 48.45525360107422, "_runtime": 20497.18627333641, "_timestamp": 1585617866.8191428, "_step": 35}
{"Episode reward": -99.03169427903389, "Episode length": 999, "Policy Loss": 4.197746276855469, "Value Loss": 2.647364616394043, "_runtime": 20498.772288560867, "_timestamp": 1585617868.405158, "_step": 36}
{"Episode reward": -97.51450702075537, "Episode length": 999, "Policy Loss": 3.91291880607605, "Value Loss": 5.193397521972656, "_runtime": 20500.381965637207, "_timestamp": 1585617870.0148351, "_step": 37}
{"Episode reward": -99.12765376943692, "Episode length": 999, "Policy Loss": 2.0864109992980957, "Value Loss": 1.0489023923873901, "_runtime": 20501.974533319473, "_timestamp": 1585617871.6074028, "_step": 38}
{"Episode reward": -98.88141809908862, "Episode length": 999, "Policy Loss": 0.4393901228904724, "Value Loss": 4.597477912902832, "_runtime": 20503.574919462204, "_timestamp": 1585617873.207789, "_step": 39}
{"Episode reward": -98.81536281663878, "Episode length": 999, "Policy Loss": 0.06570638716220856, "Value Loss": 4.989537239074707, "_runtime": 20505.18202972412, "_timestamp": 1585617874.8148992, "_step": 40}
{"Episode reward": -99.16579792761776, "Episode length": 999, "Policy Loss": -0.7849350571632385, "Value Loss": 3.443679094314575, "_runtime": 20506.784489154816, "_timestamp": 1585617876.4173586, "_step": 41}
{"Episode reward": -99.22544171958536, "Episode length": 999, "Policy Loss": -2.1892926692962646, "Value Loss": 9.244498252868652, "_runtime": 20508.385400533676, "_timestamp": 1585617878.01827, "_step": 42}
{"Episode reward": -99.21815186858159, "Episode length": 999, "Policy Loss": -2.6726343631744385, "Value Loss": 4.206099987030029, "_runtime": 20509.991428136826, "_timestamp": 1585617879.6242976, "_step": 43}
{"Episode reward": -97.7991043607901, "Episode length": 999, "Policy Loss": -3.4814560413360596, "Value Loss": 18.089635848999023, "_runtime": 20510.646021842957, "_timestamp": 1585617880.2788913, "_step": 44}
{"Episode reward": 61.69117442623235, "Episode length": 388, "Policy Loss": -7.818213939666748, "Value Loss": 56.72978973388672, "_runtime": 20512.24696969986, "_timestamp": 1585617881.8798392, "_step": 45}
{"Episode reward": -98.72457049754115, "Episode length": 999, "Policy Loss": -8.554193496704102, "Value Loss": 53.71977615356445, "_runtime": 20513.882601737976, "_timestamp": 1585617883.5154712, "_step": 46}
{"Episode reward": -99.45807094109777, "Episode length": 999, "Policy Loss": -4.471148490905762, "Value Loss": 14.607577323913574, "_runtime": 20515.417942762375, "_timestamp": 1585617885.0508122, "_step": 47}
{"Episode reward": -99.41191666175735, "Episode length": 999, "Policy Loss": -5.151018142700195, "Value Loss": 9.983901977539062, "_runtime": 20516.141845464706, "_timestamp": 1585617885.774715, "_step": 48}
{"Episode reward": 56.772927000389274, "Episode length": 434, "Policy Loss": -4.8975372314453125, "Value Loss": 40.32029342651367, "_runtime": 20517.74117398262, "_timestamp": 1585617887.3740435, "_step": 49}
{"Episode reward": -99.53825731420521, "Episode length": 999, "Policy Loss": -5.837949275970459, "Value Loss": 4.481439113616943, "_runtime": 20519.327389478683, "_timestamp": 1585617888.960259, "_step": 50}
{"Episode reward": -99.66900699138648, "Episode length": 999, "Policy Loss": -6.013922691345215, "Value Loss": 20.6740665435791, "_runtime": 20520.85745549202, "_timestamp": 1585617890.490325, "_step": 51}
{"Episode reward": -99.63160789261319, "Episode length": 999, "Policy Loss": -6.254909992218018, "Value Loss": 9.366345405578613, "_runtime": 20522.454236745834, "_timestamp": 1585617892.0871062, "_step": 52}
{"Episode reward": -99.65969743660396, "Episode length": 999, "Policy Loss": -6.1052470207214355, "Value Loss": 4.827293872833252, "_runtime": 20524.04595398903, "_timestamp": 1585617893.6788235, "_step": 53}
{"Episode reward": -99.62325755650389, "Episode length": 999, "Policy Loss": -6.692725658416748, "Value Loss": 19.98016929626465, "_runtime": 20524.943681955338, "_timestamp": 1585617894.5765514, "_step": 54}
{"Episode reward": 44.587478604982095, "Episode length": 556, "Policy Loss": -5.59843635559082, "Value Loss": 39.63078308105469, "_runtime": 20525.605537176132, "_timestamp": 1585617895.2384067, "_step": 55}
{"Episode reward": 60.55418903615181, "Episode length": 395, "Policy Loss": -4.633333206176758, "Value Loss": 30.25000762939453, "_runtime": 20527.19937634468, "_timestamp": 1585617896.8322458, "_step": 56}
{"Episode reward": -99.49810805317692, "Episode length": 999, "Policy Loss": -6.281100749969482, "Value Loss": 13.479551315307617, "_runtime": 20528.753609657288, "_timestamp": 1585617898.3864791, "_step": 57}
{"Episode reward": -99.41257608753958, "Episode length": 999, "Policy Loss": -5.673216819763184, "Value Loss": 2.9757864475250244, "_runtime": 20529.4582760334, "_timestamp": 1585617899.0911455, "_step": 58}
{"Episode reward": 55.26407195553148, "Episode length": 448, "Policy Loss": -4.247686862945557, "Value Loss": 29.57259178161621, "_runtime": 20531.057042598724, "_timestamp": 1585617900.689912, "_step": 59}
{"Episode reward": -99.61591082106322, "Episode length": 999, "Policy Loss": -4.964824199676514, "Value Loss": 2.7369203567504883, "_runtime": 20532.325443267822, "_timestamp": 1585617901.9583127, "_step": 60}
{"Episode reward": 20.29681387087355, "Episode length": 798, "Policy Loss": -3.8382527828216553, "Value Loss": 13.301154136657715, "_runtime": 20533.406447649002, "_timestamp": 1585617903.0393171, "_step": 61}
{"Episode reward": 29.64452967697261, "Episode length": 705, "Policy Loss": -3.1805732250213623, "Value Loss": 15.672417640686035, "_runtime": 20534.158884763718, "_timestamp": 1585617903.7917542, "_step": 62}
{"Episode reward": 54.499999286955784, "Episode length": 456, "Policy Loss": -2.272706985473633, "Value Loss": 22.106935501098633, "_runtime": 20535.31786775589, "_timestamp": 1585617904.9507372, "_step": 63}
{"Episode reward": 26.735221612907367, "Episode length": 734, "Policy Loss": -2.9871904850006104, "Value Loss": 15.5574312210083, "_runtime": 20536.873757600784, "_timestamp": 1585617906.506627, "_step": 64}
{"Episode reward": -99.40389958671739, "Episode length": 999, "Policy Loss": -3.7177445888519287, "Value Loss": 1.0426254272460938, "_runtime": 20538.448918819427, "_timestamp": 1585617908.0817883, "_step": 65}
{"Episode reward": -99.73247161046463, "Episode length": 999, "Policy Loss": -3.557694673538208, "Value Loss": 0.5219667553901672, "_runtime": 20540.01659154892, "_timestamp": 1585617909.649461, "_step": 66}
{"Episode reward": -99.62416437417713, "Episode length": 999, "Policy Loss": -3.249994993209839, "Value Loss": 2.4421491622924805, "_runtime": 20540.932935476303, "_timestamp": 1585617910.565805, "_step": 67}
{"Episode reward": 43.35391961056104, "Episode length": 567, "Policy Loss": -1.9577997922897339, "Value Loss": 25.235567092895508, "_runtime": 20542.511548280716, "_timestamp": 1585617912.1444178, "_step": 68}
{"Episode reward": -99.44714186557546, "Episode length": 999, "Policy Loss": -3.2103216648101807, "Value Loss": 0.6150645017623901, "_runtime": 20544.09503722191, "_timestamp": 1585617913.7279067, "_step": 69}
{"Episode reward": -99.80760039678286, "Episode length": 999, "Policy Loss": -3.080087423324585, "Value Loss": 1.031191349029541, "_runtime": 20544.708943605423, "_timestamp": 1585617914.341813, "_step": 70}
{"Episode reward": 61.64359883656699, "Episode length": 384, "Policy Loss": -1.481838345527649, "Value Loss": 28.492103576660156, "_runtime": 20545.44323015213, "_timestamp": 1585617915.0760996, "_step": 71}
{"Episode reward": 54.46071349258963, "Episode length": 457, "Policy Loss": -1.70765221118927, "Value Loss": 24.857894897460938, "_runtime": 20547.028621435165, "_timestamp": 1585617916.661491, "_step": 72}
{"Episode reward": -99.80149907022574, "Episode length": 999, "Policy Loss": -3.089974880218506, "Value Loss": 0.5420168042182922, "_runtime": 20548.557538986206, "_timestamp": 1585617918.1904085, "_step": 73}
{"Episode reward": -99.80544534644437, "Episode length": 999, "Policy Loss": -3.15533709526062, "Value Loss": 0.6039074063301086, "_runtime": 20549.749943256378, "_timestamp": 1585617919.3828127, "_step": 74}
{"Episode reward": 22.532149321935265, "Episode length": 776, "Policy Loss": -2.4398837089538574, "Value Loss": 14.177702903747559, "_runtime": 20551.324578523636, "_timestamp": 1585617920.957448, "_step": 75}
{"Episode reward": -99.7289317045929, "Episode length": 999, "Policy Loss": -3.304013967514038, "Value Loss": 0.7553505897521973, "_runtime": 20552.89049911499, "_timestamp": 1585617922.5233686, "_step": 76}
{"Episode reward": -99.51601869244922, "Episode length": 999, "Policy Loss": -3.363036870956421, "Value Loss": 1.865122675895691, "_runtime": 20553.62592458725, "_timestamp": 1585617923.258794, "_step": 77}
{"Episode reward": 54.31182893260229, "Episode length": 459, "Policy Loss": -1.4956954717636108, "Value Loss": 23.01464080810547, "_runtime": 20555.222886800766, "_timestamp": 1585617924.8557563, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.3284566402435303, "Value Loss": 1.3462005853652954, "_runtime": 20556.77460050583, "_timestamp": 1585617926.40747, "_step": 79}
{"Episode reward": 1.8949249761832476, "Episode length": 982, "Policy Loss": -2.7870683670043945, "Value Loss": 12.232263565063477, "_runtime": 20557.658876657486, "_timestamp": 1585617927.2917461, "_step": 80}
{"Episode reward": 43.39408563962154, "Episode length": 567, "Policy Loss": -2.1558101177215576, "Value Loss": 18.99681282043457, "_runtime": 20559.235509872437, "_timestamp": 1585617928.8683794, "_step": 81}
{"Episode reward": -99.69226453848977, "Episode length": 999, "Policy Loss": -3.179231643676758, "Value Loss": 0.3648132085800171, "_runtime": 20560.80799651146, "_timestamp": 1585617930.440866, "_step": 82}
{"Episode reward": -99.53373280232634, "Episode length": 999, "Policy Loss": -3.167569637298584, "Value Loss": 0.5882075428962708, "_runtime": 20562.389610528946, "_timestamp": 1585617932.02248, "_step": 83}
{"Episode reward": -99.75088013068168, "Episode length": 999, "Policy Loss": -3.073464870452881, "Value Loss": 0.2761687934398651, "_runtime": 20563.97980928421, "_timestamp": 1585617933.6126788, "_step": 84}
{"Episode reward": -99.49218173576382, "Episode length": 999, "Policy Loss": -3.021474838256836, "Value Loss": 0.4422801733016968, "_runtime": 20565.16196346283, "_timestamp": 1585617934.794833, "_step": 85}
{"Episode reward": 26.58223946520583, "Episode length": 735, "Policy Loss": -2.0785555839538574, "Value Loss": 14.745343208312988, "_runtime": 20566.746388673782, "_timestamp": 1585617936.3792582, "_step": 86}
{"Episode reward": -99.70666651732614, "Episode length": 999, "Policy Loss": -2.880312919616699, "Value Loss": 0.24249207973480225, "_runtime": 20567.7728805542, "_timestamp": 1585617937.40575, "_step": 87}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": -1.6145994663238525, "Value Loss": 16.824119567871094, "_runtime": 20568.907096624374, "_timestamp": 1585617938.539966, "_step": 88}
{"Episode reward": 28.251840601861275, "Episode length": 718, "Policy Loss": -1.8680472373962402, "Value Loss": 15.058377265930176, "_runtime": 20570.491314888, "_timestamp": 1585617940.1241844, "_step": 89}
{"Episode reward": -99.46279847461126, "Episode length": 999, "Policy Loss": -2.7826528549194336, "Value Loss": 0.23049066960811615, "_runtime": 20572.047584295273, "_timestamp": 1585617941.6804538, "_step": 90}
{"Episode reward": -99.29599144624527, "Episode length": 999, "Policy Loss": -2.7872233390808105, "Value Loss": 0.2753060758113861, "_runtime": 20573.607393980026, "_timestamp": 1585617943.2402635, "_step": 91}
{"Episode reward": -99.50532916048986, "Episode length": 999, "Policy Loss": -2.7472896575927734, "Value Loss": 0.351540207862854, "_runtime": 20574.95863342285, "_timestamp": 1585617944.591503, "_step": 92}
{"Episode reward": 14.771871297690652, "Episode length": 854, "Policy Loss": -1.9510507583618164, "Value Loss": 12.792147636413574, "_runtime": 20576.165379047394, "_timestamp": 1585617945.7982485, "_step": 93}
{"Episode reward": 23.800000000000054, "Episode length": 762, "Policy Loss": -1.9180694818496704, "Value Loss": 13.716471672058105, "_runtime": 20577.747670173645, "_timestamp": 1585617947.3805397, "_step": 94}
{"Episode reward": -99.59581991247694, "Episode length": 999, "Policy Loss": -2.7475900650024414, "Value Loss": 0.201743945479393, "_runtime": 20579.32807636261, "_timestamp": 1585617948.9609458, "_step": 95}
{"Episode reward": -99.77257040743577, "Episode length": 999, "Policy Loss": -2.7800424098968506, "Value Loss": 0.20046347379684448, "_runtime": 20579.834616422653, "_timestamp": 1585617949.467486, "_step": 96}
{"Episode reward": 70.48827886374187, "Episode length": 296, "Policy Loss": -0.5316755175590515, "Value Loss": 34.31597900390625, "_runtime": 20580.878662109375, "_timestamp": 1585617950.5115316, "_step": 97}
{"Episode reward": 34.868945751361906, "Episode length": 655, "Policy Loss": -1.822570562362671, "Value Loss": 15.889564514160156, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683, -0.11251533776521683]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 9.0], "bins": [-3.988821506500244, -3.9247381687164307, -3.860654830932617, -3.7965712547302246, -3.732487916946411, -3.6684045791625977, -3.604321241378784, -3.5402379035949707, -3.476154327392578, -3.4120709896087646, -3.347987651824951, -3.2839040756225586, -3.219820976257324, -3.1557374000549316, -3.091654062271118, -3.0275707244873047, -2.963487148284912, -2.8994040489196777, -2.835320472717285, -2.7712371349334717, -2.707153797149658, -2.6430702209472656, -2.578986883163452, -2.5149035453796387, -2.450820207595825, -2.3867368698120117, -2.322653293609619, -2.2585699558258057, -2.194486618041992, -2.1304030418395996, -2.0663199424743652, -2.0022363662719727, -1.9381530284881592, -1.8740696907043457, -1.8099863529205322, -1.7459027767181396, -1.6818194389343262, -1.6177361011505127, -1.5536527633666992, -1.4895691871643066, -1.4254858493804932, -1.3614025115966797, -1.2973191738128662, -1.2332358360290527, -1.1691522598266602, -1.1050689220428467, -1.0409855842590332, -0.9769022464752197, -0.9128189086914062, -0.8487353324890137, -0.7846519947052002, -0.7205686569213867, -0.6564853191375732, -0.5924017429351807, -0.5283184051513672, -0.4642350673675537, -0.40015172958374023, -0.33606839179992676, -0.2719848155975342, -0.2079014778137207, -0.14381814002990723, -0.07973480224609375, -0.015651226043701172, 0.0484318733215332, 0.11251544952392578]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.13315489888191223, -0.13107435405254364, -0.12899380922317505, -0.12691326439380646, -0.12483271956443787, -0.12275217473506927, -0.12067162990570068, -0.11859108507633209, -0.1165105402469635, -0.11442999541759491, -0.11234945058822632, -0.11026889830827713, -0.10818835347890854, -0.10610780864953995, -0.10402726382017136, -0.10194671899080276, -0.09986617416143417, -0.09778562933206558, -0.09570508450269699, -0.0936245396733284, -0.09154399484395981, -0.08946344256401062, -0.08738289773464203, -0.08530235290527344, -0.08322180807590485, -0.08114126324653625, -0.07906071841716766, -0.07698017358779907, -0.07489962875843048, -0.07281908392906189, -0.0707385390996933, -0.06865799427032471, -0.06657744944095612, -0.06449690461158752, -0.06241635978221893, -0.06033581495285034, -0.05825527012348175, -0.05617472529411316, -0.05409418046474457, -0.05201363563537598, -0.049933090806007385, -0.0478525385260582, -0.045771993696689606, -0.043691448867321014, -0.04161090403795242, -0.03953035920858383, -0.03744981437921524, -0.03536926954984665, -0.03328872472047806, -0.031208179891109467, -0.029127635061740875, -0.027047090232372284, -0.024966545403003693, -0.0228860005736351, -0.02080545574426651, -0.01872491091489792, -0.01664435863494873, -0.01456381380558014, -0.012483268976211548, -0.010402724146842957, -0.008322179317474365, -0.006241634488105774, -0.004161089658737183, -0.0020805448293685913, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 3.0, 1.0, 2.0, 7.0, 271.0, 22.0, 15.0, 9.0, 7.0, 11.0, 11.0, 6.0, 10.0, 5.0, 12.0, 6.0, 9.0, 15.0, 4.0, 6.0, 6.0, 9.0, 6.0, 3.0], "bins": [-0.2719860076904297, -0.2659258246421814, -0.2598656415939331, -0.2538054585456848, -0.24774529039859772, -0.24168510735034943, -0.23562493920326233, -0.22956475615501404, -0.22350457310676575, -0.21744439005851746, -0.21138422191143036, -0.20532403886318207, -0.19926387071609497, -0.19320368766784668, -0.1871435046195984, -0.1810833215713501, -0.1750231385231018, -0.1689629703760147, -0.16290278732776642, -0.15684261918067932, -0.15078243613243103, -0.14472225308418274, -0.13866207003593445, -0.13260188698768616, -0.12654171884059906, -0.12048153579235077, -0.11442135274410248, -0.10836118459701538, -0.10230100154876709, -0.0962408185005188, -0.09018063545227051, -0.08412046730518341, -0.07806028425693512, -0.07200010120868683, -0.06593993306159973, -0.05987975001335144, -0.05381956696510315, -0.04775938391685486, -0.04169921576976776, -0.03563903272151947, -0.02957884967327118, -0.023518681526184082, -0.01745849847793579, -0.0113983154296875, -0.005338132381439209, 0.000722050666809082, 0.006782233715057373, 0.012842386960983276, 0.018902570009231567, 0.02496275305747986, 0.03102293610572815, 0.03708311915397644, 0.04314330220222473, 0.04920348525047302, 0.055263638496398926, 0.06132382154464722, 0.06738400459289551, 0.0734441876411438, 0.07950437068939209, 0.08556455373764038, 0.09162473678588867, 0.09768489003181458, 0.10374507308006287, 0.10980525612831116, 0.11586543917655945]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0], "bins": [-0.930510401725769, -0.9106535911560059, -0.8907967209815979, -0.8709399104118347, -0.8510830998420715, -0.8312262892723083, -0.8113694190979004, -0.7915126085281372, -0.771655797958374, -0.7517989873886108, -0.7319421172142029, -0.7120853066444397, -0.6922284364700317, -0.6723716259002686, -0.6525148153305054, -0.6326580047607422, -0.612801194190979, -0.592944324016571, -0.5730875134468079, -0.5532306432723999, -0.5333738327026367, -0.5135170221328735, -0.49366021156311035, -0.4738033711910248, -0.4539465308189392, -0.434089720249176, -0.41423290967941284, -0.3943760395050049, -0.3745192289352417, -0.3546624183654785, -0.33480560779571533, -0.3149487376213074, -0.2950919270515442, -0.275235116481781, -0.25537824630737305, -0.23552143573760986, -0.21566462516784668, -0.1958078145980835, -0.17595094442367554, -0.15609413385391235, -0.13623732328414917, -0.11638045310974121, -0.09652364253997803, -0.07666683197021484, -0.05681002140045166, -0.0369531512260437, -0.017096340656280518, 0.002760469913482666, 0.022617340087890625, 0.04247415065765381, 0.06233096122741699, 0.08218777179718018, 0.10204458236694336, 0.12190139293670654, 0.14175832271575928, 0.16161513328552246, 0.18147194385528564, 0.20132875442504883, 0.221185564994812, 0.2410423755645752, 0.2608991861343384, 0.2807561159133911, 0.3006129264831543, 0.3204697370529175, 0.34032654762268066]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 9.0, 5.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.14037372171878815, -0.13094456493854523, -0.12151540815830231, -0.11208624392747879, -0.10265708714723587, -0.09322793036699295, -0.08379876613616943, -0.07436960935592651, -0.0649404525756836, -0.055511295795440674, -0.046082139015197754, -0.03665297478437424, -0.027223818004131317, -0.017794661223888397, -0.00836549699306488, 0.0010636597871780396, 0.01049281656742096, 0.01992197334766388, 0.0293511301279068, 0.03878028690814972, 0.04820944368839264, 0.05763861536979675, 0.06706777215003967, 0.07649692893028259, 0.08592608571052551, 0.09535524249076843, 0.10478439927101135, 0.11421357095241547, 0.12364272773265839, 0.1330718845129013, 0.14250104129314423, 0.15193019807338715, 0.16135935485363007, 0.17078851163387299, 0.1802176684141159, 0.18964682519435883, 0.19907598197460175, 0.20850513875484467, 0.21793429553508759, 0.2273634523153305, 0.23679260909557343, 0.24622179567813873, 0.25565093755722046, 0.2650800943374634, 0.2745092511177063, 0.2839384078979492, 0.29336756467819214, 0.30279672145843506, 0.312225878238678, 0.3216550350189209, 0.3310841917991638, 0.34051334857940674, 0.34994250535964966, 0.3593716621398926, 0.3688008785247803, 0.3782300353050232, 0.3876591920852661, 0.39708834886550903, 0.40651750564575195, 0.4159466624259949, 0.4253758192062378, 0.4348049759864807, 0.44423413276672363, 0.45366328954696655, 0.4630924463272095]}, "_runtime": 20582.46496272087, "_timestamp": 1585617952.0978322, "_step": 98}
{"Episode reward": -99.80627870543255, "Episode length": 999, "Policy Loss": -2.8081836700439453, "Value Loss": 0.2134464979171753, "_runtime": 20583.20823740959, "_timestamp": 1585617952.841107, "_step": 99}
{"Episode reward": 52.17765911344864, "Episode length": 480, "Policy Loss": -1.1059821844100952, "Value Loss": 21.419811248779297, "_runtime": 20584.495817899704, "_timestamp": 1585617954.1286874, "_step": 100}
{"Episode reward": 16.703225830750753, "Episode length": 835, "Policy Loss": -2.1520726680755615, "Value Loss": 12.857544898986816, "_runtime": 20586.11517906189, "_timestamp": 1585617955.7480485, "_step": 101}
{"Episode reward": -99.64825659738715, "Episode length": 999, "Policy Loss": -2.8887717723846436, "Value Loss": 0.21642650663852692, "_runtime": 20587.6461956501, "_timestamp": 1585617957.2790651, "_step": 102}
{"Episode reward": -99.74826447684178, "Episode length": 999, "Policy Loss": -2.918182373046875, "Value Loss": 0.2209736406803131, "_runtime": 20589.221114873886, "_timestamp": 1585617958.8539844, "_step": 103}
{"Episode reward": -99.66253903338082, "Episode length": 999, "Policy Loss": -2.92698073387146, "Value Loss": 0.5413194894790649, "_runtime": 20590.08544921875, "_timestamp": 1585617959.7183187, "_step": 104}
{"Episode reward": 47.1508594314563, "Episode length": 529, "Policy Loss": -1.7930840253829956, "Value Loss": 19.044151306152344, "_runtime": 20590.892636299133, "_timestamp": 1585617960.5255058, "_step": 105}
{"Episode reward": 50.19875869213095, "Episode length": 502, "Policy Loss": -1.4637553691864014, "Value Loss": 20.187326431274414, "_runtime": 20592.468656778336, "_timestamp": 1585617962.1015263, "_step": 106}
{"Episode reward": -99.1655439059935, "Episode length": 999, "Policy Loss": -2.912482261657715, "Value Loss": 0.32971569895744324, "_runtime": 20593.972146749496, "_timestamp": 1585617963.6050162, "_step": 107}
{"Episode reward": 3.239720436902772, "Episode length": 969, "Policy Loss": -2.129443883895874, "Value Loss": 10.660141944885254, "_runtime": 20594.731558561325, "_timestamp": 1585617964.364428, "_step": 108}
{"Episode reward": 52.05016582449858, "Episode length": 481, "Policy Loss": -1.1856197118759155, "Value Loss": 21.155405044555664, "_runtime": 20596.308521270752, "_timestamp": 1585617965.9413908, "_step": 109}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.8271865844726562, "Value Loss": 0.25541919469833374, "_runtime": 20597.429284334183, "_timestamp": 1585617967.0621538, "_step": 110}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": -1.9010587930679321, "Value Loss": 14.456913948059082, "_runtime": 20598.01403617859, "_timestamp": 1585617967.6469057, "_step": 111}
{"Episode reward": 63.29432511292374, "Episode length": 368, "Policy Loss": -1.1889410018920898, "Value Loss": 26.91307258605957, "_runtime": 20598.54583978653, "_timestamp": 1585617968.1787093, "_step": 112}
{"Episode reward": 68.0882213290779, "Episode length": 320, "Policy Loss": -0.5997059345245361, "Value Loss": 31.13057518005371, "_runtime": 20599.66585636139, "_timestamp": 1585617969.2987258, "_step": 113}
{"Episode reward": 27.872550177573984, "Episode length": 722, "Policy Loss": -1.9222161769866943, "Value Loss": 13.982206344604492, "_runtime": 20601.177479743958, "_timestamp": 1585617970.8103492, "_step": 114}
{"Episode reward": 1.9344071581972742, "Episode length": 985, "Policy Loss": -2.1281919479370117, "Value Loss": 10.629572868347168, "_runtime": 20602.684584379196, "_timestamp": 1585617972.3174539, "_step": 115}
{"Episode reward": -99.7345265329918, "Episode length": 999, "Policy Loss": -2.720426559448242, "Value Loss": 0.6193143725395203, "_runtime": 20603.478350162506, "_timestamp": 1585617973.1112196, "_step": 116}
{"Episode reward": 50.62446656557689, "Episode length": 495, "Policy Loss": -1.54961097240448, "Value Loss": 20.318157196044922, "_runtime": 20604.232053041458, "_timestamp": 1585617973.8649225, "_step": 117}
{"Episode reward": 53.599356303270525, "Episode length": 465, "Policy Loss": -1.4004672765731812, "Value Loss": 21.83820343017578, "_runtime": 20605.79938030243, "_timestamp": 1585617975.4322498, "_step": 118}
{"Episode reward": -99.55945037364006, "Episode length": 999, "Policy Loss": -2.725602388381958, "Value Loss": 0.2516867220401764, "_runtime": 20607.32968235016, "_timestamp": 1585617976.9625518, "_step": 119}
{"Episode reward": -99.58271864573334, "Episode length": 999, "Policy Loss": -2.738018751144409, "Value Loss": 0.2698851525783539, "_runtime": 20608.86758875847, "_timestamp": 1585617978.5004582, "_step": 120}
{"Episode reward": -99.44505703202312, "Episode length": 999, "Policy Loss": -2.749124050140381, "Value Loss": 0.2816128730773926, "_runtime": 20609.646065711975, "_timestamp": 1585617979.2789352, "_step": 121}
{"Episode reward": 55.350177299341524, "Episode length": 449, "Policy Loss": -1.4298664331436157, "Value Loss": 22.104978561401367, "_runtime": 20611.229438066483, "_timestamp": 1585617980.8623075, "_step": 122}
{"Episode reward": -99.64827647821373, "Episode length": 999, "Policy Loss": -2.7088069915771484, "Value Loss": 0.24475327134132385, "_runtime": 20611.821612358093, "_timestamp": 1585617981.4544818, "_step": 123}
{"Episode reward": 64.24826516741282, "Episode length": 360, "Policy Loss": -1.0774669647216797, "Value Loss": 27.823652267456055, "_runtime": 20612.589888572693, "_timestamp": 1585617982.222758, "_step": 124}
{"Episode reward": 50.09326565188778, "Episode length": 500, "Policy Loss": -1.4021644592285156, "Value Loss": 20.149253845214844, "_runtime": 20613.69558596611, "_timestamp": 1585617983.3284554, "_step": 125}
{"Episode reward": 30.838327804620732, "Episode length": 692, "Policy Loss": -1.7251564264297485, "Value Loss": 14.737678527832031, "_runtime": 20615.221704006195, "_timestamp": 1585617984.8545735, "_step": 126}
{"Episode reward": -99.67676346207018, "Episode length": 999, "Policy Loss": -2.6061947345733643, "Value Loss": 0.5291227102279663, "_runtime": 20616.74784064293, "_timestamp": 1585617986.3807101, "_step": 127}
{"Episode reward": -99.80000529757095, "Episode length": 999, "Policy Loss": -2.5604543685913086, "Value Loss": 0.31487393379211426, "_runtime": 20617.72370481491, "_timestamp": 1585617987.3565743, "_step": 128}
{"Episode reward": 37.72056157428245, "Episode length": 624, "Policy Loss": -1.5743132829666138, "Value Loss": 16.064882278442383, "_runtime": 20619.298305749893, "_timestamp": 1585617988.9311752, "_step": 129}
{"Episode reward": -99.784588130306, "Episode length": 999, "Policy Loss": -2.4473907947540283, "Value Loss": 0.2622259855270386, "_runtime": 20620.879878759384, "_timestamp": 1585617990.5127482, "_step": 130}
{"Episode reward": -99.80215628906596, "Episode length": 999, "Policy Loss": -2.4455738067626953, "Value Loss": 0.2812069058418274, "_runtime": 20622.432737112045, "_timestamp": 1585617992.0656066, "_step": 131}
{"Episode reward": -99.66781613572827, "Episode length": 999, "Policy Loss": -2.343299150466919, "Value Loss": 0.3142983317375183, "_runtime": 20624.016747951508, "_timestamp": 1585617993.6496174, "_step": 132}
{"Episode reward": -99.33829463346493, "Episode length": 999, "Policy Loss": -2.301053762435913, "Value Loss": 0.4297368824481964, "_runtime": 20625.60244369507, "_timestamp": 1585617995.2353132, "_step": 133}
{"Episode reward": -99.64074915514657, "Episode length": 999, "Policy Loss": -2.2227723598480225, "Value Loss": 0.3563157618045807, "_runtime": 20626.769568920135, "_timestamp": 1585617996.4024384, "_step": 134}
{"Episode reward": 27.60096097791086, "Episode length": 727, "Policy Loss": -1.415964961051941, "Value Loss": 13.942243576049805, "_runtime": 20627.945552110672, "_timestamp": 1585617997.5784216, "_step": 135}
{"Episode reward": 26.291746617271485, "Episode length": 738, "Policy Loss": -1.2063179016113281, "Value Loss": 13.742962837219238, "_runtime": 20629.52496933937, "_timestamp": 1585617999.1578388, "_step": 136}
{"Episode reward": -99.77784194499115, "Episode length": 999, "Policy Loss": -2.176309823989868, "Value Loss": 0.14463385939598083, "_runtime": 20630.770359754562, "_timestamp": 1585618000.4032292, "_step": 137}
{"Episode reward": 21.29833871123867, "Episode length": 788, "Policy Loss": -1.4021612405776978, "Value Loss": 12.763656616210938, "_runtime": 20632.327247858047, "_timestamp": 1585618001.9601173, "_step": 138}
{"Episode reward": -99.69897270039516, "Episode length": 999, "Policy Loss": -2.071863889694214, "Value Loss": 0.18425391614437103, "_runtime": 20633.9582529068, "_timestamp": 1585618003.5911224, "_step": 139}
{"Episode reward": -99.68139706570516, "Episode length": 999, "Policy Loss": -2.052750587463379, "Value Loss": 0.12803104519844055, "_runtime": 20634.867926836014, "_timestamp": 1585618004.5007963, "_step": 140}
{"Episode reward": 43.309932741685245, "Episode length": 568, "Policy Loss": -0.983907163143158, "Value Loss": 17.630979537963867, "_runtime": 20636.454941272736, "_timestamp": 1585618006.0878108, "_step": 141}
{"Episode reward": -99.76638295855815, "Episode length": 999, "Policy Loss": -2.026348352432251, "Value Loss": 0.1287003457546234, "_runtime": 20638.048992872238, "_timestamp": 1585618007.6818624, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9952234029769897, "Value Loss": 0.15731260180473328, "_runtime": 20638.99248790741, "_timestamp": 1585618008.6253574, "_step": 143}
{"Episode reward": 39.40837064038438, "Episode length": 607, "Policy Loss": -0.9604911208152771, "Value Loss": 16.366130828857422, "_runtime": 20640.316470623016, "_timestamp": 1585618009.94934, "_step": 144}
{"Episode reward": 16.600245372648814, "Episode length": 835, "Policy Loss": -1.2161365747451782, "Value Loss": 12.158011436462402, "_runtime": 20641.261695623398, "_timestamp": 1585618010.894565, "_step": 145}
{"Episode reward": 41.70421050512177, "Episode length": 586, "Policy Loss": -0.8522548079490662, "Value Loss": 17.024076461791992, "_runtime": 20642.824399232864, "_timestamp": 1585618012.4572687, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8758882284164429, "Value Loss": 0.09999570995569229, "_runtime": 20644.39281320572, "_timestamp": 1585618014.0256827, "_step": 147}
{"Episode reward": -99.4977777738867, "Episode length": 999, "Policy Loss": -1.8418647050857544, "Value Loss": 0.18925055861473083, "_runtime": 20645.941610336304, "_timestamp": 1585618015.5744798, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8282904624938965, "Value Loss": 0.20898555219173431, "_runtime": 20647.537918567657, "_timestamp": 1585618017.170788, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7885931730270386, "Value Loss": 0.09588946402072906, "_runtime": 20649.123426675797, "_timestamp": 1585618018.7562962, "_step": 150}
{"Episode reward": -99.38377216847012, "Episode length": 999, "Policy Loss": -1.7275762557983398, "Value Loss": 0.11010387539863586, "_runtime": 20650.7023832798, "_timestamp": 1585618020.3352528, "_step": 151}
{"Episode reward": -99.44156810660358, "Episode length": 999, "Policy Loss": -1.6879236698150635, "Value Loss": 0.10901708155870438, "_runtime": 20652.2946498394, "_timestamp": 1585618021.9275193, "_step": 152}
{"Episode reward": -99.49923222106746, "Episode length": 999, "Policy Loss": -1.6659053564071655, "Value Loss": 0.08217456191778183, "_runtime": 20653.882706165314, "_timestamp": 1585618023.5155756, "_step": 153}
{"Episode reward": -99.68889697005369, "Episode length": 999, "Policy Loss": -1.6235194206237793, "Value Loss": 0.08113960921764374, "_runtime": 20655.4654815197, "_timestamp": 1585618025.098351, "_step": 154}
{"Episode reward": -99.64729172442901, "Episode length": 999, "Policy Loss": -1.5998809337615967, "Value Loss": 0.09685706347227097, "_runtime": 20657.10571718216, "_timestamp": 1585618026.7385867, "_step": 155}
{"Episode reward": -99.86256574401492, "Episode length": 999, "Policy Loss": -1.5740524530410767, "Value Loss": 0.13985797762870789, "_runtime": 20658.307968854904, "_timestamp": 1585618027.9408383, "_step": 156}
{"Episode reward": 25.63176908465097, "Episode length": 746, "Policy Loss": -0.7739376425743103, "Value Loss": 13.590697288513184, "_runtime": 20659.899406194687, "_timestamp": 1585618029.5322757, "_step": 157}
{"Episode reward": -99.6753571540569, "Episode length": 999, "Policy Loss": -1.5296748876571655, "Value Loss": 0.15654624998569489, "_runtime": 20660.970022439957, "_timestamp": 1585618030.602892, "_step": 158}
{"Episode reward": 33.83766805002763, "Episode length": 665, "Policy Loss": -0.5632151961326599, "Value Loss": 15.305301666259766, "_runtime": 20661.724300146103, "_timestamp": 1585618031.3571696, "_step": 159}
{"Episode reward": 53.39918179016056, "Episode length": 467, "Policy Loss": -0.19653207063674927, "Value Loss": 21.621623992919922, "_runtime": 20663.314883232117, "_timestamp": 1585618032.9477527, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5155704021453857, "Value Loss": 0.16573257744312286, "_runtime": 20664.88146877289, "_timestamp": 1585618034.5143383, "_step": 161}
{"Episode reward": -99.72195166689204, "Episode length": 999, "Policy Loss": -1.4961163997650146, "Value Loss": 0.060550253838300705, "_runtime": 20666.425480127335, "_timestamp": 1585618036.0583496, "_step": 162}
{"Episode reward": -99.7119099617689, "Episode length": 999, "Policy Loss": -1.5047218799591064, "Value Loss": 0.10031305253505707, "_runtime": 20668.00202870369, "_timestamp": 1585618037.6348982, "_step": 163}
{"Episode reward": -99.77252821959999, "Episode length": 999, "Policy Loss": -1.5073779821395874, "Value Loss": 0.07416605949401855, "_runtime": 20669.596946954727, "_timestamp": 1585618039.2298164, "_step": 164}
{"Episode reward": -99.70404963197514, "Episode length": 999, "Policy Loss": -1.4784934520721436, "Value Loss": 0.11532804369926453, "_runtime": 20670.715614557266, "_timestamp": 1585618040.348484, "_step": 165}
{"Episode reward": 29.899999999999707, "Episode length": 701, "Policy Loss": -0.5631700158119202, "Value Loss": 14.251352310180664, "_runtime": 20672.108804941177, "_timestamp": 1585618041.7416744, "_step": 166}
{"Episode reward": 12.419491987466571, "Episode length": 876, "Policy Loss": -0.7890437841415405, "Value Loss": 11.493980407714844, "_runtime": 20673.059310913086, "_timestamp": 1585618042.6921804, "_step": 167}
{"Episode reward": 40.699999999999434, "Episode length": 593, "Policy Loss": -0.44263070821762085, "Value Loss": 16.998409271240234, "_runtime": 20674.164053440094, "_timestamp": 1585618043.796923, "_step": 168}
{"Episode reward": 30.083014769124247, "Episode length": 702, "Policy Loss": -0.6038843393325806, "Value Loss": 14.265158653259277, "_runtime": 20675.73597884178, "_timestamp": 1585618045.3688483, "_step": 169}
{"Episode reward": -99.70086259776586, "Episode length": 999, "Policy Loss": -1.468521237373352, "Value Loss": 0.16581715643405914, "_runtime": 20677.24344778061, "_timestamp": 1585618046.8763173, "_step": 170}
{"Episode reward": 3.2780309639417737, "Episode length": 968, "Policy Loss": -0.8399978280067444, "Value Loss": 10.435111045837402, "_runtime": 20678.785937547684, "_timestamp": 1585618048.418807, "_step": 171}
{"Episode reward": -99.59225455698186, "Episode length": 999, "Policy Loss": -1.47519850730896, "Value Loss": 0.24208956956863403, "_runtime": 20679.62955069542, "_timestamp": 1585618049.2624202, "_step": 172}
{"Episode reward": 47.17180548373097, "Episode length": 531, "Policy Loss": -0.2886742949485779, "Value Loss": 18.801475524902344, "_runtime": 20681.24914240837, "_timestamp": 1585618050.882012, "_step": 173}
{"Episode reward": -99.64310311612068, "Episode length": 999, "Policy Loss": -1.4018058776855469, "Value Loss": 0.09330616146326065, "_runtime": 20682.833322286606, "_timestamp": 1585618052.4661918, "_step": 174}
{"Episode reward": -99.4857780107516, "Episode length": 999, "Policy Loss": -1.3988063335418701, "Value Loss": 0.06271100789308548, "_runtime": 20684.35578560829, "_timestamp": 1585618053.988655, "_step": 175}
{"Episode reward": -99.7115866248482, "Episode length": 999, "Policy Loss": -1.3721626996994019, "Value Loss": 0.0814143568277359, "_runtime": 20685.9352953434, "_timestamp": 1585618055.5681648, "_step": 176}
{"Episode reward": -99.6598648134838, "Episode length": 999, "Policy Loss": -1.3848938941955566, "Value Loss": 0.06374867260456085, "_runtime": 20687.507291793823, "_timestamp": 1585618057.1401613, "_step": 177}
{"Episode reward": -99.59741983996798, "Episode length": 999, "Policy Loss": -1.3171143531799316, "Value Loss": 0.16363577544689178, "_runtime": 20689.07746529579, "_timestamp": 1585618058.7103348, "_step": 178}
{"Episode reward": -99.77863354764273, "Episode length": 999, "Policy Loss": -1.3325393199920654, "Value Loss": 0.0684710144996643, "_runtime": 20690.6840569973, "_timestamp": 1585618060.3169265, "_step": 179}
{"Episode reward": -99.45787062996979, "Episode length": 999, "Policy Loss": -1.3242491483688354, "Value Loss": 0.0660567581653595, "_runtime": 20691.993612527847, "_timestamp": 1585618061.626482, "_step": 180}
{"Episode reward": 18.395514775626722, "Episode length": 819, "Policy Loss": -0.5531104803085327, "Value Loss": 12.157052040100098, "_runtime": 20693.582087278366, "_timestamp": 1585618063.2149568, "_step": 181}
{"Episode reward": -99.84417494321102, "Episode length": 999, "Policy Loss": -1.3114267587661743, "Value Loss": 0.08887245506048203, "_runtime": 20695.17589211464, "_timestamp": 1585618064.8087616, "_step": 182}
{"Episode reward": -99.88717967385752, "Episode length": 999, "Policy Loss": -1.251029133796692, "Value Loss": 0.11427272111177444, "_runtime": 20696.74459552765, "_timestamp": 1585618066.377465, "_step": 183}
{"Episode reward": -99.62937305248204, "Episode length": 999, "Policy Loss": -1.263809084892273, "Value Loss": 0.058184001594781876, "_runtime": 20698.340036392212, "_timestamp": 1585618067.9729059, "_step": 184}
{"Episode reward": -99.64051170493337, "Episode length": 999, "Policy Loss": -1.2353166341781616, "Value Loss": 0.136470764875412, "_runtime": 20699.943325281143, "_timestamp": 1585618069.5761948, "_step": 185}
{"Episode reward": -99.56804665797253, "Episode length": 999, "Policy Loss": -1.2217738628387451, "Value Loss": 0.05376940220594406, "_runtime": 20701.44980931282, "_timestamp": 1585618071.0826788, "_step": 186}
{"Episode reward": 5.794232939109122, "Episode length": 945, "Policy Loss": -0.4192006587982178, "Value Loss": 10.675048828125, "_runtime": 20703.044774770737, "_timestamp": 1585618072.6776443, "_step": 187}
{"Episode reward": -99.60349319306995, "Episode length": 999, "Policy Loss": -1.1877833604812622, "Value Loss": 0.05488353967666626, "_runtime": 20704.67943096161, "_timestamp": 1585618074.3123004, "_step": 188}
{"Episode reward": -99.59521453590575, "Episode length": 999, "Policy Loss": -1.1669560670852661, "Value Loss": 0.12081243842840195, "_runtime": 20706.259342432022, "_timestamp": 1585618075.892212, "_step": 189}
{"Episode reward": -99.65470981449333, "Episode length": 999, "Policy Loss": -1.1756515502929688, "Value Loss": 0.05290086567401886, "_runtime": 20706.87522482872, "_timestamp": 1585618076.5080943, "_step": 190}
{"Episode reward": 62.99999999999975, "Episode length": 370, "Policy Loss": 0.4611853063106537, "Value Loss": 26.73333168029785, "_runtime": 20708.44701075554, "_timestamp": 1585618078.0798802, "_step": 191}
{"Episode reward": -99.63915750149035, "Episode length": 999, "Policy Loss": -1.1511571407318115, "Value Loss": 0.13848528265953064, "_runtime": 20710.028913021088, "_timestamp": 1585618079.6617825, "_step": 192}
{"Episode reward": -99.64411074996322, "Episode length": 999, "Policy Loss": -1.1295796632766724, "Value Loss": 0.06199858710169792, "_runtime": 20711.53488636017, "_timestamp": 1585618081.1677558, "_step": 193}
{"Episode reward": -99.74411903864682, "Episode length": 999, "Policy Loss": -1.131067156791687, "Value Loss": 0.0941392108798027, "_runtime": 20713.01173067093, "_timestamp": 1585618082.6446002, "_step": 194}
{"Episode reward": 6.326518066205196, "Episode length": 938, "Policy Loss": -0.45633265376091003, "Value Loss": 10.79149341583252, "_runtime": 20714.587804079056, "_timestamp": 1585618084.2206736, "_step": 195}
{"Episode reward": -99.54759795241851, "Episode length": 999, "Policy Loss": -1.0911080837249756, "Value Loss": 0.04323912039399147, "_runtime": 20715.30290389061, "_timestamp": 1585618084.9357734, "_step": 196}
{"Episode reward": 55.97669223502127, "Episode length": 442, "Policy Loss": 0.433563232421875, "Value Loss": 22.512935638427734, "_runtime": 20716.85733127594, "_timestamp": 1585618086.4902008, "_step": 197}
{"Episode reward": -99.76760501547112, "Episode length": 999, "Policy Loss": -1.0725265741348267, "Value Loss": 0.04275905713438988, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131, -0.06035454943776131]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 9.0], "bins": [-2.250967264175415, -2.214852809906006, -2.1787383556365967, -2.1426241397857666, -2.1065096855163574, -2.0703952312469482, -2.034280776977539, -1.9981664419174194, -1.9620521068572998, -1.9259376525878906, -1.8898231983184814, -1.8537088632583618, -1.8175944089889526, -1.781480073928833, -1.7453656196594238, -1.7092511653900146, -1.673136830329895, -1.6370224952697754, -1.6009080410003662, -1.564793586730957, -1.5286792516708374, -1.4925647974014282, -1.4564504623413086, -1.4203360080718994, -1.3842215538024902, -1.3481072187423706, -1.311992883682251, -1.2758784294128418, -1.2397639751434326, -1.203649640083313, -1.1675351858139038, -1.1314208507537842, -1.095306396484375, -1.0591919422149658, -1.0230776071548462, -0.986963152885437, -0.9508488178253174, -0.9147343635559082, -0.8786200284957886, -0.8425055742263794, -0.8063912391662598, -0.7702767848968506, -0.7341623306274414, -0.6980479955673218, -0.6619335412979126, -0.625819206237793, -0.5897047519683838, -0.5535904169082642, -0.517475962638855, -0.4813615083694458, -0.44524717330932617, -0.409132719039917, -0.37301838397979736, -0.3369039297103882, -0.30078959465026855, -0.2646751403808594, -0.2285606861114502, -0.19244623184204102, -0.15633201599121094, -0.12021756172180176, -0.08410310745239258, -0.0479886531829834, -0.01187443733215332, 0.02424001693725586, 0.06035447120666504]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0], "bins": [-0.07163968682289124, -0.07052031904459, -0.06940094381570816, -0.06828157603740692, -0.06716220825910568, -0.06604283303022385, -0.06492346525192261, -0.06380409747362137, -0.06268472224473953, -0.06156535446643829, -0.060445986688137054, -0.05932661518454552, -0.05820724368095398, -0.05708787590265274, -0.0559685043990612, -0.054849132895469666, -0.053729765117168427, -0.05261039361357689, -0.05149102210998535, -0.05037165433168411, -0.049252282828092575, -0.04813291132450104, -0.0470135435461998, -0.04589417204260826, -0.044774800539016724, -0.043655432760715485, -0.04253606125712395, -0.04141668975353241, -0.04029732197523117, -0.03917795047163963, -0.038058578968048096, -0.03693921118974686, -0.03581983968615532, -0.03470046818256378, -0.03358110040426254, -0.032461728900671005, -0.03134235739707947, -0.03022298961877823, -0.02910361811518669, -0.027984246611595154, -0.026864878833293915, -0.025745507329702377, -0.02462613582611084, -0.0235067680478096, -0.022387396544218063, -0.021268025040626526, -0.020148657262325287, -0.01902928575873375, -0.017909914255142212, -0.016790546476840973, -0.015671174973249435, -0.014551807194948196, -0.013432435691356659, -0.012313064187765121, -0.011193696409463882, -0.010074324905872345, -0.008954957127571106, -0.00783558189868927, -0.006716214120388031, -0.005596846342086792, -0.004477471113204956, -0.003358103334903717, -0.002238735556602478, -0.001119360327720642, 7.450580596923828e-09]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 5.0, 2.0, 1.0, 1.0, 0.0, 0.0, 7.0, 16.0, 275.0, 2.0, 6.0, 14.0, 9.0, 5.0, 5.0, 7.0, 14.0, 13.0, 11.0, 10.0, 12.0, 10.0, 6.0, 3.0, 10.0, 6.0, 5.0, 4.0], "bins": [-0.1402495950460434, -0.1370932012796402, -0.1339367926120758, -0.1307803988456726, -0.12762399017810822, -0.12446758896112442, -0.12131118774414062, -0.11815478652715683, -0.11499838531017303, -0.11184198409318924, -0.10868558287620544, -0.10552918910980225, -0.10237278044223785, -0.09921638667583466, -0.09605997800827026, -0.09290358424186707, -0.08974717557430267, -0.08659078180789948, -0.08343437314033508, -0.08027797937393188, -0.07712157815694809, -0.0739651769399643, -0.0708087757229805, -0.0676523745059967, -0.06449597328901291, -0.061339572072029114, -0.05818317085504532, -0.05502676963806152, -0.05187036842107773, -0.04871396720409393, -0.04555756598711014, -0.04240116477012634, -0.03924476355314255, -0.03608836233615875, -0.03293196111917496, -0.029775559902191162, -0.026619158685207367, -0.023462757468223572, -0.020306356251239777, -0.01714995503425598, -0.013993561267852783, -0.010837152600288391, -0.007680758833885193, -0.004524350166320801, -0.0013679563999176025, 0.0017884522676467896, 0.004944846034049988, 0.00810125470161438, 0.011257648468017578, 0.01441405713558197, 0.01757045090198517, 0.02072685956954956, 0.02388325333595276, 0.02703966200351715, 0.03019605576992035, 0.03335246443748474, 0.03650885820388794, 0.03966526687145233, 0.04282166063785553, 0.04597806930541992, 0.04913446307182312, 0.05229087173938751, 0.05544726550579071, 0.0586036741733551, 0.0617600679397583]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0], "bins": [-0.4971529543399811, -0.48640063405036926, -0.47564828395843506, -0.46489596366882324, -0.4541436433792114, -0.4433912932872772, -0.4326389729976654, -0.4218866229057312, -0.4111343026161194, -0.40038198232650757, -0.38962966203689575, -0.37887731194496155, -0.36812499165534973, -0.3573726415634155, -0.3466203212738037, -0.3358680009841919, -0.3251156806945801, -0.3143633306026459, -0.30361101031303406, -0.29285866022109985, -0.28210633993148804, -0.2713540196418762, -0.2606016993522644, -0.2498493492603302, -0.23909702897071838, -0.22834467887878418, -0.21759235858917236, -0.20684003829956055, -0.19608768820762634, -0.18533536791801453, -0.1745830476284027, -0.1638306975364685, -0.1530783772468567, -0.14232605695724487, -0.13157370686531067, -0.12082138657569885, -0.11006906628608704, -0.09931671619415283, -0.08856439590454102, -0.0778120756149292, -0.067059725522995, -0.05630740523338318, -0.04555508494377136, -0.03480273485183716, -0.024050414562225342, -0.013298094272613525, -0.0025457441806793213, 0.008206576108932495, 0.01895889639854431, 0.029711216688156128, 0.04046359658241272, 0.051215916872024536, 0.06196823716163635, 0.07272055745124817, 0.08347287774085999, 0.0942251980304718, 0.1049775779247284, 0.11572989821434021, 0.12648221850395203, 0.13723453879356384, 0.14798685908317566, 0.15873917937278748, 0.16949155926704407, 0.18024387955665588, 0.1909961998462677]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 3.0, 5.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 5.0, 6.0, 7.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.20984292030334473, -0.20327961444854736, -0.19671630859375, -0.19015300273895264, -0.18358969688415527, -0.1770263910293579, -0.17046308517456055, -0.16389977931976318, -0.15733647346496582, -0.15077316761016846, -0.1442098617553711, -0.13764655590057373, -0.13108325004577637, -0.124519944190979, -0.11795663833618164, -0.11139333248138428, -0.10483002662658691, -0.09826672077178955, -0.09170341491699219, -0.08514010906219482, -0.07857680320739746, -0.0720134973526001, -0.06545019149780273, -0.05888688564300537, -0.05232357978820801, -0.045760273933410645, -0.03919696807861328, -0.03263366222381592, -0.026070356369018555, -0.01950705051422119, -0.012943744659423828, -0.006380438804626465, 0.00018286705017089844, 0.006746172904968262, 0.013309478759765625, 0.01987278461456299, 0.02643609046936035, 0.032999396324157715, 0.03956270217895508, 0.04612600803375244, 0.052689313888549805, 0.05925261974334717, 0.06581592559814453, 0.0723792314529419, 0.07894253730773926, 0.08550584316253662, 0.09206914901733398, 0.09863245487213135, 0.10519576072692871, 0.11175906658172607, 0.11832237243652344, 0.1248856782913208, 0.13144898414611816, 0.13801229000091553, 0.1445755958557129, 0.15113890171051025, 0.15770220756530762, 0.16426551342010498, 0.17082881927490234, 0.1773921251296997, 0.18395543098449707, 0.19051873683929443, 0.1970820426940918, 0.20364534854888916, 0.21020865440368652]}, "_runtime": 20718.44353866577, "_timestamp": 1585618088.0764081, "_step": 198}
{"Episode reward": -99.52601355430532, "Episode length": 999, "Policy Loss": -1.053152084350586, "Value Loss": 0.04307335242629051, "_runtime": 20719.661428928375, "_timestamp": 1585618089.2942984, "_step": 199}
{"Episode reward": 20.27834518996559, "Episode length": 798, "Policy Loss": -0.2948336601257324, "Value Loss": 12.473017692565918, "_runtime": 20721.25226354599, "_timestamp": 1585618090.885133, "_step": 200}
{"Episode reward": -99.73174243923721, "Episode length": 999, "Policy Loss": -1.0376890897750854, "Value Loss": 0.04953385517001152, "_runtime": 20722.32984304428, "_timestamp": 1585618091.9627125, "_step": 201}
{"Episode reward": 32.38843581163631, "Episode length": 678, "Policy Loss": -0.08906647562980652, "Value Loss": 14.670869827270508, "_runtime": 20723.883687973022, "_timestamp": 1585618093.5165575, "_step": 202}
{"Episode reward": -99.81420156704705, "Episode length": 999, "Policy Loss": -1.0132302045822144, "Value Loss": 0.17659059166908264, "_runtime": 20724.338861465454, "_timestamp": 1585618093.971731, "_step": 203}
{"Episode reward": 74.58589774179265, "Episode length": 255, "Policy Loss": 1.3993191719055176, "Value Loss": 39.789371490478516, "_runtime": 20725.897565603256, "_timestamp": 1585618095.530435, "_step": 204}
{"Episode reward": -99.77631731091394, "Episode length": 999, "Policy Loss": -1.0561426877975464, "Value Loss": 0.0534990094602108, "_runtime": 20727.471787452698, "_timestamp": 1585618097.104657, "_step": 205}
{"Episode reward": -99.71173507603679, "Episode length": 999, "Policy Loss": -1.0468636751174927, "Value Loss": 0.0692867860198021, "_runtime": 20728.963547945023, "_timestamp": 1585618098.5964174, "_step": 206}
{"Episode reward": -99.73953854956059, "Episode length": 999, "Policy Loss": -1.0803872346878052, "Value Loss": 0.10163012146949768, "_runtime": 20730.586389541626, "_timestamp": 1585618100.219259, "_step": 207}
{"Episode reward": -99.5479382932405, "Episode length": 999, "Policy Loss": -1.05610990524292, "Value Loss": 0.08453521132469177, "_runtime": 20731.352566242218, "_timestamp": 1585618100.9854357, "_step": 208}
{"Episode reward": 53.03710480609403, "Episode length": 471, "Policy Loss": 0.31782248616218567, "Value Loss": 21.13433837890625, "_runtime": 20732.89785552025, "_timestamp": 1585618102.530725, "_step": 209}
{"Episode reward": -99.61836154577183, "Episode length": 999, "Policy Loss": -1.0438319444656372, "Value Loss": 0.114284947514534, "_runtime": 20734.492527008057, "_timestamp": 1585618104.1253965, "_step": 210}
{"Episode reward": -99.81592879034439, "Episode length": 999, "Policy Loss": -1.0330793857574463, "Value Loss": 0.06402955949306488, "_runtime": 20736.019733428955, "_timestamp": 1585618105.652603, "_step": 211}
{"Episode reward": -99.56165917187325, "Episode length": 999, "Policy Loss": -1.012014389038086, "Value Loss": 0.05124306678771973, "_runtime": 20737.58669948578, "_timestamp": 1585618107.219569, "_step": 212}
{"Episode reward": -99.80491253235238, "Episode length": 999, "Policy Loss": -1.0038930177688599, "Value Loss": 0.046849366277456284, "_runtime": 20739.168414592743, "_timestamp": 1585618108.801284, "_step": 213}
{"Episode reward": -99.83936061300197, "Episode length": 999, "Policy Loss": -0.9950841069221497, "Value Loss": 0.06823065131902695, "_runtime": 20740.723209619522, "_timestamp": 1585618110.356079, "_step": 214}
{"Episode reward": -99.72161286817725, "Episode length": 999, "Policy Loss": -0.966281533241272, "Value Loss": 0.04410601779818535, "_runtime": 20742.309475183487, "_timestamp": 1585618111.9423447, "_step": 215}
{"Episode reward": -99.61375848399337, "Episode length": 999, "Policy Loss": -0.9338458180427551, "Value Loss": 0.0676446259021759, "_runtime": 20743.071977376938, "_timestamp": 1585618112.7048469, "_step": 216}
{"Episode reward": 53.99999999999962, "Episode length": 460, "Policy Loss": 0.6339702010154724, "Value Loss": 21.5373477935791, "_runtime": 20744.65194106102, "_timestamp": 1585618114.2848105, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9046698808670044, "Value Loss": 0.0931166261434555, "_runtime": 20745.651427030563, "_timestamp": 1585618115.2842965, "_step": 218}
{"Episode reward": 37.60858832106399, "Episode length": 626, "Policy Loss": 0.05115579068660736, "Value Loss": 15.90284252166748, "_runtime": 20747.029753923416, "_timestamp": 1585618116.6626234, "_step": 219}
{"Episode reward": 9.856214255741477, "Episode length": 903, "Policy Loss": -0.10933105647563934, "Value Loss": 11.054676055908203, "_runtime": 20748.13144183159, "_timestamp": 1585618117.7643113, "_step": 220}
{"Episode reward": 31.668454405641725, "Episode length": 685, "Policy Loss": 0.016980770975351334, "Value Loss": 14.62405776977539, "_runtime": 20749.664016008377, "_timestamp": 1585618119.2968855, "_step": 221}
{"Episode reward": -99.6919328384786, "Episode length": 999, "Policy Loss": -0.8905859589576721, "Value Loss": 0.10291990637779236, "_runtime": 20751.22418141365, "_timestamp": 1585618120.857051, "_step": 222}
{"Episode reward": -99.76175644958718, "Episode length": 999, "Policy Loss": -0.8814077973365784, "Value Loss": 0.04543647542595863, "_runtime": 20752.44215106964, "_timestamp": 1585618122.0750206, "_step": 223}
{"Episode reward": 22.351933860842976, "Episode length": 778, "Policy Loss": -0.12608422338962555, "Value Loss": 12.748351097106934, "_runtime": 20753.477846622467, "_timestamp": 1585618123.110716, "_step": 224}
{"Episode reward": 35.178635337575685, "Episode length": 649, "Policy Loss": 0.06459875404834747, "Value Loss": 15.358734130859375, "_runtime": 20755.081777572632, "_timestamp": 1585618124.714647, "_step": 225}
{"Episode reward": -99.67378603311234, "Episode length": 999, "Policy Loss": -0.8673934936523438, "Value Loss": 0.046613965183496475, "_runtime": 20756.596337795258, "_timestamp": 1585618126.2292073, "_step": 226}
{"Episode reward": 3.563911354793291, "Episode length": 966, "Policy Loss": -0.1862349808216095, "Value Loss": 10.414308547973633, "_runtime": 20757.633959054947, "_timestamp": 1585618127.2668285, "_step": 227}
{"Episode reward": 34.16766019753942, "Episode length": 660, "Policy Loss": 0.06491634249687195, "Value Loss": 15.076743125915527, "_runtime": 20759.211481809616, "_timestamp": 1585618128.8443513, "_step": 228}
{"Episode reward": -99.6220238618306, "Episode length": 999, "Policy Loss": -0.8428523540496826, "Value Loss": 0.10976003110408783, "_runtime": 20760.790534734726, "_timestamp": 1585618130.4234042, "_step": 229}
{"Episode reward": -99.87429747551656, "Episode length": 999, "Policy Loss": -0.8093401789665222, "Value Loss": 0.11664854735136032, "_runtime": 20762.340579032898, "_timestamp": 1585618131.9734485, "_step": 230}
{"Episode reward": -99.75079168474628, "Episode length": 999, "Policy Loss": -0.8029815554618835, "Value Loss": 0.03930675610899925, "_runtime": 20763.878888130188, "_timestamp": 1585618133.5117576, "_step": 231}
{"Episode reward": 2.884785799217724, "Episode length": 975, "Policy Loss": 0.15129265189170837, "Value Loss": 10.269654273986816, "_runtime": 20764.783764362335, "_timestamp": 1585618134.4166338, "_step": 232}
{"Episode reward": 44.095744593697084, "Episode length": 561, "Policy Loss": 0.36123913526535034, "Value Loss": 17.713598251342773, "_runtime": 20766.13833975792, "_timestamp": 1585618135.7712092, "_step": 233}
{"Episode reward": 13.870857164054797, "Episode length": 864, "Policy Loss": -0.06593208760023117, "Value Loss": 11.49029541015625, "_runtime": 20767.655866146088, "_timestamp": 1585618137.2887356, "_step": 234}
{"Episode reward": 4.485448645382419, "Episode length": 956, "Policy Loss": -0.07349005341529846, "Value Loss": 10.429055213928223, "_runtime": 20769.20169854164, "_timestamp": 1585618138.834568, "_step": 235}
{"Episode reward": -99.63339556534636, "Episode length": 999, "Policy Loss": -0.7686379551887512, "Value Loss": 0.113074891269207, "_runtime": 20769.699591875076, "_timestamp": 1585618139.3324614, "_step": 236}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 1.204618215560913, "Value Loss": 33.4980583190918, "_runtime": 20771.265614271164, "_timestamp": 1585618140.8984838, "_step": 237}
{"Episode reward": -99.55595702014261, "Episode length": 999, "Policy Loss": -0.736609697341919, "Value Loss": 0.06161032244563103, "_runtime": 20772.403386592865, "_timestamp": 1585618142.036256, "_step": 238}
{"Episode reward": 28.567977139260407, "Episode length": 715, "Policy Loss": 0.09774814546108246, "Value Loss": 13.962535858154297, "_runtime": 20773.909902334213, "_timestamp": 1585618143.5427718, "_step": 239}
{"Episode reward": -99.65846722090943, "Episode length": 999, "Policy Loss": -0.7589273452758789, "Value Loss": 0.0960201844573021, "_runtime": 20775.484934329987, "_timestamp": 1585618145.1178038, "_step": 240}
{"Episode reward": -99.84929470198556, "Episode length": 999, "Policy Loss": -0.8004833459854126, "Value Loss": 0.10830572247505188, "_runtime": 20776.093763113022, "_timestamp": 1585618145.7266326, "_step": 241}
{"Episode reward": 61.990596571302476, "Episode length": 381, "Policy Loss": 0.9007288813591003, "Value Loss": 26.008018493652344, "_runtime": 20777.64854979515, "_timestamp": 1585618147.2814193, "_step": 242}
{"Episode reward": -99.72158115887875, "Episode length": 999, "Policy Loss": -0.7608477473258972, "Value Loss": 0.05923466756939888, "_runtime": 20779.273334264755, "_timestamp": 1585618148.9062037, "_step": 243}
{"Episode reward": -99.44479667083222, "Episode length": 999, "Policy Loss": -0.7604408860206604, "Value Loss": 0.03962787985801697, "_runtime": 20780.491996526718, "_timestamp": 1585618150.124866, "_step": 244}
{"Episode reward": 19.852298453840476, "Episode length": 805, "Policy Loss": -0.023939108476042747, "Value Loss": 12.428140640258789, "_runtime": 20782.05443239212, "_timestamp": 1585618151.6873019, "_step": 245}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7500407099723816, "Value Loss": 0.07373658567667007, "_runtime": 20783.450535058975, "_timestamp": 1585618153.0834045, "_step": 246}
{"Episode reward": 11.649698207970516, "Episode length": 886, "Policy Loss": 0.15553036332130432, "Value Loss": 11.298606872558594, "_runtime": 20784.994218587875, "_timestamp": 1585618154.627088, "_step": 247}
{"Episode reward": -99.63470626338245, "Episode length": 999, "Policy Loss": -0.6988213658332825, "Value Loss": 0.04571845009922981, "_runtime": 20786.561750650406, "_timestamp": 1585618156.1946201, "_step": 248}
{"Episode reward": -99.6376155341263, "Episode length": 999, "Policy Loss": -0.6716187000274658, "Value Loss": 0.037532906979322433, "_runtime": 20788.129462242126, "_timestamp": 1585618157.7623317, "_step": 249}
{"Episode reward": -99.62613368858445, "Episode length": 999, "Policy Loss": -0.6430925726890564, "Value Loss": 0.04369044676423073, "_runtime": 20789.70082426071, "_timestamp": 1585618159.3336937, "_step": 250}
{"Episode reward": -99.6168143348056, "Episode length": 999, "Policy Loss": -0.6332521438598633, "Value Loss": 0.0861566811800003, "_runtime": 20791.272505044937, "_timestamp": 1585618160.9053745, "_step": 251}
{"Episode reward": -99.75856432039153, "Episode length": 999, "Policy Loss": -0.5949998497962952, "Value Loss": 0.030176158994436264, "_runtime": 20792.10683465004, "_timestamp": 1585618161.7397041, "_step": 252}
{"Episode reward": 47.8929425484438, "Episode length": 522, "Policy Loss": 0.7871730327606201, "Value Loss": 19.004562377929688, "_runtime": 20793.313680648804, "_timestamp": 1585618162.9465501, "_step": 253}
{"Episode reward": 23.49853395033867, "Episode length": 768, "Policy Loss": 0.24218524992465973, "Value Loss": 13.055374145507812, "_runtime": 20794.09233522415, "_timestamp": 1585618163.7252047, "_step": 254}
{"Episode reward": 52.066976444213246, "Episode length": 480, "Policy Loss": 1.5724495649337769, "Value Loss": 20.790931701660156, "_runtime": 20795.63309955597, "_timestamp": 1585618165.265969, "_step": 255}
{"Episode reward": -99.70314731609402, "Episode length": 999, "Policy Loss": -0.5433841347694397, "Value Loss": 0.06916267424821854, "_runtime": 20797.18944501877, "_timestamp": 1585618166.8223145, "_step": 256}
{"Episode reward": -99.73599910214404, "Episode length": 999, "Policy Loss": -0.5487608313560486, "Value Loss": 0.024423066526651382, "_runtime": 20798.71224975586, "_timestamp": 1585618168.3451192, "_step": 257}
{"Episode reward": -99.73604085915582, "Episode length": 999, "Policy Loss": -0.5585950613021851, "Value Loss": 0.016992757096886635, "_runtime": 20800.281844615936, "_timestamp": 1585618169.914714, "_step": 258}
{"Episode reward": -99.71604030502355, "Episode length": 999, "Policy Loss": -0.5572346448898315, "Value Loss": 0.034358520060777664, "_runtime": 20801.902005195618, "_timestamp": 1585618171.5348747, "_step": 259}
{"Episode reward": -99.68099602884475, "Episode length": 999, "Policy Loss": -0.556153416633606, "Value Loss": 0.05509023740887642, "_runtime": 20803.469176769257, "_timestamp": 1585618173.1020463, "_step": 260}
{"Episode reward": -99.72940906353621, "Episode length": 999, "Policy Loss": -0.5642991662025452, "Value Loss": 0.016661543399095535, "_runtime": 20805.051789045334, "_timestamp": 1585618174.6846585, "_step": 261}
{"Episode reward": -99.800692834727, "Episode length": 999, "Policy Loss": -0.5714019536972046, "Value Loss": 0.025245636701583862, "_runtime": 20806.63484096527, "_timestamp": 1585618176.2677104, "_step": 262}
{"Episode reward": -99.70924573393864, "Episode length": 999, "Policy Loss": -0.5567961931228638, "Value Loss": 0.020086223259568214, "_runtime": 20808.2102060318, "_timestamp": 1585618177.8430755, "_step": 263}
{"Episode reward": -99.71496943803365, "Episode length": 999, "Policy Loss": -0.5573392510414124, "Value Loss": 0.019422467797994614, "_runtime": 20809.75010251999, "_timestamp": 1585618179.382972, "_step": 264}
{"Episode reward": 1.7000000000013102, "Episode length": 983, "Policy Loss": 0.055788569152355194, "Value Loss": 10.20678424835205, "_runtime": 20811.167021036148, "_timestamp": 1585618180.7998905, "_step": 265}
{"Episode reward": 10.778996521188745, "Episode length": 894, "Policy Loss": 0.19334693253040314, "Value Loss": 11.092045783996582, "_runtime": 20811.68018746376, "_timestamp": 1585618181.313057, "_step": 266}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 1.4824165105819702, "Value Loss": 33.250282287597656, "_runtime": 20813.24866247177, "_timestamp": 1585618182.881532, "_step": 267}
{"Episode reward": -99.83237786425603, "Episode length": 999, "Policy Loss": -0.5256947875022888, "Value Loss": 0.027667971327900887, "_runtime": 20814.716327667236, "_timestamp": 1585618184.3491971, "_step": 268}
{"Episode reward": 7.196682350315228, "Episode length": 929, "Policy Loss": 0.20795726776123047, "Value Loss": 10.736801147460938, "_runtime": 20816.225705623627, "_timestamp": 1585618185.858575, "_step": 269}
{"Episode reward": -99.60390065754625, "Episode length": 999, "Policy Loss": -0.5487374067306519, "Value Loss": 0.016502737998962402, "_runtime": 20817.804777622223, "_timestamp": 1585618187.437647, "_step": 270}
{"Episode reward": -99.46402843508267, "Episode length": 999, "Policy Loss": -0.542819619178772, "Value Loss": 0.05625222250819206, "_runtime": 20819.385175704956, "_timestamp": 1585618189.0180452, "_step": 271}
{"Episode reward": -99.67509899013538, "Episode length": 999, "Policy Loss": -0.548128068447113, "Value Loss": 0.035960853099823, "_runtime": 20820.926099538803, "_timestamp": 1585618190.558969, "_step": 272}
{"Episode reward": -99.74584016282903, "Episode length": 999, "Policy Loss": -0.5550184845924377, "Value Loss": 0.0304883923381567, "_runtime": 20821.23043036461, "_timestamp": 1585618190.8632998, "_step": 273}
{"Episode reward": 85.29712870863736, "Episode length": 148, "Policy Loss": 3.489933729171753, "Value Loss": 66.8827133178711, "_runtime": 20821.83432006836, "_timestamp": 1585618191.4671896, "_step": 274}
{"Episode reward": 63.433456546853755, "Episode length": 367, "Policy Loss": 1.1355924606323242, "Value Loss": 26.99441146850586, "_runtime": 20822.807471752167, "_timestamp": 1585618192.4403412, "_step": 275}
{"Episode reward": 38.313139536603686, "Episode length": 619, "Policy Loss": 0.4302508234977722, "Value Loss": 16.075176239013672, "_runtime": 20824.321111679077, "_timestamp": 1585618193.9539812, "_step": 276}
{"Episode reward": -99.75608018527136, "Episode length": 999, "Policy Loss": -0.6066226959228516, "Value Loss": 0.013558401726186275, "_runtime": 20825.676856279373, "_timestamp": 1585618195.3097258, "_step": 277}
{"Episode reward": 12.89439040361971, "Episode length": 875, "Policy Loss": 0.07098304480314255, "Value Loss": 11.337455749511719, "_runtime": 20827.212327718735, "_timestamp": 1585618196.8451972, "_step": 278}
{"Episode reward": -99.24137660780552, "Episode length": 999, "Policy Loss": -0.6324610114097595, "Value Loss": 0.06430220603942871, "_runtime": 20828.05569577217, "_timestamp": 1585618197.6885653, "_step": 279}
{"Episode reward": 46.49999999999952, "Episode length": 535, "Policy Loss": 0.5634332299232483, "Value Loss": 18.590717315673828, "_runtime": 20829.606350421906, "_timestamp": 1585618199.23922, "_step": 280}
{"Episode reward": -99.66930951402034, "Episode length": 999, "Policy Loss": -0.6241977214813232, "Value Loss": 0.044998649507761, "_runtime": 20831.160028219223, "_timestamp": 1585618200.7928977, "_step": 281}
{"Episode reward": -99.19657317412066, "Episode length": 999, "Policy Loss": -0.6253127455711365, "Value Loss": 0.14902594685554504, "_runtime": 20832.69554042816, "_timestamp": 1585618202.32841, "_step": 282}
{"Episode reward": -99.47994763292236, "Episode length": 999, "Policy Loss": -0.6399285793304443, "Value Loss": 0.03401966020464897, "_runtime": 20834.273330926895, "_timestamp": 1585618203.9062004, "_step": 283}
{"Episode reward": -99.64795044327481, "Episode length": 999, "Policy Loss": -0.6358557939529419, "Value Loss": 0.11187251657247543, "_runtime": 20835.419905424118, "_timestamp": 1585618205.052775, "_step": 284}
{"Episode reward": 28.058284206245844, "Episode length": 720, "Policy Loss": 0.191023588180542, "Value Loss": 13.912129402160645, "_runtime": 20836.95688176155, "_timestamp": 1585618206.5897512, "_step": 285}
{"Episode reward": -99.71893460084546, "Episode length": 999, "Policy Loss": -0.5940658450126648, "Value Loss": 0.10910547524690628, "_runtime": 20838.534298181534, "_timestamp": 1585618208.1671677, "_step": 286}
{"Episode reward": -99.45641053062727, "Episode length": 999, "Policy Loss": -0.6080060005187988, "Value Loss": 0.10447600483894348, "_runtime": 20839.826410531998, "_timestamp": 1585618209.45928, "_step": 287}
{"Episode reward": 17.251609066356167, "Episode length": 830, "Policy Loss": 0.15527553856372833, "Value Loss": 11.90217399597168, "_runtime": 20841.39820098877, "_timestamp": 1585618211.0310705, "_step": 288}
{"Episode reward": -99.85121912378678, "Episode length": 999, "Policy Loss": -0.6124152541160583, "Value Loss": 0.11412972956895828, "_runtime": 20842.125155448914, "_timestamp": 1585618211.758025, "_step": 289}
{"Episode reward": 55.49562729212886, "Episode length": 447, "Policy Loss": 0.7354950308799744, "Value Loss": 22.137916564941406, "_runtime": 20843.69820022583, "_timestamp": 1585618213.3310697, "_step": 290}
{"Episode reward": -99.86181487524742, "Episode length": 999, "Policy Loss": -0.594153642654419, "Value Loss": 0.03745346888899803, "_runtime": 20844.977130413055, "_timestamp": 1585618214.61, "_step": 291}
{"Episode reward": 19.12934721744999, "Episode length": 811, "Policy Loss": 0.13963456451892853, "Value Loss": 12.178556442260742, "_runtime": 20845.568676948547, "_timestamp": 1585618215.2015464, "_step": 292}
{"Episode reward": 62.539035828574306, "Episode length": 377, "Policy Loss": 0.9986304044723511, "Value Loss": 26.18239402770996, "_runtime": 20846.817321300507, "_timestamp": 1585618216.4501908, "_step": 293}
{"Episode reward": 20.75379099002481, "Episode length": 795, "Policy Loss": 0.2867753207683563, "Value Loss": 12.430919647216797, "_runtime": 20848.36603140831, "_timestamp": 1585618217.998901, "_step": 294}
{"Episode reward": -99.70644319428109, "Episode length": 999, "Policy Loss": -0.6363540291786194, "Value Loss": 0.15452207624912262, "_runtime": 20849.92369866371, "_timestamp": 1585618219.5565681, "_step": 295}
{"Episode reward": -99.70290842414694, "Episode length": 999, "Policy Loss": -0.6013033390045166, "Value Loss": 0.11879400163888931, "_runtime": 20851.482942342758, "_timestamp": 1585618221.1158118, "_step": 296}
{"Episode reward": -99.43289911249167, "Episode length": 999, "Policy Loss": -0.5871077179908752, "Value Loss": 0.03805236890912056, "_runtime": 20853.044196128845, "_timestamp": 1585618222.6770656, "_step": 297}
{"Episode reward": -99.53942934716915, "Episode length": 999, "Policy Loss": -0.5831899642944336, "Value Loss": 0.05263611674308777, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517, -1.7488266229629517]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0], "bins": [-87.38027954101562, -85.98697662353516, -84.59367370605469, -83.20036315917969, -81.80706024169922, -80.41375732421875, -79.02045440673828, -77.62715148925781, -76.23384857177734, -74.84054565429688, -73.44723510742188, -72.0539321899414, -70.66062927246094, -69.26732635498047, -67.8740234375, -66.480712890625, -65.08740997314453, -63.69410705566406, -62.300804138183594, -60.907501220703125, -59.51419448852539, -58.12089157104492, -56.72758483886719, -55.33428192138672, -53.94097900390625, -52.547672271728516, -51.15436935424805, -49.76106643676758, -48.367759704589844, -46.974456787109375, -45.581153869628906, -44.18784713745117, -42.7945442199707, -41.401241302490234, -40.0079345703125, -38.61463165283203, -37.22132873535156, -35.82802200317383, -34.43471908569336, -33.04141616821289, -31.648109436035156, -30.254806518554688, -28.86150360107422, -27.468196868896484, -26.074893951416016, -24.681591033935547, -23.288284301757812, -21.894981384277344, -20.501678466796875, -19.108375549316406, -17.715065002441406, -16.321762084960938, -14.928459167480469, -13.53515625, -12.141853332519531, -10.748550415039062, -9.355239868164062, -7.961936950683594, -6.568634033203125, -5.175331115722656, -3.7820281982421875, -2.3887252807617188, -0.9954147338867188, 0.39788818359375, 1.7911911010742188]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0], "bins": [-2.0720877647399902, -2.0397021770477295, -2.007316827774048, -1.974931240081787, -1.942545771598816, -1.9101603031158447, -1.877774715423584, -1.8453892469406128, -1.8130037784576416, -1.7806181907653809, -1.7482327222824097, -1.7158472537994385, -1.6834616661071777, -1.6510761976242065, -1.6186907291412354, -1.5863052606582642, -1.553919792175293, -1.5215342044830322, -1.489148736000061, -1.4567632675170898, -1.424377679824829, -1.391992211341858, -1.3596067428588867, -1.327221155166626, -1.2948356866836548, -1.2624502182006836, -1.2300646305084229, -1.1976792812347412, -1.1652936935424805, -1.1329082250595093, -1.100522756576538, -1.0681371688842773, -1.0357517004013062, -1.003366231918335, -0.9709806442260742, -0.938595175743103, -0.9062097072601318, -0.8738242387771606, -0.8414386510848999, -0.8090531826019287, -0.7766677141189575, -0.7442821264266968, -0.7118966579437256, -0.6795111894607544, -0.6471257209777832, -0.6147401332855225, -0.5823546648025513, -0.5499691963195801, -0.5175836086273193, -0.48519814014434814, -0.45281267166137695, -0.42042720317840576, -0.388041615486145, -0.35565614700317383, -0.32327067852020264, -0.29088521003723145, -0.2584996223449707, -0.2261141538619995, -0.19372868537902832, -0.16134309768676758, -0.1289576292037964, -0.0965721607208252, -0.06418657302856445, -0.03180122375488281, 0.0005843639373779297]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 5.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 2.0, 1.0, 2.0, 8.0, 9.0, 293.0, 19.0, 12.0, 8.0, 3.0, 1.0, 3.0, 3.0, 7.0, 17.0, 7.0, 9.0, 10.0, 11.0, 12.0, 10.0, 5.0], "bins": [-5.316450119018555, -5.203935623168945, -5.091421127319336, -4.978906631469727, -4.866392135620117, -4.753877639770508, -4.64136266708374, -4.528848171234131, -4.4163336753845215, -4.303819179534912, -4.191304683685303, -4.078790187835693, -3.966275691986084, -3.8537609577178955, -3.741246461868286, -3.6287317276000977, -3.5162172317504883, -3.403702735900879, -3.2911882400512695, -3.17867374420166, -3.066159248352051, -2.9536445140838623, -2.841130018234253, -2.7286155223846436, -2.616101026535034, -2.503586530685425, -2.3910717964172363, -2.278557300567627, -2.1660428047180176, -2.053528308868408, -1.9410135746002197, -1.8284990787506104, -1.715984582901001, -1.6034700870513916, -1.4909555912017822, -1.3784408569335938, -1.2659263610839844, -1.153411865234375, -1.0408973693847656, -0.9283828735351562, -0.8158683776855469, -0.7033538818359375, -0.5908389091491699, -0.47832441329956055, -0.36580991744995117, -0.2532954216003418, -0.14078092575073242, -0.028266429901123047, 0.08424806594848633, 0.1967625617980957, 0.3092770576477051, 0.42179203033447266, 0.534306526184082, 0.6468210220336914, 0.7593355178833008, 0.8718500137329102, 0.9843645095825195, 1.096879005432129, 1.2093935012817383, 1.3219079971313477, 1.4344229698181152, 1.5469374656677246, 1.659451961517334, 1.7719664573669434, 1.8844809532165527]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 4.0, 3.0], "bins": [-15.090435028076172, -14.806020736694336, -14.5216064453125, -14.237192153930664, -13.952777862548828, -13.668364524841309, -13.383950233459473, -13.099535942077637, -12.8151216506958, -12.530707359313965, -12.246293067932129, -11.96187973022461, -11.677465438842773, -11.393051147460938, -11.108636856079102, -10.824222564697266, -10.53980827331543, -10.255393981933594, -9.970979690551758, -9.686565399169922, -9.402151107788086, -9.11773681640625, -8.83332347869873, -8.548909187316895, -8.264494895935059, -7.980080604553223, -7.695666313171387, -7.411252498626709, -7.126838207244873, -6.842424392700195, -6.558010101318359, -6.273595809936523, -5.9891815185546875, -5.704767227172852, -5.420352935791016, -5.13593864440918, -4.851524353027344, -4.567111015319824, -4.282696723937988, -3.9982824325561523, -3.7138681411743164, -3.4294538497924805, -3.1450395584106445, -2.8606252670288086, -2.576211929321289, -2.291797637939453, -2.007383346557617, -1.7229690551757812, -1.4385547637939453, -1.1541404724121094, -0.8697261810302734, -0.5853118896484375, -0.30089759826660156, -0.01648426055908203, 0.2679300308227539, 0.5523443222045898, 0.8367586135864258, 1.1211719512939453, 1.4055862426757812, 1.6900005340576172, 1.9744148254394531, 2.258829116821289, 2.543243408203125, 2.827657699584961, 3.112071990966797]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 4.0, 4.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 10.0, 16.0, 7.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.114783763885498, -1.01718270778656, -0.9195815324783325, -0.8219804763793945, -0.7243793606758118, -0.626778244972229, -0.529177188873291, -0.43157607316970825, -0.3339749574661255, -0.23637384176254272, -0.13877272605895996, -0.04117166996002197, 0.056429386138916016, 0.15403056144714355, 0.25163161754608154, 0.3492327928543091, 0.44683384895324707, 0.5444349050521851, 0.6420360803604126, 0.7396371364593506, 0.8372383117675781, 0.9348392486572266, 1.032440423965454, 1.1300415992736816, 1.22764253616333, 1.3252437114715576, 1.4228448867797852, 1.5204460620880127, 1.6180469989776611, 1.7156481742858887, 1.8132493495941162, 1.9108502864837646, 2.008451461791992, 2.1060526371002197, 2.203653573989868, 2.3012547492980957, 2.3988559246063232, 2.4964568614959717, 2.594058036804199, 2.6916592121124268, 2.7892603874206543, 2.8868613243103027, 2.984462261199951, 3.082063674926758, 3.1796646118164062, 3.2772655487060547, 3.3748669624328613, 3.4724678993225098, 3.570068836212158, 3.667670249938965, 3.7652711868286133, 3.86287260055542, 3.9604735374450684, 4.058074474334717, 4.155675888061523, 4.253276824951172, 4.35087776184082, 4.448479175567627, 4.546080112457275, 4.643681049346924, 4.7412824630737305, 4.838883399963379, 4.936484336853027, 5.034085750579834, 5.131686687469482]}, "_runtime": 20854.592135429382, "_timestamp": 1585618224.225005, "_step": 298}
{"Episode reward": 0.4980258926763099, "Episode length": 996, "Policy Loss": 0.3310178220272064, "Value Loss": 9.891923904418945, "_runtime": 20856.17244720459, "_timestamp": 1585618225.8053167, "_step": 299}
{"Episode reward": -99.69878627781733, "Episode length": 999, "Policy Loss": -0.5624129176139832, "Value Loss": 0.2169758528470993, "_runtime": 20857.75213599205, "_timestamp": 1585618227.3850055, "_step": 300}
{"Episode reward": -99.47246254437931, "Episode length": 999, "Policy Loss": -0.5007116198539734, "Value Loss": 0.05433862656354904, "_runtime": 20859.322677373886, "_timestamp": 1585618228.9555469, "_step": 301}
{"Episode reward": -99.79886889208434, "Episode length": 999, "Policy Loss": -0.504011332988739, "Value Loss": 0.03129787743091583, "_runtime": 20860.511436462402, "_timestamp": 1585618230.144306, "_step": 302}
{"Episode reward": 26.134991582430587, "Episode length": 741, "Policy Loss": 0.31651660799980164, "Value Loss": 13.386510848999023, "_runtime": 20862.108535289764, "_timestamp": 1585618231.7414048, "_step": 303}
{"Episode reward": -99.78150449925894, "Episode length": 999, "Policy Loss": -0.45536357164382935, "Value Loss": 0.07678810507059097, "_runtime": 20863.68515729904, "_timestamp": 1585618233.3180268, "_step": 304}
{"Episode reward": -99.70068957367772, "Episode length": 999, "Policy Loss": -0.4462334215641022, "Value Loss": 0.09543711692094803, "_runtime": 20864.755947351456, "_timestamp": 1585618234.3888168, "_step": 305}
{"Episode reward": 32.980813887854566, "Episode length": 673, "Policy Loss": 0.4727214574813843, "Value Loss": 14.695222854614258, "_runtime": 20866.289486169815, "_timestamp": 1585618235.9223557, "_step": 306}
{"Episode reward": 4.097139167484144, "Episode length": 961, "Policy Loss": 0.3229253590106964, "Value Loss": 10.352827072143555, "_runtime": 20867.879012823105, "_timestamp": 1585618237.5118823, "_step": 307}
{"Episode reward": -99.77547755990969, "Episode length": 999, "Policy Loss": -0.39217668771743774, "Value Loss": 0.08714202791452408, "_runtime": 20869.44249844551, "_timestamp": 1585618239.075368, "_step": 308}
{"Episode reward": -99.68503029071587, "Episode length": 999, "Policy Loss": -0.3864821791648865, "Value Loss": 0.011180851608514786, "_runtime": 20871.0286591053, "_timestamp": 1585618240.6615286, "_step": 309}
{"Episode reward": -99.79985526106763, "Episode length": 999, "Policy Loss": -0.3452097773551941, "Value Loss": 0.07760938256978989, "_runtime": 20872.65270423889, "_timestamp": 1585618242.2855737, "_step": 310}
{"Episode reward": -99.6965705924188, "Episode length": 999, "Policy Loss": -0.36893829703330994, "Value Loss": 0.17319725453853607, "_runtime": 20874.238458633423, "_timestamp": 1585618243.871328, "_step": 311}
{"Episode reward": -99.59141997821142, "Episode length": 999, "Policy Loss": -0.3199477195739746, "Value Loss": 0.06222022324800491, "_runtime": 20875.767113924026, "_timestamp": 1585618245.3999834, "_step": 312}
{"Episode reward": 3.8787339641724543, "Episode length": 962, "Policy Loss": 0.3810173273086548, "Value Loss": 10.321395874023438, "_runtime": 20877.354187726974, "_timestamp": 1585618246.9870572, "_step": 313}
{"Episode reward": -99.7605835924144, "Episode length": 999, "Policy Loss": -0.2945614159107208, "Value Loss": 0.06277066469192505, "_runtime": 20878.952778577805, "_timestamp": 1585618248.585648, "_step": 314}
{"Episode reward": -99.79739670352872, "Episode length": 999, "Policy Loss": -0.2854669392108917, "Value Loss": 0.018134668469429016, "_runtime": 20880.5477206707, "_timestamp": 1585618250.1805902, "_step": 315}
{"Episode reward": -99.69141930719348, "Episode length": 999, "Policy Loss": -0.2625918984413147, "Value Loss": 0.050622373819351196, "_runtime": 20881.822700977325, "_timestamp": 1585618251.4555705, "_step": 316}
{"Episode reward": 20.120763769414296, "Episode length": 800, "Policy Loss": 0.5153464078903198, "Value Loss": 12.390210151672363, "_runtime": 20882.711736679077, "_timestamp": 1585618252.3446062, "_step": 317}
{"Episode reward": 45.49772962543598, "Episode length": 547, "Policy Loss": 0.8807307481765747, "Value Loss": 18.162429809570312, "_runtime": 20884.30595779419, "_timestamp": 1585618253.9388273, "_step": 318}
{"Episode reward": -99.80924907533777, "Episode length": 999, "Policy Loss": -0.23808196187019348, "Value Loss": 0.039733368903398514, "_runtime": 20885.877956867218, "_timestamp": 1585618255.5108263, "_step": 319}
{"Episode reward": -99.62681094277511, "Episode length": 999, "Policy Loss": -0.2319173514842987, "Value Loss": 0.013876665383577347, "_runtime": 20887.076701402664, "_timestamp": 1585618256.709571, "_step": 320}
{"Episode reward": 22.67295796871197, "Episode length": 774, "Policy Loss": 0.5369685292243958, "Value Loss": 12.871687889099121, "_runtime": 20888.036135435104, "_timestamp": 1585618257.669005, "_step": 321}
{"Episode reward": 40.41662912492118, "Episode length": 598, "Policy Loss": 0.7498108148574829, "Value Loss": 16.671236038208008, "_runtime": 20888.45548558235, "_timestamp": 1585618258.088355, "_step": 322}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": 2.6751174926757812, "Value Loss": 42.65116882324219, "_runtime": 20888.84103822708, "_timestamp": 1585618258.4739077, "_step": 323}
{"Episode reward": 77.29954944474153, "Episode length": 228, "Policy Loss": 2.2989845275878906, "Value Loss": 43.54883575439453, "_runtime": 20889.98969745636, "_timestamp": 1585618259.622567, "_step": 324}
{"Episode reward": 26.191127693105884, "Episode length": 740, "Policy Loss": 0.4916493892669678, "Value Loss": 13.537442207336426, "_runtime": 20891.50097131729, "_timestamp": 1585618261.1338408, "_step": 325}
{"Episode reward": -99.68118770976876, "Episode length": 999, "Policy Loss": -0.3355446457862854, "Value Loss": 0.023331694304943085, "_runtime": 20892.55567908287, "_timestamp": 1585618262.1885486, "_step": 326}
{"Episode reward": 29.899999999999707, "Episode length": 701, "Policy Loss": 0.5541581511497498, "Value Loss": 14.23843765258789, "_runtime": 20894.115153312683, "_timestamp": 1585618263.7480228, "_step": 327}
{"Episode reward": -99.65560260671053, "Episode length": 999, "Policy Loss": -0.3986288607120514, "Value Loss": 0.033464834094047546, "_runtime": 20895.704585552216, "_timestamp": 1585618265.337455, "_step": 328}
{"Episode reward": -99.71519317715871, "Episode length": 999, "Policy Loss": -0.4602413773536682, "Value Loss": 0.14467604458332062, "_runtime": 20896.380278348923, "_timestamp": 1585618266.0131478, "_step": 329}
{"Episode reward": 60.033315690396996, "Episode length": 400, "Policy Loss": 1.1763590574264526, "Value Loss": 24.866113662719727, "_runtime": 20897.867636680603, "_timestamp": 1585618267.5005062, "_step": 330}
{"Episode reward": 6.437923317194091, "Episode length": 936, "Policy Loss": 0.2697860896587372, "Value Loss": 10.634642601013184, "_runtime": 20899.452375650406, "_timestamp": 1585618269.0852451, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37861281633377075, "Value Loss": 0.0859634280204773, "_runtime": 20900.142926692963, "_timestamp": 1585618269.7757962, "_step": 332}
{"Episode reward": 55.20146749843807, "Episode length": 450, "Policy Loss": 1.0543947219848633, "Value Loss": 22.052419662475586, "_runtime": 20901.715404748917, "_timestamp": 1585618271.3482742, "_step": 333}
{"Episode reward": -99.82922357953944, "Episode length": 999, "Policy Loss": -0.3634854853153229, "Value Loss": 0.10920678824186325, "_runtime": 20902.105587244034, "_timestamp": 1585618271.7384567, "_step": 334}
{"Episode reward": 78.79367117022628, "Episode length": 213, "Policy Loss": 2.615971088409424, "Value Loss": 46.14946365356445, "_runtime": 20903.63277864456, "_timestamp": 1585618273.2656481, "_step": 335}
{"Episode reward": -99.5947659833343, "Episode length": 999, "Policy Loss": -0.37037235498428345, "Value Loss": 0.08218460530042648, "_runtime": 20905.186758041382, "_timestamp": 1585618274.8196275, "_step": 336}
{"Episode reward": 2.5062362408918375, "Episode length": 979, "Policy Loss": 0.23363730311393738, "Value Loss": 10.218092918395996, "_runtime": 20906.696009397507, "_timestamp": 1585618276.3288789, "_step": 337}
{"Episode reward": -99.82087841501786, "Episode length": 999, "Policy Loss": -0.369983434677124, "Value Loss": 0.053447701036930084, "_runtime": 20908.17783522606, "_timestamp": 1585618277.8107047, "_step": 338}
{"Episode reward": 7.041831804673265, "Episode length": 932, "Policy Loss": 0.36035361886024475, "Value Loss": 10.710211753845215, "_runtime": 20909.351865053177, "_timestamp": 1585618278.9847345, "_step": 339}
{"Episode reward": 26.575440724287077, "Episode length": 736, "Policy Loss": 0.5231451392173767, "Value Loss": 13.417618751525879, "_runtime": 20910.922558546066, "_timestamp": 1585618280.555428, "_step": 340}
{"Episode reward": -99.80257868836495, "Episode length": 999, "Policy Loss": -0.39722582697868347, "Value Loss": 0.10901595652103424, "_runtime": 20911.916938066483, "_timestamp": 1585618281.5498075, "_step": 341}
{"Episode reward": 37.332858860119565, "Episode length": 627, "Policy Loss": 0.5022978782653809, "Value Loss": 15.776659965515137, "_runtime": 20913.497841358185, "_timestamp": 1585618283.1307108, "_step": 342}
{"Episode reward": -99.84630750997317, "Episode length": 999, "Policy Loss": -0.4216346740722656, "Value Loss": 0.2070755958557129, "_runtime": 20915.080821990967, "_timestamp": 1585618284.7136915, "_step": 343}
{"Episode reward": -99.46866453240955, "Episode length": 999, "Policy Loss": -0.458006888628006, "Value Loss": 0.2178085893392563, "_runtime": 20916.143262386322, "_timestamp": 1585618285.7761319, "_step": 344}
{"Episode reward": 32.49999999999956, "Episode length": 675, "Policy Loss": 0.6176667213439941, "Value Loss": 14.559226989746094, "_runtime": 20916.670268297195, "_timestamp": 1585618286.3031378, "_step": 345}
{"Episode reward": 68.8918315645713, "Episode length": 312, "Policy Loss": 1.630662202835083, "Value Loss": 31.543983459472656, "_runtime": 20917.811307907104, "_timestamp": 1585618287.4441774, "_step": 346}
{"Episode reward": 28.05403495489135, "Episode length": 722, "Policy Loss": 0.4953962564468384, "Value Loss": 13.83635139465332, "_runtime": 20919.366916656494, "_timestamp": 1585618288.9997861, "_step": 347}
{"Episode reward": -99.58288695101955, "Episode length": 999, "Policy Loss": -0.423107385635376, "Value Loss": 0.10513503104448318, "_runtime": 20920.91587114334, "_timestamp": 1585618290.5487406, "_step": 348}
{"Episode reward": -99.33285859334146, "Episode length": 999, "Policy Loss": -0.43658319115638733, "Value Loss": 0.04234873875975609, "_runtime": 20922.483650445938, "_timestamp": 1585618292.11652, "_step": 349}
{"Episode reward": -99.56038155406574, "Episode length": 999, "Policy Loss": -0.4164850115776062, "Value Loss": 0.05348709225654602, "_runtime": 20923.829921483994, "_timestamp": 1585618293.462791, "_step": 350}
{"Episode reward": 14.681128124055093, "Episode length": 854, "Policy Loss": 0.35988301038742065, "Value Loss": 11.574885368347168, "_runtime": 20924.88492321968, "_timestamp": 1585618294.5177927, "_step": 351}
{"Episode reward": 33.08740826369565, "Episode length": 671, "Policy Loss": 0.850007176399231, "Value Loss": 14.721957206726074, "_runtime": 20926.107355594635, "_timestamp": 1585618295.740225, "_step": 352}
{"Episode reward": 23.161817117332347, "Episode length": 770, "Policy Loss": 0.3837071359157562, "Value Loss": 12.860105514526367, "_runtime": 20927.67390346527, "_timestamp": 1585618297.306773, "_step": 353}
{"Episode reward": -99.70984489140544, "Episode length": 999, "Policy Loss": -0.3604940176010132, "Value Loss": 0.10141848772764206, "_runtime": 20928.655445337296, "_timestamp": 1585618298.2883148, "_step": 354}
{"Episode reward": 37.39999999999939, "Episode length": 626, "Policy Loss": 0.7367976903915405, "Value Loss": 15.931514739990234, "_runtime": 20930.11372900009, "_timestamp": 1585618299.7465985, "_step": 355}
{"Episode reward": 7.091050389992148, "Episode length": 932, "Policy Loss": 0.31229642033576965, "Value Loss": 10.679512977600098, "_runtime": 20931.69149708748, "_timestamp": 1585618301.3243666, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3867347240447998, "Value Loss": 0.11934850364923477, "_runtime": 20933.23644709587, "_timestamp": 1585618302.8693166, "_step": 357}
{"Episode reward": -99.5610010702382, "Episode length": 999, "Policy Loss": -0.34792178869247437, "Value Loss": 0.026977932080626488, "_runtime": 20934.814729452133, "_timestamp": 1585618304.447599, "_step": 358}
{"Episode reward": -99.75526065651654, "Episode length": 999, "Policy Loss": -0.3463554382324219, "Value Loss": 0.10727101564407349, "_runtime": 20936.39974617958, "_timestamp": 1585618306.0326157, "_step": 359}
{"Episode reward": -99.37506210645523, "Episode length": 999, "Policy Loss": -0.28931093215942383, "Value Loss": 0.010128029622137547, "_runtime": 20937.524407863617, "_timestamp": 1585618307.1572773, "_step": 360}
{"Episode reward": 29.443068167171177, "Episode length": 706, "Policy Loss": 0.5998579859733582, "Value Loss": 14.095911979675293, "_runtime": 20939.06089735031, "_timestamp": 1585618308.6937668, "_step": 361}
{"Episode reward": 4.221793810483064, "Episode length": 962, "Policy Loss": 0.3983581066131592, "Value Loss": 10.33813762664795, "_runtime": 20940.658520936966, "_timestamp": 1585618310.2913904, "_step": 362}
{"Episode reward": -99.65687511782023, "Episode length": 999, "Policy Loss": -0.19726617634296417, "Value Loss": 0.021823212504386902, "_runtime": 20942.216233730316, "_timestamp": 1585618311.8491032, "_step": 363}
{"Episode reward": -99.68839670515014, "Episode length": 999, "Policy Loss": -0.16635474562644958, "Value Loss": 0.03979683667421341, "_runtime": 20943.855570554733, "_timestamp": 1585618313.48844, "_step": 364}
{"Episode reward": -99.70801521660621, "Episode length": 999, "Policy Loss": -0.14089560508728027, "Value Loss": 0.03349386528134346, "_runtime": 20945.219551563263, "_timestamp": 1585618314.852421, "_step": 365}
{"Episode reward": 14.40761127013306, "Episode length": 857, "Policy Loss": 0.5682339072227478, "Value Loss": 11.608882904052734, "_runtime": 20946.806205272675, "_timestamp": 1585618316.4390748, "_step": 366}
{"Episode reward": -99.8344006207292, "Episode length": 999, "Policy Loss": -0.12081555277109146, "Value Loss": 0.029130026698112488, "_runtime": 20948.3965883255, "_timestamp": 1585618318.0294578, "_step": 367}
{"Episode reward": -99.54086986312039, "Episode length": 999, "Policy Loss": -0.11959576606750488, "Value Loss": 0.006141123827546835, "_runtime": 20949.96860074997, "_timestamp": 1585618319.6014702, "_step": 368}
{"Episode reward": -99.88925053948047, "Episode length": 999, "Policy Loss": -0.1191416010260582, "Value Loss": 0.03751153126358986, "_runtime": 20951.066783428192, "_timestamp": 1585618320.699653, "_step": 369}
{"Episode reward": 30.937517507647513, "Episode length": 691, "Policy Loss": 0.7622227668762207, "Value Loss": 14.342605590820312, "_runtime": 20952.644580602646, "_timestamp": 1585618322.27745, "_step": 370}
{"Episode reward": -99.48765555433793, "Episode length": 999, "Policy Loss": -0.10869693011045456, "Value Loss": 0.02155359461903572, "_runtime": 20953.396693468094, "_timestamp": 1585618323.029563, "_step": 371}
{"Episode reward": 54.63048271992557, "Episode length": 455, "Policy Loss": 1.2038980722427368, "Value Loss": 21.731182098388672, "_runtime": 20953.87229990959, "_timestamp": 1585618323.5051694, "_step": 372}
{"Episode reward": 71.82502677596628, "Episode length": 284, "Policy Loss": 1.9547512531280518, "Value Loss": 34.800018310546875, "_runtime": 20955.45645213127, "_timestamp": 1585618325.0893216, "_step": 373}
{"Episode reward": -99.81270967759052, "Episode length": 999, "Policy Loss": -0.18012626469135284, "Value Loss": 0.009840489365160465, "_runtime": 20956.983651399612, "_timestamp": 1585618326.616521, "_step": 374}
{"Episode reward": -99.77751366100135, "Episode length": 999, "Policy Loss": -0.22868464887142181, "Value Loss": 0.05075694993138313, "_runtime": 20957.498355150223, "_timestamp": 1585618327.1312246, "_step": 375}
{"Episode reward": 67.42054964245744, "Episode length": 327, "Policy Loss": 1.5765011310577393, "Value Loss": 30.23539924621582, "_runtime": 20959.08289027214, "_timestamp": 1585618328.7157598, "_step": 376}
{"Episode reward": -99.63491943739798, "Episode length": 999, "Policy Loss": -0.253637433052063, "Value Loss": 0.10382827371358871, "_runtime": 20960.65485739708, "_timestamp": 1585618330.2877269, "_step": 377}
{"Episode reward": -99.58553592047983, "Episode length": 999, "Policy Loss": -0.2626563608646393, "Value Loss": 0.056716565042734146, "_runtime": 20962.043380260468, "_timestamp": 1585618331.6762497, "_step": 378}
{"Episode reward": 8.124693819310991, "Episode length": 923, "Policy Loss": 0.5570376515388489, "Value Loss": 10.784582138061523, "_runtime": 20963.642911434174, "_timestamp": 1585618333.275781, "_step": 379}
{"Episode reward": -99.62227363551362, "Episode length": 999, "Policy Loss": -0.2528296709060669, "Value Loss": 0.06460513919591904, "_runtime": 20964.620107889175, "_timestamp": 1585618334.2529774, "_step": 380}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 0.7176950573921204, "Value Loss": 16.320890426635742, "_runtime": 20965.864054441452, "_timestamp": 1585618335.496924, "_step": 381}
{"Episode reward": 20.109124750178566, "Episode length": 800, "Policy Loss": 0.4562751352787018, "Value Loss": 12.373115539550781, "_runtime": 20966.49988079071, "_timestamp": 1585618336.1327503, "_step": 382}
{"Episode reward": 61.48545041298467, "Episode length": 386, "Policy Loss": 1.2614637613296509, "Value Loss": 25.57784652709961, "_runtime": 20968.09879565239, "_timestamp": 1585618337.7316651, "_step": 383}
{"Episode reward": -99.75622735358635, "Episode length": 999, "Policy Loss": -0.2936893701553345, "Value Loss": 0.04048943892121315, "_runtime": 20969.65202856064, "_timestamp": 1585618339.284898, "_step": 384}
{"Episode reward": -99.73669731470734, "Episode length": 999, "Policy Loss": -0.3119816184043884, "Value Loss": 0.047416504472494125, "_runtime": 20970.647099256516, "_timestamp": 1585618340.2799687, "_step": 385}
{"Episode reward": 34.89989897736757, "Episode length": 652, "Policy Loss": 0.8404572010040283, "Value Loss": 15.207194328308105, "_runtime": 20971.69366288185, "_timestamp": 1585618341.3265324, "_step": 386}
{"Episode reward": 34.29747467669023, "Episode length": 658, "Policy Loss": 0.5710529685020447, "Value Loss": 14.989898681640625, "_runtime": 20973.264085054398, "_timestamp": 1585618342.8969545, "_step": 387}
{"Episode reward": -99.81756942132348, "Episode length": 999, "Policy Loss": -0.32514241337776184, "Value Loss": 0.1052553802728653, "_runtime": 20974.805898427963, "_timestamp": 1585618344.438768, "_step": 388}
{"Episode reward": -99.62203721992998, "Episode length": 999, "Policy Loss": -0.3368944823741913, "Value Loss": 0.012096134014427662, "_runtime": 20975.912508010864, "_timestamp": 1585618345.5453775, "_step": 389}
{"Episode reward": 29.751346018723865, "Episode length": 703, "Policy Loss": 0.5199811458587646, "Value Loss": 14.121726989746094, "_runtime": 20977.492434501648, "_timestamp": 1585618347.125304, "_step": 390}
{"Episode reward": -99.64761632720918, "Episode length": 999, "Policy Loss": -0.3551708161830902, "Value Loss": 0.038474053144454956, "_runtime": 20977.985383987427, "_timestamp": 1585618347.6182535, "_step": 391}
{"Episode reward": 71.09999999999987, "Episode length": 289, "Policy Loss": 2.029846668243408, "Value Loss": 34.03964614868164, "_runtime": 20979.53480243683, "_timestamp": 1585618349.167672, "_step": 392}
{"Episode reward": -99.80919254729385, "Episode length": 999, "Policy Loss": -0.36679473519325256, "Value Loss": 0.09931597113609314, "_runtime": 20980.308825731277, "_timestamp": 1585618349.9416952, "_step": 393}
{"Episode reward": 52.692208084667406, "Episode length": 476, "Policy Loss": 0.9253100156784058, "Value Loss": 20.64764976501465, "_runtime": 20981.73290348053, "_timestamp": 1585618351.365773, "_step": 394}
{"Episode reward": 5.667500466831186, "Episode length": 944, "Policy Loss": 0.2882007956504822, "Value Loss": 10.487038612365723, "_runtime": 20982.398963928223, "_timestamp": 1585618352.0318334, "_step": 395}
{"Episode reward": 59.69064668433246, "Episode length": 404, "Policy Loss": 1.1996631622314453, "Value Loss": 24.56576156616211, "_runtime": 20983.930066108704, "_timestamp": 1585618353.5629356, "_step": 396}
{"Episode reward": -99.79607943990128, "Episode length": 999, "Policy Loss": -0.37991589307785034, "Value Loss": 0.1403292417526245, "_runtime": 20985.483850479126, "_timestamp": 1585618355.11672, "_step": 397}
{"Episode reward": -99.7204001427847, "Episode length": 999, "Policy Loss": -0.3799315094947815, "Value Loss": 0.06472568958997726, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726, 0.5150577425956726]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6116477847099304, -0.1920776069164276, 0.2274925708770752, 0.6470627188682556, 1.0666329860687256, 1.4862029552459717, 1.9057731628417969, 2.325343370437622, 2.7449135780334473, 3.1644837856292725, 3.5840537548065186, 4.003624439239502, 4.423194408416748, 4.842764854431152, 5.262334823608398, 5.681905269622803, 6.101475238800049, 6.521045207977295, 6.940615653991699, 7.360185623168945, 7.779755592346191, 8.199326515197754, 8.618896484375, 9.038466453552246, 9.458036422729492, 9.877606391906738, 10.2971773147583, 10.716747283935547, 11.136317253112793, 11.555887222290039, 11.975458145141602, 12.395028114318848, 12.814598083496094, 13.23416805267334, 13.653738021850586, 14.073308944702148, 14.492878913879395, 14.91244888305664, 15.332018852233887, 15.75158977508545, 16.171157836914062, 16.590728759765625, 17.010299682617188, 17.429868698120117, 17.84943962097168, 18.26900863647461, 18.688579559326172, 19.108150482177734, 19.527719497680664, 19.947290420532227, 20.366859436035156, 20.78643035888672, 21.20600128173828, 21.62557029724121, 22.045141220092773, 22.464712142944336, 22.884281158447266, 23.303852081298828, 23.723421096801758, 24.14299201965332, 24.562562942504883, 24.982131958007812, 25.401702880859375, 25.821271896362305, 26.240842819213867]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 6.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.02933432161808014, -0.01936189830303192, -0.009389476850628853, 0.0005829446017742157, 0.010555367916822433, 0.02052779123187065, 0.03050021082162857, 0.04047263413667679, 0.050445057451725006, 0.060417480766773224, 0.07038990408182144, 0.08036232739686966, 0.09033474326133728, 0.1003071665763855, 0.11027958989143372, 0.12025201320648193, 0.13022443652153015, 0.14019685983657837, 0.1501692831516266, 0.1601417064666748, 0.17011412978172302, 0.18008655309677124, 0.19005897641181946, 0.20003139972686768, 0.2100038081407547, 0.21997623145580292, 0.22994865477085114, 0.23992107808589935, 0.24989350140094757, 0.259865939617157, 0.2698383331298828, 0.2798107862472534, 0.28978317975997925, 0.29975563287734985, 0.3097280263900757, 0.3197004795074463, 0.3296728730201721, 0.3396453261375427, 0.34961771965026855, 0.35959017276763916, 0.369562566280365, 0.3795350193977356, 0.3895074129104614, 0.39947986602783203, 0.40945225954055786, 0.41942471265792847, 0.4293971061706543, 0.4393695592880249, 0.44934195280075073, 0.45931434631347656, 0.46928679943084717, 0.4792592525482178, 0.4892316460609436, 0.4992040991783142, 0.50917649269104, 0.5191489458084106, 0.5291213393211365, 0.5390937924385071, 0.5490661859512329, 0.5590386390686035, 0.5690110325813293, 0.5789834856987, 0.5889558792114258, 0.5989283323287964, 0.6089007258415222]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [5.0, 15.0, 13.0, 10.0, 6.0, 11.0, 16.0, 11.0, 4.0, 3.0, 1.0, 0.0, 17.0, 13.0, 32.0, 280.0, 3.0, 8.0, 2.0, 1.0, 5.0, 3.0, 1.0, 5.0, 5.0, 3.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 6.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.5897631049156189, -0.5513253808021545, -0.5128876566886902, -0.4744499623775482, -0.43601226806640625, -0.3975745439529419, -0.35913681983947754, -0.32069912552833557, -0.2822614014148712, -0.24382367730140686, -0.2053859829902649, -0.16694825887680054, -0.12851053476333618, -0.09007284045219421, -0.051635146141052246, -0.01319742202758789, 0.025240302085876465, 0.06367802619934082, 0.10211575031280518, 0.14055341482162476, 0.1789911389350891, 0.21742886304855347, 0.2558665871620178, 0.2943043112754822, 0.33274203538894653, 0.3711796998977661, 0.40961742401123047, 0.44805508852005005, 0.4864928126335144, 0.5249305367469788, 0.5633682608604431, 0.6018059849739075, 0.6402437090873718, 0.6786814332008362, 0.7171191573143005, 0.7555568814277649, 0.7939946055412292, 0.8324323296546936, 0.8708699345588684, 0.9093076586723328, 0.9477453827857971, 0.9861831068992615, 1.024620771408081, 1.063058614730835, 1.1014962196350098, 1.1399340629577637, 1.1783716678619385, 1.2168095111846924, 1.2552471160888672, 1.293684720993042, 1.332122564315796, 1.3705601692199707, 1.4089980125427246, 1.4474356174468994, 1.4858732223510742, 1.5243110656738281, 1.562748670578003, 1.6011865139007568, 1.6396241188049316, 1.6780619621276855, 1.7164995670318604, 1.7549374103546143, 1.793375015258789, 1.831812858581543, 1.8702504634857178]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [6.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.6981077194213867, -0.6178346276283264, -0.5375615358352661, -0.4572884142398834, -0.3770153224468231, -0.2967422306537628, -0.21646910905838013, -0.13619601726531982, -0.05592292547225952, 0.02435016632080078, 0.10462325811386108, 0.1848963499069214, 0.26516950130462646, 0.345442533493042, 0.42571568489074707, 0.5059887170791626, 0.5862618684768677, 0.6665350198745728, 0.7468080520629883, 0.8270812034606934, 0.9073542356491089, 0.987627387046814, 1.0679004192352295, 1.1481735706329346, 1.2284467220306396, 1.3087198734283447, 1.3889927864074707, 1.4692659378051758, 1.5495390892028809, 1.629812240600586, 1.710085153579712, 1.790358304977417, 1.870631456375122, 1.9509046077728271, 2.0311777591705322, 2.111450672149658, 2.1917238235473633, 2.2719969749450684, 2.3522701263427734, 2.4325430393218994, 2.5128161907196045, 2.5930893421173096, 2.6733624935150146, 2.7536356449127197, 2.8339085578918457, 2.914181709289551, 2.994454860687256, 3.074728012084961, 3.155001163482666, 3.235274076461792, 3.315547466278076, 3.395820140838623, 3.476093292236328, 3.556366443634033, 3.6366395950317383, 3.7169127464294434, 3.7971858978271484, 3.8774590492248535, 3.9577322006225586, 4.038005352020264, 4.1182780265808105, 4.198551177978516, 4.278824329376221, 4.359097480773926, 4.439370632171631]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 4.0, 3.0, 9.0, 18.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.1553704738616943, -3.088489294052124, -3.0216081142425537, -2.9547271728515625, -2.887845993041992, -2.820964813232422, -2.7540836334228516, -2.6872024536132812, -2.620321273803711, -2.5534403324127197, -2.4865591526031494, -2.419677972793579, -2.352796792984009, -2.2859158515930176, -2.2190346717834473, -2.152153491973877, -2.0852723121643066, -2.0183911323547363, -1.9515100717544556, -1.8846288919448853, -1.8177478313446045, -1.7508666515350342, -1.6839854717254639, -1.617104411125183, -1.5502232313156128, -1.4833420515060425, -1.4164609909057617, -1.3495798110961914, -1.282698631286621, -1.2158175706863403, -1.1489365100860596, -1.0820553302764893, -1.015174150466919, -0.9482929706573486, -0.8814117908477783, -0.8145308494567871, -0.7476496696472168, -0.6807684898376465, -0.6138873100280762, -0.5470061302185059, -0.48012518882751465, -0.41324400901794434, -0.346362829208374, -0.2794816493988037, -0.2126004695892334, -0.14571928977966309, -0.07883834838867188, -0.011957168579101562, 0.05492401123046875, 0.12180519104003906, 0.18868637084960938, 0.2555673122406006, 0.3224484920501709, 0.3893296718597412, 0.4562108516693115, 0.5230920314788818, 0.5899732112884521, 0.6568541526794434, 0.7237353324890137, 0.790616512298584, 0.8574974536895752, 0.9243786334991455, 0.9912598133087158, 1.0581409931182861, 1.1250221729278564]}, "_runtime": 20985.866599321365, "_timestamp": 1585618355.4994688, "_step": 398}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": 2.1849422454833984, "Value Loss": 42.42014694213867, "_runtime": 20987.42120361328, "_timestamp": 1585618357.054073, "_step": 399}
{"Episode reward": -99.67948882330535, "Episode length": 999, "Policy Loss": -0.44824156165122986, "Value Loss": 0.05279725790023804, "_runtime": 20988.99459695816, "_timestamp": 1585618358.6274664, "_step": 400}
{"Episode reward": -99.88031372358533, "Episode length": 999, "Policy Loss": -0.4616505205631256, "Value Loss": 0.09679177403450012, "_runtime": 20990.03489089012, "_timestamp": 1585618359.6677604, "_step": 401}
{"Episode reward": 30.35752113672757, "Episode length": 698, "Policy Loss": 0.37043097615242004, "Value Loss": 14.12641716003418, "_runtime": 20991.006420373917, "_timestamp": 1585618360.6392899, "_step": 402}
{"Episode reward": 39.34552622092829, "Episode length": 608, "Policy Loss": 0.49006131291389465, "Value Loss": 16.21208381652832, "_runtime": 20991.634531497955, "_timestamp": 1585618361.267401, "_step": 403}
{"Episode reward": 61.682795783108766, "Episode length": 384, "Policy Loss": 1.625022053718567, "Value Loss": 25.512998580932617, "_runtime": 20992.806476593018, "_timestamp": 1585618362.439346, "_step": 404}
{"Episode reward": 25.141303492791465, "Episode length": 751, "Policy Loss": 0.3733677268028259, "Value Loss": 13.356307029724121, "_runtime": 20993.274613380432, "_timestamp": 1585618362.9074829, "_step": 405}
{"Episode reward": 70.80127660378335, "Episode length": 293, "Policy Loss": 1.5228935480117798, "Value Loss": 33.35000991821289, "_runtime": 20994.09690952301, "_timestamp": 1585618363.729779, "_step": 406}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 0.6110687851905823, "Value Loss": 18.147640228271484, "_runtime": 20995.63098716736, "_timestamp": 1585618365.2638566, "_step": 407}
{"Episode reward": -99.60521317914106, "Episode length": 999, "Policy Loss": -0.4755687415599823, "Value Loss": 0.05545816943049431, "_runtime": 20997.13355922699, "_timestamp": 1585618366.7664287, "_step": 408}
{"Episode reward": -99.58485416525372, "Episode length": 999, "Policy Loss": -0.45983296632766724, "Value Loss": 0.10746500641107559, "_runtime": 20997.961800575256, "_timestamp": 1585618367.59467, "_step": 409}
{"Episode reward": 47.01962747270543, "Episode length": 530, "Policy Loss": 0.6635928153991699, "Value Loss": 18.516481399536133, "_runtime": 20998.619215726852, "_timestamp": 1585618368.2520852, "_step": 410}
{"Episode reward": 58.69749355483187, "Episode length": 414, "Policy Loss": 1.1146832704544067, "Value Loss": 23.835926055908203, "_runtime": 21000.17355823517, "_timestamp": 1585618369.8064277, "_step": 411}
{"Episode reward": -99.5680607088886, "Episode length": 999, "Policy Loss": -0.4655700623989105, "Value Loss": 0.06531518697738647, "_runtime": 21001.704240322113, "_timestamp": 1585618371.3371098, "_step": 412}
{"Episode reward": -99.74533366081165, "Episode length": 999, "Policy Loss": -0.46493008732795715, "Value Loss": 0.04470207914710045, "_runtime": 21003.02094936371, "_timestamp": 1585618372.6538188, "_step": 413}
{"Episode reward": 13.563352230302456, "Episode length": 867, "Policy Loss": 0.21734867990016937, "Value Loss": 11.359272956848145, "_runtime": 21004.337164402008, "_timestamp": 1585618373.970034, "_step": 414}
{"Episode reward": 15.748417681915967, "Episode length": 843, "Policy Loss": 0.24335898458957672, "Value Loss": 11.698976516723633, "_runtime": 21005.905962228775, "_timestamp": 1585618375.5388317, "_step": 415}
{"Episode reward": -99.65953247677395, "Episode length": 999, "Policy Loss": -0.49149808287620544, "Value Loss": 0.04117153584957123, "_runtime": 21007.455196857452, "_timestamp": 1585618377.0880663, "_step": 416}
{"Episode reward": -99.52492630467611, "Episode length": 999, "Policy Loss": -0.48945775628089905, "Value Loss": 0.24136076867580414, "_runtime": 21009.011324882507, "_timestamp": 1585618378.6441944, "_step": 417}
{"Episode reward": -99.7526719611357, "Episode length": 999, "Policy Loss": -0.47279536724090576, "Value Loss": 0.03628483787178993, "_runtime": 21010.59601187706, "_timestamp": 1585618380.2288814, "_step": 418}
{"Episode reward": -99.7068911915864, "Episode length": 999, "Policy Loss": -0.44647595286369324, "Value Loss": 0.14189907908439636, "_runtime": 21011.706782341003, "_timestamp": 1585618381.3396518, "_step": 419}
{"Episode reward": 29.778645156806746, "Episode length": 704, "Policy Loss": 0.6317158341407776, "Value Loss": 14.120792388916016, "_runtime": 21012.876475334167, "_timestamp": 1585618382.5093448, "_step": 420}
{"Episode reward": 26.37601188709951, "Episode length": 737, "Policy Loss": 0.45306479930877686, "Value Loss": 13.301200866699219, "_runtime": 21014.14363884926, "_timestamp": 1585618383.7765083, "_step": 421}
{"Episode reward": 20.480834361142726, "Episode length": 798, "Policy Loss": 0.415778249502182, "Value Loss": 12.408536911010742, "_runtime": 21014.907717227936, "_timestamp": 1585618384.5405867, "_step": 422}
{"Episode reward": 51.842834217816886, "Episode length": 483, "Policy Loss": 1.0464905500411987, "Value Loss": 20.445756912231445, "_runtime": 21016.490718364716, "_timestamp": 1585618386.1235878, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33251044154167175, "Value Loss": 0.07876455038785934, "_runtime": 21018.045382499695, "_timestamp": 1585618387.678252, "_step": 424}
{"Episode reward": -99.73071519947123, "Episode length": 999, "Policy Loss": -0.31000566482543945, "Value Loss": 0.13313256204128265, "_runtime": 21018.61743736267, "_timestamp": 1585618388.2503068, "_step": 425}
{"Episode reward": 64.26926387231191, "Episode length": 360, "Policy Loss": 1.3784180879592896, "Value Loss": 27.240997314453125, "_runtime": 21020.17651796341, "_timestamp": 1585618389.8093874, "_step": 426}
{"Episode reward": -99.79415066777588, "Episode length": 999, "Policy Loss": -0.3261730670928955, "Value Loss": 0.11221727728843689, "_runtime": 21021.755268096924, "_timestamp": 1585618391.3881376, "_step": 427}
{"Episode reward": -99.83532370203618, "Episode length": 999, "Policy Loss": -0.35722997784614563, "Value Loss": 0.08586934953927994, "_runtime": 21023.265523195267, "_timestamp": 1585618392.8983927, "_step": 428}
{"Episode reward": -99.52542404164421, "Episode length": 999, "Policy Loss": -0.32976555824279785, "Value Loss": 0.05365673452615738, "_runtime": 21024.8444750309, "_timestamp": 1585618394.4773445, "_step": 429}
{"Episode reward": -99.75665858206199, "Episode length": 999, "Policy Loss": -0.31427648663520813, "Value Loss": 0.028750881552696228, "_runtime": 21026.416253566742, "_timestamp": 1585618396.049123, "_step": 430}
{"Episode reward": -99.70227245858267, "Episode length": 999, "Policy Loss": -0.29839131236076355, "Value Loss": 0.019375823438167572, "_runtime": 21027.96522974968, "_timestamp": 1585618397.5980992, "_step": 431}
{"Episode reward": -99.77408838835406, "Episode length": 999, "Policy Loss": -0.28321412205696106, "Value Loss": 0.028860731050372124, "_runtime": 21029.539140462875, "_timestamp": 1585618399.17201, "_step": 432}
{"Episode reward": -99.4433076353963, "Episode length": 999, "Policy Loss": -0.2620640695095062, "Value Loss": 0.03177976608276367, "_runtime": 21031.12581706047, "_timestamp": 1585618400.7586865, "_step": 433}
{"Episode reward": -99.65094070819184, "Episode length": 999, "Policy Loss": -0.25383153557777405, "Value Loss": 0.097963847219944, "_runtime": 21032.166826725006, "_timestamp": 1585618401.7996962, "_step": 434}
{"Episode reward": 34.09657081216521, "Episode length": 660, "Policy Loss": 0.7005073428153992, "Value Loss": 14.954549789428711, "_runtime": 21032.960148334503, "_timestamp": 1585618402.5930178, "_step": 435}
{"Episode reward": 51.197075620921844, "Episode length": 490, "Policy Loss": 1.0523960590362549, "Value Loss": 20.220918655395508, "_runtime": 21034.543077230453, "_timestamp": 1585618404.1759467, "_step": 436}
{"Episode reward": -99.68307817261527, "Episode length": 999, "Policy Loss": -0.21519450843334198, "Value Loss": 0.03258207440376282, "_runtime": 21035.60634803772, "_timestamp": 1585618405.2392175, "_step": 437}
{"Episode reward": 32.01930156815173, "Episode length": 680, "Policy Loss": 0.6823159456253052, "Value Loss": 14.561409950256348, "_runtime": 21037.120247602463, "_timestamp": 1585618406.753117, "_step": 438}
{"Episode reward": -99.34981875747772, "Episode length": 999, "Policy Loss": -0.17192967236042023, "Value Loss": 0.03773336112499237, "_runtime": 21038.7010948658, "_timestamp": 1585618408.3339643, "_step": 439}
{"Episode reward": -99.20858032859843, "Episode length": 999, "Policy Loss": -0.1665528267621994, "Value Loss": 0.02880539372563362, "_runtime": 21040.28182578087, "_timestamp": 1585618409.9146953, "_step": 440}
{"Episode reward": -99.6995212187744, "Episode length": 999, "Policy Loss": -0.14770381152629852, "Value Loss": 0.051884207874536514, "_runtime": 21041.30581355095, "_timestamp": 1585618410.938683, "_step": 441}
{"Episode reward": 35.66122075314571, "Episode length": 644, "Policy Loss": 0.7776076793670654, "Value Loss": 15.363815307617188, "_runtime": 21041.880173921585, "_timestamp": 1585618411.5130434, "_step": 442}
{"Episode reward": 65.79999999999978, "Episode length": 342, "Policy Loss": 1.5675565004348755, "Value Loss": 28.814716339111328, "_runtime": 21042.58047389984, "_timestamp": 1585618412.2133434, "_step": 443}
{"Episode reward": 56.06185498600791, "Episode length": 440, "Policy Loss": 1.1593314409255981, "Value Loss": 22.467100143432617, "_runtime": 21044.131299734116, "_timestamp": 1585618413.7641692, "_step": 444}
{"Episode reward": -99.89751924136515, "Episode length": 999, "Policy Loss": -0.21786096692085266, "Value Loss": 0.08728190511465073, "_runtime": 21045.64364552498, "_timestamp": 1585618415.276515, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.23666715621948242, "Value Loss": 0.0449494868516922, "_runtime": 21047.164754152298, "_timestamp": 1585618416.7976236, "_step": 446}
{"Episode reward": -99.59292275940976, "Episode length": 999, "Policy Loss": -0.26137226819992065, "Value Loss": 0.022885426878929138, "_runtime": 21048.509246349335, "_timestamp": 1585618418.1421158, "_step": 447}
{"Episode reward": 14.603836384905136, "Episode length": 856, "Policy Loss": 0.41841182112693787, "Value Loss": 11.537030220031738, "_runtime": 21050.073628902435, "_timestamp": 1585618419.7064984, "_step": 448}
{"Episode reward": -99.73443295867044, "Episode length": 999, "Policy Loss": -0.30131077766418457, "Value Loss": 0.13568048179149628, "_runtime": 21051.62845349312, "_timestamp": 1585618421.261323, "_step": 449}
{"Episode reward": -99.55751711655618, "Episode length": 999, "Policy Loss": -0.2715877294540405, "Value Loss": 0.06538086384534836, "_runtime": 21052.176931619644, "_timestamp": 1585618421.809801, "_step": 450}
{"Episode reward": 66.6630166910354, "Episode length": 334, "Policy Loss": 2.0700767040252686, "Value Loss": 29.679725646972656, "_runtime": 21053.740825891495, "_timestamp": 1585618423.3736954, "_step": 451}
{"Episode reward": -99.7804556517906, "Episode length": 999, "Policy Loss": -0.28049278259277344, "Value Loss": 0.03607584163546562, "_runtime": 21055.312942266464, "_timestamp": 1585618424.9458117, "_step": 452}
{"Episode reward": -99.80606598055316, "Episode length": 999, "Policy Loss": -0.25325244665145874, "Value Loss": 0.04141818732023239, "_runtime": 21056.828548908234, "_timestamp": 1585618426.4614184, "_step": 453}
{"Episode reward": -99.68333436364635, "Episode length": 999, "Policy Loss": -0.24282300472259521, "Value Loss": 0.017527109012007713, "_runtime": 21057.87674689293, "_timestamp": 1585618427.5096164, "_step": 454}
{"Episode reward": 33.397169415559134, "Episode length": 667, "Policy Loss": 0.6952948570251465, "Value Loss": 14.785441398620605, "_runtime": 21059.44211101532, "_timestamp": 1585618429.0749805, "_step": 455}
{"Episode reward": -99.5845711059447, "Episode length": 999, "Policy Loss": -0.20633049309253693, "Value Loss": 0.0718708261847496, "_runtime": 21060.511700630188, "_timestamp": 1585618430.14457, "_step": 456}
{"Episode reward": 31.999999999999588, "Episode length": 680, "Policy Loss": 0.7749413251876831, "Value Loss": 14.51402473449707, "_runtime": 21061.590769052505, "_timestamp": 1585618431.2236385, "_step": 457}
{"Episode reward": 31.209687046100953, "Episode length": 691, "Policy Loss": 0.6596857905387878, "Value Loss": 14.406590461730957, "_runtime": 21063.16541171074, "_timestamp": 1585618432.7982812, "_step": 458}
{"Episode reward": -99.66694126506198, "Episode length": 999, "Policy Loss": -0.22000537812709808, "Value Loss": 0.023511378094553947, "_runtime": 21064.73984336853, "_timestamp": 1585618434.3727129, "_step": 459}
{"Episode reward": -99.81193524526758, "Episode length": 999, "Policy Loss": -0.2239857316017151, "Value Loss": 0.023039182648062706, "_runtime": 21066.112023115158, "_timestamp": 1585618435.7448926, "_step": 460}
{"Episode reward": 11.257773182442932, "Episode length": 888, "Policy Loss": 0.44617128372192383, "Value Loss": 11.124584197998047, "_runtime": 21067.68269252777, "_timestamp": 1585618437.315562, "_step": 461}
{"Episode reward": -99.64810776305247, "Episode length": 999, "Policy Loss": -0.24118366837501526, "Value Loss": 0.006855164188891649, "_runtime": 21069.25303387642, "_timestamp": 1585618438.8859034, "_step": 462}
{"Episode reward": -99.8413083154927, "Episode length": 999, "Policy Loss": -0.2513805627822876, "Value Loss": 0.008098209276795387, "_runtime": 21069.73889684677, "_timestamp": 1585618439.3717663, "_step": 463}
{"Episode reward": 71.60274571893956, "Episode length": 285, "Policy Loss": 1.8133718967437744, "Value Loss": 34.51813507080078, "_runtime": 21071.311730146408, "_timestamp": 1585618440.9445996, "_step": 464}
{"Episode reward": -99.6546164725253, "Episode length": 999, "Policy Loss": -0.28591158986091614, "Value Loss": 0.041757721453905106, "_runtime": 21072.875445842743, "_timestamp": 1585618442.5083153, "_step": 465}
{"Episode reward": -99.48651746739496, "Episode length": 999, "Policy Loss": -0.28859320282936096, "Value Loss": 0.013340647332370281, "_runtime": 21073.47958636284, "_timestamp": 1585618443.1124558, "_step": 466}
{"Episode reward": 60.062368956621214, "Episode length": 400, "Policy Loss": 1.1923646926879883, "Value Loss": 24.590293884277344, "_runtime": 21075.051884412766, "_timestamp": 1585618444.684754, "_step": 467}
{"Episode reward": -99.62477010405719, "Episode length": 999, "Policy Loss": -0.296049028635025, "Value Loss": 0.04235987737774849, "_runtime": 21076.62794971466, "_timestamp": 1585618446.2608192, "_step": 468}
{"Episode reward": 0.12618023985554316, "Episode length": 999, "Policy Loss": 0.5907784700393677, "Value Loss": 9.868538856506348, "_runtime": 21078.14107632637, "_timestamp": 1585618447.7739458, "_step": 469}
{"Episode reward": -99.75298178765085, "Episode length": 999, "Policy Loss": -0.35092511773109436, "Value Loss": 0.11420460790395737, "_runtime": 21079.70723414421, "_timestamp": 1585618449.3401036, "_step": 470}
{"Episode reward": -99.71262801657873, "Episode length": 999, "Policy Loss": -0.3241329789161682, "Value Loss": 0.1002177968621254, "_runtime": 21081.27897810936, "_timestamp": 1585618450.9118476, "_step": 471}
{"Episode reward": -99.6532337044352, "Episode length": 999, "Policy Loss": -0.322412371635437, "Value Loss": 0.023816939443349838, "_runtime": 21082.49999165535, "_timestamp": 1585618452.1328611, "_step": 472}
{"Episode reward": 21.970493633276945, "Episode length": 781, "Policy Loss": 0.5084683299064636, "Value Loss": 12.617507934570312, "_runtime": 21084.086651325226, "_timestamp": 1585618453.7195208, "_step": 473}
{"Episode reward": -99.70376577928988, "Episode length": 999, "Policy Loss": -0.30023595690727234, "Value Loss": 0.009737840853631496, "_runtime": 21084.458070516586, "_timestamp": 1585618454.09094, "_step": 474}
{"Episode reward": 80.3, "Episode length": 197, "Policy Loss": 2.9191901683807373, "Value Loss": 49.751319885253906, "_runtime": 21086.013862371445, "_timestamp": 1585618455.6467319, "_step": 475}
{"Episode reward": -99.6062631381196, "Episode length": 999, "Policy Loss": -0.32469335198402405, "Value Loss": 0.05759932100772858, "_runtime": 21086.65635037422, "_timestamp": 1585618456.2892199, "_step": 476}
{"Episode reward": 61.59999999999973, "Episode length": 384, "Policy Loss": 2.3869612216949463, "Value Loss": 25.59547996520996, "_runtime": 21087.85833787918, "_timestamp": 1585618457.4912074, "_step": 477}
{"Episode reward": 23.367517535411835, "Episode length": 770, "Policy Loss": 0.3560140132904053, "Value Loss": 12.907273292541504, "_runtime": 21089.44031214714, "_timestamp": 1585618459.0731816, "_step": 478}
{"Episode reward": -99.83980798183335, "Episode length": 999, "Policy Loss": -0.3673306703567505, "Value Loss": 0.060305316001176834, "_runtime": 21090.96883916855, "_timestamp": 1585618460.6017087, "_step": 479}
{"Episode reward": -99.74605201261444, "Episode length": 999, "Policy Loss": -0.37849190831184387, "Value Loss": 0.05811244621872902, "_runtime": 21091.855838298798, "_timestamp": 1585618461.4887078, "_step": 480}
{"Episode reward": 44.44521146651772, "Episode length": 558, "Policy Loss": 0.7702562808990479, "Value Loss": 17.68146514892578, "_runtime": 21092.921565771103, "_timestamp": 1585618462.5544353, "_step": 481}
{"Episode reward": 32.6877943836148, "Episode length": 675, "Policy Loss": 0.6091973185539246, "Value Loss": 14.622154235839844, "_runtime": 21094.474349737167, "_timestamp": 1585618464.1072192, "_step": 482}
{"Episode reward": -99.81463468747539, "Episode length": 999, "Policy Loss": -0.40564337372779846, "Value Loss": 0.07993900030851364, "_runtime": 21095.18013048172, "_timestamp": 1585618464.813, "_step": 483}
{"Episode reward": 54.66598883531951, "Episode length": 454, "Policy Loss": 0.9074017405509949, "Value Loss": 21.7137393951416, "_runtime": 21096.729758501053, "_timestamp": 1585618466.362628, "_step": 484}
{"Episode reward": -99.65320046518907, "Episode length": 999, "Policy Loss": -0.3985460698604584, "Value Loss": 0.16268078982830048, "_runtime": 21097.3043320179, "_timestamp": 1585618466.9372015, "_step": 485}
{"Episode reward": 65.67961891390712, "Episode length": 344, "Policy Loss": 1.6626423597335815, "Value Loss": 28.504179000854492, "_runtime": 21098.835829496384, "_timestamp": 1585618468.468699, "_step": 486}
{"Episode reward": -99.7150658369167, "Episode length": 999, "Policy Loss": -0.4637397825717926, "Value Loss": 0.16423429548740387, "_runtime": 21100.407953977585, "_timestamp": 1585618470.0408235, "_step": 487}
{"Episode reward": -99.8780894320677, "Episode length": 999, "Policy Loss": -0.4788702130317688, "Value Loss": 0.1515287458896637, "_runtime": 21101.40290570259, "_timestamp": 1585618471.0357752, "_step": 488}
{"Episode reward": 34.33930057394264, "Episode length": 658, "Policy Loss": 0.572015106678009, "Value Loss": 15.041909217834473, "_runtime": 21102.953622817993, "_timestamp": 1585618472.5864923, "_step": 489}
{"Episode reward": -99.79542409668072, "Episode length": 999, "Policy Loss": -0.4251873195171356, "Value Loss": 0.0942673608660698, "_runtime": 21103.887248516083, "_timestamp": 1585618473.520118, "_step": 490}
{"Episode reward": 42.333860339130666, "Episode length": 577, "Policy Loss": 0.6655786633491516, "Value Loss": 17.11320686340332, "_runtime": 21105.44526195526, "_timestamp": 1585618475.0781314, "_step": 491}
{"Episode reward": -99.69375387108748, "Episode length": 999, "Policy Loss": -0.3714601993560791, "Value Loss": 0.05448851361870766, "_runtime": 21106.051501750946, "_timestamp": 1585618475.6843712, "_step": 492}
{"Episode reward": 64.49094296412053, "Episode length": 356, "Policy Loss": 1.317771315574646, "Value Loss": 27.496091842651367, "_runtime": 21107.606544733047, "_timestamp": 1585618477.2394142, "_step": 493}
{"Episode reward": -99.79098357765331, "Episode length": 999, "Policy Loss": -0.3358578681945801, "Value Loss": 0.19999970495700836, "_runtime": 21109.18981862068, "_timestamp": 1585618478.822688, "_step": 494}
{"Episode reward": -99.66454246750082, "Episode length": 999, "Policy Loss": -0.30228886008262634, "Value Loss": 0.0339837446808815, "_runtime": 21110.71079969406, "_timestamp": 1585618480.3436692, "_step": 495}
{"Episode reward": -99.89973772102827, "Episode length": 999, "Policy Loss": -0.23960669338703156, "Value Loss": 0.10821287333965302, "_runtime": 21112.340294599533, "_timestamp": 1585618481.973164, "_step": 496}
{"Episode reward": -99.7043246211703, "Episode length": 999, "Policy Loss": -0.2574452757835388, "Value Loss": 0.037593476474285126, "_runtime": 21113.291554927826, "_timestamp": 1585618482.9244244, "_step": 497}
{"Episode reward": 41.07965128559098, "Episode length": 590, "Policy Loss": 0.9273549318313599, "Value Loss": 16.6591739654541, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442, -0.12798291444778442]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 1.0, 0.0, 1.0], "bins": [-6.036052703857422, -5.932949542999268, -5.829845905303955, -5.726742744445801, -5.623639106750488, -5.520535945892334, -5.41743278503418, -5.314329147338867, -5.211225986480713, -5.1081223487854, -5.005019187927246, -4.901915550231934, -4.798812389373779, -4.695709228515625, -4.5926055908203125, -4.489502429962158, -4.386399269104004, -4.283295631408691, -4.180192470550537, -4.077088832855225, -3.9739856719970703, -3.870882272720337, -3.7677788734436035, -3.66467547416687, -3.5615720748901367, -3.4584689140319824, -3.355365514755249, -3.2522621154785156, -3.1491587162017822, -3.046055316925049, -2.9429521560668945, -2.839848756790161, -2.7367453575134277, -2.6336419582366943, -2.530538558959961, -2.4274353981018066, -2.3243319988250732, -2.22122859954834, -2.1181252002716064, -2.015021800994873, -1.9119186401367188, -1.8088150024414062, -1.705711841583252, -1.6026086807250977, -1.4995050430297852, -1.3964018821716309, -1.2932982444763184, -1.190195083618164, -1.0870914459228516, -0.9839882850646973, -0.880885124206543, -0.7777814865112305, -0.6746783256530762, -0.5715746879577637, -0.4684715270996094, -0.3653683662414551, -0.2622647285461426, -0.15916156768798828, -0.05605792999267578, 0.047045230865478516, 0.1501483917236328, 0.2532520294189453, 0.3563551902770996, 0.4594588279724121, 0.5625619888305664]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.15160080790519714, -0.14872920513153076, -0.14585758745670319, -0.1429859697818756, -0.14011436700820923, -0.13724276423454285, -0.13437114655971527, -0.1314995288848877, -0.1286279261112213, -0.12575632333755493, -0.12288470566272736, -0.12001309543848038, -0.1171414852142334, -0.11426987498998642, -0.11139826476573944, -0.10852665454149246, -0.10565504431724548, -0.1027834340929985, -0.09991182386875153, -0.09704021364450455, -0.09416860342025757, -0.09129699319601059, -0.08842538297176361, -0.08555377274751663, -0.08268216252326965, -0.07981055229902267, -0.0769389420747757, -0.07406733185052872, -0.07119572162628174, -0.06832411140203476, -0.06545250117778778, -0.0625808909535408, -0.05970928072929382, -0.056837670505046844, -0.053966060280799866, -0.05109445005655289, -0.04822283983230591, -0.04535122960805893, -0.04247961938381195, -0.03960800915956497, -0.03673639893531799, -0.033864788711071014, -0.030993178486824036, -0.028121568262577057, -0.025249958038330078, -0.022378355264663696, -0.01950673758983612, -0.016635119915008545, -0.013763517141342163, -0.010891914367675781, -0.008020296692848206, -0.00514867901802063, -0.002277076244354248, 0.0005945265293121338, 0.0034661442041397095, 0.006337761878967285, 0.009209364652633667, 0.012080967426300049, 0.014952585101127625, 0.0178242027759552, 0.020695805549621582, 0.023567408323287964, 0.02643902599811554, 0.029310643672943115, 0.0321822464466095]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 5.0, 4.0, 4.0, 3.0, 8.0, 6.0, 10.0, 3.0, 14.0, 37.0, 226.0, 14.0, 31.0, 16.0, 1.0, 12.0, 7.0, 18.0, 17.0, 6.0, 16.0, 15.0, 9.0, 7.0], "bins": [-0.6498768329620361, -0.637071430683136, -0.6242660880088806, -0.6114606857299805, -0.5986552834510803, -0.5858498811721802, -0.5730445384979248, -0.5602391362190247, -0.5474337339401245, -0.5346283912658691, -0.521822988986969, -0.5090175867080688, -0.4962122142314911, -0.48340684175491333, -0.4706014394760132, -0.45779603719711304, -0.4449906647205353, -0.4321852922439575, -0.4193798899650574, -0.4065744876861572, -0.39376911520957947, -0.3809637427330017, -0.36815834045410156, -0.3553529679775238, -0.34254759550094604, -0.3297421932220459, -0.31693682074546814, -0.304131418466568, -0.29132604598999023, -0.2785206437110901, -0.26571527123451233, -0.2529098689556122, -0.24010449647903442, -0.22729912400245667, -0.21449372172355652, -0.20168834924697876, -0.1888829469680786, -0.17607757449150085, -0.1632721722126007, -0.15046679973602295, -0.1376613974571228, -0.12485605478286743, -0.11205065250396729, -0.09924525022506714, -0.08643984794616699, -0.07363450527191162, -0.060829102993011475, -0.04802370071411133, -0.03521835803985596, -0.02241295576095581, -0.009607553482055664, 0.0031978487968444824, 0.016003191471099854, 0.02880859375, 0.041613996028900146, 0.05441939830780029, 0.06722474098205566, 0.08003014326095581, 0.09283554553985596, 0.10564088821411133, 0.11844629049301147, 0.13125169277191162, 0.14405709505081177, 0.15686243772506714, 0.16966784000396729]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 0.0, 5.0], "bins": [-1.0694632530212402, -1.0505257844924927, -1.0315884351730347, -1.012650966644287, -0.9937134981155396, -0.9747760891914368, -0.955838680267334, -0.9369012117385864, -0.9179638028144836, -0.8990263938903809, -0.8800889253616333, -0.8611515164375305, -0.8422141075134277, -0.8232766389846802, -0.8043392300605774, -0.7854018211364746, -0.766464352607727, -0.7475268840789795, -0.7285894751548767, -0.7096520662307739, -0.6907145977020264, -0.6717771887779236, -0.6528397798538208, -0.6339023113250732, -0.6149649024009705, -0.5960274934768677, -0.5770900249481201, -0.5581526160240173, -0.5392152070999146, -0.520277738571167, -0.5013403296470642, -0.48240286111831665, -0.46346545219421387, -0.4445280432701111, -0.4255905747413635, -0.40665316581726074, -0.3877156972885132, -0.3687782883644104, -0.3498408794403076, -0.33090341091156006, -0.3119660019874573, -0.2930285930633545, -0.27409112453460693, -0.25515371561050415, -0.23621630668640137, -0.2172788381576538, -0.19834142923355103, -0.17940396070480347, -0.16046655178070068, -0.1415291428565979, -0.12259167432785034, -0.10365426540374756, -0.084716796875, -0.06577944755554199, -0.046841979026794434, -0.027904510498046875, -0.008967161178588867, 0.009970307350158691, 0.02890777587890625, 0.04784524440765381, 0.06678259372711182, 0.08572006225585938, 0.10465753078460693, 0.12359488010406494, 0.1425323486328125]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 5.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 10.0, 5.0, 2.0, 3.0, 3.0, 6.0, 3.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.661833643913269, -0.6241885423660278, -0.5865433812141418, -0.5488982200622559, -0.5112531185150146, -0.47360798716545105, -0.43596285581588745, -0.39831772446632385, -0.36067259311676025, -0.32302746176719666, -0.28538233041763306, -0.24773719906806946, -0.21009206771850586, -0.17244693636894226, -0.13480180501937866, -0.09715664386749268, -0.059511542320251465, -0.021866440773010254, 0.015778720378875732, 0.05342388153076172, 0.09106898307800293, 0.12871408462524414, 0.16635924577713013, 0.2040044069290161, 0.24164950847625732, 0.27929461002349854, 0.3169397711753845, 0.3545849323272705, 0.3922300338745117, 0.42987513542175293, 0.4675203561782837, 0.5051654577255249, 0.5428105592727661, 0.5804556608200073, 0.6181007623672485, 0.6557459831237793, 0.6933910846710205, 0.7310361862182617, 0.7686814069747925, 0.8063265085220337, 0.8439716100692749, 0.8816167116165161, 0.9192618131637573, 0.9569070339202881, 0.9945521354675293, 1.0321972370147705, 1.0698424577713013, 1.1074875593185425, 1.1451326608657837, 1.182777762413025, 1.2204228639602661, 1.2580680847167969, 1.295713186264038, 1.3333582878112793, 1.37100350856781, 1.4086486101150513, 1.4462937116622925, 1.4839388132095337, 1.521583914756775, 1.5592290163040161, 1.5968743562698364, 1.6345194578170776, 1.6721645593643188, 1.70980966091156, 1.7474547624588013]}, "_runtime": 21114.535390853882, "_timestamp": 1585618484.1682603, "_step": 498}
{"Episode reward": 21.311886935978166, "Episode length": 789, "Policy Loss": 0.5519461631774902, "Value Loss": 12.572649002075195, "_runtime": 21114.535390853882, "_timestamp": 1585618484.1682603, "_step": 499}
