{"Episode reward": -41.98829724930244, "Episode length": 999, "Policy Loss": -0.030715471133589745, "Value Loss": 0.007564297877252102, "_runtime": 3980.004874229431, "_timestamp": 1585601349.6377437, "_step": 0}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.820467472076416, "Value Loss": 4.5502495765686035, "_runtime": 3981.5280735492706, "_timestamp": 1585601351.160943, "_step": 1}
{"Episode reward": -93.90434327858978, "Episode length": 999, "Policy Loss": -4.155887603759766, "Value Loss": 3293.364013671875, "_runtime": 3983.102970600128, "_timestamp": 1585601352.73584, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -26.44508171081543, "Value Loss": 230.49818420410156, "_runtime": 3984.6366255283356, "_timestamp": 1585601354.269495, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.636917591094971, "Value Loss": 125.14673614501953, "_runtime": 3986.1608114242554, "_timestamp": 1585601355.793681, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3900954723358154, "Value Loss": 42.2879753112793, "_runtime": 3987.739761352539, "_timestamp": 1585601357.3726308, "_step": 5}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0236246585845947, "Value Loss": 1341.599365234375, "_runtime": 3989.2746572494507, "_timestamp": 1585601358.9075267, "_step": 6}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5160712003707886, "Value Loss": 9.122735977172852, "_runtime": 3990.8066523075104, "_timestamp": 1585601360.4395218, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -6.306057929992676, "Value Loss": 305.55865478515625, "_runtime": 3992.3890686035156, "_timestamp": 1585601362.021938, "_step": 8}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 31.949758529663086, "Value Loss": 887.3587036132812, "_runtime": 3992.8657596111298, "_timestamp": 1585601362.498629, "_step": 9}
{"Episode reward": 79.48297775248025, "Episode length": 273, "Policy Loss": 5.564635753631592, "Value Loss": 649.6781616210938, "_runtime": 3994.3977375030518, "_timestamp": 1585601364.030607, "_step": 10}
{"Episode reward": -91.66231054664152, "Episode length": 999, "Policy Loss": 0.2798660397529602, "Value Loss": 7.47769021987915, "_runtime": 3995.9759702682495, "_timestamp": 1585601365.6088398, "_step": 11}
{"Episode reward": -94.02112397730848, "Episode length": 999, "Policy Loss": -0.2871817350387573, "Value Loss": 46.78717041015625, "_runtime": 3997.370024204254, "_timestamp": 1585601367.0028937, "_step": 12}
{"Episode reward": 11.908206366775218, "Episode length": 933, "Policy Loss": -1.2398465871810913, "Value Loss": 82.4275131225586, "_runtime": 3998.91730093956, "_timestamp": 1585601368.5501704, "_step": 13}
{"Episode reward": -97.45823555104629, "Episode length": 999, "Policy Loss": -0.3152274489402771, "Value Loss": 5.206149101257324, "_runtime": 4000.487872838974, "_timestamp": 1585601370.1207423, "_step": 14}
{"Episode reward": -98.60859187101184, "Episode length": 999, "Policy Loss": 1.53565514087677, "Value Loss": 100.6858901977539, "_runtime": 4002.0260047912598, "_timestamp": 1585601371.6588743, "_step": 15}
{"Episode reward": -99.18987515904439, "Episode length": 999, "Policy Loss": -0.6298550963401794, "Value Loss": 1.1263350248336792, "_runtime": 4003.577909708023, "_timestamp": 1585601373.2107792, "_step": 16}
{"Episode reward": -99.13385982401024, "Episode length": 999, "Policy Loss": -1.0092175006866455, "Value Loss": 3.1384174823760986, "_runtime": 4005.1735973358154, "_timestamp": 1585601374.8064668, "_step": 17}
{"Episode reward": -99.0104790409075, "Episode length": 999, "Policy Loss": -0.5435894131660461, "Value Loss": 7.73276948928833, "_runtime": 4005.810081243515, "_timestamp": 1585601375.4429507, "_step": 18}
{"Episode reward": 62.18814319818923, "Episode length": 390, "Policy Loss": -0.9908633232116699, "Value Loss": 83.38919067382812, "_runtime": 4007.3567066192627, "_timestamp": 1585601376.989576, "_step": 19}
{"Episode reward": -98.88442702743106, "Episode length": 999, "Policy Loss": 0.06534871459007263, "Value Loss": 6.815952301025391, "_runtime": 4008.9244005680084, "_timestamp": 1585601378.55727, "_step": 20}
{"Episode reward": 1.3071557050267302, "Episode length": 993, "Policy Loss": 1.7848743200302124, "Value Loss": 18.947072982788086, "_runtime": 4010.4167325496674, "_timestamp": 1585601380.049602, "_step": 21}
{"Episode reward": -99.87066580867837, "Episode length": 999, "Policy Loss": 3.022841215133667, "Value Loss": 17.054412841796875, "_runtime": 4011.949354171753, "_timestamp": 1585601381.5822237, "_step": 22}
{"Episode reward": 2.080959165347977, "Episode length": 987, "Policy Loss": 1.8477369546890259, "Value Loss": 15.86257266998291, "_runtime": 4013.5238020420074, "_timestamp": 1585601383.1566715, "_step": 23}
{"Episode reward": -99.45745070062122, "Episode length": 999, "Policy Loss": 2.099080801010132, "Value Loss": 0.7187557816505432, "_runtime": 4015.0826346874237, "_timestamp": 1585601384.7155042, "_step": 24}
{"Episode reward": -99.34810166345568, "Episode length": 999, "Policy Loss": 2.0532267093658447, "Value Loss": 1.475561499595642, "_runtime": 4016.6469321250916, "_timestamp": 1585601386.2798016, "_step": 25}
{"Episode reward": -99.59889785022176, "Episode length": 999, "Policy Loss": 1.3197283744812012, "Value Loss": 5.995044231414795, "_runtime": 4018.2090151309967, "_timestamp": 1585601387.8418846, "_step": 26}
{"Episode reward": -99.46187176739485, "Episode length": 999, "Policy Loss": 1.3797526359558105, "Value Loss": 2.682051658630371, "_runtime": 4019.7640426158905, "_timestamp": 1585601389.396912, "_step": 27}
{"Episode reward": -99.80645924210408, "Episode length": 999, "Policy Loss": 1.5154730081558228, "Value Loss": 0.8900812864303589, "_runtime": 4021.32022857666, "_timestamp": 1585601390.953098, "_step": 28}
{"Episode reward": -99.58426116293833, "Episode length": 999, "Policy Loss": 1.3146425485610962, "Value Loss": 2.9239792823791504, "_runtime": 4022.8946413993835, "_timestamp": 1585601392.527511, "_step": 29}
{"Episode reward": -99.73065609105403, "Episode length": 999, "Policy Loss": 1.1316663026809692, "Value Loss": 2.6931161880493164, "_runtime": 4024.4603996276855, "_timestamp": 1585601394.093269, "_step": 30}
{"Episode reward": -99.54154033272505, "Episode length": 999, "Policy Loss": 0.5649488568305969, "Value Loss": 0.7901447415351868, "_runtime": 4026.0247201919556, "_timestamp": 1585601395.6575897, "_step": 31}
{"Episode reward": -99.6356385172913, "Episode length": 999, "Policy Loss": -0.043188635259866714, "Value Loss": 1.7609481811523438, "_runtime": 4027.188976049423, "_timestamp": 1585601396.8218455, "_step": 32}
{"Episode reward": 25.470634037398455, "Episode length": 747, "Policy Loss": 0.874102771282196, "Value Loss": 17.589221954345703, "_runtime": 4028.788342475891, "_timestamp": 1585601398.421212, "_step": 33}
{"Episode reward": -99.61832415028337, "Episode length": 999, "Policy Loss": -0.1235566958785057, "Value Loss": 0.9392967820167542, "_runtime": 4030.356133699417, "_timestamp": 1585601399.9890032, "_step": 34}
{"Episode reward": -99.82581521741237, "Episode length": 999, "Policy Loss": -0.3730330169200897, "Value Loss": 0.7421537041664124, "_runtime": 4031.9081659317017, "_timestamp": 1585601401.5410354, "_step": 35}
{"Episode reward": -99.65467398699701, "Episode length": 999, "Policy Loss": -0.771564245223999, "Value Loss": 0.1507674753665924, "_runtime": 4033.131946325302, "_timestamp": 1585601402.7648158, "_step": 36}
{"Episode reward": 23.36204890641541, "Episode length": 778, "Policy Loss": 0.6284903287887573, "Value Loss": 14.642779350280762, "_runtime": 4034.525216817856, "_timestamp": 1585601404.1580863, "_step": 37}
{"Episode reward": 10.283980107914331, "Episode length": 899, "Policy Loss": -0.02291790395975113, "Value Loss": 11.541715621948242, "_runtime": 4035.053265810013, "_timestamp": 1585601404.6861353, "_step": 38}
{"Episode reward": 69.17766282738141, "Episode length": 310, "Policy Loss": 1.2496312856674194, "Value Loss": 33.728240966796875, "_runtime": 4036.599582672119, "_timestamp": 1585601406.2324522, "_step": 39}
{"Episode reward": -99.44839764912474, "Episode length": 999, "Policy Loss": -1.7145085334777832, "Value Loss": 0.07589677721261978, "_runtime": 4037.417570590973, "_timestamp": 1585601407.05044, "_step": 40}
{"Episode reward": 48.93154854577888, "Episode length": 520, "Policy Loss": -0.11907517910003662, "Value Loss": 18.548595428466797, "_runtime": 4038.9108562469482, "_timestamp": 1585601408.5437257, "_step": 41}
{"Episode reward": -99.4825626005463, "Episode length": 999, "Policy Loss": -1.9400323629379272, "Value Loss": 0.13068091869354248, "_runtime": 4040.4278008937836, "_timestamp": 1585601410.0606704, "_step": 42}
{"Episode reward": 3.090409062804028, "Episode length": 970, "Policy Loss": -1.2461282014846802, "Value Loss": 10.067320823669434, "_runtime": 4041.0124609470367, "_timestamp": 1585601410.6453304, "_step": 43}
{"Episode reward": 63.58193729050244, "Episode length": 367, "Policy Loss": -0.09458662569522858, "Value Loss": 24.999732971191406, "_runtime": 4041.849217891693, "_timestamp": 1585601411.4820874, "_step": 44}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": -0.49251070618629456, "Value Loss": 18.56048011779785, "_runtime": 4043.401332616806, "_timestamp": 1585601413.034202, "_step": 45}
{"Episode reward": -99.83763759592408, "Episode length": 999, "Policy Loss": -1.8541697263717651, "Value Loss": 0.06761076301336288, "_runtime": 4044.6396420001984, "_timestamp": 1585601414.2725115, "_step": 46}
{"Episode reward": 17.591305618076802, "Episode length": 828, "Policy Loss": -0.885867714881897, "Value Loss": 10.759716033935547, "_runtime": 4045.8755609989166, "_timestamp": 1585601415.5084305, "_step": 47}
{"Episode reward": 18.506176978035953, "Episode length": 821, "Policy Loss": -0.7042053937911987, "Value Loss": 11.063249588012695, "_runtime": 4047.435882091522, "_timestamp": 1585601417.0687516, "_step": 48}
{"Episode reward": -99.74057147092978, "Episode length": 999, "Policy Loss": -1.4581459760665894, "Value Loss": 0.041423313319683075, "_runtime": 4048.965500831604, "_timestamp": 1585601418.5983703, "_step": 49}
{"Episode reward": -99.75105379577734, "Episode length": 999, "Policy Loss": -1.2496577501296997, "Value Loss": 0.03177518770098686, "_runtime": 4050.022388458252, "_timestamp": 1585601419.655258, "_step": 50}
{"Episode reward": 33.12582192871277, "Episode length": 680, "Policy Loss": -0.13187846541404724, "Value Loss": 12.572935104370117, "_runtime": 4051.186775445938, "_timestamp": 1585601420.819645, "_step": 51}
{"Episode reward": 28.192536955693313, "Episode length": 719, "Policy Loss": 0.17155104875564575, "Value Loss": 13.889113426208496, "_runtime": 4052.753499507904, "_timestamp": 1585601422.386369, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7121168971061707, "Value Loss": 0.009916375391185284, "_runtime": 4054.2361149787903, "_timestamp": 1585601423.8689845, "_step": 53}
{"Episode reward": 4.122811377701595, "Episode length": 959, "Policy Loss": 0.1885768473148346, "Value Loss": 10.41739559173584, "_runtime": 4054.639375925064, "_timestamp": 1585601424.2722454, "_step": 54}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": 2.706580400466919, "Value Loss": 42.875450134277344, "_runtime": 4056.2075459957123, "_timestamp": 1585601425.8404155, "_step": 55}
{"Episode reward": -99.74377128416533, "Episode length": 999, "Policy Loss": -0.3311838209629059, "Value Loss": 0.002175368834286928, "_runtime": 4057.5070312023163, "_timestamp": 1585601427.1399007, "_step": 56}
{"Episode reward": 17.590520252677635, "Episode length": 828, "Policy Loss": 0.6656380891799927, "Value Loss": 12.069426536560059, "_runtime": 4059.001953125, "_timestamp": 1585601428.6348226, "_step": 57}
{"Episode reward": -99.63888446623467, "Episode length": 999, "Policy Loss": -0.24118414521217346, "Value Loss": 0.0012049806537106633, "_runtime": 4060.5854375362396, "_timestamp": 1585601430.218307, "_step": 58}
{"Episode reward": -99.65742530806317, "Episode length": 999, "Policy Loss": -0.20796135067939758, "Value Loss": 0.0008885206771083176, "_runtime": 4061.8074357509613, "_timestamp": 1585601431.4403052, "_step": 59}
{"Episode reward": 22.458755315589343, "Episode length": 785, "Policy Loss": 0.7510474920272827, "Value Loss": 12.73335075378418, "_runtime": 4063.3613419532776, "_timestamp": 1585601432.9942114, "_step": 60}
{"Episode reward": -99.51681272295475, "Episode length": 999, "Policy Loss": -0.15477415919303894, "Value Loss": 0.0005283781210891902, "_runtime": 4063.883749485016, "_timestamp": 1585601433.516619, "_step": 61}
{"Episode reward": 69.7956812062241, "Episode length": 303, "Policy Loss": 2.316288709640503, "Value Loss": 32.99013137817383, "_runtime": 4065.440047979355, "_timestamp": 1585601435.0729175, "_step": 62}
{"Episode reward": -99.86809221210284, "Episode length": 999, "Policy Loss": -0.21216244995594025, "Value Loss": 0.0008697788580320776, "_runtime": 4066.92027425766, "_timestamp": 1585601436.5531437, "_step": 63}
{"Episode reward": 6.231653949852614, "Episode length": 943, "Policy Loss": 0.502463698387146, "Value Loss": 10.598026275634766, "_runtime": 4067.958915233612, "_timestamp": 1585601437.5917847, "_step": 64}
{"Episode reward": 30.921009956951835, "Episode length": 691, "Policy Loss": 0.6954150199890137, "Value Loss": 14.460439682006836, "_runtime": 4069.0632660388947, "_timestamp": 1585601438.6961355, "_step": 65}
{"Episode reward": 31.32667684322884, "Episode length": 693, "Policy Loss": 0.8543424010276794, "Value Loss": 14.41673755645752, "_runtime": 4070.6295986175537, "_timestamp": 1585601440.262468, "_step": 66}
{"Episode reward": -99.75786060686666, "Episode length": 999, "Policy Loss": -0.5066853761672974, "Value Loss": 0.0049902223981916904, "_runtime": 4072.1610612869263, "_timestamp": 1585601441.7939308, "_step": 67}
{"Episode reward": -99.8199255653643, "Episode length": 999, "Policy Loss": -0.5737563967704773, "Value Loss": 0.006481496151536703, "_runtime": 4073.708640098572, "_timestamp": 1585601443.3415096, "_step": 68}
{"Episode reward": -99.88483068833453, "Episode length": 999, "Policy Loss": -0.6229504942893982, "Value Loss": 0.007487448398023844, "_runtime": 4075.2985417842865, "_timestamp": 1585601444.9314113, "_step": 69}
{"Episode reward": -99.8973866851055, "Episode length": 999, "Policy Loss": -0.6457811594009399, "Value Loss": 0.007886730134487152, "_runtime": 4076.8648295402527, "_timestamp": 1585601446.497699, "_step": 70}
{"Episode reward": -99.78142685762002, "Episode length": 999, "Policy Loss": -0.6162176132202148, "Value Loss": 0.00765943480655551, "_runtime": 4077.7859008312225, "_timestamp": 1585601447.4187703, "_step": 71}
{"Episode reward": 42.49999999999946, "Episode length": 575, "Policy Loss": 0.6691340208053589, "Value Loss": 17.369274139404297, "_runtime": 4079.3557953834534, "_timestamp": 1585601448.9886649, "_step": 72}
{"Episode reward": -99.73637081161002, "Episode length": 999, "Policy Loss": -0.5792560577392578, "Value Loss": 0.006824379321187735, "_runtime": 4080.9262659549713, "_timestamp": 1585601450.5591354, "_step": 73}
{"Episode reward": -99.79833983899887, "Episode length": 999, "Policy Loss": -0.5739723443984985, "Value Loss": 0.006245004944503307, "_runtime": 4082.4611003398895, "_timestamp": 1585601452.0939698, "_step": 74}
{"Episode reward": -99.6706523902351, "Episode length": 999, "Policy Loss": -0.5097652077674866, "Value Loss": 0.005293155554682016, "_runtime": 4083.220778942108, "_timestamp": 1585601452.8536484, "_step": 75}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.099821925163269, "Value Loss": 21.481801986694336, "_runtime": 4084.7812712192535, "_timestamp": 1585601454.4141407, "_step": 76}
{"Episode reward": -99.77213019300113, "Episode length": 999, "Policy Loss": -0.4456552267074585, "Value Loss": 0.003907587844878435, "_runtime": 4086.3458952903748, "_timestamp": 1585601455.9787648, "_step": 77}
{"Episode reward": -99.7868991795215, "Episode length": 999, "Policy Loss": -0.4105006158351898, "Value Loss": 0.0034141498617827892, "_runtime": 4087.87086558342, "_timestamp": 1585601457.503735, "_step": 78}
{"Episode reward": -99.72217239388708, "Episode length": 999, "Policy Loss": -0.3742222785949707, "Value Loss": 0.0027524197939783335, "_runtime": 4089.030506849289, "_timestamp": 1585601458.6633763, "_step": 79}
{"Episode reward": 26.599999999999895, "Episode length": 734, "Policy Loss": 0.7495540380477905, "Value Loss": 13.61371898651123, "_runtime": 4090.6001377105713, "_timestamp": 1585601460.2330072, "_step": 80}
{"Episode reward": -99.80090281313612, "Episode length": 999, "Policy Loss": -0.3048083484172821, "Value Loss": 0.001760690938681364, "_runtime": 4092.171003341675, "_timestamp": 1585601461.8038728, "_step": 81}
{"Episode reward": -99.73492199634062, "Episode length": 999, "Policy Loss": -0.26535817980766296, "Value Loss": 0.0014030084712430835, "_runtime": 4093.23966217041, "_timestamp": 1585601462.8725317, "_step": 82}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.8258687853813171, "Value Loss": 14.718374252319336, "_runtime": 4094.269874572754, "_timestamp": 1585601463.902744, "_step": 83}
{"Episode reward": 35.59999999999938, "Episode length": 644, "Policy Loss": 0.9407953023910522, "Value Loss": 15.519163131713867, "_runtime": 4095.8395807743073, "_timestamp": 1585601465.4724503, "_step": 84}
{"Episode reward": -99.8729635450975, "Episode length": 999, "Policy Loss": -0.2599828243255615, "Value Loss": 0.0012995741562917829, "_runtime": 4096.213243961334, "_timestamp": 1585601465.8461134, "_step": 85}
{"Episode reward": 77.89999999999996, "Episode length": 221, "Policy Loss": 2.9976725578308105, "Value Loss": 45.21535110473633, "_runtime": 4097.762249946594, "_timestamp": 1585601467.3951194, "_step": 86}
{"Episode reward": -99.27726409168436, "Episode length": 999, "Policy Loss": -0.389725923538208, "Value Loss": 0.0033107497729361057, "_runtime": 4098.29642367363, "_timestamp": 1585601467.9292932, "_step": 87}
{"Episode reward": 68.69999999999983, "Episode length": 313, "Policy Loss": 1.9386605024337769, "Value Loss": 31.90773582458496, "_runtime": 4099.835713148117, "_timestamp": 1585601469.4685826, "_step": 88}
{"Episode reward": -99.87482609012956, "Episode length": 999, "Policy Loss": -0.6893941164016724, "Value Loss": 0.009192063473165035, "_runtime": 4101.422573804855, "_timestamp": 1585601471.0554433, "_step": 89}
{"Episode reward": -99.81878183344239, "Episode length": 999, "Policy Loss": -0.8228657841682434, "Value Loss": 0.012782501056790352, "_runtime": 4102.31402015686, "_timestamp": 1585601471.9468896, "_step": 90}
{"Episode reward": 40.39192931286468, "Episode length": 598, "Policy Loss": 0.8446683287620544, "Value Loss": 16.696264266967773, "_runtime": 4103.247457265854, "_timestamp": 1585601472.8803267, "_step": 91}
{"Episode reward": 40.873085219057046, "Episode length": 593, "Policy Loss": 0.24016962945461273, "Value Loss": 16.83599853515625, "_runtime": 4104.829072237015, "_timestamp": 1585601474.4619417, "_step": 92}
{"Episode reward": -99.79702507110639, "Episode length": 999, "Policy Loss": -1.0593409538269043, "Value Loss": 0.021805807948112488, "_runtime": 4106.355352401733, "_timestamp": 1585601475.988222, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1032145023345947, "Value Loss": 0.02324320562183857, "_runtime": 4107.135663032532, "_timestamp": 1585601476.7685325, "_step": 94}
{"Episode reward": 50.27948216674806, "Episode length": 499, "Policy Loss": 0.46114009618759155, "Value Loss": 20.002338409423828, "_runtime": 4108.7014973163605, "_timestamp": 1585601478.3343668, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.063265323638916, "Value Loss": 0.02268940582871437, "_runtime": 4110.2654592990875, "_timestamp": 1585601479.8983288, "_step": 96}
{"Episode reward": -99.73492473906232, "Episode length": 999, "Policy Loss": -1.0297996997833252, "Value Loss": 0.020860834047198296, "_runtime": 4111.787478923798, "_timestamp": 1585601481.4203484, "_step": 97}
{"Episode reward": -99.76020043804752, "Episode length": 999, "Policy Loss": -0.950766921043396, "Value Loss": 0.017662350088357925, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626, -0.04011278226971626]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-1.5818195343017578, -1.5564768314361572, -1.5311341285705566, -1.505791425704956, -1.480448842048645, -1.4551061391830444, -1.4297634363174438, -1.4044207334518433, -1.3790780305862427, -1.353735327720642, -1.328392744064331, -1.3030500411987305, -1.2777073383331299, -1.2523646354675293, -1.2270219326019287, -1.2016792297363281, -1.1763365268707275, -1.150993824005127, -1.1256511211395264, -1.1003085374832153, -1.0749658346176147, -1.0496231317520142, -1.0242804288864136, -0.998937726020813, -0.9735950827598572, -0.9482523798942566, -0.922909677028656, -0.8975670337677002, -0.8722243309020996, -0.846881628036499, -0.8215389251708984, -0.7961962819099426, -0.770853579044342, -0.7455108761787415, -0.7201682329177856, -0.6948255300521851, -0.6694828271865845, -0.6441401243209839, -0.6187974810600281, -0.5934547781944275, -0.5681121349334717, -0.5427694320678711, -0.5174267292022705, -0.4920840263366699, -0.46674132347106934, -0.44139862060546875, -0.41605591773986816, -0.39071333408355713, -0.36537063121795654, -0.34002792835235596, -0.31468522548675537, -0.2893425226211548, -0.2639998197555542, -0.2386571168899536, -0.21331453323364258, -0.187971830368042, -0.1626291275024414, -0.13728642463684082, -0.11194372177124023, -0.08660101890563965, -0.06125831604003906, -0.03591573238372803, -0.010573029518127441, 0.014769673347473145, 0.04011237621307373]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06028341129422188, -0.058408547192811966, -0.056533683091402054, -0.05465881898999214, -0.05278395488858223, -0.05090909078717232, -0.049034230411052704, -0.04715936630964279, -0.04528450220823288, -0.04340963810682297, -0.041534774005413055, -0.03965990990400314, -0.03778504580259323, -0.03591018170118332, -0.03403531759977341, -0.032160453498363495, -0.030285589396953583, -0.02841072529554367, -0.02653586119413376, -0.024660997092723846, -0.022786132991313934, -0.020911268889904022, -0.01903640478849411, -0.017161540687084198, -0.015286680310964584, -0.013411816209554672, -0.01153695210814476, -0.009662088006734848, -0.007787223905324936, -0.005912359803915024, -0.004037495702505112, -0.0021626316010951996, -0.0002877674996852875, 0.0015870966017246246, 0.0034619607031345367, 0.005336824804544449, 0.007211688905954361, 0.009086553007364273, 0.010961417108774185, 0.012836281210184097, 0.01471114531159401, 0.01658600941300392, 0.018460873514413834, 0.020335737615823746, 0.022210601717233658, 0.02408546581864357, 0.025960329920053482, 0.027835194021463394, 0.02971005067229271, 0.03158491477370262, 0.033459778875112534, 0.035334642976522446, 0.03720950707793236, 0.03908437117934227, 0.04095923528075218, 0.042834099382162094, 0.044708963483572006, 0.04658382758498192, 0.04845869168639183, 0.05033355578780174, 0.052208419889211655, 0.05408328399062157, 0.05595814809203148, 0.05783301219344139, 0.0597078762948513]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 1.0, 5.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 4.0, 6.0, 2.0, 3.0, 1.0, 1.0, 5.0, 9.0, 10.0, 7.0, 11.0, 14.0, 13.0, 8.0, 6.0, 2.0, 1.0, 4.0, 29.0, 76.0, 44.0, 31.0, 32.0, 26.0, 14.0, 18.0, 9.0, 19.0, 19.0, 15.0, 18.0, 15.0, 15.0, 3.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.12205324321985245, -0.11825728416442871, -0.11446132510900497, -0.11066536605358124, -0.1068694069981575, -0.10307344794273376, -0.09927748888731003, -0.09548152983188629, -0.09168557077646255, -0.08788961172103882, -0.08409365266561508, -0.08029769361019135, -0.07650173455476761, -0.07270577549934387, -0.06890981644392014, -0.0651138573884964, -0.06131789833307266, -0.057521939277648926, -0.05372598022222519, -0.04993002116680145, -0.046134062111377716, -0.04233810305595398, -0.03854214400053024, -0.034746184945106506, -0.03095022588968277, -0.027154266834259033, -0.023358307778835297, -0.01956234872341156, -0.015766389667987823, -0.011970430612564087, -0.00817447155714035, -0.004378512501716614, -0.0005825534462928772, 0.0032133981585502625, 0.007009364664554596, 0.01080533117055893, 0.014601282775402069, 0.01839723438024521, 0.022193200886249542, 0.025989167392253876, 0.029785118997097015, 0.033581070601940155, 0.03737703710794449, 0.04117300361394882, 0.04496895521879196, 0.0487649068236351, 0.052560873329639435, 0.05635683983564377, 0.06015279144048691, 0.06394874304533005, 0.06774470955133438, 0.07154067605733871, 0.07533662766218185, 0.079132579267025, 0.08292854577302933, 0.08672451227903366, 0.0905204638838768, 0.09431641548871994, 0.09811238199472427, 0.10190834850072861, 0.10570430010557175, 0.10950025171041489, 0.11329621821641922, 0.11709218472242355, 0.1208881363272667]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.9871137738227844, -0.9643614292144775, -0.9416090846061707, -0.9188567996025085, -0.8961044549942017, -0.8733521103858948, -0.8505997657775879, -0.8278474807739258, -0.8050951361656189, -0.782342791557312, -0.7595904469490051, -0.7368381023406982, -0.7140858173370361, -0.6913334727287292, -0.6685811281204224, -0.6458288431167603, -0.6230764389038086, -0.6003241539001465, -0.5775718092918396, -0.5548194646835327, -0.5320671796798706, -0.509314775466919, -0.48656249046325684, -0.46381014585494995, -0.44105780124664307, -0.4183054566383362, -0.3955531716346741, -0.3728008270263672, -0.3500484824180603, -0.3272961378097534, -0.3045438528060913, -0.2817915081977844, -0.25903916358947754, -0.23628681898117065, -0.21353447437286377, -0.19078218936920166, -0.16802984476089478, -0.1452775001525879, -0.122525155544281, -0.0997728705406189, -0.07702052593231201, -0.05426818132400513, -0.03151583671569824, -0.008763492107391357, 0.013988792896270752, 0.03674119710922241, 0.05949348211288452, 0.08224576711654663, 0.10499817132949829, 0.1277504563331604, 0.15050286054611206, 0.17325514554977417, 0.19600743055343628, 0.21875983476638794, 0.24151211977005005, 0.26426440477371216, 0.2870168089866638, 0.3097690939903259, 0.3325214982032776, 0.3552737832069397, 0.3780260682106018, 0.40077847242355347, 0.4235307574272156, 0.44628316164016724, 0.46903544664382935]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 1.0, 3.0, 5.0, 8.0, 5.0, 4.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.1212599128484726, -0.1176692470908165, -0.1140785738825798, -0.1104879081249237, -0.10689723491668701, -0.10330656915903091, -0.09971590340137482, -0.09612523019313812, -0.09253456443548203, -0.08894389867782593, -0.08535322546958923, -0.08176255971193314, -0.07817189395427704, -0.07458122074604034, -0.07099055498838425, -0.06739988923072815, -0.06380921602249146, -0.06021854653954506, -0.05662787705659866, -0.053037211298942566, -0.04944653809070587, -0.045855872333049774, -0.04226520657539368, -0.03867453336715698, -0.035083867609500885, -0.03149320185184479, -0.027902528643608093, -0.024311862885951996, -0.0207211971282959, -0.017130523920059204, -0.013539858162403107, -0.009949184954166412, -0.006358519196510315, -0.0027678534388542175, 0.0008228197693824768, 0.004413485527038574, 0.008004158735275269, 0.011594817042350769, 0.015185490250587463, 0.018776163458824158, 0.022366836667060852, 0.025957494974136353, 0.029548168182373047, 0.03313884139060974, 0.03672949969768524, 0.040320172905921936, 0.04391084611415863, 0.04750150442123413, 0.051092177629470825, 0.05468285083770752, 0.05827350914478302, 0.061864182353019714, 0.06545485556125641, 0.06904551386833191, 0.0726361870765686, 0.0762268602848053, 0.0798175185918808, 0.08340819180011749, 0.08699886500835419, 0.09058953821659088, 0.09418019652366638, 0.09777086973190308, 0.10136154294013977, 0.10495220124721527, 0.10854287445545197]}, "_runtime": 4113.3654799461365, "_timestamp": 1585601482.9983494, "_step": 98}
{"Episode reward": -99.63757696563705, "Episode length": 999, "Policy Loss": -0.8354281783103943, "Value Loss": 0.01364337932318449, "_runtime": 4113.919927120209, "_timestamp": 1585601483.5527966, "_step": 99}
{"Episode reward": 67.18182162260618, "Episode length": 329, "Policy Loss": 1.9101566076278687, "Value Loss": 30.34534454345703, "_runtime": 4115.471754074097, "_timestamp": 1585601485.1046236, "_step": 100}
{"Episode reward": -99.79661724206386, "Episode length": 999, "Policy Loss": -0.6320487856864929, "Value Loss": 0.007875975221395493, "_runtime": 4117.011031866074, "_timestamp": 1585601486.6439013, "_step": 101}
{"Episode reward": 2.8392228451104273, "Episode length": 975, "Policy Loss": 0.2084481567144394, "Value Loss": 10.24650764465332, "_runtime": 4118.5121121406555, "_timestamp": 1585601488.1449816, "_step": 102}
{"Episode reward": -99.7704307246008, "Episode length": 999, "Policy Loss": -0.492072731256485, "Value Loss": 0.004569493234157562, "_runtime": 4120.078364610672, "_timestamp": 1585601489.711234, "_step": 103}
{"Episode reward": -99.81186317400866, "Episode length": 999, "Policy Loss": -0.4082777500152588, "Value Loss": 0.003155502025038004, "_runtime": 4121.527538537979, "_timestamp": 1585601491.160408, "_step": 104}
{"Episode reward": 8.963859375524365, "Episode length": 919, "Policy Loss": 0.5499179363250732, "Value Loss": 10.873820304870605, "_runtime": 4121.943058252335, "_timestamp": 1585601491.5759277, "_step": 105}
{"Episode reward": 76.52127232645537, "Episode length": 236, "Policy Loss": 3.278576612472534, "Value Loss": 42.344608306884766, "_runtime": 4123.536875963211, "_timestamp": 1585601493.1697454, "_step": 106}
{"Episode reward": -99.82085708314413, "Episode length": 999, "Policy Loss": -0.3163016736507416, "Value Loss": 0.0019178842194378376, "_runtime": 4125.118320465088, "_timestamp": 1585601494.75119, "_step": 107}
{"Episode reward": -99.48081485909796, "Episode length": 999, "Policy Loss": -0.35087350010871887, "Value Loss": 0.0024964495096355677, "_runtime": 4126.614579677582, "_timestamp": 1585601496.2474492, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3909868896007538, "Value Loss": 0.002869824878871441, "_runtime": 4128.181973695755, "_timestamp": 1585601497.8148432, "_step": 109}
{"Episode reward": -99.82778983451287, "Episode length": 999, "Policy Loss": -0.3840186893939972, "Value Loss": 0.0029565554577857256, "_runtime": 4129.762053489685, "_timestamp": 1585601499.394923, "_step": 110}
{"Episode reward": -99.87982218414405, "Episode length": 999, "Policy Loss": -0.38138583302497864, "Value Loss": 0.0027821080293506384, "_runtime": 4131.181727647781, "_timestamp": 1585601500.8145971, "_step": 111}
{"Episode reward": 9.499019715686202, "Episode length": 907, "Policy Loss": 0.47789180278778076, "Value Loss": 11.016942024230957, "_runtime": 4132.768393278122, "_timestamp": 1585601502.4012628, "_step": 112}
{"Episode reward": -99.66409651725415, "Episode length": 999, "Policy Loss": -0.34227854013442993, "Value Loss": 0.002322278218343854, "_runtime": 4133.291915893555, "_timestamp": 1585601502.9247854, "_step": 113}
{"Episode reward": 70.22700727713635, "Episode length": 303, "Policy Loss": 2.110079526901245, "Value Loss": 32.9752311706543, "_runtime": 4133.818911552429, "_timestamp": 1585601503.451781, "_step": 114}
{"Episode reward": 68.39500369150262, "Episode length": 324, "Policy Loss": 2.5892996788024902, "Value Loss": 30.832897186279297, "_runtime": 4135.254776716232, "_timestamp": 1585601504.8876462, "_step": 115}
{"Episode reward": 8.100000000000946, "Episode length": 919, "Policy Loss": 0.23244249820709229, "Value Loss": 10.870622634887695, "_runtime": 4136.7650582790375, "_timestamp": 1585601506.3979278, "_step": 116}
{"Episode reward": -99.6505007242901, "Episode length": 999, "Policy Loss": -0.6835004687309265, "Value Loss": 0.009219969622790813, "_runtime": 4138.269063234329, "_timestamp": 1585601507.9019327, "_step": 117}
{"Episode reward": -99.81569692634372, "Episode length": 999, "Policy Loss": -0.7833694219589233, "Value Loss": 0.012078375555574894, "_runtime": 4139.841743707657, "_timestamp": 1585601509.4746132, "_step": 118}
{"Episode reward": -99.8756320783447, "Episode length": 999, "Policy Loss": -0.8330764770507812, "Value Loss": 0.013796002604067326, "_runtime": 4140.691375255585, "_timestamp": 1585601510.3242447, "_step": 119}
{"Episode reward": 46.744379940255996, "Episode length": 533, "Policy Loss": 0.47549310326576233, "Value Loss": 18.731048583984375, "_runtime": 4142.234158992767, "_timestamp": 1585601511.8670285, "_step": 120}
{"Episode reward": -99.83523669452849, "Episode length": 999, "Policy Loss": -0.8809287548065186, "Value Loss": 0.015223746187984943, "_runtime": 4143.814286708832, "_timestamp": 1585601513.4471562, "_step": 121}
{"Episode reward": -99.58090123995069, "Episode length": 999, "Policy Loss": -0.8709143400192261, "Value Loss": 0.014792852103710175, "_runtime": 4144.991068124771, "_timestamp": 1585601514.6239376, "_step": 122}
{"Episode reward": 23.562315213191326, "Episode length": 770, "Policy Loss": 0.1064225509762764, "Value Loss": 12.968557357788086, "_runtime": 4145.59587430954, "_timestamp": 1585601515.2287438, "_step": 123}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 1.1256426572799683, "Value Loss": 26.451496124267578, "_runtime": 4146.928725719452, "_timestamp": 1585601516.5615952, "_step": 124}
{"Episode reward": 17.10615881411256, "Episode length": 830, "Policy Loss": 0.06825003772974014, "Value Loss": 12.0337553024292, "_runtime": 4148.478478193283, "_timestamp": 1585601518.1113477, "_step": 125}
{"Episode reward": -99.89096547798695, "Episode length": 999, "Policy Loss": -0.8191236257553101, "Value Loss": 0.01301853358745575, "_runtime": 4149.113435268402, "_timestamp": 1585601518.7463048, "_step": 126}
{"Episode reward": 58.79999999999969, "Episode length": 412, "Policy Loss": 0.9849293828010559, "Value Loss": 24.230289459228516, "_runtime": 4149.729443788528, "_timestamp": 1585601519.3623133, "_step": 127}
{"Episode reward": 62.048131255781946, "Episode length": 380, "Policy Loss": 0.9978857040405273, "Value Loss": 26.265674591064453, "_runtime": 4151.2843542099, "_timestamp": 1585601520.9172237, "_step": 128}
{"Episode reward": -99.83663707114617, "Episode length": 999, "Policy Loss": -0.8999424576759338, "Value Loss": 0.015461140312254429, "_runtime": 4152.099192380905, "_timestamp": 1585601521.7320619, "_step": 129}
{"Episode reward": 47.35585047532916, "Episode length": 532, "Policy Loss": 0.4077543318271637, "Value Loss": 17.99462890625, "_runtime": 4153.604953527451, "_timestamp": 1585601523.237823, "_step": 130}
{"Episode reward": -99.3399774937305, "Episode length": 999, "Policy Loss": -0.9398604035377502, "Value Loss": 0.017635365948081017, "_runtime": 4154.616435289383, "_timestamp": 1585601524.2493048, "_step": 131}
{"Episode reward": 35.38517405649144, "Episode length": 649, "Policy Loss": 0.17982564866542816, "Value Loss": 14.194918632507324, "_runtime": 4155.894812583923, "_timestamp": 1585601525.527682, "_step": 132}
{"Episode reward": 16.20199089842255, "Episode length": 840, "Policy Loss": -0.05498732253909111, "Value Loss": 11.890674591064453, "_runtime": 4157.286287546158, "_timestamp": 1585601526.919157, "_step": 133}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": -0.10325712710618973, "Value Loss": 10.736418724060059, "_runtime": 4158.819498538971, "_timestamp": 1585601528.452368, "_step": 134}
{"Episode reward": -99.8240207327574, "Episode length": 999, "Policy Loss": -0.9348800182342529, "Value Loss": 0.016679853200912476, "_runtime": 4160.359414577484, "_timestamp": 1585601529.992284, "_step": 135}
{"Episode reward": -99.80845480561116, "Episode length": 999, "Policy Loss": -0.8654451966285706, "Value Loss": 0.014743371866643429, "_runtime": 4161.909925937653, "_timestamp": 1585601531.5427954, "_step": 136}
{"Episode reward": -99.79193185688789, "Episode length": 999, "Policy Loss": -0.7828647494316101, "Value Loss": 0.011801508255302906, "_runtime": 4162.822083711624, "_timestamp": 1585601532.4549532, "_step": 137}
{"Episode reward": 43.913141106191866, "Episode length": 569, "Policy Loss": 0.8145221471786499, "Value Loss": 16.669668197631836, "_runtime": 4164.3899483680725, "_timestamp": 1585601534.0228179, "_step": 138}
{"Episode reward": -99.35127056363278, "Episode length": 999, "Policy Loss": -0.5553736686706543, "Value Loss": 0.009128032252192497, "_runtime": 4165.913904428482, "_timestamp": 1585601535.546774, "_step": 139}
{"Episode reward": 3.399934637448794, "Episode length": 967, "Policy Loss": 0.24299058318138123, "Value Loss": 9.69363784790039, "_runtime": 4167.20397901535, "_timestamp": 1585601536.8368485, "_step": 140}
{"Episode reward": 16.215931924388514, "Episode length": 842, "Policy Loss": 0.4258924424648285, "Value Loss": 11.5148286819458, "_runtime": 4168.777642965317, "_timestamp": 1585601538.4105124, "_step": 141}
{"Episode reward": -99.82749460972705, "Episode length": 999, "Policy Loss": -0.3447433114051819, "Value Loss": 0.002343043452128768, "_runtime": 4169.861223459244, "_timestamp": 1585601539.494093, "_step": 142}
{"Episode reward": 31.279913365468005, "Episode length": 688, "Policy Loss": 0.8205142617225647, "Value Loss": 13.280097007751465, "_runtime": 4170.7714812755585, "_timestamp": 1585601540.4043508, "_step": 143}
{"Episode reward": 43.99999999999948, "Episode length": 560, "Policy Loss": 0.9068883061408997, "Value Loss": 17.168514251708984, "_runtime": 4172.331454515457, "_timestamp": 1585601541.964324, "_step": 144}
{"Episode reward": -98.66809825369971, "Episode length": 999, "Policy Loss": -0.3058830201625824, "Value Loss": 0.314679890871048, "_runtime": 4173.8759508132935, "_timestamp": 1585601543.5088203, "_step": 145}
{"Episode reward": -99.36853521066692, "Episode length": 999, "Policy Loss": -0.28392162919044495, "Value Loss": 0.0018510898808017373, "_runtime": 4174.906001091003, "_timestamp": 1585601544.5388706, "_step": 146}
{"Episode reward": 32.19999998714151, "Episode length": 679, "Policy Loss": 0.6512126922607422, "Value Loss": 12.880134582519531, "_runtime": 4176.45765209198, "_timestamp": 1585601546.0905216, "_step": 147}
{"Episode reward": -99.17212885372554, "Episode length": 999, "Policy Loss": -0.29767537117004395, "Value Loss": 0.0019390461966395378, "_runtime": 4177.913927793503, "_timestamp": 1585601547.5467973, "_step": 148}
{"Episode reward": 7.652954863251168, "Episode length": 928, "Policy Loss": 0.40946459770202637, "Value Loss": 10.25303840637207, "_runtime": 4179.174589633942, "_timestamp": 1585601548.807459, "_step": 149}
{"Episode reward": 18.329039037577232, "Episode length": 820, "Policy Loss": 0.518490731716156, "Value Loss": 12.175281524658203, "_runtime": 4180.726850509644, "_timestamp": 1585601550.35972, "_step": 150}
{"Episode reward": -99.72826607218455, "Episode length": 999, "Policy Loss": -0.4097484350204468, "Value Loss": 0.003247757675126195, "_runtime": 4182.006735801697, "_timestamp": 1585601551.6396053, "_step": 151}
{"Episode reward": 18.000000000000384, "Episode length": 820, "Policy Loss": 0.48581409454345703, "Value Loss": 12.045103073120117, "_runtime": 4183.54971241951, "_timestamp": 1585601553.182582, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4704967737197876, "Value Loss": 0.0045330883003771305, "_runtime": 4185.109629154205, "_timestamp": 1585601554.7424986, "_step": 153}
{"Episode reward": -99.84569278098503, "Episode length": 999, "Policy Loss": -0.5047018527984619, "Value Loss": 0.004864598624408245, "_runtime": 4186.4307651519775, "_timestamp": 1585601556.0636346, "_step": 154}
{"Episode reward": 14.840246694250354, "Episode length": 852, "Policy Loss": 0.2956077754497528, "Value Loss": 11.377640724182129, "_runtime": 4187.99000787735, "_timestamp": 1585601557.6228774, "_step": 155}
{"Episode reward": -99.86903222298575, "Episode length": 999, "Policy Loss": -0.5053316354751587, "Value Loss": 0.004849249962717295, "_runtime": 4189.02215051651, "_timestamp": 1585601558.65502, "_step": 156}
{"Episode reward": 35.1988659647986, "Episode length": 649, "Policy Loss": 0.5540378093719482, "Value Loss": 14.044705390930176, "_runtime": 4190.5888204574585, "_timestamp": 1585601560.22169, "_step": 157}
{"Episode reward": -99.82713892331672, "Episode length": 999, "Policy Loss": -0.49901431798934937, "Value Loss": 0.0047593070194125175, "_runtime": 4192.153708696365, "_timestamp": 1585601561.7865782, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48244431614875793, "Value Loss": 0.0045074401423335075, "_runtime": 4193.725890636444, "_timestamp": 1585601563.35876, "_step": 159}
{"Episode reward": -99.82283059516782, "Episode length": 999, "Policy Loss": -0.44541066884994507, "Value Loss": 0.003838262055069208, "_runtime": 4195.290151596069, "_timestamp": 1585601564.923021, "_step": 160}
{"Episode reward": -99.85208656200999, "Episode length": 999, "Policy Loss": -0.39118480682373047, "Value Loss": 0.0029278399888426065, "_runtime": 4196.859522342682, "_timestamp": 1585601566.4923918, "_step": 161}
{"Episode reward": -99.74632497283025, "Episode length": 999, "Policy Loss": -0.31516915559768677, "Value Loss": 0.0019569105934351683, "_runtime": 4198.430522203445, "_timestamp": 1585601568.0633917, "_step": 162}
{"Episode reward": -99.71117084108998, "Episode length": 999, "Policy Loss": -0.23589858412742615, "Value Loss": 0.0010909115662798285, "_runtime": 4199.171303510666, "_timestamp": 1585601568.804173, "_step": 163}
{"Episode reward": 54.69999999999963, "Episode length": 453, "Policy Loss": 1.3456913232803345, "Value Loss": 20.932188034057617, "_runtime": 4200.747907161713, "_timestamp": 1585601570.3807766, "_step": 164}
{"Episode reward": -99.68822434204637, "Episode length": 999, "Policy Loss": -0.14166666567325592, "Value Loss": 0.0004313022654969245, "_runtime": 4202.32385134697, "_timestamp": 1585601571.9567208, "_step": 165}
{"Episode reward": -99.63216040765408, "Episode length": 999, "Policy Loss": -0.12918272614479065, "Value Loss": 0.00036711234133690596, "_runtime": 4203.83029460907, "_timestamp": 1585601573.463164, "_step": 166}
{"Episode reward": 1.3245065413195931, "Episode length": 990, "Policy Loss": 0.5898585319519043, "Value Loss": 9.274401664733887, "_runtime": 4205.416581630707, "_timestamp": 1585601575.049451, "_step": 167}
{"Episode reward": -99.86753160434183, "Episode length": 999, "Policy Loss": -0.12887409329414368, "Value Loss": 0.0003294819325674325, "_runtime": 4206.984646320343, "_timestamp": 1585601576.6175158, "_step": 168}
{"Episode reward": -99.83648944534221, "Episode length": 999, "Policy Loss": -0.13415731489658356, "Value Loss": 0.0003569531545508653, "_runtime": 4208.549236059189, "_timestamp": 1585601578.1821055, "_step": 169}
{"Episode reward": -99.75435010650988, "Episode length": 999, "Policy Loss": -0.13095441460609436, "Value Loss": 0.0003482922038529068, "_runtime": 4210.13264131546, "_timestamp": 1585601579.7655108, "_step": 170}
{"Episode reward": -99.50499869424829, "Episode length": 999, "Policy Loss": -0.11791069805622101, "Value Loss": 0.00042910518823191524, "_runtime": 4211.702092409134, "_timestamp": 1585601581.334962, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10936500877141953, "Value Loss": 0.0002280533080920577, "_runtime": 4212.590883731842, "_timestamp": 1585601582.2237532, "_step": 172}
{"Episode reward": 44.69521331231182, "Episode length": 555, "Policy Loss": 1.0600558519363403, "Value Loss": 18.002281188964844, "_runtime": 4213.466868400574, "_timestamp": 1585601583.099738, "_step": 173}
{"Episode reward": 45.80434617020024, "Episode length": 544, "Policy Loss": 1.1155052185058594, "Value Loss": 17.631563186645508, "_runtime": 4214.277143716812, "_timestamp": 1585601583.9100132, "_step": 174}
{"Episode reward": 50.144535319785426, "Episode length": 502, "Policy Loss": 1.1240986585617065, "Value Loss": 18.95757484436035, "_runtime": 4215.8127110004425, "_timestamp": 1585601585.4455805, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3473995625972748, "Value Loss": 0.0023447696585208178, "_runtime": 4216.555317640305, "_timestamp": 1585601586.1881871, "_step": 176}
{"Episode reward": 53.508511570143625, "Episode length": 473, "Policy Loss": 0.9913339614868164, "Value Loss": 19.857601165771484, "_runtime": 4217.577574253082, "_timestamp": 1585601587.2104437, "_step": 177}
{"Episode reward": 33.7376671028609, "Episode length": 665, "Policy Loss": 0.48420006036758423, "Value Loss": 14.522645950317383, "_runtime": 4219.165739774704, "_timestamp": 1585601588.7986093, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.771811306476593, "Value Loss": 0.011740355752408504, "_runtime": 4220.689150094986, "_timestamp": 1585601590.3220196, "_step": 179}
{"Episode reward": -99.81081773756902, "Episode length": 999, "Policy Loss": -0.8682666420936584, "Value Loss": 0.015147353522479534, "_runtime": 4222.227841377258, "_timestamp": 1585601591.8607109, "_step": 180}
{"Episode reward": -99.72540464177588, "Episode length": 999, "Policy Loss": -0.9403853416442871, "Value Loss": 0.01682000607252121, "_runtime": 4223.788479566574, "_timestamp": 1585601593.421349, "_step": 181}
{"Episode reward": -99.68543870644505, "Episode length": 999, "Policy Loss": -0.9241060614585876, "Value Loss": 0.016542324796319008, "_runtime": 4224.808140516281, "_timestamp": 1585601594.44101, "_step": 182}
{"Episode reward": 35.93893444159558, "Episode length": 641, "Policy Loss": 0.3280707597732544, "Value Loss": 13.90311050415039, "_runtime": 4225.685532808304, "_timestamp": 1585601595.3184023, "_step": 183}
{"Episode reward": 45.05264411435878, "Episode length": 550, "Policy Loss": 0.34365442395210266, "Value Loss": 15.37121295928955, "_runtime": 4226.270660638809, "_timestamp": 1585601595.9035301, "_step": 184}
{"Episode reward": 64.72920442920855, "Episode length": 354, "Policy Loss": 1.0113160610198975, "Value Loss": 26.310888290405273, "_runtime": 4227.806408405304, "_timestamp": 1585601597.439278, "_step": 185}
{"Episode reward": -99.83279771245876, "Episode length": 999, "Policy Loss": -0.8565585017204285, "Value Loss": 0.014118463732302189, "_runtime": 4229.337322235107, "_timestamp": 1585601598.9701917, "_step": 186}
{"Episode reward": -99.81545431865821, "Episode length": 999, "Policy Loss": -0.8577011823654175, "Value Loss": 0.013946294784545898, "_runtime": 4230.841507911682, "_timestamp": 1585601600.4743774, "_step": 187}
{"Episode reward": -99.80068145105476, "Episode length": 999, "Policy Loss": -0.7702509164810181, "Value Loss": 0.01230892725288868, "_runtime": 4231.468754529953, "_timestamp": 1585601601.101624, "_step": 188}
{"Episode reward": 62.34700235109605, "Episode length": 379, "Policy Loss": 0.8996261358261108, "Value Loss": 23.925363540649414, "_runtime": 4233.030474662781, "_timestamp": 1585601602.6633441, "_step": 189}
{"Episode reward": -99.71594755523698, "Episode length": 999, "Policy Loss": -0.6838202476501465, "Value Loss": 0.00899997353553772, "_runtime": 4234.592575073242, "_timestamp": 1585601604.2254446, "_step": 190}
{"Episode reward": -99.56797317250029, "Episode length": 999, "Policy Loss": -0.609137237071991, "Value Loss": 0.007467292249202728, "_runtime": 4236.111395120621, "_timestamp": 1585601605.7442646, "_step": 191}
{"Episode reward": -99.85603431281494, "Episode length": 999, "Policy Loss": -0.540123701095581, "Value Loss": 0.00550604984164238, "_runtime": 4237.086789131165, "_timestamp": 1585601606.7196586, "_step": 192}
{"Episode reward": 39.236742050716344, "Episode length": 609, "Policy Loss": 0.5907787680625916, "Value Loss": 15.054655075073242, "_runtime": 4238.644381046295, "_timestamp": 1585601608.2772505, "_step": 193}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35719627141952515, "Value Loss": 0.0025361496955156326, "_runtime": 4239.73140835762, "_timestamp": 1585601609.3642778, "_step": 194}
{"Episode reward": 30.999999999999645, "Episode length": 690, "Policy Loss": 0.6512462496757507, "Value Loss": 12.800305366516113, "_runtime": 4240.702040910721, "_timestamp": 1585601610.3349104, "_step": 195}
{"Episode reward": 37.99922430179953, "Episode length": 621, "Policy Loss": 0.6926352977752686, "Value Loss": 15.238259315490723, "_runtime": 4242.296714305878, "_timestamp": 1585601611.9295838, "_step": 196}
{"Episode reward": -99.80345863737026, "Episode length": 999, "Policy Loss": -0.27623528242111206, "Value Loss": 0.0014718082966282964, "_runtime": 4242.784799575806, "_timestamp": 1585601612.417669, "_step": 197}
{"Episode reward": 70.39999999999986, "Episode length": 296, "Policy Loss": 2.108541250228882, "Value Loss": 31.41982650756836, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233, 0.027887415140867233]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.011886175721883774, 0.2108074128627777, 0.4335010051727295, 0.6561946272850037, 0.8788881897926331, 1.1015818119049072, 1.3242754936218262, 1.5469690561294556, 1.769662618637085, 1.992356300354004, 2.2150497436523438, 2.4377434253692627, 2.6604371070861816, 2.8831305503845215, 3.1058242321014404, 3.3285176753997803, 3.551211357116699, 3.773905038833618, 3.996598720550537, 4.219292163848877, 4.441985607147217, 4.664679527282715, 4.887372970581055, 5.1100664138793945, 5.332760334014893, 5.555453777313232, 5.778147220611572, 6.000840663909912, 6.22353458404541, 6.44622802734375, 6.66892147064209, 6.891615390777588, 7.114308834075928, 7.337002277374268, 7.559696197509766, 7.7823896408081055, 8.005083084106445, 8.227776527404785, 8.450469970703125, 8.673163414001465, 8.895856857299805, 9.118550300598145, 9.3412446975708, 9.56393814086914, 9.78663158416748, 10.00932502746582, 10.23201847076416, 10.4547119140625, 10.677406311035156, 10.900099754333496, 11.122793197631836, 11.345486640930176, 11.568180084228516, 11.790873527526855, 12.013566970825195, 12.236261367797852, 12.458954811096191, 12.681648254394531, 12.904341697692871, 13.127035140991211, 13.34972858428955, 13.572422981262207, 13.795116424560547, 14.017809867858887, 14.240503311157227]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0], "bins": [-0.40571531653404236, -0.393277645111084, -0.3808399736881256, -0.36840230226516724, -0.35596466064453125, -0.3435269892215729, -0.3310893177986145, -0.31865164637565613, -0.30621397495269775, -0.29377633333206177, -0.281338632106781, -0.268900990486145, -0.25646331906318665, -0.24402564764022827, -0.2315879762172699, -0.21915031969547272, -0.20671264827251434, -0.19427497684955597, -0.1818373203277588, -0.16939964890480042, -0.15696197748184204, -0.14452430605888367, -0.1320866346359253, -0.1196489930152893, -0.10721132159233093, -0.09477365016937256, -0.08233597874641418, -0.06989830732345581, -0.057460635900497437, -0.04502299427986145, -0.032585322856903076, -0.020147651433944702, -0.007709980010986328, 0.004727691411972046, 0.01716536283493042, 0.029603034257888794, 0.04204067587852478, 0.054478347301483154, 0.06691601872444153, 0.0793536901473999, 0.09179136157035828, 0.10422900319099426, 0.11666670441627502, 0.129104346036911, 0.14154204726219177, 0.15397968888282776, 0.16641733050346375, 0.1788550317287445, 0.1912926733493805, 0.20373037457466125, 0.21616801619529724, 0.228605717420578, 0.241043359041214, 0.25348100066185, 0.26591870188713074, 0.2783563435077667, 0.2907940447330475, 0.30323168635368347, 0.31566932797431946, 0.3281070291996002, 0.3405446708202362, 0.35298237204551697, 0.36542001366615295, 0.3778577148914337, 0.3902953565120697]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 9.0, 13.0, 17.0, 19.0, 16.0, 34.0, 29.0, 18.0, 10.0, 5.0, 2.0, 192.0, 0.0, 1.0, 1.0, 4.0, 10.0, 7.0, 7.0, 10.0, 4.0, 16.0, 10.0, 12.0, 10.0, 9.0, 6.0, 6.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-1.0889499187469482, -1.0547140836715698, -1.0204782485961914, -0.986242413520813, -0.9520065784454346, -0.9177707433700562, -0.8835349082946777, -0.8492990732192993, -0.8150632381439209, -0.7808274030685425, -0.7465915679931641, -0.7123557329177856, -0.6781198978424072, -0.6438840627670288, -0.6096482276916504, -0.575412392616272, -0.5411765575408936, -0.5069407224655151, -0.4727048873901367, -0.4384690523147583, -0.4042332172393799, -0.36999738216400146, -0.33576154708862305, -0.30152571201324463, -0.2672898769378662, -0.2330540418624878, -0.19881820678710938, -0.16458237171173096, -0.13034653663635254, -0.09611070156097412, -0.0618748664855957, -0.027639031410217285, 0.006596803665161133, 0.04083263874053955, 0.07506847381591797, 0.10930430889129639, 0.1435401439666748, 0.17777597904205322, 0.21201181411743164, 0.24624764919281006, 0.2804834842681885, 0.3147193193435669, 0.3489551544189453, 0.38319098949432373, 0.41742682456970215, 0.45166265964508057, 0.485898494720459, 0.5201343297958374, 0.5543701648712158, 0.5886059999465942, 0.6228418350219727, 0.6570776700973511, 0.6913135051727295, 0.7255493402481079, 0.7597851753234863, 0.7940210103988647, 0.8282568454742432, 0.8624926805496216, 0.896728515625, 0.9309642314910889, 0.9652001857757568, 0.9994361400604248, 1.0336718559265137, 1.0679075717926025, 1.1021435260772705]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-1.2952767610549927, -1.189454197883606, -1.0836316347122192, -0.9778090119361877, -0.8719863891601562, -0.7661638259887695, -0.6603412628173828, -0.5545186400413513, -0.4486960768699646, -0.3428735136985779, -0.2370508909225464, -0.13122832775115967, -0.02540576457977295, 0.08041679859161377, 0.18623948097229004, 0.29206204414367676, 0.3978846073150635, 0.5037071704864502, 0.6095297336578369, 0.7153524160385132, 0.8211749792098999, 0.9269975423812866, 1.0328201055526733, 1.13864266872406, 1.2444652318954468, 1.3502877950668335, 1.4561103582382202, 1.561933159828186, 1.6677557229995728, 1.7735782861709595, 1.8794008493423462, 1.985223412513733, 2.09104585647583, 2.196868419647217, 2.3026909828186035, 2.4085135459899902, 2.514336109161377, 2.6201586723327637, 2.7259817123413086, 2.8318042755126953, 2.937626838684082, 3.0434494018554688, 3.1492719650268555, 3.255094528198242, 3.360917091369629, 3.4667396545410156, 3.5725622177124023, 3.678384780883789, 3.784207344055176, 3.8900299072265625, 3.995852470397949, 4.101675033569336, 4.207497596740723, 4.313320159912109, 4.419143199920654, 4.524965763092041, 4.630788326263428, 4.7366108894348145, 4.842433452606201, 4.948256015777588, 5.054078578948975, 5.159901142120361, 5.265723705291748, 5.371546268463135, 5.4773688316345215]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 11.0, 5.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3.9562301635742188, -3.8671770095825195, -3.778123617172241, -3.689070463180542, -3.6000170707702637, -3.5109639167785645, -3.4219107627868652, -3.332857370376587, -3.2438039779663086, -3.1547508239746094, -3.06569766998291, -2.976644277572632, -2.8875911235809326, -2.7985377311706543, -2.709484577178955, -2.620431423187256, -2.5313780307769775, -2.442324638366699, -2.353271484375, -2.264218330383301, -2.1751649379730225, -2.0861117839813232, -1.9970585107803345, -1.9080052375793457, -1.8189520835876465, -1.7298986911773682, -1.640845537185669, -1.5517921447753906, -1.4627389907836914, -1.373685598373413, -1.2846324443817139, -1.1955790519714355, -1.1065258979797363, -1.017472743988037, -0.9284193515777588, -0.8393661975860596, -0.7503128051757812, -0.661259651184082, -0.5722062587738037, -0.4831531047821045, -0.39409971237182617, -0.30504655838012695, -0.21599340438842773, -0.12694001197814941, -0.037886857986450195, 0.051166534423828125, 0.14021968841552734, 0.22927284240722656, 0.3183259963989258, 0.4073796272277832, 0.4964327812194824, 0.5854859352111816, 0.6745390892028809, 0.7635927200317383, 0.8526458740234375, 0.9416990280151367, 1.030752182006836, 1.1198053359985352, 1.2088589668273926, 1.2979121208190918, 1.386965274810791, 1.4760184288024902, 1.5650720596313477, 1.6541252136230469, 1.743178367614746]}, "_runtime": 4243.887320280075, "_timestamp": 1585601613.5201898, "_step": 198}
{"Episode reward": 28.62579188421597, "Episode length": 722, "Policy Loss": 0.47164350748062134, "Value Loss": 12.868897438049316, "_runtime": 4245.4549515247345, "_timestamp": 1585601615.087821, "_step": 199}
{"Episode reward": -99.32034669777214, "Episode length": 999, "Policy Loss": -0.5013860464096069, "Value Loss": 0.005498988088220358, "_runtime": 4246.957574605942, "_timestamp": 1585601616.590444, "_step": 200}
{"Episode reward": -99.72882344827383, "Episode length": 999, "Policy Loss": -0.6172030568122864, "Value Loss": 0.0076337214559316635, "_runtime": 4247.6931030750275, "_timestamp": 1585601617.3259726, "_step": 201}
{"Episode reward": 53.94695317409895, "Episode length": 461, "Policy Loss": 0.5376087427139282, "Value Loss": 19.00967025756836, "_runtime": 4249.26357793808, "_timestamp": 1585601618.8964474, "_step": 202}
{"Episode reward": -99.72465362446825, "Episode length": 999, "Policy Loss": -0.771226167678833, "Value Loss": 0.011309278197586536, "_runtime": 4250.822382688522, "_timestamp": 1585601620.4552522, "_step": 203}
{"Episode reward": -99.82423987621301, "Episode length": 999, "Policy Loss": -0.7920020222663879, "Value Loss": 0.012372709810733795, "_runtime": 4252.341786623001, "_timestamp": 1585601621.974656, "_step": 204}
{"Episode reward": -99.52404377530773, "Episode length": 999, "Policy Loss": -0.7857930660247803, "Value Loss": 0.011905099265277386, "_runtime": 4253.913206100464, "_timestamp": 1585601623.5460756, "_step": 205}
{"Episode reward": -99.75284341881495, "Episode length": 999, "Policy Loss": -0.7287768125534058, "Value Loss": 0.010255234315991402, "_runtime": 4255.461727380753, "_timestamp": 1585601625.0945969, "_step": 206}
{"Episode reward": -99.68218850723359, "Episode length": 999, "Policy Loss": -0.6299552321434021, "Value Loss": 0.007794841192662716, "_runtime": 4257.022128582001, "_timestamp": 1585601626.654998, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5180582404136658, "Value Loss": 0.005137485917657614, "_runtime": 4257.982645988464, "_timestamp": 1585601627.6155155, "_step": 208}
{"Episode reward": 41.230006778482576, "Episode length": 600, "Policy Loss": 0.6007635593414307, "Value Loss": 14.144413948059082, "_runtime": 4259.555161237717, "_timestamp": 1585601629.1880307, "_step": 209}
{"Episode reward": -99.74400519738417, "Episode length": 999, "Policy Loss": -0.2853040397167206, "Value Loss": 0.0016555304173380136, "_runtime": 4260.444785833359, "_timestamp": 1585601630.0776553, "_step": 210}
{"Episode reward": 44.06221622787364, "Episode length": 560, "Policy Loss": 0.9100875854492188, "Value Loss": 16.0927677154541, "_runtime": 4261.100910902023, "_timestamp": 1585601630.7337804, "_step": 211}
{"Episode reward": 59.36771645802033, "Episode length": 414, "Policy Loss": 1.8191659450531006, "Value Loss": 22.35523796081543, "_runtime": 4261.597420930862, "_timestamp": 1585601631.2302904, "_step": 212}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 1.8087302446365356, "Value Loss": 27.603078842163086, "_runtime": 4262.0573444366455, "_timestamp": 1585601631.690214, "_step": 213}
{"Episode reward": 70.69999999999986, "Episode length": 293, "Policy Loss": 1.7286385297775269, "Value Loss": 28.548677444458008, "_runtime": 4262.798369169235, "_timestamp": 1585601632.4312387, "_step": 214}
{"Episode reward": 51.67964605967959, "Episode length": 496, "Policy Loss": 0.6712413430213928, "Value Loss": 15.223681449890137, "_runtime": 4264.3020606040955, "_timestamp": 1585601633.93493, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8806400895118713, "Value Loss": 0.015621598809957504, "_runtime": 4265.828187465668, "_timestamp": 1585601635.461057, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.063184380531311, "Value Loss": 0.022274428978562355, "_runtime": 4267.068617343903, "_timestamp": 1585601636.7014868, "_step": 217}
{"Episode reward": 16.99133943833047, "Episode length": 834, "Policy Loss": -0.378693550825119, "Value Loss": 10.491471290588379, "_runtime": 4268.616951704025, "_timestamp": 1585601638.2498212, "_step": 218}
{"Episode reward": -99.75369955478097, "Episode length": 999, "Policy Loss": -1.2374101877212524, "Value Loss": 0.029402660205960274, "_runtime": 4270.152266025543, "_timestamp": 1585601639.7851355, "_step": 219}
{"Episode reward": -99.67398627843221, "Episode length": 999, "Policy Loss": -1.2147626876831055, "Value Loss": 0.02879541926085949, "_runtime": 4271.686812400818, "_timestamp": 1585601641.319682, "_step": 220}
{"Episode reward": -99.47090874258592, "Episode length": 999, "Policy Loss": -1.1009540557861328, "Value Loss": 0.025023983791470528, "_runtime": 4273.156480550766, "_timestamp": 1585601642.78935, "_step": 221}
{"Episode reward": 5.4000000000011, "Episode length": 946, "Policy Loss": -0.22977988421916962, "Value Loss": 10.139161109924316, "_runtime": 4274.712784528732, "_timestamp": 1585601644.345654, "_step": 222}
{"Episode reward": -99.70080129327113, "Episode length": 999, "Policy Loss": -0.8485202789306641, "Value Loss": 0.014263734221458435, "_runtime": 4276.272706031799, "_timestamp": 1585601645.9055755, "_step": 223}
{"Episode reward": -99.76553620863568, "Episode length": 999, "Policy Loss": -0.6751608848571777, "Value Loss": 0.009003294631838799, "_runtime": 4277.302087068558, "_timestamp": 1585601646.9349566, "_step": 224}
{"Episode reward": 34.78601086479482, "Episode length": 654, "Policy Loss": 0.5758942365646362, "Value Loss": 14.88485050201416, "_runtime": 4278.851219415665, "_timestamp": 1585601648.484089, "_step": 225}
{"Episode reward": -99.54745148585067, "Episode length": 999, "Policy Loss": -0.3403591811656952, "Value Loss": 0.002229394856840372, "_runtime": 4280.1190969944, "_timestamp": 1585601649.7519665, "_step": 226}
{"Episode reward": 19.391513988682206, "Episode length": 808, "Policy Loss": 0.7268456220626831, "Value Loss": 11.707159042358398, "_runtime": 4281.474316358566, "_timestamp": 1585601651.1071858, "_step": 227}
{"Episode reward": 11.78921612718004, "Episode length": 884, "Policy Loss": 0.46206313371658325, "Value Loss": 9.642821311950684, "_runtime": 4282.239551544189, "_timestamp": 1585601651.872421, "_step": 228}
{"Episode reward": 52.49203902759979, "Episode length": 477, "Policy Loss": 1.0201457738876343, "Value Loss": 17.86884307861328, "_runtime": 4283.777397155762, "_timestamp": 1585601653.4102666, "_step": 229}
{"Episode reward": -99.85243826228985, "Episode length": 999, "Policy Loss": -0.0652252808213234, "Value Loss": 8.435157360509038e-05, "_runtime": 4285.27592253685, "_timestamp": 1585601654.908792, "_step": 230}
{"Episode reward": 2.7503386494701516, "Episode length": 973, "Policy Loss": 0.4979807734489441, "Value Loss": 9.524252891540527, "_runtime": 4286.386120557785, "_timestamp": 1585601656.01899, "_step": 231}
{"Episode reward": 26.64284459119652, "Episode length": 734, "Policy Loss": 0.6433700323104858, "Value Loss": 11.310708999633789, "_runtime": 4287.933410406113, "_timestamp": 1585601657.56628, "_step": 232}
{"Episode reward": -99.60160767573404, "Episode length": 999, "Policy Loss": -0.22081105411052704, "Value Loss": 0.0010042546782642603, "_runtime": 4289.515181064606, "_timestamp": 1585601659.1480505, "_step": 233}
{"Episode reward": -99.77659136394365, "Episode length": 999, "Policy Loss": -0.2975977063179016, "Value Loss": 0.0016937623731791973, "_runtime": 4291.042169332504, "_timestamp": 1585601660.6750388, "_step": 234}
{"Episode reward": -99.80793592640991, "Episode length": 999, "Policy Loss": -0.34274861216545105, "Value Loss": 0.00224240287207067, "_runtime": 4291.594480514526, "_timestamp": 1585601661.22735, "_step": 235}
{"Episode reward": 67.72263774898586, "Episode length": 327, "Policy Loss": 1.2230027914047241, "Value Loss": 21.73158073425293, "_runtime": 4293.1348350048065, "_timestamp": 1585601662.7677045, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4441642463207245, "Value Loss": 0.004058898892253637, "_runtime": 4293.925199985504, "_timestamp": 1585601663.5580695, "_step": 237}
{"Episode reward": 52.48285255254573, "Episode length": 492, "Policy Loss": 0.870583713054657, "Value Loss": 15.985779762268066, "_runtime": 4294.493708372116, "_timestamp": 1585601664.1265779, "_step": 238}
{"Episode reward": 62.599999999999746, "Episode length": 374, "Policy Loss": 1.2941293716430664, "Value Loss": 24.985292434692383, "_runtime": 4295.924573659897, "_timestamp": 1585601665.5574431, "_step": 239}
{"Episode reward": 8.53960589949341, "Episode length": 923, "Policy Loss": -0.23357847332954407, "Value Loss": 7.59340238571167, "_runtime": 4296.668744564056, "_timestamp": 1585601666.301614, "_step": 240}
{"Episode reward": 51.93005143787555, "Episode length": 482, "Policy Loss": -0.1452307552099228, "Value Loss": 18.28680419921875, "_runtime": 4297.992499113083, "_timestamp": 1585601667.6253686, "_step": 241}
{"Episode reward": 10.800000000000793, "Episode length": 892, "Policy Loss": -0.18705424666404724, "Value Loss": 9.078371047973633, "_runtime": 4299.214562892914, "_timestamp": 1585601668.8474324, "_step": 242}
{"Episode reward": 21.180576841160857, "Episode length": 790, "Policy Loss": -0.3415878117084503, "Value Loss": 9.679489135742188, "_runtime": 4299.692323207855, "_timestamp": 1585601669.3251927, "_step": 243}
{"Episode reward": 69.95436908444375, "Episode length": 301, "Policy Loss": 1.1984078884124756, "Value Loss": 30.796401977539062, "_runtime": 4300.82111954689, "_timestamp": 1585601670.453989, "_step": 244}
{"Episode reward": 25.853772135579433, "Episode length": 744, "Policy Loss": -0.24179279804229736, "Value Loss": 10.816398620605469, "_runtime": 4302.364868402481, "_timestamp": 1585601671.997738, "_step": 245}
{"Episode reward": -99.71222756514187, "Episode length": 999, "Policy Loss": -1.3952142000198364, "Value Loss": 0.038191426545381546, "_runtime": 4303.852444410324, "_timestamp": 1585601673.485314, "_step": 246}
{"Episode reward": -99.79028439205, "Episode length": 999, "Policy Loss": -1.3878289461135864, "Value Loss": 0.03761884570121765, "_runtime": 4305.365528821945, "_timestamp": 1585601674.9983983, "_step": 247}
{"Episode reward": -99.69708146346245, "Episode length": 999, "Policy Loss": -1.2908021211624146, "Value Loss": 0.03269081935286522, "_runtime": 4306.590523004532, "_timestamp": 1585601676.2233925, "_step": 248}
{"Episode reward": 21.684145363180576, "Episode length": 785, "Policy Loss": -0.9606558680534363, "Value Loss": 17.290081024169922, "_runtime": 4308.055356502533, "_timestamp": 1585601677.688226, "_step": 249}
{"Episode reward": 4.685699898132285, "Episode length": 955, "Policy Loss": -0.6089892387390137, "Value Loss": 10.116084098815918, "_runtime": 4308.5842072963715, "_timestamp": 1585601678.2170768, "_step": 250}
{"Episode reward": 68.77744169242197, "Episode length": 314, "Policy Loss": 1.1248127222061157, "Value Loss": 25.24896240234375, "_runtime": 4310.125355243683, "_timestamp": 1585601679.7582247, "_step": 251}
{"Episode reward": -99.73240910931933, "Episode length": 999, "Policy Loss": -0.634914755821228, "Value Loss": 0.00787311140447855, "_runtime": 4311.678143262863, "_timestamp": 1585601681.3110127, "_step": 252}
{"Episode reward": -99.63797625684973, "Episode length": 999, "Policy Loss": -0.5030787587165833, "Value Loss": 0.004850304219871759, "_runtime": 4313.160182476044, "_timestamp": 1585601682.793052, "_step": 253}
{"Episode reward": 3.236751686037806, "Episode length": 968, "Policy Loss": 0.5120639204978943, "Value Loss": 10.322916030883789, "_runtime": 4314.328573703766, "_timestamp": 1585601683.9614432, "_step": 254}
{"Episode reward": 26.990963991359436, "Episode length": 746, "Policy Loss": 0.7415593266487122, "Value Loss": 13.397245407104492, "_runtime": 4315.875153541565, "_timestamp": 1585601685.508023, "_step": 255}
{"Episode reward": -99.74617949316604, "Episode length": 999, "Policy Loss": -0.175393208861351, "Value Loss": 0.0005943778669461608, "_runtime": 4317.41151881218, "_timestamp": 1585601687.0443883, "_step": 256}
{"Episode reward": -99.77954097027992, "Episode length": 999, "Policy Loss": -0.10766249150037766, "Value Loss": 0.00024308213323820382, "_runtime": 4318.7784633636475, "_timestamp": 1585601688.4113328, "_step": 257}
{"Episode reward": 11.55803017410669, "Episode length": 886, "Policy Loss": 0.7496986389160156, "Value Loss": 11.2852201461792, "_runtime": 4320.336333990097, "_timestamp": 1585601689.9692035, "_step": 258}
{"Episode reward": -99.72145272381464, "Episode length": 999, "Policy Loss": -0.036966703832149506, "Value Loss": 4.2243042116751894e-05, "_runtime": 4321.815453052521, "_timestamp": 1585601691.4483225, "_step": 259}
{"Episode reward": 3.728221748677342, "Episode length": 964, "Policy Loss": 0.6877852082252502, "Value Loss": 10.372698783874512, "_runtime": 4323.363948583603, "_timestamp": 1585601692.996818, "_step": 260}
{"Episode reward": -99.85404963232438, "Episode length": 999, "Policy Loss": -0.05992348864674568, "Value Loss": 7.181499677244574e-05, "_runtime": 4324.672634840012, "_timestamp": 1585601694.3055043, "_step": 261}
{"Episode reward": 16.614661376462763, "Episode length": 837, "Policy Loss": 0.7681391835212708, "Value Loss": 11.944670677185059, "_runtime": 4326.222310066223, "_timestamp": 1585601695.8551795, "_step": 262}
{"Episode reward": -99.70545148793468, "Episode length": 999, "Policy Loss": -0.15830866992473602, "Value Loss": 0.0005071586347185075, "_runtime": 4327.180824756622, "_timestamp": 1585601696.8136942, "_step": 263}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 0.9505536556243896, "Value Loss": 16.685373306274414, "_runtime": 4327.658448934555, "_timestamp": 1585601697.2913184, "_step": 264}
{"Episode reward": 71.49737106552334, "Episode length": 286, "Policy Loss": 2.4223270416259766, "Value Loss": 34.93532180786133, "_runtime": 4329.2015562057495, "_timestamp": 1585601698.8344257, "_step": 265}
{"Episode reward": -99.81670286655286, "Episode length": 999, "Policy Loss": -0.565600574016571, "Value Loss": 0.006086608860641718, "_runtime": 4330.412306308746, "_timestamp": 1585601700.0451758, "_step": 266}
{"Episode reward": 21.100000000000207, "Episode length": 789, "Policy Loss": 0.15785053372383118, "Value Loss": 12.65880298614502, "_runtime": 4331.901465415955, "_timestamp": 1585601701.534335, "_step": 267}
{"Episode reward": -99.77817848147686, "Episode length": 999, "Policy Loss": -0.9156014919281006, "Value Loss": 0.0159348975867033, "_runtime": 4333.46026301384, "_timestamp": 1585601703.0931325, "_step": 268}
{"Episode reward": -99.24133480717795, "Episode length": 999, "Policy Loss": -0.9755133986473083, "Value Loss": 0.01941206119954586, "_runtime": 4334.600830316544, "_timestamp": 1585601704.2336998, "_step": 269}
{"Episode reward": 26.82976452572069, "Episode length": 736, "Policy Loss": 0.12997865676879883, "Value Loss": 13.568428039550781, "_runtime": 4335.171476840973, "_timestamp": 1585601704.8043463, "_step": 270}
{"Episode reward": 67.29999999999981, "Episode length": 327, "Policy Loss": 1.1986770629882812, "Value Loss": 30.513059616088867, "_runtime": 4336.173022985458, "_timestamp": 1585601705.8058925, "_step": 271}
{"Episode reward": 35.34256298942431, "Episode length": 648, "Policy Loss": -0.04183414950966835, "Value Loss": 15.408255577087402, "_runtime": 4337.703479766846, "_timestamp": 1585601707.3363492, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2120060920715332, "Value Loss": 0.028689974918961525, "_runtime": 4339.193270921707, "_timestamp": 1585601708.8261404, "_step": 273}
{"Episode reward": -99.79179927802039, "Episode length": 999, "Policy Loss": -1.191771149635315, "Value Loss": 0.02841133251786232, "_runtime": 4339.9236669540405, "_timestamp": 1585601709.5565364, "_step": 274}
{"Episode reward": 54.809469421273995, "Episode length": 469, "Policy Loss": 0.5310165286064148, "Value Loss": 21.278743743896484, "_runtime": 4341.4684092998505, "_timestamp": 1585601711.1012788, "_step": 275}
{"Episode reward": -99.80003294344502, "Episode length": 999, "Policy Loss": -1.081006646156311, "Value Loss": 0.022809429094195366, "_runtime": 4342.071356534958, "_timestamp": 1585601711.704226, "_step": 276}
{"Episode reward": 62.199229935905635, "Episode length": 379, "Policy Loss": 1.0180376768112183, "Value Loss": 26.33193588256836, "_runtime": 4343.565117120743, "_timestamp": 1585601713.1979866, "_step": 277}
{"Episode reward": -99.7491977992752, "Episode length": 999, "Policy Loss": -0.8971676230430603, "Value Loss": 0.016927141696214676, "_runtime": 4344.948417425156, "_timestamp": 1585601714.581287, "_step": 278}
{"Episode reward": 12.352151639841551, "Episode length": 883, "Policy Loss": 0.0027683177031576633, "Value Loss": 11.31210994720459, "_runtime": 4346.4419984817505, "_timestamp": 1585601716.074868, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7563738822937012, "Value Loss": 0.010973064228892326, "_runtime": 4347.994268894196, "_timestamp": 1585601717.6271384, "_step": 280}
{"Episode reward": -99.69870133027295, "Episode length": 999, "Policy Loss": -0.6209270358085632, "Value Loss": 0.007579582743346691, "_runtime": 4349.540263414383, "_timestamp": 1585601719.173133, "_step": 281}
{"Episode reward": -99.80117039540643, "Episode length": 999, "Policy Loss": -0.4715600609779358, "Value Loss": 0.004333507269620895, "_runtime": 4350.611500740051, "_timestamp": 1585601720.2443702, "_step": 282}
{"Episode reward": 31.80559668925366, "Episode length": 684, "Policy Loss": 0.7268427610397339, "Value Loss": 14.609274864196777, "_runtime": 4351.004531860352, "_timestamp": 1585601720.6374013, "_step": 283}
{"Episode reward": 77.89999999999996, "Episode length": 221, "Policy Loss": 2.9591050148010254, "Value Loss": 45.224369049072266, "_runtime": 4351.993366956711, "_timestamp": 1585601721.6262364, "_step": 284}
{"Episode reward": 37.282296007643716, "Episode length": 631, "Policy Loss": 0.8375121355056763, "Value Loss": 15.83641529083252, "_runtime": 4353.407860040665, "_timestamp": 1585601723.0407295, "_step": 285}
{"Episode reward": 7.182091950967575, "Episode length": 931, "Policy Loss": 0.48058557510375977, "Value Loss": 10.73171615600586, "_runtime": 4354.903005599976, "_timestamp": 1585601724.535875, "_step": 286}
{"Episode reward": -99.71974390642578, "Episode length": 999, "Policy Loss": -0.5943789482116699, "Value Loss": 0.006696451921015978, "_runtime": 4356.106325387955, "_timestamp": 1585601725.7391949, "_step": 287}
{"Episode reward": 21.98677218554637, "Episode length": 782, "Policy Loss": 0.22613374888896942, "Value Loss": 12.772393226623535, "_runtime": 4357.124157905579, "_timestamp": 1585601726.7570274, "_step": 288}
{"Episode reward": 34.777682341029305, "Episode length": 654, "Policy Loss": 0.3666398525238037, "Value Loss": 15.268972396850586, "_runtime": 4358.153977394104, "_timestamp": 1585601727.7868469, "_step": 289}
{"Episode reward": 33.18387812405484, "Episode length": 672, "Policy Loss": 0.1668596863746643, "Value Loss": 14.859275817871094, "_runtime": 4359.022109270096, "_timestamp": 1585601728.6549788, "_step": 290}
{"Episode reward": 45.25738794640783, "Episode length": 550, "Policy Loss": 0.35808947682380676, "Value Loss": 18.150346755981445, "_runtime": 4360.598525524139, "_timestamp": 1585601730.231395, "_step": 291}
{"Episode reward": -99.86564545217412, "Episode length": 999, "Policy Loss": -1.131403923034668, "Value Loss": 0.024768901988863945, "_runtime": 4361.469035148621, "_timestamp": 1585601731.1019046, "_step": 292}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.12044389545917511, "Value Loss": 17.730667114257812, "_runtime": 4362.990317106247, "_timestamp": 1585601732.6231866, "_step": 293}
{"Episode reward": -99.77782848203067, "Episode length": 999, "Policy Loss": -1.1983517408370972, "Value Loss": 0.028186917304992676, "_runtime": 4363.768801689148, "_timestamp": 1585601733.4016712, "_step": 294}
{"Episode reward": 51.61020327440888, "Episode length": 486, "Policy Loss": 0.39490175247192383, "Value Loss": 20.53557777404785, "_runtime": 4364.789134263992, "_timestamp": 1585601734.4220037, "_step": 295}
{"Episode reward": 33.044905138715706, "Episode length": 672, "Policy Loss": -0.0479583740234375, "Value Loss": 14.85883903503418, "_runtime": 4366.156733751297, "_timestamp": 1585601735.7896032, "_step": 296}
{"Episode reward": 11.050057869439897, "Episode length": 890, "Policy Loss": -0.33312466740608215, "Value Loss": 11.225303649902344, "_runtime": 4367.665334224701, "_timestamp": 1585601737.2982037, "_step": 297}
{"Episode reward": -99.70246348997905, "Episode length": 999, "Policy Loss": -1.061063528060913, "Value Loss": 0.022972581908106804, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266, 0.030696043744683266]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.030695999041199684, -0.008885063230991364, 0.012925872579216957, 0.034736812114715576, 0.05654774606227875, 0.07835868000984192, 0.10016962140798569, 0.12198055535554886, 0.14379148185253143, 0.1656024158000946, 0.18741334974765778, 0.20922428369522095, 0.2310352325439453, 0.2528461515903473, 0.27465710043907166, 0.29646801948547363, 0.318278968334198, 0.34008991718292236, 0.36190083622932434, 0.3837117850780487, 0.4055227041244507, 0.42733365297317505, 0.449144572019577, 0.4709555208683014, 0.49276646971702576, 0.5145774483680725, 0.5363883376121521, 0.5581992864608765, 0.5800102353096008, 0.6018211841583252, 0.6236320734024048, 0.6454430222511292, 0.6672539710998535, 0.6890649199485779, 0.7108758687973022, 0.7326867580413818, 0.7544977068901062, 0.7763086557388306, 0.7981196045875549, 0.8199304938316345, 0.8417414426803589, 0.8635523915290833, 0.8853633403778076, 0.907174289226532, 0.9289851784706116, 0.9507961273193359, 0.9726070761680603, 0.9944179654121399, 1.0162289142608643, 1.0380398035049438, 1.059850811958313, 1.0816617012023926, 1.1034725904464722, 1.1252835988998413, 1.147094488143921, 1.1689053773880005, 1.1907163858413696, 1.2125272750854492, 1.2343382835388184, 1.256149172782898, 1.2779600620269775, 1.2997710704803467, 1.3215819597244263, 1.3433929681777954, 1.365203857421875]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0], "bins": [-0.04569864645600319, -0.044263679534196854, -0.04282871633768082, -0.04139374941587448, -0.039958786219358444, -0.03852381929755211, -0.03708885610103607, -0.035653889179229736, -0.0342189222574234, -0.032783959060907364, -0.03134899213910103, -0.029914027079939842, -0.028479062020778656, -0.02704409696161747, -0.025609130039811134, -0.024174164980649948, -0.022739199921488762, -0.021304234862327576, -0.01986926980316639, -0.018434302881360054, -0.016999337822198868, -0.015564372763037682, -0.014129407703876495, -0.01269444078207016, -0.011259477585554123, -0.009824510663747787, -0.00838954746723175, -0.006954580545425415, -0.00551961362361908, -0.004084650427103043, -0.002649683505296707, -0.0012147203087806702, 0.00022024661302566528, 0.0016552135348320007, 0.0030901767313480377, 0.004525143653154373, 0.00596010684967041, 0.007395073771476746, 0.008830040693283081, 0.010265003889799118, 0.011699970811605453, 0.01313493400812149, 0.014569900929927826, 0.01600486785173416, 0.0174398310482502, 0.018874797970056534, 0.02030976489186287, 0.021744724363088608, 0.023179691284894943, 0.02461465820670128, 0.026049625128507614, 0.02748459205031395, 0.028919551521539688, 0.030354518443346024, 0.03178948536515236, 0.033224452286958694, 0.03465941920876503, 0.03609437867999077, 0.037529345601797104, 0.03896431252360344, 0.040399279445409775, 0.04183424636721611, 0.04326920583844185, 0.044704172760248184, 0.04613913968205452]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 3.0, 15.0, 20.0, 17.0, 23.0, 19.0, 22.0, 19.0, 15.0, 7.0, 3.0, 4.0, 18.0, 107.0, 72.0, 1.0, 0.0, 5.0, 6.0, 8.0, 5.0, 7.0, 7.0, 11.0, 13.0, 15.0, 11.0, 4.0, 6.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0], "bins": [-0.09223107993602753, -0.08933496475219727, -0.086438849568367, -0.08354274183511734, -0.08064662665128708, -0.07775051146745682, -0.07485440373420715, -0.07195828855037689, -0.06906217336654663, -0.06616605818271637, -0.06326994299888611, -0.060373835265636444, -0.05747772008180618, -0.05458160489797592, -0.05168549343943596, -0.048789381980895996, -0.045893266797065735, -0.042997151613235474, -0.04010104015469551, -0.03720492869615555, -0.03430881351232529, -0.031412698328495026, -0.02851659059524536, -0.0256204754114151, -0.02272436022758484, -0.019828245043754578, -0.016932129859924316, -0.014036022126674652, -0.011139906942844391, -0.00824379175901413, -0.005347684025764465, -0.002451568841934204, 0.00044454634189605713, 0.0033406615257263184, 0.00623677670955658, 0.009132884442806244, 0.012028999626636505, 0.014925114810466766, 0.01782122254371643, 0.020717337727546692, 0.023613452911376953, 0.026509568095207214, 0.029405683279037476, 0.03230179101228714, 0.035197898745536804, 0.038094013929367065, 0.04099012911319733, 0.04388624429702759, 0.04678235948085785, 0.04967847466468811, 0.05257458984851837, 0.05547070503234863, 0.058366820216178894, 0.06126292049884796, 0.06415903568267822, 0.06705515086650848, 0.06995126605033875, 0.072847381234169, 0.07574349641799927, 0.07863961160182953, 0.0815357118844986, 0.08443182706832886, 0.08732794225215912, 0.09022405743598938, 0.09312017261981964]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.2630206346511841, -0.2473190277814865, -0.23161742091178894, -0.21591582894325256, -0.200214222073555, -0.18451261520385742, -0.16881102323532104, -0.15310941636562347, -0.1374078094959259, -0.12170620262622833, -0.10600459575653076, -0.09030300378799438, -0.07460139691829681, -0.05889979004859924, -0.043198198080062866, -0.027496591210365295, -0.011794984340667725, 0.003906607627868652, 0.019608229398727417, 0.035309821367263794, 0.05101144313812256, 0.06671303510665894, 0.08241462707519531, 0.09811624884605408, 0.11381784081459045, 0.12951943278312683, 0.1452210545539856, 0.16092264652252197, 0.17662423849105835, 0.19232586026191711, 0.2080274522304535, 0.22372907400131226, 0.23943066596984863, 0.255132257938385, 0.2708338499069214, 0.28653550148010254, 0.3022370934486389, 0.3179386854171753, 0.33364027738571167, 0.34934186935424805, 0.3650435209274292, 0.3807451128959656, 0.39644670486450195, 0.41214829683303833, 0.4278498888015747, 0.4435514807701111, 0.45925313234329224, 0.4749547243118286, 0.490656316280365, 0.5063579082489014, 0.5220595002174377, 0.5377611517906189, 0.5534627437591553, 0.5691643357276917, 0.584865927696228, 0.6005675196647644, 0.6162691116333008, 0.6319707632064819, 0.6476723551750183, 0.6633739471435547, 0.6790755391120911, 0.6947771310806274, 0.7104787826538086, 0.726180374622345, 0.7418819665908813]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 6.0, 9.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.025409961119294167, -0.02442530356347561, -0.02344064600765705, -0.022455988451838493, -0.021471329033374786, -0.02048667147755623, -0.01950201392173767, -0.018517356365919113, -0.017532698810100555, -0.016548041254281998, -0.01556338369846344, -0.014578725211322308, -0.01359406765550375, -0.012609410099685192, -0.01162475161254406, -0.010640094056725502, -0.009655436500906944, -0.008670778945088387, -0.007686121389269829, -0.006701463833451271, -0.005716806277632713, -0.004732146859169006, -0.0037474893033504486, -0.002762831747531891, -0.0017781741917133331, -0.0007935166358947754, 0.00019114091992378235, 0.00117579847574234, 0.002160457894206047, 0.003145115450024605, 0.0041297730058431625, 0.00511443056166172, 0.006099088117480278, 0.007083745673298836, 0.008068403229117393, 0.009053060784935951, 0.010037718340754509, 0.011022375896573067, 0.012007033452391624, 0.012991691008210182, 0.01397634856402874, 0.014961009845137596, 0.015945667400956154, 0.01693032495677471, 0.01791498251259327, 0.018899640068411827, 0.019884297624230385, 0.020868955180048943, 0.0218536127358675, 0.022838270291686058, 0.023822927847504616, 0.024807585403323174, 0.02579224295914173, 0.02677690051496029, 0.027761558070778847, 0.028746215626597404, 0.02973087690770626, 0.03071553446352482, 0.031700193881988525, 0.032684847712516785, 0.03366950899362564, 0.0346541628241539, 0.035638824105262756, 0.036623477935791016, 0.03760813921689987]}, "_runtime": 4369.1777901649475, "_timestamp": 1585601738.8106596, "_step": 298}
{"Episode reward": -99.78269366782486, "Episode length": 999, "Policy Loss": -1.0035051107406616, "Value Loss": 0.018780451267957687, "_runtime": 4369.848117589951, "_timestamp": 1585601739.480987, "_step": 299}
{"Episode reward": 58.399957014769875, "Episode length": 417, "Policy Loss": 0.9814122319221497, "Value Loss": 23.938796997070312, "_runtime": 4371.134508371353, "_timestamp": 1585601740.7673779, "_step": 300}
{"Episode reward": 17.743952443643337, "Episode length": 836, "Policy Loss": 0.177666574716568, "Value Loss": 11.947474479675293, "_runtime": 4372.691051006317, "_timestamp": 1585601742.3239205, "_step": 301}
{"Episode reward": -99.55718926409035, "Episode length": 999, "Policy Loss": -0.6643653512001038, "Value Loss": 0.008805690333247185, "_runtime": 4374.206716775894, "_timestamp": 1585601743.8395863, "_step": 302}
{"Episode reward": -99.63438208655433, "Episode length": 999, "Policy Loss": -0.5630289912223816, "Value Loss": 0.006297421175986528, "_runtime": 4375.747656583786, "_timestamp": 1585601745.380526, "_step": 303}
{"Episode reward": -98.62505201075086, "Episode length": 999, "Policy Loss": -0.42176303267478943, "Value Loss": 0.003696500789374113, "_runtime": 4376.70968747139, "_timestamp": 1585601746.342557, "_step": 304}
{"Episode reward": 39.265354806986, "Episode length": 609, "Policy Loss": 0.8864494562149048, "Value Loss": 16.408594131469727, "_runtime": 4378.243335723877, "_timestamp": 1585601747.8762052, "_step": 305}
{"Episode reward": 0.6498118702480866, "Episode length": 996, "Policy Loss": 0.5947772860527039, "Value Loss": 10.034966468811035, "_runtime": 4379.514850139618, "_timestamp": 1585601749.1477196, "_step": 306}
{"Episode reward": 18.88439136861858, "Episode length": 817, "Policy Loss": 0.7327601909637451, "Value Loss": 12.23429012298584, "_runtime": 4380.639169216156, "_timestamp": 1585601750.2720387, "_step": 307}
{"Episode reward": 26.199999999999918, "Episode length": 738, "Policy Loss": 0.7877416610717773, "Value Loss": 13.543392181396484, "_runtime": 4381.151497602463, "_timestamp": 1585601750.784367, "_step": 308}
{"Episode reward": 69.78391061767755, "Episode length": 307, "Policy Loss": 2.077073097229004, "Value Loss": 32.55080032348633, "_runtime": 4382.681494951248, "_timestamp": 1585601752.3143644, "_step": 309}
{"Episode reward": -99.82651457944745, "Episode length": 999, "Policy Loss": -0.4513836205005646, "Value Loss": 0.003991430159658194, "_runtime": 4384.2451095581055, "_timestamp": 1585601753.877979, "_step": 310}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6041554808616638, "Value Loss": 0.00691509572789073, "_runtime": 4385.732889413834, "_timestamp": 1585601755.365759, "_step": 311}
{"Episode reward": -99.71375531629657, "Episode length": 999, "Policy Loss": -0.6665177941322327, "Value Loss": 0.009145455434918404, "_runtime": 4387.290881156921, "_timestamp": 1585601756.9237506, "_step": 312}
{"Episode reward": -99.85084741450707, "Episode length": 999, "Policy Loss": -0.7313076257705688, "Value Loss": 0.010172813199460506, "_runtime": 4388.847900629044, "_timestamp": 1585601758.48077, "_step": 313}
{"Episode reward": -99.70455105823682, "Episode length": 999, "Policy Loss": -0.6961522698402405, "Value Loss": 0.00977572612464428, "_runtime": 4389.484135150909, "_timestamp": 1585601759.1170046, "_step": 314}
{"Episode reward": 59.8027819854857, "Episode length": 404, "Policy Loss": 1.3282585144042969, "Value Loss": 24.715669631958008, "_runtime": 4390.714476585388, "_timestamp": 1585601760.347346, "_step": 315}
{"Episode reward": 20.49505871385361, "Episode length": 796, "Policy Loss": 0.18793603777885437, "Value Loss": 12.548043251037598, "_runtime": 4391.572883605957, "_timestamp": 1585601761.205753, "_step": 316}
{"Episode reward": 46.19470317529, "Episode length": 539, "Policy Loss": 0.6003290414810181, "Value Loss": 18.526033401489258, "_runtime": 4392.786508798599, "_timestamp": 1585601762.4193783, "_step": 317}
{"Episode reward": 19.681541522119673, "Episode length": 805, "Policy Loss": 0.14535558223724365, "Value Loss": 12.407147407531738, "_runtime": 4394.31885433197, "_timestamp": 1585601763.9517238, "_step": 318}
{"Episode reward": -99.75178746499448, "Episode length": 999, "Policy Loss": -0.8460366725921631, "Value Loss": 0.01396805141121149, "_runtime": 4395.818608283997, "_timestamp": 1585601765.4514778, "_step": 319}
{"Episode reward": -99.80614969767491, "Episode length": 999, "Policy Loss": -0.831351101398468, "Value Loss": 0.014273621141910553, "_runtime": 4396.971392869949, "_timestamp": 1585601766.6042624, "_step": 320}
{"Episode reward": 26.431013610834782, "Episode length": 751, "Policy Loss": 0.19585470855236053, "Value Loss": 13.29797649383545, "_runtime": 4398.52725815773, "_timestamp": 1585601768.1601276, "_step": 321}
{"Episode reward": -99.84784646965423, "Episode length": 999, "Policy Loss": -0.762371301651001, "Value Loss": 0.011723833158612251, "_runtime": 4399.472090959549, "_timestamp": 1585601769.1049604, "_step": 322}
{"Episode reward": 39.77220212107001, "Episode length": 603, "Policy Loss": 0.4604807496070862, "Value Loss": 16.56097984313965, "_runtime": 4400.984941244125, "_timestamp": 1585601770.6178107, "_step": 323}
{"Episode reward": -99.6539261744111, "Episode length": 999, "Policy Loss": -0.6497518420219421, "Value Loss": 0.00836658850312233, "_runtime": 4402.539185523987, "_timestamp": 1585601772.172055, "_step": 324}
{"Episode reward": -99.8441384408609, "Episode length": 999, "Policy Loss": -0.5761098265647888, "Value Loss": 0.00648815231397748, "_runtime": 4403.905712604523, "_timestamp": 1585601773.538582, "_step": 325}
{"Episode reward": 10.401688364129157, "Episode length": 901, "Policy Loss": 0.3653029501438141, "Value Loss": 11.088501930236816, "_runtime": 4404.281318187714, "_timestamp": 1585601773.9141877, "_step": 326}
{"Episode reward": 79.25544104427098, "Episode length": 209, "Policy Loss": 2.9811582565307617, "Value Loss": 47.79751205444336, "_runtime": 4405.238696575165, "_timestamp": 1585601774.871566, "_step": 327}
{"Episode reward": 38.51881766178207, "Episode length": 615, "Policy Loss": 0.6400332450866699, "Value Loss": 16.24173927307129, "_runtime": 4406.818181037903, "_timestamp": 1585601776.4510505, "_step": 328}
{"Episode reward": -99.4223524645854, "Episode length": 999, "Policy Loss": -0.648985743522644, "Value Loss": 0.009038294665515423, "_runtime": 4408.299859523773, "_timestamp": 1585601777.932729, "_step": 329}
{"Episode reward": 0.2231272286516628, "Episode length": 999, "Policy Loss": -0.07806111872196198, "Value Loss": 10.000046730041504, "_runtime": 4409.759404420853, "_timestamp": 1585601779.392274, "_step": 330}
{"Episode reward": 5.657214204319786, "Episode length": 958, "Policy Loss": -0.044052474200725555, "Value Loss": 10.427560806274414, "_runtime": 4410.882892608643, "_timestamp": 1585601780.515762, "_step": 331}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.1293015480041504, "Value Loss": 13.736299514770508, "_runtime": 4412.423608779907, "_timestamp": 1585601782.0564783, "_step": 332}
{"Episode reward": -99.70042726620893, "Episode length": 999, "Policy Loss": -1.0101195573806763, "Value Loss": 0.019662093371152878, "_runtime": 4413.9721574783325, "_timestamp": 1585601783.605027, "_step": 333}
{"Episode reward": -99.76160017673253, "Episode length": 999, "Policy Loss": -1.0149592161178589, "Value Loss": 0.01941872201859951, "_runtime": 4414.961589097977, "_timestamp": 1585601784.5944586, "_step": 334}
{"Episode reward": 37.59666724590324, "Episode length": 633, "Policy Loss": 0.3157501518726349, "Value Loss": 15.773394584655762, "_runtime": 4416.499015331268, "_timestamp": 1585601786.1318848, "_step": 335}
{"Episode reward": -99.2199022194676, "Episode length": 999, "Policy Loss": -0.8488083481788635, "Value Loss": 0.014877211302518845, "_runtime": 4418.0629234313965, "_timestamp": 1585601787.695793, "_step": 336}
{"Episode reward": -99.7147650868618, "Episode length": 999, "Policy Loss": -0.7759220004081726, "Value Loss": 0.011647723615169525, "_runtime": 4419.588073730469, "_timestamp": 1585601789.2209432, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6294334530830383, "Value Loss": 0.007729771081358194, "_runtime": 4421.1327357292175, "_timestamp": 1585601790.7656052, "_step": 338}
{"Episode reward": -99.80548574020487, "Episode length": 999, "Policy Loss": -0.45458510518074036, "Value Loss": 0.004087945446372032, "_runtime": 4422.693905353546, "_timestamp": 1585601792.3267748, "_step": 339}
{"Episode reward": -99.80750130524383, "Episode length": 999, "Policy Loss": -0.2653736174106598, "Value Loss": 0.001450733165256679, "_runtime": 4424.249064922333, "_timestamp": 1585601793.8819344, "_step": 340}
{"Episode reward": -99.62222800800234, "Episode length": 999, "Policy Loss": -0.08343067020177841, "Value Loss": 0.0001703331945464015, "_runtime": 4425.438833236694, "_timestamp": 1585601795.0717027, "_step": 341}
{"Episode reward": 24.776824286052644, "Episode length": 762, "Policy Loss": 1.0068202018737793, "Value Loss": 13.126726150512695, "_runtime": 4427.005792379379, "_timestamp": 1585601796.6386619, "_step": 342}
{"Episode reward": -99.67589477965403, "Episode length": 999, "Policy Loss": 0.1701715737581253, "Value Loss": 0.0005911282496526837, "_runtime": 4428.558793067932, "_timestamp": 1585601798.1916625, "_step": 343}
{"Episode reward": -98.77524715879697, "Episode length": 999, "Policy Loss": 0.23175965249538422, "Value Loss": 0.0012484195176512003, "_runtime": 4429.965014696121, "_timestamp": 1585601799.5978842, "_step": 344}
{"Episode reward": 11.138197495865668, "Episode length": 889, "Policy Loss": 1.058297038078308, "Value Loss": 11.258935928344727, "_runtime": 4430.93220615387, "_timestamp": 1585601800.5650756, "_step": 345}
{"Episode reward": 41.812754254487146, "Episode length": 608, "Policy Loss": 1.5492099523544312, "Value Loss": 16.460514068603516, "_runtime": 4432.486689329147, "_timestamp": 1585601802.1195588, "_step": 346}
{"Episode reward": -99.82151727676252, "Episode length": 999, "Policy Loss": 0.12147195637226105, "Value Loss": 0.0002834643528331071, "_runtime": 4433.768959283829, "_timestamp": 1585601803.4018288, "_step": 347}
{"Episode reward": 18.182893363924038, "Episode length": 826, "Policy Loss": 0.8956313133239746, "Value Loss": 12.106473922729492, "_runtime": 4435.295790195465, "_timestamp": 1585601804.9286597, "_step": 348}
{"Episode reward": -99.82806076444545, "Episode length": 999, "Policy Loss": -0.17316733300685883, "Value Loss": 0.0005885763675905764, "_runtime": 4436.860020160675, "_timestamp": 1585601806.4928896, "_step": 349}
{"Episode reward": -99.80000387579062, "Episode length": 999, "Policy Loss": -0.30871203541755676, "Value Loss": 0.001929644146002829, "_runtime": 4438.140825510025, "_timestamp": 1585601807.773695, "_step": 350}
{"Episode reward": 17.751362218219242, "Episode length": 825, "Policy Loss": 0.43847885727882385, "Value Loss": 12.110444068908691, "_runtime": 4439.69810962677, "_timestamp": 1585601809.330979, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5510560870170593, "Value Loss": 0.005816180258989334, "_runtime": 4441.263622999191, "_timestamp": 1585601810.8964925, "_step": 352}
{"Episode reward": -97.73397381822737, "Episode length": 999, "Policy Loss": -0.5853852033615112, "Value Loss": 0.0073692528530955315, "_runtime": 4442.146226882935, "_timestamp": 1585601811.7790964, "_step": 353}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 0.6665483713150024, "Value Loss": 17.675182342529297, "_runtime": 4442.78132724762, "_timestamp": 1585601812.4141967, "_step": 354}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.0570834875106812, "Value Loss": 25.148481369018555, "_runtime": 4443.648857593536, "_timestamp": 1585601813.281727, "_step": 355}
{"Episode reward": 44.87678868239695, "Episode length": 553, "Policy Loss": 0.4395340085029602, "Value Loss": 18.05426597595215, "_runtime": 4445.178696393967, "_timestamp": 1585601814.8115659, "_step": 356}
{"Episode reward": -99.5259143341628, "Episode length": 999, "Policy Loss": -0.9685972332954407, "Value Loss": 0.01948222704231739, "_runtime": 4446.683470487595, "_timestamp": 1585601816.31634, "_step": 357}
{"Episode reward": -99.73019842423825, "Episode length": 999, "Policy Loss": -1.048435926437378, "Value Loss": 0.02227124385535717, "_runtime": 4448.196534872055, "_timestamp": 1585601817.8294044, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.055041790008545, "Value Loss": 0.02184300124645233, "_runtime": 4449.7452182769775, "_timestamp": 1585601819.3780878, "_step": 359}
{"Episode reward": -99.83136314460867, "Episode length": 999, "Policy Loss": -0.9796319603919983, "Value Loss": 0.01858091913163662, "_runtime": 4451.288365602493, "_timestamp": 1585601820.921235, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8354609608650208, "Value Loss": 0.013647432439029217, "_runtime": 4452.882751941681, "_timestamp": 1585601822.5156214, "_step": 361}
{"Episode reward": -99.8749383251227, "Episode length": 999, "Policy Loss": -0.6538770198822021, "Value Loss": 0.008329376578330994, "_runtime": 4454.425025701523, "_timestamp": 1585601824.0578952, "_step": 362}
{"Episode reward": -99.70487115729927, "Episode length": 999, "Policy Loss": -0.44951191544532776, "Value Loss": 0.003848011838272214, "_runtime": 4455.985762119293, "_timestamp": 1585601825.6186316, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22713753581047058, "Value Loss": 0.000994285219348967, "_runtime": 4457.548877000809, "_timestamp": 1585601827.1817465, "_step": 364}
{"Episode reward": -97.45025405790336, "Episode length": 999, "Policy Loss": 0.005409122444689274, "Value Loss": 0.00019418972078710794, "_runtime": 4458.600565195084, "_timestamp": 1585601828.2334347, "_step": 365}
{"Episode reward": 33.52999654465479, "Episode length": 669, "Policy Loss": 1.2067861557006836, "Value Loss": 14.955842971801758, "_runtime": 4459.904157876968, "_timestamp": 1585601829.5370274, "_step": 366}
{"Episode reward": 15.951136681941193, "Episode length": 847, "Policy Loss": 1.1380608081817627, "Value Loss": 11.816564559936523, "_runtime": 4461.470834493637, "_timestamp": 1585601831.103704, "_step": 367}
{"Episode reward": -99.58099424468679, "Episode length": 999, "Policy Loss": 0.26926347613334656, "Value Loss": 0.0014346728567034006, "_runtime": 4463.002702713013, "_timestamp": 1585601832.6355722, "_step": 368}
{"Episode reward": -99.0204363710106, "Episode length": 999, "Policy Loss": 0.23519182205200195, "Value Loss": 0.0013467095559462905, "_runtime": 4464.55473613739, "_timestamp": 1585601834.1876056, "_step": 369}
{"Episode reward": -99.77824826836446, "Episode length": 999, "Policy Loss": 0.21863915026187897, "Value Loss": 0.0009284655097872019, "_runtime": 4466.032382249832, "_timestamp": 1585601835.6652517, "_step": 370}
{"Episode reward": 7.771005130142925, "Episode length": 947, "Policy Loss": 0.9533146023750305, "Value Loss": 10.56568431854248, "_runtime": 4467.592458486557, "_timestamp": 1585601837.225328, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06746427714824677, "Value Loss": 8.736571908229962e-05, "_runtime": 4468.240601062775, "_timestamp": 1585601837.8734705, "_step": 372}
{"Episode reward": 61.52741367438511, "Episode length": 399, "Policy Loss": 1.8505128622055054, "Value Loss": 25.0606746673584, "_runtime": 4468.840699195862, "_timestamp": 1585601838.4735687, "_step": 373}
{"Episode reward": 62.999677279754295, "Episode length": 371, "Policy Loss": 1.7932907342910767, "Value Loss": 26.936952590942383, "_runtime": 4470.375875234604, "_timestamp": 1585601840.0087447, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5612287521362305, "Value Loss": 0.005895914975553751, "_runtime": 4471.609073638916, "_timestamp": 1585601841.2419431, "_step": 375}
{"Episode reward": 18.49189721976326, "Episode length": 817, "Policy Loss": 0.09130165725946426, "Value Loss": 12.225025177001953, "_runtime": 4473.107876062393, "_timestamp": 1585601842.7407455, "_step": 376}
{"Episode reward": -99.79763629920642, "Episode length": 999, "Policy Loss": -1.003879189491272, "Value Loss": 0.019814515486359596, "_runtime": 4473.735291957855, "_timestamp": 1585601843.3681614, "_step": 377}
{"Episode reward": 60.99999999999972, "Episode length": 390, "Policy Loss": 0.7150578498840332, "Value Loss": 25.58478355407715, "_runtime": 4474.708525657654, "_timestamp": 1585601844.3413951, "_step": 378}
{"Episode reward": 36.77903744612342, "Episode length": 634, "Policy Loss": -0.16376209259033203, "Value Loss": 15.748509407043457, "_runtime": 4475.536031484604, "_timestamp": 1585601845.168901, "_step": 379}
{"Episode reward": 46.44337400756728, "Episode length": 536, "Policy Loss": -0.08760190010070801, "Value Loss": 18.622058868408203, "_runtime": 4476.600256443024, "_timestamp": 1585601846.233126, "_step": 380}
{"Episode reward": 31.81558571511046, "Episode length": 685, "Policy Loss": -0.48997536301612854, "Value Loss": 14.582119941711426, "_runtime": 4478.1197147369385, "_timestamp": 1585601847.7525842, "_step": 381}
{"Episode reward": -99.5660911297019, "Episode length": 999, "Policy Loss": -1.6179859638214111, "Value Loss": 0.05134233832359314, "_runtime": 4479.631707906723, "_timestamp": 1585601849.2645774, "_step": 382}
{"Episode reward": -99.39913960351932, "Episode length": 999, "Policy Loss": -1.542954683303833, "Value Loss": 0.048206597566604614, "_runtime": 4481.162922620773, "_timestamp": 1585601850.795792, "_step": 383}
{"Episode reward": -99.4611674594188, "Episode length": 999, "Policy Loss": -1.384108066558838, "Value Loss": 0.03931569680571556, "_runtime": 4482.583958864212, "_timestamp": 1585601852.2168283, "_step": 384}
{"Episode reward": 10.368617824793645, "Episode length": 907, "Policy Loss": -0.15265411138534546, "Value Loss": 11.015986442565918, "_runtime": 4484.140631437302, "_timestamp": 1585601853.773501, "_step": 385}
{"Episode reward": -99.86486520925396, "Episode length": 999, "Policy Loss": -0.9337114095687866, "Value Loss": 0.017542975023388863, "_runtime": 4485.167893886566, "_timestamp": 1585601854.8007634, "_step": 386}
{"Episode reward": 35.04284920543374, "Episode length": 650, "Policy Loss": 0.41678884625434875, "Value Loss": 15.364603042602539, "_runtime": 4486.690718650818, "_timestamp": 1585601856.3235881, "_step": 387}
{"Episode reward": 2.995185845234502, "Episode length": 979, "Policy Loss": 0.3027782142162323, "Value Loss": 10.205618858337402, "_runtime": 4488.261379241943, "_timestamp": 1585601857.8942487, "_step": 388}
{"Episode reward": -99.82627860801738, "Episode length": 999, "Policy Loss": -0.26524272561073303, "Value Loss": 0.0013779522851109505, "_runtime": 4489.8021783828735, "_timestamp": 1585601859.4350479, "_step": 389}
{"Episode reward": -99.87252821378648, "Episode length": 999, "Policy Loss": -0.08390385657548904, "Value Loss": 0.0001412346464348957, "_runtime": 4491.123247861862, "_timestamp": 1585601860.7561173, "_step": 390}
{"Episode reward": 16.143671843223757, "Episode length": 840, "Policy Loss": 0.9677374958992004, "Value Loss": 11.907693862915039, "_runtime": 4492.688325643539, "_timestamp": 1585601862.3211951, "_step": 391}
{"Episode reward": -99.76294282683963, "Episode length": 999, "Policy Loss": 0.17378318309783936, "Value Loss": 0.000584052293561399, "_runtime": 4494.2590508461, "_timestamp": 1585601863.8919203, "_step": 392}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23481504619121552, "Value Loss": 0.0010947342962026596, "_runtime": 4495.8311858177185, "_timestamp": 1585601865.4640553, "_step": 393}
{"Episode reward": -99.58252504657001, "Episode length": 999, "Policy Loss": 0.28088101744651794, "Value Loss": 0.0015759844100102782, "_runtime": 4497.388513326645, "_timestamp": 1585601867.0213828, "_step": 394}
{"Episode reward": -99.01105211189103, "Episode length": 999, "Policy Loss": 0.288728266954422, "Value Loss": 0.0018996349535882473, "_runtime": 4498.592655658722, "_timestamp": 1585601868.2255251, "_step": 395}
{"Episode reward": 23.699214595556327, "Episode length": 764, "Policy Loss": 1.2008322477340698, "Value Loss": 13.101558685302734, "_runtime": 4499.962295293808, "_timestamp": 1585601869.5951648, "_step": 396}
{"Episode reward": 15.648404524382727, "Episode length": 844, "Policy Loss": 1.042324423789978, "Value Loss": 11.855999946594238, "_runtime": 4500.933781862259, "_timestamp": 1585601870.5666513, "_step": 397}
{"Episode reward": 39.3990899231279, "Episode length": 607, "Policy Loss": 1.4810339212417603, "Value Loss": 16.476913452148438, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374, 0.001395046478137374]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0], "bins": [-0.12468446791172028, -0.12275820225477219, -0.1208319365978241, -0.1189056783914566, -0.11697941273450851, -0.11505314707756042, -0.11312688142061234, -0.11120062321424484, -0.10927435755729675, -0.10734809190034866, -0.10542182624340057, -0.10349556803703308, -0.10156930238008499, -0.0996430367231369, -0.09771677106618881, -0.09579050540924072, -0.09386424720287323, -0.09193798154592514, -0.09001171588897705, -0.08808545768260956, -0.08615918457508087, -0.08423292636871338, -0.08230666071176529, -0.0803803950548172, -0.07845413684844971, -0.07652787119150162, -0.07460160553455353, -0.07267534732818604, -0.07074907422065735, -0.06882281601428986, -0.06689655035734177, -0.06497028470039368, -0.06304402649402618, -0.061117760837078094, -0.059191495180130005, -0.057265229523181915, -0.055338963866233826, -0.05341270565986633, -0.05148644000291824, -0.049560174345970154, -0.047633908689022064, -0.04570765048265457, -0.04378138482570648, -0.04185511916875839, -0.0399288535118103, -0.03800259530544281, -0.03607632964849472, -0.03415006399154663, -0.03222379833459854, -0.03029753267765045, -0.02837127447128296, -0.02644500881433487, -0.02451874315738678, -0.02259247750043869, -0.020666219294071198, -0.018739953637123108, -0.01681368798017502, -0.014887422323226929, -0.012961164116859436, -0.011034898459911346, -0.009108632802963257, -0.007182367146015167, -0.0052561089396476746, -0.003329843282699585, -0.0014035776257514954]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0], "bins": [-0.004675837699323893, -0.004570013843476772, -0.004464189987629652, -0.004358366131782532, -0.0042525422759354115, -0.004146718420088291, -0.004040894564241171, -0.003935070708394051, -0.0038292466197162867, -0.0037234227638691664, -0.003617598908022046, -0.003511774819344282, -0.003405950963497162, -0.0033001271076500416, -0.0031943032518029213, -0.003088479395955801, -0.0029826555401086807, -0.0028768316842615604, -0.00277100782841444, -0.00266518397256732, -0.0025593601167201996, -0.0024535360280424356, -0.0023477121721953154, -0.002241888316348195, -0.002136064460501075, -0.0020302406046539545, -0.0019244167488068342, -0.001818592892959714, -0.00171276880428195, -0.0016069449484348297, -0.0015011210925877094, -0.0013952972367405891, -0.0012894733808934689, -0.0011836495250463486, -0.0010778256691992283, -0.000972001813352108, -0.0008661779575049877, -0.0007603541016578674, -0.0006545302458107471, -0.0005487063899636269, -0.0004428825341165066, -0.000337058212608099, -0.0002312343567609787, -0.00012541050091385841, -1.958664506673813e-05, 8.623721078038216e-05, 0.00019206106662750244, 0.0002978849224746227, 0.000403708778321743, 0.0005095326341688633, 0.0006153564900159836, 0.0007211803458631039, 0.0008270042017102242, 0.0009328280575573444, 0.0010386519134044647, 0.001144475769251585, 0.0012503000907599926, 0.0013561239466071129, 0.0014619478024542332, 0.0015677716583013535, 0.0016735955141484737, 0.001779419369995594, 0.0018852432258427143, 0.0019910670816898346, 0.002096890937536955]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 7.0, 3.0, 4.0, 2.0, 3.0, 6.0, 2.0, 4.0, 3.0, 1.0, 4.0, 3.0, 3.0, 6.0, 4.0, 6.0, 8.0, 5.0, 7.0, 6.0, 1.0, 2.0, 2.0, 5.0, 15.0, 18.0, 11.0, 4.0, 6.0, 41.0, 53.0, 61.0, 35.0, 25.0, 16.0, 12.0, 3.0, 9.0, 16.0, 8.0, 10.0, 9.0, 7.0, 7.0, 7.0, 5.0, 3.0, 5.0, 5.0, 1.0, 6.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 1.0], "bins": [-0.010932757519185543, -0.010592739097774029, -0.01025271974503994, -0.009912701323628426, -0.009572682902216911, -0.009232664480805397, -0.008892646059393883, -0.008552626706659794, -0.00821260828524828, -0.007872589863836765, -0.007532570976763964, -0.007192552089691162, -0.006852533668279648, -0.0065125152468681335, -0.006172496359795332, -0.00583247747272253, -0.005492459051311016, -0.005152440629899502, -0.0048124217428267, -0.004472402855753899, -0.004132384434342384, -0.00379236601293087, -0.0034523471258580685, -0.003112328238785267, -0.0027723098173737526, -0.0024322913959622383, -0.002092272974550724, -0.0017522536218166351, -0.0014122352004051208, -0.0010722167789936066, -0.0007321974262595177, -0.0003921790048480034, -5.2160583436489105e-05, 0.0002878578379750252, 0.0006278762593865395, 0.0009678956121206284, 0.0013079140335321426, 0.001647932454943657, 0.001987951807677746, 0.00232797022908926, 0.0026679886505007744, 0.0030080070719122887, 0.003348025493323803, 0.003688044846057892, 0.004028063267469406, 0.00436808168888092, 0.004708101041615009, 0.005048119463026524, 0.005388137884438038, 0.005728156305849552, 0.0060681747272610664, 0.006408193148672581, 0.006748211570084095, 0.0070882318541407585, 0.007428250275552273, 0.007768268696963787, 0.008108287118375301, 0.008448305539786816, 0.00878832396119833, 0.009128342382609844, 0.009468362666666508, 0.009808381088078022, 0.010148399509489536, 0.01048841793090105, 0.010828436352312565]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0], "bins": [-0.09387663006782532, -0.09225274622440338, -0.09062886983156204, -0.0890049859881401, -0.08738110214471817, -0.08575722575187683, -0.0841333419084549, -0.08250945806503296, -0.08088557422161102, -0.07926169782876968, -0.07763781398534775, -0.07601393014192581, -0.07439005374908447, -0.07276616990566254, -0.0711422860622406, -0.06951840221881866, -0.06789452582597733, -0.06627064198255539, -0.06464675813913345, -0.06302288174629211, -0.06139899790287018, -0.05977511405944824, -0.058151233941316605, -0.05652735382318497, -0.05490346997976303, -0.05327958986163139, -0.05165570601820946, -0.05003182590007782, -0.04840794578194618, -0.046784061938524246, -0.04516018182039261, -0.04353629797697067, -0.041912417858839035, -0.0402885377407074, -0.03866465389728546, -0.037040773779153824, -0.03541688993573189, -0.03379300981760025, -0.03216912969946861, -0.030545249581336975, -0.02892136573791504, -0.027297481894493103, -0.025673598051071167, -0.024049721658229828, -0.022425837814807892, -0.020801953971385956, -0.019178077578544617, -0.01755419373512268, -0.015930309891700745, -0.014306433498859406, -0.01268254965543747, -0.011058665812015533, -0.009434781968593597, -0.007810905575752258, -0.006187021732330322, -0.004563137888908386, -0.002939261496067047, -0.001315377652645111, 0.00030850619077682495, 0.001932382583618164, 0.0035562664270401, 0.005180150270462036, 0.006804034113883972, 0.008427910506725311, 0.010051794350147247]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 10.0, 6.0, 4.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06932532042264938, -0.06736578047275543, -0.06540624052286148, -0.06344670802354813, -0.061487168073654175, -0.05952762812376022, -0.05756808817386627, -0.05560855194926262, -0.053649015724658966, -0.051689475774765015, -0.04972993582487106, -0.04777039960026741, -0.04581085965037346, -0.043851323425769806, -0.041891783475875854, -0.0399322435259819, -0.03797270730137825, -0.0360131673514843, -0.034053631126880646, -0.032094091176986694, -0.03013455495238304, -0.02817501500248909, -0.026215478777885437, -0.024255938827991486, -0.022296398878097534, -0.02033686265349388, -0.01837732270359993, -0.016417786478996277, -0.014458246529102325, -0.012498710304498672, -0.010539170354604721, -0.008579634130001068, -0.006620094180107117, -0.004660554230213165, -0.002701014280319214, -0.0007414817810058594, 0.001218058168888092, 0.0031775981187820435, 0.005137138068675995, 0.007096670567989349, 0.0090562105178833, 0.011015750467777252, 0.012975290417671204, 0.014934830367565155, 0.01689436286687851, 0.01885390281677246, 0.020813442766666412, 0.022772982716560364, 0.024732522666454315, 0.02669205516576767, 0.02865159511566162, 0.030611135065555573, 0.032570675015449524, 0.03453020751476288, 0.03648974746465683, 0.03844928741455078, 0.04040882736444473, 0.042368367314338684, 0.04432789981365204, 0.04628743976354599, 0.04824697971343994, 0.05020651966333389, 0.05216605216264725, 0.0541255921125412, 0.05608513206243515]}, "_runtime": 4502.487016439438, "_timestamp": 1585601872.119886, "_step": 398}
{"Episode reward": -99.75369230452786, "Episode length": 999, "Policy Loss": -0.1721271425485611, "Value Loss": 0.000588097725994885, "_runtime": 4504.04950594902, "_timestamp": 1585601873.6823754, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36684224009513855, "Value Loss": 0.002581981709226966, "_runtime": 4504.40220117569, "_timestamp": 1585601874.0350707, "_step": 400}
{"Episode reward": 79.5845036630926, "Episode length": 205, "Policy Loss": 2.8998770713806152, "Value Loss": 48.716007232666016, "_runtime": 4505.168825387955, "_timestamp": 1585601874.8016949, "_step": 401}
{"Episode reward": 51.55952664885431, "Episode length": 485, "Policy Loss": 0.642586350440979, "Value Loss": 20.583702087402344, "_runtime": 4506.7230525016785, "_timestamp": 1585601876.355922, "_step": 402}
{"Episode reward": -99.84605449794186, "Episode length": 999, "Policy Loss": -1.2082761526107788, "Value Loss": 0.027905507013201714, "_runtime": 4507.157187461853, "_timestamp": 1585601876.790057, "_step": 403}
{"Episode reward": 70.88521314931555, "Episode length": 292, "Policy Loss": 1.020372986793518, "Value Loss": 34.14973449707031, "_runtime": 4508.650812625885, "_timestamp": 1585601878.283682, "_step": 404}
{"Episode reward": -99.80460791922965, "Episode length": 999, "Policy Loss": -1.7273210287094116, "Value Loss": 0.05669207498431206, "_runtime": 4509.4259469509125, "_timestamp": 1585601879.0588164, "_step": 405}
{"Episode reward": 52.10722261252003, "Episode length": 488, "Policy Loss": -0.05787063390016556, "Value Loss": 20.4516658782959, "_runtime": 4510.921548128128, "_timestamp": 1585601880.5544176, "_step": 406}
{"Episode reward": -99.8020602217163, "Episode length": 999, "Policy Loss": -1.8970056772232056, "Value Loss": 0.07273987680673599, "_runtime": 4512.469888448715, "_timestamp": 1585601882.102758, "_step": 407}
{"Episode reward": -99.84488770998875, "Episode length": 999, "Policy Loss": -1.8702913522720337, "Value Loss": 0.06910116970539093, "_runtime": 4513.406121253967, "_timestamp": 1585601883.0389907, "_step": 408}
{"Episode reward": 38.246509935869234, "Episode length": 618, "Policy Loss": -0.5453158617019653, "Value Loss": 16.16089630126953, "_runtime": 4514.941072463989, "_timestamp": 1585601884.573942, "_step": 409}
{"Episode reward": -99.62946101971764, "Episode length": 999, "Policy Loss": -1.5126185417175293, "Value Loss": 0.04457872733473778, "_runtime": 4516.484325885773, "_timestamp": 1585601886.1171954, "_step": 410}
{"Episode reward": -99.80485752560058, "Episode length": 999, "Policy Loss": -1.2334824800491333, "Value Loss": 0.02965395525097847, "_runtime": 4518.001834154129, "_timestamp": 1585601887.6347036, "_step": 411}
{"Episode reward": -99.8816208139048, "Episode length": 999, "Policy Loss": -0.9085676670074463, "Value Loss": 0.015673115849494934, "_runtime": 4518.942172527313, "_timestamp": 1585601888.575042, "_step": 412}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 0.6341821551322937, "Value Loss": 16.67525863647461, "_runtime": 4519.703488349915, "_timestamp": 1585601889.3363578, "_step": 413}
{"Episode reward": 52.699999999999605, "Episode length": 473, "Policy Loss": 1.288814902305603, "Value Loss": 21.12820816040039, "_runtime": 4521.256189823151, "_timestamp": 1585601890.8890593, "_step": 414}
{"Episode reward": -99.71400874028774, "Episode length": 999, "Policy Loss": -0.07938642054796219, "Value Loss": 0.00013425399083644152, "_runtime": 4522.7879321575165, "_timestamp": 1585601892.4208016, "_step": 415}
{"Episode reward": -99.81626426586742, "Episode length": 999, "Policy Loss": 0.07751487195491791, "Value Loss": 0.00012332794722169638, "_runtime": 4524.334611415863, "_timestamp": 1585601893.967481, "_step": 416}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2117796540260315, "Value Loss": 0.0008790498250164092, "_runtime": 4525.897032499313, "_timestamp": 1585601895.529902, "_step": 417}
{"Episode reward": -99.69420849694731, "Episode length": 999, "Policy Loss": 0.3256562352180481, "Value Loss": 0.0020279132295399904, "_runtime": 4527.071194887161, "_timestamp": 1585601896.7040644, "_step": 418}
{"Episode reward": 25.29998434446749, "Episode length": 748, "Policy Loss": 1.3160719871520996, "Value Loss": 13.386768341064453, "_runtime": 4528.611064195633, "_timestamp": 1585601898.2439337, "_step": 419}
{"Episode reward": -99.72336058898843, "Episode length": 999, "Policy Loss": 0.35879918932914734, "Value Loss": 0.00266859563998878, "_runtime": 4530.174831151962, "_timestamp": 1585601899.8077006, "_step": 420}
{"Episode reward": -99.58910797535799, "Episode length": 999, "Policy Loss": 0.3177090287208557, "Value Loss": 0.002021591644734144, "_runtime": 4531.7113444805145, "_timestamp": 1585601901.344214, "_step": 421}
{"Episode reward": -99.59762129918678, "Episode length": 999, "Policy Loss": 0.24435871839523315, "Value Loss": 0.0012634629383683205, "_runtime": 4533.26375079155, "_timestamp": 1585601902.8966203, "_step": 422}
{"Episode reward": -99.81039731837669, "Episode length": 999, "Policy Loss": 0.1760071963071823, "Value Loss": 0.0005906036822125316, "_runtime": 4534.271137714386, "_timestamp": 1585601903.9040072, "_step": 423}
{"Episode reward": 35.677255688139965, "Episode length": 644, "Policy Loss": 1.1913857460021973, "Value Loss": 15.531997680664062, "_runtime": 4535.818638086319, "_timestamp": 1585601905.4515076, "_step": 424}
{"Episode reward": -99.7677719252403, "Episode length": 999, "Policy Loss": -0.06806174665689468, "Value Loss": 9.876271360553801e-05, "_runtime": 4536.908131122589, "_timestamp": 1585601906.5410006, "_step": 425}
{"Episode reward": 31.796324466441405, "Episode length": 694, "Policy Loss": 0.8352888822555542, "Value Loss": 14.401790618896484, "_runtime": 4538.160423755646, "_timestamp": 1585601907.7932932, "_step": 426}
{"Episode reward": 19.79768289111584, "Episode length": 815, "Policy Loss": 0.581782877445221, "Value Loss": 12.25948429107666, "_runtime": 4539.66076540947, "_timestamp": 1585601909.293635, "_step": 427}
{"Episode reward": 2.6523734642903634, "Episode length": 975, "Policy Loss": 0.23368345201015472, "Value Loss": 10.24628734588623, "_runtime": 4541.193034410477, "_timestamp": 1585601910.825904, "_step": 428}
{"Episode reward": -99.89795369217032, "Episode length": 999, "Policy Loss": -0.7768210768699646, "Value Loss": 0.011876381002366543, "_runtime": 4542.662186861038, "_timestamp": 1585601912.2950563, "_step": 429}
{"Episode reward": 4.795756032854527, "Episode length": 953, "Policy Loss": -0.15292836725711823, "Value Loss": 10.482563018798828, "_runtime": 4543.8850021362305, "_timestamp": 1585601913.5178716, "_step": 430}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.13889607787132263, "Value Loss": 12.6904878616333, "_runtime": 4545.106158733368, "_timestamp": 1585601914.7390282, "_step": 431}
{"Episode reward": 22.10386665028979, "Episode length": 780, "Policy Loss": -0.010353944264352322, "Value Loss": 12.804511070251465, "_runtime": 4546.686996936798, "_timestamp": 1585601916.3198664, "_step": 432}
{"Episode reward": -99.71423509325695, "Episode length": 999, "Policy Loss": -1.121095061302185, "Value Loss": 0.024945072829723358, "_runtime": 4548.224591016769, "_timestamp": 1585601917.8574605, "_step": 433}
{"Episode reward": -99.81506391204753, "Episode length": 999, "Policy Loss": -1.0865110158920288, "Value Loss": 0.02386770211160183, "_runtime": 4549.513291120529, "_timestamp": 1585601919.1461606, "_step": 434}
{"Episode reward": 16.711475677015642, "Episode length": 836, "Policy Loss": -0.14404326677322388, "Value Loss": 11.947773933410645, "_runtime": 4550.967225551605, "_timestamp": 1585601920.600095, "_step": 435}
{"Episode reward": 7.065853439272459, "Episode length": 930, "Policy Loss": -0.07388545572757721, "Value Loss": 10.74145793914795, "_runtime": 4552.527926683426, "_timestamp": 1585601922.1607962, "_step": 436}
{"Episode reward": -99.62480166386675, "Episode length": 999, "Policy Loss": -0.8023841381072998, "Value Loss": 0.012555776163935661, "_runtime": 4553.739128112793, "_timestamp": 1585601923.3719976, "_step": 437}
{"Episode reward": 22.59674451276672, "Episode length": 776, "Policy Loss": 0.3470112085342407, "Value Loss": 12.871374130249023, "_runtime": 4554.243759155273, "_timestamp": 1585601923.8766286, "_step": 438}
{"Episode reward": 71.06837756608977, "Episode length": 302, "Policy Loss": 1.869494915008545, "Value Loss": 33.067935943603516, "_runtime": 4555.795228242874, "_timestamp": 1585601925.4280977, "_step": 439}
{"Episode reward": -99.59734881652847, "Episode length": 999, "Policy Loss": -0.5724611282348633, "Value Loss": 0.006322389934211969, "_runtime": 4557.34416270256, "_timestamp": 1585601926.9770322, "_step": 440}
{"Episode reward": -99.82814165213937, "Episode length": 999, "Policy Loss": -0.5578699707984924, "Value Loss": 0.006027489434927702, "_runtime": 4558.834096193314, "_timestamp": 1585601928.4669657, "_step": 441}
{"Episode reward": -99.79213090308338, "Episode length": 999, "Policy Loss": -0.5066655278205872, "Value Loss": 0.004942433442920446, "_runtime": 4560.392659902573, "_timestamp": 1585601930.0255294, "_step": 442}
{"Episode reward": -99.76857306347088, "Episode length": 999, "Policy Loss": -0.41901543736457825, "Value Loss": 0.0034508437383919954, "_runtime": 4561.945985078812, "_timestamp": 1585601931.5788546, "_step": 443}
{"Episode reward": -99.77213891727963, "Episode length": 999, "Policy Loss": -0.31262385845184326, "Value Loss": 0.001954801846295595, "_runtime": 4563.482531547546, "_timestamp": 1585601933.115401, "_step": 444}
{"Episode reward": -99.11294206344701, "Episode length": 999, "Policy Loss": -0.1899789273738861, "Value Loss": 0.0008024516282603145, "_runtime": 4565.047136545181, "_timestamp": 1585601934.680006, "_step": 445}
{"Episode reward": -99.81180801540474, "Episode length": 999, "Policy Loss": -0.08079589158296585, "Value Loss": 0.00013384627527557313, "_runtime": 4566.613889932632, "_timestamp": 1585601936.2467594, "_step": 446}
{"Episode reward": -99.62371781091647, "Episode length": 999, "Policy Loss": 0.034091766923666, "Value Loss": 4.7978246584534645e-05, "_runtime": 4568.165890693665, "_timestamp": 1585601937.7987602, "_step": 447}
{"Episode reward": -99.61073372490215, "Episode length": 999, "Policy Loss": 0.13276034593582153, "Value Loss": 0.0003750405157916248, "_runtime": 4569.770820856094, "_timestamp": 1585601939.4036903, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21247193217277527, "Value Loss": 0.0008713756105862558, "_runtime": 4571.341330051422, "_timestamp": 1585601940.9741995, "_step": 449}
{"Episode reward": -99.84106006510417, "Episode length": 999, "Policy Loss": 0.2706335783004761, "Value Loss": 0.0014105739537626505, "_runtime": 4572.898866653442, "_timestamp": 1585601942.5317361, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3052543103694916, "Value Loss": 0.0017597416881471872, "_runtime": 4574.455035209656, "_timestamp": 1585601944.0879047, "_step": 451}
{"Episode reward": -99.73504925102323, "Episode length": 999, "Policy Loss": 0.31070148944854736, "Value Loss": 0.0018712999299168587, "_runtime": 4576.024227380753, "_timestamp": 1585601945.6570969, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.29457971453666687, "Value Loss": 0.0016628579469397664, "_runtime": 4577.584538221359, "_timestamp": 1585601947.2174077, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.25656816363334656, "Value Loss": 0.0012864917516708374, "_runtime": 4579.1600596904755, "_timestamp": 1585601948.7929292, "_step": 454}
{"Episode reward": -99.78155641229684, "Episode length": 999, "Policy Loss": 0.20968039333820343, "Value Loss": 0.0008485809667035937, "_runtime": 4579.809443473816, "_timestamp": 1585601949.442313, "_step": 455}
{"Episode reward": 60.892238484229615, "Episode length": 392, "Policy Loss": 2.0121378898620605, "Value Loss": 25.521066665649414, "_runtime": 4581.371052026749, "_timestamp": 1585601951.0039215, "_step": 456}
{"Episode reward": -99.81608996987204, "Episode length": 999, "Policy Loss": -0.04957897216081619, "Value Loss": 5.512253846973181e-05, "_runtime": 4582.900964021683, "_timestamp": 1585601952.5338335, "_step": 457}
{"Episode reward": 2.343756923231723, "Episode length": 979, "Policy Loss": 0.5713944435119629, "Value Loss": 10.209094047546387, "_runtime": 4583.844838142395, "_timestamp": 1585601953.4777076, "_step": 458}
{"Episode reward": 37.66668996810852, "Episode length": 624, "Policy Loss": 0.9324306845664978, "Value Loss": 16.01032066345215, "_runtime": 4585.394384622574, "_timestamp": 1585601955.027254, "_step": 459}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6402828097343445, "Value Loss": 0.008111003786325455, "_runtime": 4586.768865346909, "_timestamp": 1585601956.4017348, "_step": 460}
{"Episode reward": 12.100000000000719, "Episode length": 879, "Policy Loss": 0.014013509266078472, "Value Loss": 11.363629341125488, "_runtime": 4588.283132314682, "_timestamp": 1585601957.9160018, "_step": 461}
{"Episode reward": -99.86153223011503, "Episode length": 999, "Policy Loss": -0.9599233865737915, "Value Loss": 0.01745760813355446, "_runtime": 4589.835726976395, "_timestamp": 1585601959.4685965, "_step": 462}
{"Episode reward": -99.65880809354135, "Episode length": 999, "Policy Loss": -1.0098927021026611, "Value Loss": 0.01971529610455036, "_runtime": 4591.385141372681, "_timestamp": 1585601961.0180109, "_step": 463}
{"Episode reward": -99.736406941175, "Episode length": 999, "Policy Loss": -0.9996811747550964, "Value Loss": 0.019015563651919365, "_runtime": 4591.888252735138, "_timestamp": 1585601961.5211222, "_step": 464}
{"Episode reward": 70.19999999999985, "Episode length": 298, "Policy Loss": 1.556191325187683, "Value Loss": 33.48847579956055, "_runtime": 4593.47599697113, "_timestamp": 1585601963.1088665, "_step": 465}
{"Episode reward": -99.81483735479274, "Episode length": 999, "Policy Loss": -0.9376285076141357, "Value Loss": 0.016829781234264374, "_runtime": 4594.596960067749, "_timestamp": 1585601964.2298295, "_step": 466}
{"Episode reward": 28.567180772264294, "Episode length": 718, "Policy Loss": 0.11400612443685532, "Value Loss": 13.908333778381348, "_runtime": 4596.083045721054, "_timestamp": 1585601965.7159152, "_step": 467}
{"Episode reward": -99.8063665047274, "Episode length": 999, "Policy Loss": -0.8439302444458008, "Value Loss": 0.014402375556528568, "_runtime": 4597.637983560562, "_timestamp": 1585601967.270853, "_step": 468}
{"Episode reward": -99.714524646946, "Episode length": 999, "Policy Loss": -0.7668395638465881, "Value Loss": 0.011578907258808613, "_runtime": 4598.998291015625, "_timestamp": 1585601968.6311605, "_step": 469}
{"Episode reward": 12.792109143868544, "Episode length": 873, "Policy Loss": 0.1719483733177185, "Value Loss": 11.442281723022461, "_runtime": 4600.549592018127, "_timestamp": 1585601970.1824615, "_step": 470}
{"Episode reward": -99.74425914594764, "Episode length": 999, "Policy Loss": -0.5332882404327393, "Value Loss": 0.005415244027972221, "_runtime": 4601.5979199409485, "_timestamp": 1585601971.2307894, "_step": 471}
{"Episode reward": 34.95576463034705, "Episode length": 654, "Policy Loss": 0.7446346879005432, "Value Loss": 15.276782035827637, "_runtime": 4602.362553596497, "_timestamp": 1585601971.995423, "_step": 472}
{"Episode reward": 52.301085135293725, "Episode length": 478, "Policy Loss": 1.2534281015396118, "Value Loss": 20.9038028717041, "_runtime": 4603.830492734909, "_timestamp": 1585601973.4633622, "_step": 473}
{"Episode reward": 6.741972332684142, "Episode length": 954, "Policy Loss": 0.48097506165504456, "Value Loss": 10.474396705627441, "_runtime": 4605.381806850433, "_timestamp": 1585601975.0146763, "_step": 474}
{"Episode reward": -99.86714614117378, "Episode length": 999, "Policy Loss": -0.3903024196624756, "Value Loss": 0.0030030258931219578, "_runtime": 4606.90154504776, "_timestamp": 1585601976.5344145, "_step": 475}
{"Episode reward": 0.6481262114682949, "Episode length": 999, "Policy Loss": 0.3481205403804779, "Value Loss": 10.001800537109375, "_runtime": 4608.457616567612, "_timestamp": 1585601978.090486, "_step": 476}
{"Episode reward": -99.75142955556373, "Episode length": 999, "Policy Loss": -0.45630183815956116, "Value Loss": 0.003898061579093337, "_runtime": 4609.205331087112, "_timestamp": 1585601978.8382006, "_step": 477}
{"Episode reward": 53.79999999999962, "Episode length": 462, "Policy Loss": 1.124099850654602, "Value Loss": 21.621801376342773, "_runtime": 4610.766176939011, "_timestamp": 1585601980.3990464, "_step": 478}
{"Episode reward": -99.83572841940774, "Episode length": 999, "Policy Loss": -0.5319212079048157, "Value Loss": 0.005499260500073433, "_runtime": 4612.328600883484, "_timestamp": 1585601981.9614704, "_step": 479}
{"Episode reward": -99.82131000757077, "Episode length": 999, "Policy Loss": -0.5483894348144531, "Value Loss": 0.0062476894818246365, "_runtime": 4613.849900722504, "_timestamp": 1585601983.4827702, "_step": 480}
{"Episode reward": -99.86941054016212, "Episode length": 999, "Policy Loss": -0.565348744392395, "Value Loss": 0.006032788660377264, "_runtime": 4615.384491920471, "_timestamp": 1585601985.0173614, "_step": 481}
{"Episode reward": 3.207479164393419, "Episode length": 975, "Policy Loss": 0.24346096813678741, "Value Loss": 10.246855735778809, "_runtime": 4616.290359735489, "_timestamp": 1585601985.9232292, "_step": 482}
{"Episode reward": 46.22826853989924, "Episode length": 539, "Policy Loss": 0.8182565569877625, "Value Loss": 18.532564163208008, "_runtime": 4617.844843864441, "_timestamp": 1585601987.4777133, "_step": 483}
{"Episode reward": -99.70215832844703, "Episode length": 999, "Policy Loss": -0.5202218890190125, "Value Loss": 0.005186689086258411, "_runtime": 4619.424426078796, "_timestamp": 1585601989.0572956, "_step": 484}
{"Episode reward": -99.83506209784979, "Episode length": 999, "Policy Loss": -0.5217249393463135, "Value Loss": 0.005108923185616732, "_runtime": 4620.956533908844, "_timestamp": 1585601990.5894034, "_step": 485}
{"Episode reward": -99.71959192618677, "Episode length": 999, "Policy Loss": -0.4684032201766968, "Value Loss": 0.004313808400183916, "_runtime": 4622.489349603653, "_timestamp": 1585601992.122219, "_step": 486}
{"Episode reward": 2.9245772354491777, "Episode length": 972, "Policy Loss": 0.385988712310791, "Value Loss": 10.279696464538574, "_runtime": 4624.014126062393, "_timestamp": 1585601993.6469955, "_step": 487}
{"Episode reward": 3.884415128156732, "Episode length": 968, "Policy Loss": 0.39493608474731445, "Value Loss": 10.322738647460938, "_runtime": 4625.5805311203, "_timestamp": 1585601995.2134006, "_step": 488}
{"Episode reward": -99.78362829035474, "Episode length": 999, "Policy Loss": -0.34863778948783875, "Value Loss": 0.00240556919015944, "_runtime": 4627.1575355529785, "_timestamp": 1585601996.790405, "_step": 489}
{"Episode reward": -99.8015431056018, "Episode length": 999, "Policy Loss": -0.3206859827041626, "Value Loss": 0.0019826944917440414, "_runtime": 4628.718849182129, "_timestamp": 1585601998.3517187, "_step": 490}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2687845528125763, "Value Loss": 0.001376928761601448, "_runtime": 4630.276681661606, "_timestamp": 1585601999.9095511, "_step": 491}
{"Episode reward": -99.75902386503155, "Episode length": 999, "Policy Loss": -0.19969657063484192, "Value Loss": 0.00076850107870996, "_runtime": 4631.833963394165, "_timestamp": 1585602001.4668329, "_step": 492}
{"Episode reward": -99.6972741173159, "Episode length": 999, "Policy Loss": -0.1208731085062027, "Value Loss": 0.00030243920627981424, "_runtime": 4633.393149137497, "_timestamp": 1585602003.0260186, "_step": 493}
{"Episode reward": -99.8166729465113, "Episode length": 999, "Policy Loss": -0.04502428323030472, "Value Loss": 4.64954755443614e-05, "_runtime": 4634.933799266815, "_timestamp": 1585602004.5666687, "_step": 494}
{"Episode reward": -99.8255091557629, "Episode length": 999, "Policy Loss": 0.02763229049742222, "Value Loss": 1.7846499758888967e-05, "_runtime": 4636.224196910858, "_timestamp": 1585602005.8570664, "_step": 495}
{"Episode reward": 17.363431789736197, "Episode length": 834, "Policy Loss": 1.224640965461731, "Value Loss": 11.993695259094238, "_runtime": 4637.780661582947, "_timestamp": 1585602007.413531, "_step": 496}
{"Episode reward": -99.80534680941933, "Episode length": 999, "Policy Loss": 0.07686444371938705, "Value Loss": 0.00012575849541462958, "_runtime": 4639.051529407501, "_timestamp": 1585602008.684399, "_step": 497}
{"Episode reward": 20.648065824731248, "Episode length": 795, "Policy Loss": 0.9630329608917236, "Value Loss": 12.580743789672852, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824, 0.00032725458731874824]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0012309651356190443, -0.001199629856273532, -0.0011682945769280195, -0.0011369591811671853, -0.001105623901821673, -0.0010742886224761605, -0.0010429533431306481, -0.0010116180637851357, -0.0009802826680243015, -0.0009489473886787891, -0.0009176121093332767, -0.0008862768299877644, -0.000854941550642252, -0.0008236062130890787, -0.0007922709337435663, -0.000760935596190393, -0.0007296003168448806, -0.0006982650374993682, -0.0006669296999461949, -0.0006355944206006825, -0.0006042590830475092, -0.0005729238037019968, -0.0005415885243564844, -0.0005102531868033111, -0.0004789179074577987, -0.00044758262811228633, -0.000416247290559113, -0.00038491201121360064, -0.00035357673186808825, -0.00032224139431491494, -0.00029090611496940255, -0.00025957077741622925, -0.00022823549807071686, -0.00019690021872520447, -0.00016556493937969208, -0.00013422954361885786, -0.00010289426427334547, -7.155898492783308e-05, -4.022370558232069e-05, -8.8884262368083e-06, 2.2446969524025917e-05, 5.378224886953831e-05, 8.51175282150507e-05, 0.00011645280756056309, 0.00014778808690607548, 0.00017912336625158787, 0.00021045876201242208, 0.00024179404135793447, 0.00027312932070344687, 0.00030446460004895926, 0.00033579987939447165, 0.00036713527515530586, 0.00039847055450081825, 0.00042980583384633064, 0.00046114111319184303, 0.0004924763925373554, 0.0005238116718828678, 0.000555147067643702, 0.0005864823469892144, 0.0006178176263347268, 0.0006491529056802392, 0.0006804881850257516, 0.0007118235807865858, 0.0007431588601320982, 0.0007744941394776106]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0], "bins": [-0.00048720272025093436, -0.0004719042917713523, -0.0004566058923956007, -0.00044130749301984906, -0.000426009064540267, -0.0004107106360606849, -0.0003954122366849333, -0.0003801138373091817, -0.0003648154088295996, -0.00034951698035001755, -0.00033421858097426593, -0.0003189201815985143, -0.00030362175311893225, -0.0002883233246393502, -0.00027302492526359856, -0.00025772652588784695, -0.00024242809740826488, -0.0002271296689286828, -0.0002118312695529312, -0.00019653287017717957, -0.0001812344416975975, -0.00016593601321801543, -0.00015063761384226382, -0.0001353392144665122, -0.00012004078598693013, -0.00010474235750734806, -8.944395813159645e-05, -7.414555875584483e-05, -5.884713027626276e-05, -4.354870179668069e-05, -2.8250302420929074e-05, -1.295190304517746e-05, 2.3465254344046116e-06, 1.7644953913986683e-05, 3.2943382393568754e-05, 4.824175266548991e-05, 6.354018114507198e-05, 7.883860962465405e-05, 9.413697989657521e-05, 0.00010943540837615728, 0.00012473383685573936, 0.00014003226533532143, 0.0001553306938149035, 0.00017062906408682466, 0.00018592749256640673, 0.0002012259210459888, 0.00021652429131790996, 0.00023182271979749203, 0.0002471211482770741, 0.00026241957675665617, 0.00027771800523623824, 0.0002930163755081594, 0.00030831480398774147, 0.00032361323246732354, 0.0003389116027392447, 0.00035421003121882677, 0.00036950845969840884, 0.0003848068881779909, 0.000400105316657573, 0.00041540368692949414, 0.0004307021154090762, 0.0004460005438886583, 0.00046129891416057944, 0.0004765973426401615, 0.0004918957711197436]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [6.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 4.0, 2.0, 0.0, 4.0, 5.0, 3.0, 6.0, 7.0, 9.0, 17.0, 11.0, 17.0, 23.0, 16.0, 19.0, 29.0, 7.0, 19.0, 26.0, 14.0, 16.0, 31.0, 32.0, 36.0, 22.0, 43.0, 18.0, 22.0, 8.0, 6.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.0008357222541235387, -0.0008097304962575436, -0.0007837387383915484, -0.0007577469805255532, -0.0007317552226595581, -0.0007057634647935629, -0.0006797716487199068, -0.0006537799490615726, -0.0006277881329879165, -0.0006017964333295822, -0.0005758046172559261, -0.0005498129175975919, -0.0005238211015239358, -0.0004978293436579406, -0.00047183758579194546, -0.0004458458279259503, -0.0004198540700599551, -0.00039386231219395995, -0.0003678705543279648, -0.0003418787964619696, -0.00031588703859597445, -0.0002898952807299793, -0.0002639035228639841, -0.00023791176499798894, -0.00021191994892433286, -0.0001859281910583377, -0.00015993643319234252, -0.00013394467532634735, -0.00010795291746035218, -8.196115959435701e-05, -5.5969401728361845e-05, -2.9977643862366676e-05, -3.985885996371508e-06, 2.200587186962366e-05, 4.799762973561883e-05, 7.3989387601614e-05, 9.998114546760917e-05, 0.00012597290333360434, 0.0001519646611995995, 0.0001779564772732556, 0.00020394817693158984, 0.00022993999300524592, 0.0002559316926635802, 0.00028192350873723626, 0.0003079152083955705, 0.0003339070244692266, 0.00035989872412756085, 0.00038589054020121694, 0.000411882356274873, 0.0004378740559332073, 0.00046386587200686336, 0.0004898575716651976, 0.0005158493877388537, 0.000541841087397188, 0.000567832903470844, 0.0005938246031291783, 0.0006198164192028344, 0.0006458081188611686, 0.0006717999349348247, 0.000697791634593159, 0.000723783450666815, 0.0007497751503251493, 0.0007757669663988054, 0.0008017586660571396, 0.0008277504821307957]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005086615681648254, -0.004876496270298958, -0.004666376858949661, -0.004456257913261652, -0.004246138501912355, -0.004036019090563059, -0.003825899912044406, -0.003615780733525753, -0.0034056613221764565, -0.00319554191082716, -0.002985422732308507, -0.002775303553789854, -0.0025651841424405575, -0.002355064731091261, -0.002144945552572608, -0.001934826374053955, -0.0017247069627046585, -0.001514587551355362, -0.001304468372836709, -0.001094349194318056, -0.0008842297829687595, -0.000674110371619463, -0.0004639914259314537, -0.00025387201458215714, -4.3752603232860565e-05, 0.000166366808116436, 0.0003764862194657326, 0.0005866051651537418, 0.0007967245765030384, 0.001006843987852335, 0.0012169629335403442, 0.0014270823448896408, 0.0016372017562389374, 0.001847321167588234, 0.0020574405789375305, 0.0022675595246255398, 0.0024776789359748363, 0.002687798347324133, 0.002897917293012142, 0.0031080367043614388, 0.0033181561157107353, 0.003528275527060032, 0.0037383949384093285, 0.003948514349758625, 0.004158632829785347, 0.0043687522411346436, 0.00457887165248394, 0.004788991063833237, 0.004999110475182533, 0.00520922988653183, 0.005419349297881126, 0.005629468709230423, 0.0058395881205797195, 0.0060497066006064415, 0.006259826011955738, 0.006469945423305035, 0.006680064834654331, 0.006890184246003628, 0.007100303657352924, 0.007310423068702221, 0.007520541548728943, 0.0077306609600782394, 0.007940780371427536, 0.008150899782776833, 0.00836101919412613]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 5.0, 9.0, 6.0, 6.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.013972461223602295, -0.013575280085206032, -0.013178099878132343, -0.01278091873973608, -0.012383738532662392, -0.011986557394266129, -0.011589376255869865, -0.011192195117473602, -0.010795014910399914, -0.010397834703326225, -0.010000653564929962, -0.009603472426533699, -0.009206291288137436, -0.008809111081063747, -0.008411929942667484, -0.008014749735593796, -0.007617568597197533, -0.007220387924462557, -0.006823207251727581, -0.006426026113331318, -0.006028845906257629, -0.005631664767861366, -0.005234483629465103, -0.004837303422391415, -0.0044401222839951515, -0.004042941145598888, -0.0036457609385252, -0.0032485798001289368, -0.0028513986617326736, -0.002454218454658985, -0.002057037316262722, -0.0016598571091890335, -0.0012626759707927704, -0.0008654948323965073, -0.00046831462532281876, -7.113348692655563e-05, 0.0003260467201471329, 0.000723227858543396, 0.0011204089969396591, 0.0015175892040133476, 0.0019147694110870361, 0.0023119505494832993, 0.0027091316878795624, 0.0031063128262758255, 0.0035034939646720886, 0.0039006751030683517, 0.004297854378819466, 0.004695035517215729, 0.005092216655611992, 0.005489397794008255, 0.005886578932404518, 0.006283758208155632, 0.006680939346551895, 0.007078120484948158, 0.007475301623344421, 0.007872482761740685, 0.008269663900136948, 0.008666843175888062, 0.009064024314284325, 0.009461205452680588, 0.009858386591076851, 0.010255567729473114, 0.010652747005224228, 0.011049928143620491, 0.011447109282016754]}, "_runtime": 4640.582844495773, "_timestamp": 1585602010.215714, "_step": 498}
{"Episode reward": -99.61968249075443, "Episode length": 999, "Policy Loss": -0.027896961197257042, "Value Loss": 4.1544590203557163e-05, "_runtime": 4640.582844495773, "_timestamp": 1585602010.215714, "_step": 499}
