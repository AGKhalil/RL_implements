{"Episode reward": 43.464298958414545, "Episode length": 935, "Policy Loss": 0.06948477774858475, "Value Loss": 10.620131492614746, "_runtime": 11797.430249214172, "_timestamp": 1585609167.0631187, "_step": 0}
{"Episode reward": 1.3615885657095959, "Episode length": 998, "Policy Loss": -3.067906379699707, "Value Loss": 327.3122253417969, "_runtime": 11798.943115711212, "_timestamp": 1585609168.5759852, "_step": 1}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.03714411333203316, "Value Loss": 3.3508312702178955, "_runtime": 11800.535818576813, "_timestamp": 1585609170.168688, "_step": 2}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6385092735290527, "Value Loss": 1.9275938272476196, "_runtime": 11802.141704797745, "_timestamp": 1585609171.7745743, "_step": 3}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -4.765612602233887, "Value Loss": 160.07955932617188, "_runtime": 11803.68250489235, "_timestamp": 1585609173.3153744, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.742929220199585, "Value Loss": 51.77610397338867, "_runtime": 11805.276445627213, "_timestamp": 1585609174.909315, "_step": 5}
{"Episode reward": -98.42486270725767, "Episode length": 999, "Policy Loss": 4.097537994384766, "Value Loss": 40.75802993774414, "_runtime": 11806.838193893433, "_timestamp": 1585609176.4710634, "_step": 6}
{"Episode reward": -98.2156862737832, "Episode length": 999, "Policy Loss": 9.826191902160645, "Value Loss": 254.7623748779297, "_runtime": 11808.3790371418, "_timestamp": 1585609178.0119066, "_step": 7}
{"Episode reward": -99.29277715380614, "Episode length": 999, "Policy Loss": -2.0377798080444336, "Value Loss": 62.58903884887695, "_runtime": 11809.954364538193, "_timestamp": 1585609179.587234, "_step": 8}
{"Episode reward": -99.54820295088436, "Episode length": 999, "Policy Loss": -2.6140356063842773, "Value Loss": 29.165096282958984, "_runtime": 11811.534377098083, "_timestamp": 1585609181.1672466, "_step": 9}
{"Episode reward": -98.91941660079458, "Episode length": 999, "Policy Loss": -7.37739896774292, "Value Loss": 42.1392822265625, "_runtime": 11813.097869873047, "_timestamp": 1585609182.7307394, "_step": 10}
{"Episode reward": -98.49118291626253, "Episode length": 999, "Policy Loss": -3.763446807861328, "Value Loss": 5.92580509185791, "_runtime": 11814.684757947922, "_timestamp": 1585609184.3176274, "_step": 11}
{"Episode reward": -97.50698804111383, "Episode length": 999, "Policy Loss": -2.2957842350006104, "Value Loss": 27.804962158203125, "_runtime": 11816.268388986588, "_timestamp": 1585609185.9012585, "_step": 12}
{"Episode reward": -95.28659379892747, "Episode length": 999, "Policy Loss": -1.0239266157150269, "Value Loss": 2.8274803161621094, "_runtime": 11817.828970193863, "_timestamp": 1585609187.4618397, "_step": 13}
{"Episode reward": -82.36905349219118, "Episode length": 999, "Policy Loss": -0.09389951080083847, "Value Loss": 0.15016289055347443, "_runtime": 11819.420841693878, "_timestamp": 1585609189.0537112, "_step": 14}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.573905348777771, "Value Loss": 6.514596939086914, "_runtime": 11821.007124900818, "_timestamp": 1585609190.6399944, "_step": 15}
{"Episode reward": -98.55901632263513, "Episode length": 999, "Policy Loss": -0.9347344636917114, "Value Loss": 1.8659406900405884, "_runtime": 11822.579972743988, "_timestamp": 1585609192.2128422, "_step": 16}
{"Episode reward": -99.67694053559288, "Episode length": 999, "Policy Loss": -0.6602378487586975, "Value Loss": 7.500972270965576, "_runtime": 11824.175594568253, "_timestamp": 1585609193.808464, "_step": 17}
{"Episode reward": -99.79314972281297, "Episode length": 999, "Policy Loss": 0.37738871574401855, "Value Loss": 11.870942115783691, "_runtime": 11825.791059970856, "_timestamp": 1585609195.4239295, "_step": 18}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15275178849697113, "Value Loss": 10.559721946716309, "_runtime": 11827.366258144379, "_timestamp": 1585609196.9991276, "_step": 19}
{"Episode reward": -99.66612185952913, "Episode length": 999, "Policy Loss": 3.6628224849700928, "Value Loss": 39.14145278930664, "_runtime": 11828.961607933044, "_timestamp": 1585609198.5944774, "_step": 20}
{"Episode reward": -99.89478420056263, "Episode length": 999, "Policy Loss": -0.5460766553878784, "Value Loss": 48.10162353515625, "_runtime": 11830.554721593857, "_timestamp": 1585609200.187591, "_step": 21}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -9.248955726623535, "Value Loss": 483.12908935546875, "_runtime": 11832.126066684723, "_timestamp": 1585609201.7589362, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6230053305625916, "Value Loss": 104.16447448730469, "_runtime": 11833.720018863678, "_timestamp": 1585609203.3528883, "_step": 23}
{"Episode reward": -99.74579886430736, "Episode length": 999, "Policy Loss": 2.3150668144226074, "Value Loss": 955.0333862304688, "_runtime": 11835.302020549774, "_timestamp": 1585609204.93489, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8864011764526367, "Value Loss": 523.3748168945312, "_runtime": 11835.956352949142, "_timestamp": 1585609205.5892224, "_step": 25}
{"Episode reward": 61.0979427084324, "Episode length": 390, "Policy Loss": 2.990459680557251, "Value Loss": 62.31470489501953, "_runtime": 11837.546163320541, "_timestamp": 1585609207.1790328, "_step": 26}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7567355632781982, "Value Loss": 47.234134674072266, "_runtime": 11838.825299263, "_timestamp": 1585609208.4581687, "_step": 27}
{"Episode reward": 19.80000000000028, "Episode length": 802, "Policy Loss": 1.0463560819625854, "Value Loss": 144.42942810058594, "_runtime": 11840.351422071457, "_timestamp": 1585609209.9842916, "_step": 28}
{"Episode reward": -99.8050999224172, "Episode length": 999, "Policy Loss": 1.8152387142181396, "Value Loss": 3.1145663261413574, "_runtime": 11841.95021367073, "_timestamp": 1585609211.5830832, "_step": 29}
{"Episode reward": -99.80163660049298, "Episode length": 999, "Policy Loss": 1.2890076637268066, "Value Loss": 7.365057468414307, "_runtime": 11843.186883687973, "_timestamp": 1585609212.8197532, "_step": 30}
{"Episode reward": 21.83735215663927, "Episode length": 782, "Policy Loss": 2.464646577835083, "Value Loss": 39.255924224853516, "_runtime": 11844.745799064636, "_timestamp": 1585609214.3786685, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8442729115486145, "Value Loss": 5.017068862915039, "_runtime": 11846.230905771255, "_timestamp": 1585609215.8637753, "_step": 32}
{"Episode reward": 7.300000000000992, "Episode length": 927, "Policy Loss": 2.047556161880493, "Value Loss": 67.08232879638672, "_runtime": 11847.79383802414, "_timestamp": 1585609217.4267075, "_step": 33}
{"Episode reward": -99.80006571411947, "Episode length": 999, "Policy Loss": 0.5878540277481079, "Value Loss": 1.2210575342178345, "_runtime": 11848.462362766266, "_timestamp": 1585609218.0952322, "_step": 34}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 2.7155487537384033, "Value Loss": 25.51506233215332, "_runtime": 11850.070167303085, "_timestamp": 1585609219.7030368, "_step": 35}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4664176106452942, "Value Loss": 1.9689714908599854, "_runtime": 11851.64972114563, "_timestamp": 1585609221.2825906, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6142408847808838, "Value Loss": 4.218898296356201, "_runtime": 11853.173212766647, "_timestamp": 1585609222.8060822, "_step": 37}
{"Episode reward": -99.84616432785849, "Episode length": 999, "Policy Loss": 0.22067275643348694, "Value Loss": 51.59429931640625, "_runtime": 11854.571491718292, "_timestamp": 1585609224.2043612, "_step": 38}
{"Episode reward": 11.800000000000736, "Episode length": 882, "Policy Loss": 1.0397629737854004, "Value Loss": 89.93132781982422, "_runtime": 11855.690067768097, "_timestamp": 1585609225.3229373, "_step": 39}
{"Episode reward": 30.39046343564955, "Episode length": 697, "Policy Loss": 0.8533864617347717, "Value Loss": 26.395008087158203, "_runtime": 11856.403423309326, "_timestamp": 1585609226.0362928, "_step": 40}
{"Episode reward": 55.99999999999965, "Episode length": 440, "Policy Loss": 1.0312014818191528, "Value Loss": 25.595670700073242, "_runtime": 11857.976058483124, "_timestamp": 1585609227.608928, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.638043999671936, "Value Loss": 3.255204200744629, "_runtime": 11859.540975093842, "_timestamp": 1585609229.1738446, "_step": 42}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.2079050540924072, "Value Loss": 24.619441986083984, "_runtime": 11859.930432081223, "_timestamp": 1585609229.5633016, "_step": 43}
{"Episode reward": 76.69999999999995, "Episode length": 233, "Policy Loss": 2.1445274353027344, "Value Loss": 119.78277587890625, "_runtime": 11860.4454164505, "_timestamp": 1585609230.078286, "_step": 44}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 1.1436998844146729, "Value Loss": 142.05157470703125, "_runtime": 11862.008542776108, "_timestamp": 1585609231.6414123, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.212435245513916, "Value Loss": 2.990318775177002, "_runtime": 11862.804010629654, "_timestamp": 1585609232.43688, "_step": 46}
{"Episode reward": 47.699999999999534, "Episode length": 523, "Policy Loss": -2.0225412845611572, "Value Loss": 30.446063995361328, "_runtime": 11864.306770563126, "_timestamp": 1585609233.93964, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -3.6563475131988525, "Value Loss": 27.632633209228516, "_runtime": 11865.865105628967, "_timestamp": 1585609235.497975, "_step": 48}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": -2.0974957942962646, "Value Loss": 35.75444793701172, "_runtime": 11866.882810115814, "_timestamp": 1585609236.5156796, "_step": 49}
{"Episode reward": 33.69999999999949, "Episode length": 663, "Policy Loss": -2.057234764099121, "Value Loss": 59.39714813232422, "_runtime": 11868.1859228611, "_timestamp": 1585609237.8187923, "_step": 50}
{"Episode reward": 15.800000000000509, "Episode length": 842, "Policy Loss": -1.211823582649231, "Value Loss": 21.649906158447266, "_runtime": 11869.429597139359, "_timestamp": 1585609239.0624666, "_step": 51}
{"Episode reward": 22.10000000000015, "Episode length": 779, "Policy Loss": -0.6610810160636902, "Value Loss": 15.40607738494873, "_runtime": 11870.984734773636, "_timestamp": 1585609240.6176043, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1005704402923584, "Value Loss": 6.894576072692871, "_runtime": 11872.53235077858, "_timestamp": 1585609242.1652203, "_step": 53}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.98261958360672, "Value Loss": 2.6297192573547363, "_runtime": 11873.62796163559, "_timestamp": 1585609243.260831, "_step": 54}
{"Episode reward": 33.4999999999995, "Episode length": 665, "Policy Loss": 1.1729800701141357, "Value Loss": 18.234867095947266, "_runtime": 11875.188681602478, "_timestamp": 1585609244.821551, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.35187527537345886, "Value Loss": 1.3743252754211426, "_runtime": 11876.45426940918, "_timestamp": 1585609246.087139, "_step": 56}
{"Episode reward": 20.20000000000026, "Episode length": 798, "Policy Loss": 0.9992274045944214, "Value Loss": 18.626142501831055, "_runtime": 11877.99677991867, "_timestamp": 1585609247.6296494, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05376999452710152, "Value Loss": 4.174583911895752, "_runtime": 11879.345175266266, "_timestamp": 1585609248.9780447, "_step": 58}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": 1.1458992958068848, "Value Loss": 14.937968254089355, "_runtime": 11880.897107601166, "_timestamp": 1585609250.529977, "_step": 59}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.10720379650592804, "Value Loss": 4.036670207977295, "_runtime": 11881.733249664307, "_timestamp": 1585609251.3661191, "_step": 60}
{"Episode reward": 48.69999999999955, "Episode length": 513, "Policy Loss": 1.8696290254592896, "Value Loss": 22.612064361572266, "_runtime": 11883.281298875809, "_timestamp": 1585609252.9141684, "_step": 61}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08298607170581818, "Value Loss": 1.930586576461792, "_runtime": 11884.852533340454, "_timestamp": 1585609254.4854028, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16972871124744415, "Value Loss": 0.8760657906532288, "_runtime": 11886.245866537094, "_timestamp": 1585609255.878736, "_step": 63}
{"Episode reward": 9.500000000000867, "Episode length": 905, "Policy Loss": 0.8345483541488647, "Value Loss": 12.925748825073242, "_runtime": 11887.832576990128, "_timestamp": 1585609257.4654465, "_step": 64}
{"Episode reward": -99.812932592629, "Episode length": 999, "Policy Loss": -0.3440413773059845, "Value Loss": 0.7619776725769043, "_runtime": 11889.414341926575, "_timestamp": 1585609259.0472114, "_step": 65}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5040209889411926, "Value Loss": 0.2497812956571579, "_runtime": 11890.978814601898, "_timestamp": 1585609260.611684, "_step": 66}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5998643636703491, "Value Loss": 0.04743937402963638, "_runtime": 11892.557157993317, "_timestamp": 1585609262.1900275, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6829597353935242, "Value Loss": 0.1090867668390274, "_runtime": 11893.221308708191, "_timestamp": 1585609262.8541782, "_step": 68}
{"Episode reward": 60.2707302093503, "Episode length": 398, "Policy Loss": 1.589089035987854, "Value Loss": 25.497882843017578, "_runtime": 11894.805229187012, "_timestamp": 1585609264.4380987, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8509771227836609, "Value Loss": 0.07938875257968903, "_runtime": 11895.869497299194, "_timestamp": 1585609265.5023668, "_step": 70}
{"Episode reward": 33.89999999999948, "Episode length": 661, "Policy Loss": 0.4113612473011017, "Value Loss": 15.230162620544434, "_runtime": 11897.441727161407, "_timestamp": 1585609267.0745966, "_step": 71}
{"Episode reward": -99.82238657474377, "Episode length": 999, "Policy Loss": -1.0104458332061768, "Value Loss": 0.027006519958376884, "_runtime": 11899.020889759064, "_timestamp": 1585609268.6537592, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.098449468612671, "Value Loss": 0.12050990015268326, "_runtime": 11900.570223808289, "_timestamp": 1585609270.2030933, "_step": 73}
{"Episode reward": -99.8157393515096, "Episode length": 999, "Policy Loss": -1.1444947719573975, "Value Loss": 0.06654267758131027, "_runtime": 11902.147276639938, "_timestamp": 1585609271.7801461, "_step": 74}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1875709295272827, "Value Loss": 0.040599215775728226, "_runtime": 11903.741803884506, "_timestamp": 1585609273.3746734, "_step": 75}
{"Episode reward": -99.86633338928083, "Episode length": 999, "Policy Loss": -1.2393971681594849, "Value Loss": 0.07941581308841705, "_runtime": 11904.62902879715, "_timestamp": 1585609274.2618983, "_step": 76}
{"Episode reward": 45.4999999999995, "Episode length": 545, "Policy Loss": 0.388347327709198, "Value Loss": 18.33660316467285, "_runtime": 11905.610936164856, "_timestamp": 1585609275.2438056, "_step": 77}
{"Episode reward": 38.3999999999994, "Episode length": 616, "Policy Loss": 0.21016442775726318, "Value Loss": 16.16526985168457, "_runtime": 11907.067215919495, "_timestamp": 1585609276.7000854, "_step": 78}
{"Episode reward": 7.628147888184557, "Episode length": 924, "Policy Loss": -0.3513730764389038, "Value Loss": 10.767021179199219, "_runtime": 11908.475599527359, "_timestamp": 1585609278.108469, "_step": 79}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": -0.31195172667503357, "Value Loss": 10.891047477722168, "_runtime": 11909.94155216217, "_timestamp": 1585609279.5744216, "_step": 80}
{"Episode reward": 5.100000000001117, "Episode length": 949, "Policy Loss": -0.04378988593816757, "Value Loss": 10.475607872009277, "_runtime": 11910.67464375496, "_timestamp": 1585609280.3075132, "_step": 81}
{"Episode reward": 54.99999999999964, "Episode length": 450, "Policy Loss": 0.623150646686554, "Value Loss": 21.986085891723633, "_runtime": 11911.614579916, "_timestamp": 1585609281.2474494, "_step": 82}
{"Episode reward": 40.799999999999436, "Episode length": 592, "Policy Loss": 0.23544195294380188, "Value Loss": 16.976926803588867, "_runtime": 11912.914749860764, "_timestamp": 1585609282.5476193, "_step": 83}
{"Episode reward": 17.800000000000395, "Episode length": 822, "Policy Loss": -0.349578857421875, "Value Loss": 12.1217622756958, "_runtime": 11914.36916422844, "_timestamp": 1585609284.0020337, "_step": 84}
{"Episode reward": 5.500000000001094, "Episode length": 945, "Policy Loss": -0.39248067140579224, "Value Loss": 10.547263145446777, "_runtime": 11915.91609287262, "_timestamp": 1585609285.5489624, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5030161142349243, "Value Loss": 0.056450992822647095, "_runtime": 11917.483172416687, "_timestamp": 1585609287.116042, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5171293020248413, "Value Loss": 0.059059374034404755, "_runtime": 11919.045691013336, "_timestamp": 1585609288.6785605, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5217442512512207, "Value Loss": 0.049147844314575195, "_runtime": 11920.615381240845, "_timestamp": 1585609290.2482507, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5126214027404785, "Value Loss": 0.07066962867975235, "_runtime": 11921.065761089325, "_timestamp": 1585609290.6986306, "_step": 89}
{"Episode reward": 77.48474121093746, "Episode length": 226, "Policy Loss": 2.4970765113830566, "Value Loss": 43.54645919799805, "_runtime": 11922.635627746582, "_timestamp": 1585609292.2684972, "_step": 90}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5262762308120728, "Value Loss": 0.05110381543636322, "_runtime": 11924.235846757889, "_timestamp": 1585609293.8687162, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.52451753616333, "Value Loss": 0.04966419190168381, "_runtime": 11924.717658758163, "_timestamp": 1585609294.3505282, "_step": 92}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 1.3564326763153076, "Value Loss": 31.364355087280273, "_runtime": 11926.303839683533, "_timestamp": 1585609295.9367092, "_step": 93}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5142889022827148, "Value Loss": 0.034677449613809586, "_runtime": 11926.843957185745, "_timestamp": 1585609296.4768267, "_step": 94}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 1.6147959232330322, "Value Loss": 31.853862762451172, "_runtime": 11928.37673664093, "_timestamp": 1585609298.0096061, "_step": 95}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5277845859527588, "Value Loss": 0.17264686524868011, "_runtime": 11929.383181810379, "_timestamp": 1585609299.0160513, "_step": 96}
{"Episode reward": 37.70648316740929, "Episode length": 623, "Policy Loss": 0.014621532522141933, "Value Loss": 15.801161766052246, "_runtime": 11930.913097381592, "_timestamp": 1585609300.5459669, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.505807876586914, "Value Loss": 0.06575146317481995, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343, -0.005764206871390343]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0], "bins": [-0.8582601547241211, -0.8447487950325012, -0.8312374353408813, -0.8177260160446167, -0.8042146563529968, -0.790703296661377, -0.7771919369697571, -0.7636805176734924, -0.7501691579818726, -0.7366577982902527, -0.7231464385986328, -0.7096350193023682, -0.6961236596107483, -0.6826122999191284, -0.6691009402275085, -0.6555895805358887, -0.642078161239624, -0.6285668015480042, -0.6150554418563843, -0.6015440225601196, -0.5880327224731445, -0.5745213031768799, -0.56100994348526, -0.5474985837936401, -0.5339871644973755, -0.5204758048057556, -0.5069644451141357, -0.4934530556201935, -0.4799416959285736, -0.46643030643463135, -0.4529189467430115, -0.4394075572490692, -0.42589619755744934, -0.41238483786582947, -0.3988734483718872, -0.38536208868026733, -0.3718506991863251, -0.3583393394947052, -0.34482795000076294, -0.33131659030914307, -0.3178052306175232, -0.30429381132125854, -0.29078245162963867, -0.2772710919380188, -0.2637597322463989, -0.2502483129501343, -0.2367369532585144, -0.22322559356689453, -0.20971423387527466, -0.19620287418365479, -0.18269145488739014, -0.16918009519577026, -0.1556687355041504, -0.14215737581253052, -0.12864595651626587, -0.115134596824646, -0.10162323713302612, -0.08811187744140625, -0.0746004581451416, -0.06108909845352173, -0.047577738761901855, -0.03406637907028198, -0.020554959774017334, -0.007043600082397461, 0.006467759609222412]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.028027409687638283, -0.027549216523766518, -0.027071023359894753, -0.026592828333377838, -0.026114635169506073, -0.025636442005634308, -0.025158248841762543, -0.024680055677890778, -0.024201862514019012, -0.023723669350147247, -0.023245476186275482, -0.022767281159758568, -0.022289087995886803, -0.021810894832015038, -0.021332701668143272, -0.020854508504271507, -0.020376313477754593, -0.019898120313882828, -0.019419927150011063, -0.018941733986139297, -0.018463540822267532, -0.017985347658395767, -0.017507154494524002, -0.017028961330652237, -0.016550766304135323, -0.016072573140263557, -0.015594379976391792, -0.015116186812520027, -0.014637992717325687, -0.014159799553453922, -0.013681606389582157, -0.013203412294387817, -0.012725219130516052, -0.012247025966644287, -0.011768832802772522, -0.011290639638900757, -0.010812444612383842, -0.010334251448512077, -0.009856058284640312, -0.009377865120768547, -0.008899671956896782, -0.008421478793025017, -0.007943283766508102, -0.007465090602636337, -0.006986897438764572, -0.006508704274892807, -0.006030511111021042, -0.005552317947149277, -0.005074122920632362, -0.004595929756760597, -0.004117736592888832, -0.003639543429017067, -0.003161350265145302, -0.0026831571012735367, -0.0022049639374017715, -0.0017267689108848572, -0.001248575747013092, -0.0007703825831413269, -0.00029218941926956177, 0.00018600374460220337, 0.0006641969084739685, 0.0011423919349908829, 0.001620585098862648, 0.002098778262734413, 0.0025769714266061783]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 2.0, 5.0, 1.0, 4.0, 6.0, 10.0, 4.0, 8.0, 37.0, 252.0, 18.0, 12.0, 12.0, 12.0, 14.0, 10.0, 16.0, 20.0, 18.0], "bins": [-0.1580192744731903, -0.15511377155780792, -0.15220826864242554, -0.14930276572704315, -0.14639726281166077, -0.14349175989627838, -0.140586256980896, -0.1376807540655136, -0.13477525115013123, -0.13186974823474884, -0.12896424531936646, -0.12605875730514526, -0.12315324693918228, -0.1202477440237999, -0.11734224855899811, -0.11443674564361572, -0.11153124272823334, -0.10862573981285095, -0.10572023689746857, -0.10281473398208618, -0.0999092310667038, -0.09700372815132141, -0.09409822523593903, -0.09119272232055664, -0.08828721940517426, -0.08538171648979187, -0.08247621357440948, -0.0795707181096077, -0.07666521519422531, -0.07375971227884293, -0.07085420936346054, -0.06794870644807816, -0.06504320353269577, -0.062137700617313385, -0.059232197701931, -0.056326694786548615, -0.05342119187116623, -0.050515688955783844, -0.047610193490982056, -0.04470469057559967, -0.041799187660217285, -0.0388936847448349, -0.035988181829452515, -0.03308267891407013, -0.030177175998687744, -0.02727167308330536, -0.024366170167922974, -0.02146066725254059, -0.018555164337158203, -0.015649661421775818, -0.012744158506393433, -0.009838655591011047, -0.006933152675628662, -0.004027649760246277, -0.0011221617460250854, 0.0017833411693572998, 0.004688844084739685, 0.00759434700012207, 0.010499849915504456, 0.01340535283088684, 0.016310855746269226, 0.01921635866165161, 0.022121861577033997, 0.025027364492416382, 0.027932867407798767]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 8.0, 2.0, 2.0], "bins": [-0.6238661408424377, -0.6137004494667053, -0.6035347580909729, -0.5933690667152405, -0.5832034349441528, -0.5730377435684204, -0.562872052192688, -0.5527063608169556, -0.5425406694412231, -0.5323749780654907, -0.5222092866897583, -0.5120435953140259, -0.5018779039382935, -0.4917122423648834, -0.4815465807914734, -0.47138088941574097, -0.46121519804000854, -0.4510495066642761, -0.4408838152885437, -0.43071815371513367, -0.42055246233940125, -0.4103867709636688, -0.4002211093902588, -0.39005541801452637, -0.37988972663879395, -0.3697240352630615, -0.3595583438873291, -0.34939268231391907, -0.33922699093818665, -0.3290612995624542, -0.3188956379890442, -0.30872994661331177, -0.29856425523757935, -0.2883985638618469, -0.2782328724861145, -0.26806721091270447, -0.25790151953697205, -0.24773582816123962, -0.2375701665878296, -0.22740447521209717, -0.21723878383636475, -0.20707309246063232, -0.1969074010848999, -0.18674173951148987, -0.17657604813575745, -0.16641035676002502, -0.156244695186615, -0.14607900381088257, -0.13591331243515015, -0.12574762105941772, -0.1155819296836853, -0.10541623830795288, -0.09525054693222046, -0.08508491516113281, -0.07491922378540039, -0.06475353240966797, -0.05458784103393555, -0.044422149658203125, -0.0342564582824707, -0.02409076690673828, -0.013925135135650635, -0.003759443759918213, 0.006406247615814209, 0.01657193899154663, 0.026737630367279053]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 1.0, 18.0, 6.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.055799711495637894, -0.0528264082968235, -0.04985310882329941, -0.046879805624485016, -0.043906502425670624, -0.04093319922685623, -0.03795989602804184, -0.034986596554517746, -0.032013293355703354, -0.029039990156888962, -0.02606668882071972, -0.023093387484550476, -0.020120084285736084, -0.017146781086921692, -0.014173481613397598, -0.011200178414583206, -0.008226875215768814, -0.005253572016954422, -0.00228026881814003, 0.0006930306553840637, 0.003666333854198456, 0.006639637053012848, 0.009612936526536942, 0.012586239725351334, 0.015559542924165726, 0.018532846122980118, 0.02150614932179451, 0.024479452520608902, 0.027452748268842697, 0.03042605146765709, 0.03339935466647148, 0.03637265786528587, 0.039345961064100266, 0.04231926426291466, 0.04529256746172905, 0.04826587066054344, 0.051239173859357834, 0.05421246960759163, 0.05718577280640602, 0.06015907600522041, 0.0631323754787445, 0.0661056786775589, 0.06907898187637329, 0.07205228507518768, 0.07502558827400208, 0.07799889147281647, 0.08097219467163086, 0.08394549787044525, 0.08691880106925964, 0.08989210426807404, 0.09286540746688843, 0.09583871066570282, 0.09881201386451721, 0.1017853170633316, 0.104758620262146, 0.10773192346096039, 0.11070521175861359, 0.11367851495742798, 0.11665181815624237, 0.11962512135505676, 0.12259842455387115, 0.12557172775268555, 0.12854503095149994, 0.13151833415031433, 0.13449163734912872]}, "_runtime": 11932.49382853508, "_timestamp": 1585609302.126698, "_step": 98}
{"Episode reward": -99.74542461633543, "Episode length": 999, "Policy Loss": -1.507156252861023, "Value Loss": 0.08302615582942963, "_runtime": 11934.053129911423, "_timestamp": 1585609303.6859994, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4931272268295288, "Value Loss": 0.07000679522752762, "_runtime": 11935.637096881866, "_timestamp": 1585609305.2699664, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4537224769592285, "Value Loss": 0.07245045155286789, "_runtime": 11936.717172384262, "_timestamp": 1585609306.3500419, "_step": 101}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": -0.028805101290345192, "Value Loss": 14.590299606323242, "_runtime": 11937.88407087326, "_timestamp": 1585609307.5169404, "_step": 102}
{"Episode reward": 27.19999999999986, "Episode length": 728, "Policy Loss": -0.20384995639324188, "Value Loss": 13.555021286010742, "_runtime": 11939.006893634796, "_timestamp": 1585609308.639763, "_step": 103}
{"Episode reward": 29.399999999999736, "Episode length": 706, "Policy Loss": -0.12405642122030258, "Value Loss": 13.9924955368042, "_runtime": 11940.094536781311, "_timestamp": 1585609309.7274063, "_step": 104}
{"Episode reward": 30.599999999999667, "Episode length": 694, "Policy Loss": -0.04379050061106682, "Value Loss": 14.2995023727417, "_runtime": 11941.646793365479, "_timestamp": 1585609311.2796628, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3727303743362427, "Value Loss": 0.09489872306585312, "_runtime": 11943.208015680313, "_timestamp": 1585609312.8408852, "_step": 106}
{"Episode reward": -99.80458436608176, "Episode length": 999, "Policy Loss": -1.3439936637878418, "Value Loss": 0.334865927696228, "_runtime": 11943.96083188057, "_timestamp": 1585609313.5937014, "_step": 107}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 0.6710239052772522, "Value Loss": 21.033123016357422, "_runtime": 11945.586834669113, "_timestamp": 1585609315.2197042, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2934077978134155, "Value Loss": 0.17376579344272614, "_runtime": 11946.742733478546, "_timestamp": 1585609316.375603, "_step": 109}
{"Episode reward": 27.39999999999985, "Episode length": 726, "Policy Loss": -0.019614920020103455, "Value Loss": 13.601359367370605, "_runtime": 11948.281679391861, "_timestamp": 1585609317.9145489, "_step": 110}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2575536966323853, "Value Loss": 0.15483969449996948, "_runtime": 11949.874888420105, "_timestamp": 1585609319.507758, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2073328495025635, "Value Loss": 0.033510658890008926, "_runtime": 11951.434858322144, "_timestamp": 1585609321.0677278, "_step": 112}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.169571876525879, "Value Loss": 0.040505073964595795, "_runtime": 11953.012570858002, "_timestamp": 1585609322.6454403, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.136473298072815, "Value Loss": 0.1578989326953888, "_runtime": 11954.596298217773, "_timestamp": 1585609324.2291677, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.084659457206726, "Value Loss": 0.09220188856124878, "_runtime": 11955.385476827621, "_timestamp": 1585609325.0183463, "_step": 115}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": 0.8225415945053101, "Value Loss": 20.56442642211914, "_runtime": 11956.974860668182, "_timestamp": 1585609326.6077302, "_step": 116}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0263761281967163, "Value Loss": 0.051619693636894226, "_runtime": 11957.700402975082, "_timestamp": 1585609327.3332725, "_step": 117}
{"Episode reward": 56.39548852443661, "Episode length": 437, "Policy Loss": 1.1641258001327515, "Value Loss": 22.5112247467041, "_runtime": 11959.043267250061, "_timestamp": 1585609328.6761367, "_step": 118}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 0.2808026969432831, "Value Loss": 11.51137924194336, "_runtime": 11960.620062351227, "_timestamp": 1585609330.2529318, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9286107420921326, "Value Loss": 0.032054077833890915, "_runtime": 11961.400485754013, "_timestamp": 1585609331.0333552, "_step": 120}
{"Episode reward": 50.09999999999957, "Episode length": 499, "Policy Loss": 1.2404179573059082, "Value Loss": 19.793514251708984, "_runtime": 11962.970969676971, "_timestamp": 1585609332.6038392, "_step": 121}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8842491507530212, "Value Loss": 0.015042918734252453, "_runtime": 11964.546393156052, "_timestamp": 1585609334.1792626, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8703088760375977, "Value Loss": 0.09041241556406021, "_runtime": 11966.08490562439, "_timestamp": 1585609335.717775, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8364549875259399, "Value Loss": 0.05456830561161041, "_runtime": 11967.671625852585, "_timestamp": 1585609337.3044953, "_step": 124}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8155880570411682, "Value Loss": 0.023826392367482185, "_runtime": 11969.00142621994, "_timestamp": 1585609338.6342957, "_step": 125}
{"Episode reward": 19.000000000000327, "Episode length": 810, "Policy Loss": 0.3284516930580139, "Value Loss": 12.178803443908691, "_runtime": 11970.56323313713, "_timestamp": 1585609340.1961026, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.754990816116333, "Value Loss": 0.043977122753858566, "_runtime": 11972.166111946106, "_timestamp": 1585609341.7989814, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7413530349731445, "Value Loss": 0.014936789870262146, "_runtime": 11973.390018463135, "_timestamp": 1585609343.022888, "_step": 128}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.5712210536003113, "Value Loss": 12.776839256286621, "_runtime": 11974.833619594574, "_timestamp": 1585609344.466489, "_step": 129}
{"Episode reward": 9.454430907965573, "Episode length": 906, "Policy Loss": 0.32402652502059937, "Value Loss": 10.924351692199707, "_runtime": 11975.599968910217, "_timestamp": 1585609345.2328384, "_step": 130}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 1.2833833694458008, "Value Loss": 21.296646118164062, "_runtime": 11976.558098316193, "_timestamp": 1585609346.1909678, "_step": 131}
{"Episode reward": 40.099999999999426, "Episode length": 599, "Policy Loss": 0.86156165599823, "Value Loss": 16.50942611694336, "_runtime": 11977.447653055191, "_timestamp": 1585609347.0805225, "_step": 132}
{"Episode reward": 44.39999999999949, "Episode length": 556, "Policy Loss": 0.9579374194145203, "Value Loss": 17.771503448486328, "_runtime": 11978.995428323746, "_timestamp": 1585609348.6282978, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6579720973968506, "Value Loss": 0.04516849294304848, "_runtime": 11980.096141815186, "_timestamp": 1585609349.7290113, "_step": 134}
{"Episode reward": 30.099999999999696, "Episode length": 699, "Policy Loss": 0.6684189438819885, "Value Loss": 14.12510871887207, "_runtime": 11981.354923248291, "_timestamp": 1585609350.9877927, "_step": 135}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.5572920441627502, "Value Loss": 11.964964866638184, "_runtime": 11982.13524389267, "_timestamp": 1585609351.7681134, "_step": 136}
{"Episode reward": 52.2999999999996, "Episode length": 477, "Policy Loss": 1.2526297569274902, "Value Loss": 20.67033576965332, "_runtime": 11983.037779569626, "_timestamp": 1585609352.670649, "_step": 137}
{"Episode reward": 42.799999999999464, "Episode length": 572, "Policy Loss": 0.9262971878051758, "Value Loss": 17.25198745727539, "_runtime": 11983.892616271973, "_timestamp": 1585609353.5254858, "_step": 138}
{"Episode reward": 45.79999999999951, "Episode length": 542, "Policy Loss": 0.9689898490905762, "Value Loss": 18.249149322509766, "_runtime": 11985.439197301865, "_timestamp": 1585609355.0720668, "_step": 139}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7319768071174622, "Value Loss": 0.038309331983327866, "_runtime": 11986.126968622208, "_timestamp": 1585609355.759838, "_step": 140}
{"Episode reward": 56.899999999999665, "Episode length": 431, "Policy Loss": 1.3373178243637085, "Value Loss": 22.872007369995117, "_runtime": 11987.666479825974, "_timestamp": 1585609357.2993493, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7472817301750183, "Value Loss": 0.17748484015464783, "_runtime": 11989.076061487198, "_timestamp": 1585609358.708931, "_step": 142}
{"Episode reward": 10.800000000000793, "Episode length": 892, "Policy Loss": 0.2743198275566101, "Value Loss": 11.120824813842773, "_runtime": 11989.696906805038, "_timestamp": 1585609359.3297763, "_step": 143}
{"Episode reward": 59.89999999999971, "Episode length": 401, "Policy Loss": 1.446672797203064, "Value Loss": 24.575759887695312, "_runtime": 11990.586331605911, "_timestamp": 1585609360.219201, "_step": 144}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.8603144288063049, "Value Loss": 17.783220291137695, "_runtime": 11991.911538124084, "_timestamp": 1585609361.5444076, "_step": 145}
{"Episode reward": 16.07346341610004, "Episode length": 840, "Policy Loss": 0.400232195854187, "Value Loss": 11.785346031188965, "_runtime": 11993.443985462189, "_timestamp": 1585609363.076855, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8621010184288025, "Value Loss": 0.14934682846069336, "_runtime": 11994.31511926651, "_timestamp": 1585609363.9479887, "_step": 147}
{"Episode reward": 47.29999999999953, "Episode length": 527, "Policy Loss": 0.9226506352424622, "Value Loss": 18.699443817138672, "_runtime": 11995.261003255844, "_timestamp": 1585609364.8938727, "_step": 148}
{"Episode reward": 40.49999999999943, "Episode length": 595, "Policy Loss": 0.5977774858474731, "Value Loss": 16.551128387451172, "_runtime": 11996.837020635605, "_timestamp": 1585609366.46989, "_step": 149}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9193311333656311, "Value Loss": 0.0200059674680233, "_runtime": 11997.795136451721, "_timestamp": 1585609367.428006, "_step": 150}
{"Episode reward": 38.87172544002474, "Episode length": 612, "Policy Loss": 0.5884449481964111, "Value Loss": 16.100439071655273, "_runtime": 11999.336537122726, "_timestamp": 1585609368.9694066, "_step": 151}
{"Episode reward": -99.71808417439321, "Episode length": 999, "Policy Loss": -0.9572818279266357, "Value Loss": 0.043998125940561295, "_runtime": 12000.920655488968, "_timestamp": 1585609370.553525, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9510403871536255, "Value Loss": 0.11744093149900436, "_runtime": 12002.472322702408, "_timestamp": 1585609372.1051922, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9777409434318542, "Value Loss": 0.06761269271373749, "_runtime": 12003.027266979218, "_timestamp": 1585609372.6601365, "_step": 154}
{"Episode reward": 67.69999999999982, "Episode length": 323, "Policy Loss": 1.8720955848693848, "Value Loss": 30.399051666259766, "_runtime": 12004.607681274414, "_timestamp": 1585609374.2405508, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.974067747592926, "Value Loss": 0.049798641353845596, "_runtime": 12006.189396858215, "_timestamp": 1585609375.8222663, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9739258289337158, "Value Loss": 0.06849772483110428, "_runtime": 12007.715365409851, "_timestamp": 1585609377.348235, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9717615246772766, "Value Loss": 0.159115269780159, "_runtime": 12009.318259000778, "_timestamp": 1585609378.9511285, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.979505717754364, "Value Loss": 0.02448018081486225, "_runtime": 12010.912140369415, "_timestamp": 1585609380.5450099, "_step": 159}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9613015055656433, "Value Loss": 0.020488141104578972, "_runtime": 12012.471035957336, "_timestamp": 1585609382.1039054, "_step": 160}
{"Episode reward": -99.82727103829244, "Episode length": 999, "Policy Loss": -0.9440531730651855, "Value Loss": 0.031089387834072113, "_runtime": 12013.380732059479, "_timestamp": 1585609383.0136015, "_step": 161}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 1.1735601425170898, "Value Loss": 17.826025009155273, "_runtime": 12014.967510223389, "_timestamp": 1585609384.6003797, "_step": 162}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": -0.01947118528187275, "Value Loss": 9.882528305053711, "_runtime": 12015.436167240143, "_timestamp": 1585609385.0690367, "_step": 163}
{"Episode reward": 73.39999999999989, "Episode length": 266, "Policy Loss": 2.496865749359131, "Value Loss": 37.048789978027344, "_runtime": 12016.195092201233, "_timestamp": 1585609385.8279617, "_step": 164}
{"Episode reward": 51.199999999999584, "Episode length": 488, "Policy Loss": 0.9865950345993042, "Value Loss": 20.21935272216797, "_runtime": 12017.77879524231, "_timestamp": 1585609387.4116647, "_step": 165}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9132592082023621, "Value Loss": 0.03660356625914574, "_runtime": 12019.338862657547, "_timestamp": 1585609388.9717321, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9114773869514465, "Value Loss": 0.05468984693288803, "_runtime": 12020.873542547226, "_timestamp": 1585609390.506412, "_step": 167}
{"Episode reward": -99.80226173400739, "Episode length": 999, "Policy Loss": -0.9184642434120178, "Value Loss": 0.01780441589653492, "_runtime": 12022.468077659607, "_timestamp": 1585609392.1009471, "_step": 168}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.917211651802063, "Value Loss": 0.10713467746973038, "_runtime": 12024.03894329071, "_timestamp": 1585609393.6718128, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8884716033935547, "Value Loss": 0.16052614152431488, "_runtime": 12024.611948013306, "_timestamp": 1585609394.2448175, "_step": 170}
{"Episode reward": 66.0999999999998, "Episode length": 339, "Policy Loss": 1.7359637022018433, "Value Loss": 29.051008224487305, "_runtime": 12026.204725503922, "_timestamp": 1585609395.837595, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8702678084373474, "Value Loss": 0.037708695977926254, "_runtime": 12027.789340019226, "_timestamp": 1585609397.4222095, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8700942397117615, "Value Loss": 0.23312850296497345, "_runtime": 12029.268903493881, "_timestamp": 1585609398.901773, "_step": 173}
{"Episode reward": 3.1000000000012307, "Episode length": 969, "Policy Loss": 0.08381851017475128, "Value Loss": 10.181035041809082, "_runtime": 12030.87402176857, "_timestamp": 1585609400.5068913, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.831666111946106, "Value Loss": 0.04494562745094299, "_runtime": 12032.455482721329, "_timestamp": 1585609402.0883522, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8202294707298279, "Value Loss": 0.03471699729561806, "_runtime": 12033.468537807465, "_timestamp": 1585609403.1014073, "_step": 176}
{"Episode reward": 36.599999999999376, "Episode length": 634, "Policy Loss": 0.745255708694458, "Value Loss": 15.521718978881836, "_runtime": 12035.054938554764, "_timestamp": 1585609404.687808, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7910407185554504, "Value Loss": 0.02364114299416542, "_runtime": 12036.330719709396, "_timestamp": 1585609405.9635892, "_step": 178}
{"Episode reward": 20.400000000000247, "Episode length": 796, "Policy Loss": 0.4491623044013977, "Value Loss": 12.392800331115723, "_runtime": 12037.876997947693, "_timestamp": 1585609407.5098674, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7618465423583984, "Value Loss": 0.017087461426854134, "_runtime": 12039.44785118103, "_timestamp": 1585609409.0807207, "_step": 180}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": 0.21623028814792633, "Value Loss": 9.996052742004395, "_runtime": 12041.018040895462, "_timestamp": 1585609410.6509104, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7257178425788879, "Value Loss": 0.014775163494050503, "_runtime": 12042.645423650742, "_timestamp": 1585609412.2782931, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7171595692634583, "Value Loss": 0.01615886576473713, "_runtime": 12044.238547801971, "_timestamp": 1585609413.8714173, "_step": 183}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6926828026771545, "Value Loss": 0.03961487114429474, "_runtime": 12045.125612258911, "_timestamp": 1585609414.7584817, "_step": 184}
{"Episode reward": 45.599999999999504, "Episode length": 544, "Policy Loss": 0.9742463231086731, "Value Loss": 18.16314125061035, "_runtime": 12046.69911289215, "_timestamp": 1585609416.3319824, "_step": 185}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6742104887962341, "Value Loss": 0.05225341394543648, "_runtime": 12048.179669618607, "_timestamp": 1585609417.812539, "_step": 186}
{"Episode reward": 7.5000000000009805, "Episode length": 925, "Policy Loss": 0.32643362879753113, "Value Loss": 10.667806625366211, "_runtime": 12049.403613567352, "_timestamp": 1585609419.036483, "_step": 187}
{"Episode reward": 21.495834255218696, "Episode length": 786, "Policy Loss": 0.5024157762527466, "Value Loss": 12.547269821166992, "_runtime": 12050.979074954987, "_timestamp": 1585609420.6119444, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6397212743759155, "Value Loss": 0.08259958773851395, "_runtime": 12052.57796573639, "_timestamp": 1585609422.2108352, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6265846490859985, "Value Loss": 0.04509586840867996, "_runtime": 12054.144100666046, "_timestamp": 1585609423.7769701, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6095757484436035, "Value Loss": 0.013986240141093731, "_runtime": 12055.728929281235, "_timestamp": 1585609425.3617988, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6082278490066528, "Value Loss": 0.07762569934129715, "_runtime": 12057.081389188766, "_timestamp": 1585609426.7142587, "_step": 192}
{"Episode reward": 15.400000000000531, "Episode length": 846, "Policy Loss": 0.47963815927505493, "Value Loss": 11.64915657043457, "_runtime": 12058.659579992294, "_timestamp": 1585609428.2924495, "_step": 193}
{"Episode reward": -99.81432001590589, "Episode length": 999, "Policy Loss": -0.5696109533309937, "Value Loss": 0.006160747725516558, "_runtime": 12060.030669927597, "_timestamp": 1585609429.6635394, "_step": 194}
{"Episode reward": 13.900000000000617, "Episode length": 861, "Policy Loss": 0.5040488243103027, "Value Loss": 11.479832649230957, "_runtime": 12061.625126361847, "_timestamp": 1585609431.2579958, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5580258965492249, "Value Loss": 0.019794195890426636, "_runtime": 12063.219468355179, "_timestamp": 1585609432.8523378, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5410642027854919, "Value Loss": 0.05682516098022461, "_runtime": 12063.909641504288, "_timestamp": 1585609433.542511, "_step": 197}
{"Episode reward": 58.2741382062432, "Episode length": 418, "Policy Loss": 1.5892055034637451, "Value Loss": 23.64518165588379, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445, -0.0038669658824801445]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 7.0], "bins": [-0.6477317214012146, -0.6375504732131958, -0.6273692846298218, -0.617188036441803, -0.6070067882537842, -0.5968255996704102, -0.5866443514823914, -0.5764631032943726, -0.5662819147109985, -0.5561006665229797, -0.5459194183349609, -0.5357382297515869, -0.5255569815635681, -0.5153757333755493, -0.5051945447921753, -0.4950132966041565, -0.4848320484161377, -0.4746508002281189, -0.4644695818424225, -0.4542883634567261, -0.4441071152687073, -0.43392589688301086, -0.42374467849731445, -0.41356343030929565, -0.40338221192359924, -0.39320099353790283, -0.38301974534988403, -0.3728385269641876, -0.3626573085784912, -0.3524760603904724, -0.342294842004776, -0.3321135938167572, -0.3219323754310608, -0.3117511570453644, -0.3015699088573456, -0.29138869047164917, -0.28120744228363037, -0.27102622389793396, -0.26084500551223755, -0.25066375732421875, -0.24048253893852234, -0.23030132055282593, -0.22012007236480713, -0.20993885397911072, -0.1997576355934143, -0.1895763874053955, -0.1793951690196991, -0.1692139208316803, -0.1590327024459839, -0.14885148406028748, -0.13867026567459106, -0.12848901748657227, -0.11830776929855347, -0.10812658071517944, -0.09794533252716064, -0.08776408433914185, -0.07758289575576782, -0.06740164756774902, -0.057220399379730225, -0.047039151191711426, -0.0368579626083374, -0.026676714420318604, -0.016495466232299805, -0.006314277648925781, 0.0038669705390930176]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.018804987892508507, -0.018484173342585564, -0.01816335693001747, -0.017842542380094528, -0.017521727830171585, -0.017200911417603493, -0.01688009686768055, -0.016559280455112457, -0.016238465905189514, -0.01591765135526657, -0.015596835874021053, -0.015276020392775536, -0.014955205842852592, -0.0146343894302845, -0.014313574880361557, -0.01399275939911604, -0.013671943917870522, -0.013351129367947578, -0.01303031388670206, -0.012709498405456543, -0.0123886838555336, -0.012067868374288082, -0.011747052893042564, -0.011426238343119621, -0.011105422861874104, -0.010784607380628586, -0.010463791899383068, -0.010142977349460125, -0.009822161868214607, -0.00950134638696909, -0.009180530905723572, -0.008859716355800629, -0.008538900874555111, -0.008218085393309593, -0.00789727084338665, -0.007576455362141132, -0.007255639880895615, -0.006934824399650097, -0.006614009849727154, -0.006293194368481636, -0.005972378887236118, -0.005651564337313175, -0.0053307488560676575, -0.00500993337482214, -0.004689117893576622, -0.004368303343653679, -0.004047487862408161, -0.0037266723811626434, -0.0034058578312397003, -0.003085041418671608, -0.002764226868748665, -0.0024434123188257217, -0.0021225959062576294, -0.0018017813563346863, -0.0014809668064117432, -0.0011601503938436508, -0.0008393358439207077, -0.0005185212939977646, -0.00019770488142967224, 0.00012310966849327087, 0.0004439260810613632, 0.0007647406309843063, 0.0010855551809072495, 0.0014063715934753418, 0.001727186143398285]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 3.0, 5.0, 4.0, 2.0, 2.0, 7.0, 5.0, 5.0, 4.0, 0.0, 2.0, 8.0, 7.0, 10.0, 12.0, 31.0, 209.0, 60.0, 11.0, 11.0, 1.0, 10.0, 28.0, 30.0, 24.0], "bins": [-0.12613841891288757, -0.12387491017580032, -0.12161140888929367, -0.11934790015220642, -0.11708439886569977, -0.11482089012861252, -0.11255738884210587, -0.11029388010501862, -0.10803037881851196, -0.10576687008142471, -0.10350336879491806, -0.10123986005783081, -0.09897635877132416, -0.09671285003423691, -0.09444934129714966, -0.092185840010643, -0.08992233872413635, -0.0876588299870491, -0.08539532124996185, -0.0831318199634552, -0.08086831867694855, -0.0786048099398613, -0.07634130120277405, -0.0740777999162674, -0.07181429117918015, -0.0695507824420929, -0.06728728115558624, -0.06502377986907959, -0.06276027113199234, -0.06049676984548569, -0.05823326110839844, -0.055969759821891785, -0.053706251084804535, -0.051442742347717285, -0.04917924106121063, -0.04691573232412338, -0.04465223103761673, -0.04238872230052948, -0.04012522101402283, -0.03786171227693558, -0.035598210990428925, -0.033334702253341675, -0.031071200966835022, -0.028807692229747772, -0.02654419094324112, -0.02428068220615387, -0.022017180919647217, -0.019753672182559967, -0.017490163445472717, -0.015226662158966064, -0.012963153421878815, -0.010699652135372162, -0.008436143398284912, -0.006172642111778259, -0.0039091333746910095, -0.0016456320881843567, 0.0006178766489028931, 0.002881377935409546, 0.005144879221916199, 0.007408395409584045, 0.009671896696090698, 0.011935397982597351, 0.014198899269104004, 0.01646241545677185, 0.018725916743278503]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 12.0], "bins": [-0.4124901592731476, -0.4059208631515503, -0.3993515372276306, -0.3927822411060333, -0.38621291518211365, -0.37964361906051636, -0.3730742931365967, -0.3665049970149994, -0.3599356710910797, -0.3533663749694824, -0.34679704904556274, -0.34022775292396545, -0.33365845680236816, -0.3270891308784485, -0.3205198049545288, -0.3139505088329315, -0.30738121271133423, -0.30081188678741455, -0.2942425608634949, -0.2876732647418976, -0.2811039686203003, -0.2745346426963806, -0.26796531677246094, -0.26139602065086365, -0.25482672452926636, -0.24825741350650787, -0.2416881024837494, -0.2351187914609909, -0.22854948043823242, -0.22198016941547394, -0.21541085839271545, -0.20884154736995697, -0.2022722363471985, -0.19570292532444, -0.18913361430168152, -0.18256430327892303, -0.17599499225616455, -0.16942568123340607, -0.16285637021064758, -0.1562870740890503, -0.14971774816513062, -0.14314845204353333, -0.13657912611961365, -0.13000982999801636, -0.12344050407409668, -0.11687120795249939, -0.11030188202857971, -0.10373258590698242, -0.09716328978538513, -0.09059396386146545, -0.08402466773986816, -0.07745534181594849, -0.0708860456943512, -0.06431671977043152, -0.05774742364883423, -0.05117809772491455, -0.04460880160331726, -0.03803947567939758, -0.03147017955780029, -0.024900853633880615, -0.018331557512283325, -0.011762231588363647, -0.005192935466766357, 0.0013763904571533203, 0.00794568657875061]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [5.0, 6.0, 2.0, 16.0, 11.0, 7.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.01032901369035244, -0.007895169779658318, -0.0054613263346254826, -0.0030274828895926476, -0.0005936389788985252, 0.001840204931795597, 0.004274047911167145, 0.006707891821861267, 0.00914173573255539, 0.011575579643249512, 0.014009423553943634, 0.016443267464637756, 0.01887710951268673, 0.021310953423380852, 0.023744797334074974, 0.026178641244769096, 0.02861248515546322, 0.03104632906615734, 0.03348017483949661, 0.035914018750190735, 0.03834786266088486, 0.04078170657157898, 0.0432155504822731, 0.045649394392967224, 0.04808323085308075, 0.05051707476377487, 0.052950918674468994, 0.055384762585163116, 0.05781860649585724, 0.06025245040655136, 0.06268629431724548, 0.0651201382279396, 0.06755398213863373, 0.06998782604932785, 0.07242166996002197, 0.0748555138707161, 0.07728935778141022, 0.07972320169210434, 0.08215704560279846, 0.08459088951349258, 0.0870247334241867, 0.08945857733488083, 0.09189242124557495, 0.09432626515626907, 0.0967601090669632, 0.09919395297765732, 0.10162779688835144, 0.10406164079904556, 0.10649547725915909, 0.10892932116985321, 0.11136316508054733, 0.11379700899124146, 0.11623085290193558, 0.1186647042632103, 0.12109854072332382, 0.12353239208459854, 0.12596623599529266, 0.12840008735656738, 0.1308339238166809, 0.13326777517795563, 0.13570161163806915, 0.13813546299934387, 0.1405692994594574, 0.14300315082073212, 0.14543698728084564]}, "_runtime": 12065.544988632202, "_timestamp": 1585609435.177858, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5243942141532898, "Value Loss": 0.02274385467171669, "_runtime": 12067.142454862595, "_timestamp": 1585609436.7753243, "_step": 199}
{"Episode reward": -99.89182468056539, "Episode length": 999, "Policy Loss": -0.5286705493927002, "Value Loss": 0.03809814155101776, "_runtime": 12068.358489274979, "_timestamp": 1585609437.9913588, "_step": 200}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.6220340132713318, "Value Loss": 12.535501480102539, "_runtime": 12069.876305818558, "_timestamp": 1585609439.5091753, "_step": 201}
{"Episode reward": 4.3000000000011624, "Episode length": 957, "Policy Loss": 0.4954848885536194, "Value Loss": 10.332625389099121, "_runtime": 12071.463830471039, "_timestamp": 1585609441.0967, "_step": 202}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5290241241455078, "Value Loss": 0.03200758993625641, "_runtime": 12072.220509290695, "_timestamp": 1585609441.8533788, "_step": 203}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.3949544429779053, "Value Loss": 21.120336532592773, "_runtime": 12073.10924744606, "_timestamp": 1585609442.742117, "_step": 204}
{"Episode reward": 45.3999999999995, "Episode length": 546, "Policy Loss": 1.1628857851028442, "Value Loss": 18.078702926635742, "_runtime": 12074.699514865875, "_timestamp": 1585609444.3323843, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5475422143936157, "Value Loss": 0.03821571543812752, "_runtime": 12076.25627565384, "_timestamp": 1585609445.8891451, "_step": 206}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5602461099624634, "Value Loss": 0.03101406618952751, "_runtime": 12077.461755752563, "_timestamp": 1585609447.0946252, "_step": 207}
{"Episode reward": 22.400000000000134, "Episode length": 776, "Policy Loss": 0.5907866954803467, "Value Loss": 12.708343505859375, "_runtime": 12079.057295799255, "_timestamp": 1585609448.6901653, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5751045942306519, "Value Loss": 0.011069784872233868, "_runtime": 12080.646484613419, "_timestamp": 1585609450.279354, "_step": 209}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5695120096206665, "Value Loss": 0.013020655140280724, "_runtime": 12081.672867298126, "_timestamp": 1585609451.3057368, "_step": 210}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 1.0035984516143799, "Value Loss": 15.272953987121582, "_runtime": 12083.265679597855, "_timestamp": 1585609452.898549, "_step": 211}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5837160348892212, "Value Loss": 0.013415011577308178, "_runtime": 12084.618943929672, "_timestamp": 1585609454.2518134, "_step": 212}
{"Episode reward": 13.800000000000622, "Episode length": 862, "Policy Loss": 0.54534512758255, "Value Loss": 11.433894157409668, "_runtime": 12086.177664518356, "_timestamp": 1585609455.810534, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5899922847747803, "Value Loss": 0.01400679349899292, "_runtime": 12087.595074892044, "_timestamp": 1585609457.2279444, "_step": 214}
{"Episode reward": 10.700000000000799, "Episode length": 893, "Policy Loss": 0.43532925844192505, "Value Loss": 11.059591293334961, "_runtime": 12089.21802020073, "_timestamp": 1585609458.8508897, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5897181630134583, "Value Loss": 0.02244056761264801, "_runtime": 12089.976303577423, "_timestamp": 1585609459.609173, "_step": 216}
{"Episode reward": 53.89999999999962, "Episode length": 461, "Policy Loss": 1.349521517753601, "Value Loss": 21.387540817260742, "_runtime": 12091.50723862648, "_timestamp": 1585609461.140108, "_step": 217}
{"Episode reward": 3.800000000001191, "Episode length": 962, "Policy Loss": 0.32901039719581604, "Value Loss": 10.25545883178711, "_runtime": 12093.098859786987, "_timestamp": 1585609462.7317293, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6179395914077759, "Value Loss": 0.04104571416974068, "_runtime": 12093.608420610428, "_timestamp": 1585609463.24129, "_step": 219}
{"Episode reward": 68.59999999999982, "Episode length": 314, "Policy Loss": 2.6024487018585205, "Value Loss": 31.332420349121094, "_runtime": 12094.530402421951, "_timestamp": 1585609464.163272, "_step": 220}
{"Episode reward": 42.59999999999946, "Episode length": 574, "Policy Loss": 1.089314579963684, "Value Loss": 17.194089889526367, "_runtime": 12095.881597995758, "_timestamp": 1585609465.5144675, "_step": 221}
{"Episode reward": 14.400000000000588, "Episode length": 856, "Policy Loss": 0.4071754515171051, "Value Loss": 11.503100395202637, "_runtime": 12097.420706987381, "_timestamp": 1585609467.0535765, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6844887733459473, "Value Loss": 0.01923270709812641, "_runtime": 12098.972285747528, "_timestamp": 1585609468.6051552, "_step": 223}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.704582929611206, "Value Loss": 0.07647032290697098, "_runtime": 12100.186170578003, "_timestamp": 1585609469.81904, "_step": 224}
{"Episode reward": 23.400000000000077, "Episode length": 766, "Policy Loss": 0.45453080534935, "Value Loss": 12.854859352111816, "_runtime": 12101.742486715317, "_timestamp": 1585609471.3753562, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7239916324615479, "Value Loss": 0.016022056341171265, "_runtime": 12103.24654507637, "_timestamp": 1585609472.8794146, "_step": 226}
{"Episode reward": 5.753802490235458, "Episode length": 943, "Policy Loss": 0.2235596925020218, "Value Loss": 10.508748054504395, "_runtime": 12104.81292963028, "_timestamp": 1585609474.445799, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7487691044807434, "Value Loss": 0.07110724598169327, "_runtime": 12106.39179611206, "_timestamp": 1585609476.0246656, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7474959492683411, "Value Loss": 0.011069747619330883, "_runtime": 12107.970811843872, "_timestamp": 1585609477.6036813, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7361094951629639, "Value Loss": 0.0436599925160408, "_runtime": 12109.213055849075, "_timestamp": 1585609478.8459253, "_step": 230}
{"Episode reward": 22.700000000000117, "Episode length": 773, "Policy Loss": 0.5039604306221008, "Value Loss": 12.711832046508789, "_runtime": 12110.762218475342, "_timestamp": 1585609480.395088, "_step": 231}
{"Episode reward": 2.1000000000012875, "Episode length": 979, "Policy Loss": 0.17760200798511505, "Value Loss": 10.04039192199707, "_runtime": 12112.35730791092, "_timestamp": 1585609481.9901774, "_step": 232}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7390143275260925, "Value Loss": 0.018984612077474594, "_runtime": 12113.075689792633, "_timestamp": 1585609482.7085593, "_step": 233}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": 1.3716232776641846, "Value Loss": 22.13075065612793, "_runtime": 12114.708347558975, "_timestamp": 1585609484.341217, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7253065705299377, "Value Loss": 0.1081060916185379, "_runtime": 12115.464410543442, "_timestamp": 1585609485.09728, "_step": 235}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 1.571882724761963, "Value Loss": 21.43429946899414, "_runtime": 12117.009425163269, "_timestamp": 1585609486.6422946, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7502126097679138, "Value Loss": 0.131254181265831, "_runtime": 12118.602679491043, "_timestamp": 1585609488.235549, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7515335083007812, "Value Loss": 0.03773830831050873, "_runtime": 12119.35667848587, "_timestamp": 1585609488.989548, "_step": 238}
{"Episode reward": 52.3999999999996, "Episode length": 476, "Policy Loss": 1.1225028038024902, "Value Loss": 20.637523651123047, "_runtime": 12120.005269050598, "_timestamp": 1585609489.6381385, "_step": 239}
{"Episode reward": 60.69999999999972, "Episode length": 393, "Policy Loss": 1.4856947660446167, "Value Loss": 24.9516658782959, "_runtime": 12121.58472275734, "_timestamp": 1585609491.2175922, "_step": 240}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7991697192192078, "Value Loss": 0.021422501653432846, "_runtime": 12123.131479978561, "_timestamp": 1585609492.7643495, "_step": 241}
{"Episode reward": -99.80119095444539, "Episode length": 999, "Policy Loss": -0.8186265826225281, "Value Loss": 0.025637388229370117, "_runtime": 12124.625846385956, "_timestamp": 1585609494.2587159, "_step": 242}
{"Episode reward": 2.5000000000012648, "Episode length": 975, "Policy Loss": 0.10670802742242813, "Value Loss": 10.15363883972168, "_runtime": 12126.222343683243, "_timestamp": 1585609495.8552132, "_step": 243}
{"Episode reward": -99.80999584793905, "Episode length": 999, "Policy Loss": -0.8309094905853271, "Value Loss": 0.09613131731748581, "_runtime": 12127.812183141708, "_timestamp": 1585609497.4450526, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8457596898078918, "Value Loss": 0.04985625669360161, "_runtime": 12129.385202646255, "_timestamp": 1585609499.0180721, "_step": 245}
{"Episode reward": -99.8000031530843, "Episode length": 999, "Policy Loss": -0.8535727262496948, "Value Loss": 0.05409030243754387, "_runtime": 12130.97884964943, "_timestamp": 1585609500.6117191, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.823695719242096, "Value Loss": 0.04619854316115379, "_runtime": 12132.018827915192, "_timestamp": 1585609501.6516974, "_step": 247}
{"Episode reward": 35.64928106665549, "Episode length": 645, "Policy Loss": 0.5695103406906128, "Value Loss": 15.276140213012695, "_runtime": 12132.892325162888, "_timestamp": 1585609502.5251946, "_step": 248}
{"Episode reward": 46.19999999999951, "Episode length": 538, "Policy Loss": 0.8551337718963623, "Value Loss": 18.179336547851562, "_runtime": 12134.486367225647, "_timestamp": 1585609504.1192367, "_step": 249}
{"Episode reward": -99.86280252933362, "Episode length": 999, "Policy Loss": -0.8239951133728027, "Value Loss": 0.013429374434053898, "_runtime": 12135.18899345398, "_timestamp": 1585609504.821863, "_step": 250}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 1.4602599143981934, "Value Loss": 22.497098922729492, "_runtime": 12136.57056093216, "_timestamp": 1585609506.2034304, "_step": 251}
{"Episode reward": 10.600000000000804, "Episode length": 894, "Policy Loss": 0.18306434154510498, "Value Loss": 11.027325630187988, "_runtime": 12137.583268642426, "_timestamp": 1585609507.2161381, "_step": 252}
{"Episode reward": 37.299999999999386, "Episode length": 627, "Policy Loss": 0.5916915535926819, "Value Loss": 15.58124828338623, "_runtime": 12139.120043039322, "_timestamp": 1585609508.7529125, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8454544544219971, "Value Loss": 0.017496708780527115, "_runtime": 12140.536865472794, "_timestamp": 1585609510.169735, "_step": 254}
{"Episode reward": 12.80000000000068, "Episode length": 872, "Policy Loss": 0.19076044857501984, "Value Loss": 11.34994125366211, "_runtime": 12141.816426038742, "_timestamp": 1585609511.4492955, "_step": 255}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": 0.37479037046432495, "Value Loss": 11.914338111877441, "_runtime": 12142.7846763134, "_timestamp": 1585609512.4175458, "_step": 256}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 0.6125224828720093, "Value Loss": 16.249893188476562, "_runtime": 12143.674494028091, "_timestamp": 1585609513.3073635, "_step": 257}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.7536770701408386, "Value Loss": 17.660005569458008, "_runtime": 12144.58667254448, "_timestamp": 1585609514.219542, "_step": 258}
{"Episode reward": 42.799999999999464, "Episode length": 572, "Policy Loss": 0.7894721031188965, "Value Loss": 17.09344482421875, "_runtime": 12146.148400783539, "_timestamp": 1585609515.7812703, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9342622756958008, "Value Loss": 0.018842283636331558, "_runtime": 12147.692670583725, "_timestamp": 1585609517.32554, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9377086162567139, "Value Loss": 0.02056148834526539, "_runtime": 12149.239169359207, "_timestamp": 1585609518.8720388, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9669049978256226, "Value Loss": 0.0864516943693161, "_runtime": 12150.835628986359, "_timestamp": 1585609520.4684985, "_step": 262}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9434905052185059, "Value Loss": 0.05707821995019913, "_runtime": 12152.252999782562, "_timestamp": 1585609521.8858693, "_step": 263}
{"Episode reward": 10.997811102867914, "Episode length": 891, "Policy Loss": 0.05957194045186043, "Value Loss": 10.988709449768066, "_runtime": 12153.842595338821, "_timestamp": 1585609523.4754648, "_step": 264}
{"Episode reward": -99.82691522240499, "Episode length": 999, "Policy Loss": -0.9392709136009216, "Value Loss": 0.020448090508580208, "_runtime": 12154.850855827332, "_timestamp": 1585609524.4837253, "_step": 265}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.6297773718833923, "Value Loss": 15.626749038696289, "_runtime": 12156.43319439888, "_timestamp": 1585609526.066064, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8956912755966187, "Value Loss": 0.04785158857703209, "_runtime": 12157.762401342392, "_timestamp": 1585609527.3952708, "_step": 267}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.2468193620443344, "Value Loss": 11.849726676940918, "_runtime": 12159.331189393997, "_timestamp": 1585609528.9640589, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8800605535507202, "Value Loss": 0.019719162955880165, "_runtime": 12160.915824890137, "_timestamp": 1585609530.5486944, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8537318706512451, "Value Loss": 0.0887962281703949, "_runtime": 12162.492520093918, "_timestamp": 1585609532.1253896, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8421539664268494, "Value Loss": 0.02168053202331066, "_runtime": 12163.082070350647, "_timestamp": 1585609532.7149398, "_step": 271}
{"Episode reward": 64.59999999999977, "Episode length": 354, "Policy Loss": 1.7686924934387207, "Value Loss": 27.354541778564453, "_runtime": 12164.691504001617, "_timestamp": 1585609534.3243735, "_step": 272}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8135212063789368, "Value Loss": 0.023710140958428383, "_runtime": 12165.712287664413, "_timestamp": 1585609535.3451571, "_step": 273}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.6103367209434509, "Value Loss": 15.403360366821289, "_runtime": 12166.594790697098, "_timestamp": 1585609536.2276602, "_step": 274}
{"Episode reward": 42.39999999999946, "Episode length": 576, "Policy Loss": 0.8590576648712158, "Value Loss": 17.088748931884766, "_runtime": 12167.602631092072, "_timestamp": 1585609537.2355006, "_step": 275}
{"Episode reward": 36.99999999999938, "Episode length": 630, "Policy Loss": 0.6232396364212036, "Value Loss": 15.719196319580078, "_runtime": 12168.679148197174, "_timestamp": 1585609538.3120177, "_step": 276}
{"Episode reward": 31.399999999999622, "Episode length": 686, "Policy Loss": 0.5025503635406494, "Value Loss": 14.369340896606445, "_runtime": 12170.234182596207, "_timestamp": 1585609539.867052, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8159357309341431, "Value Loss": 0.07199572771787643, "_runtime": 12171.780795812607, "_timestamp": 1585609541.4136653, "_step": 278}
{"Episode reward": -99.8388491690145, "Episode length": 999, "Policy Loss": -0.8152493834495544, "Value Loss": 0.01694626174867153, "_runtime": 12173.337117671967, "_timestamp": 1585609542.9699872, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7987567186355591, "Value Loss": 0.027818918228149414, "_runtime": 12174.746850728989, "_timestamp": 1585609544.3797202, "_step": 280}
{"Episode reward": 10.200000000000827, "Episode length": 898, "Policy Loss": 0.17558737099170685, "Value Loss": 10.843603134155273, "_runtime": 12176.327436685562, "_timestamp": 1585609545.9603062, "_step": 281}
{"Episode reward": 0.10000000000140119, "Episode length": 999, "Policy Loss": 0.08855113387107849, "Value Loss": 9.872313499450684, "_runtime": 12177.911421060562, "_timestamp": 1585609547.5442905, "_step": 282}
{"Episode reward": -99.81763343810896, "Episode length": 999, "Policy Loss": -0.8022178411483765, "Value Loss": 0.05623789131641388, "_runtime": 12179.484761714935, "_timestamp": 1585609549.1176312, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7676514983177185, "Value Loss": 0.02915159799158573, "_runtime": 12181.073680639267, "_timestamp": 1585609550.7065501, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7645211219787598, "Value Loss": 0.028427373617887497, "_runtime": 12181.970277547836, "_timestamp": 1585609551.603147, "_step": 285}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.8951917290687561, "Value Loss": 17.740190505981445, "_runtime": 12183.562764644623, "_timestamp": 1585609553.1956341, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7451111674308777, "Value Loss": 0.019128581508994102, "_runtime": 12184.000159978867, "_timestamp": 1585609553.6330295, "_step": 287}
{"Episode reward": 75.99999999999994, "Episode length": 240, "Policy Loss": 3.6685197353363037, "Value Loss": 40.60725021362305, "_runtime": 12185.557082891464, "_timestamp": 1585609555.1899524, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7541002035140991, "Value Loss": 0.020944172516465187, "_runtime": 12187.138657569885, "_timestamp": 1585609556.771527, "_step": 289}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7651724219322205, "Value Loss": 0.047430746257305145, "_runtime": 12188.693228960037, "_timestamp": 1585609558.3260984, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.76606285572052, "Value Loss": 0.023465685546398163, "_runtime": 12190.30058503151, "_timestamp": 1585609559.9334545, "_step": 291}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7644813060760498, "Value Loss": 0.010736647993326187, "_runtime": 12191.885940551758, "_timestamp": 1585609561.51881, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7642422914505005, "Value Loss": 0.01055210456252098, "_runtime": 12193.458657979965, "_timestamp": 1585609563.0915275, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7584893703460693, "Value Loss": 0.016705717891454697, "_runtime": 12195.057668447495, "_timestamp": 1585609564.690538, "_step": 294}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7375043034553528, "Value Loss": 0.009102948941290379, "_runtime": 12196.64681482315, "_timestamp": 1585609566.2796843, "_step": 295}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7183811664581299, "Value Loss": 0.009287314489483833, "_runtime": 12197.55086016655, "_timestamp": 1585609567.1837296, "_step": 296}
{"Episode reward": 43.19999999999947, "Episode length": 568, "Policy Loss": 0.8938579559326172, "Value Loss": 17.053396224975586, "_runtime": 12198.968879938126, "_timestamp": 1585609568.6017494, "_step": 297}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.33282285928726196, "Value Loss": 10.782571792602539, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05, -8.474805508740246e-05]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 7.0, 0.0, 1.0], "bins": [-0.01707545481622219, -0.01679600030183792, -0.016516543924808502, -0.016237089410424232, -0.015957634896039963, -0.015678180381655693, -0.015398724935948849, -0.015119269490242004, -0.014839814975857735, -0.014560360461473465, -0.01428090501576662, -0.014001449570059776, -0.013721995055675507, -0.013442540541291237, -0.013163085095584393, -0.012883629649877548, -0.012604175135493279, -0.012324720621109009, -0.012045265175402164, -0.01176580972969532, -0.01148635521531105, -0.01120690070092678, -0.010927445255219936, -0.010647989809513092, -0.010368535295128822, -0.010089080780744553, -0.009809625335037708, -0.009530169889330864, -0.009250715374946594, -0.008971260860562325, -0.00869180541485548, -0.008412349969148636, -0.008132895454764366, -0.007853440940380096, -0.007573985494673252, -0.007294530048966408, -0.007015075534582138, -0.006735621020197868, -0.006456165574491024, -0.00617671012878418, -0.00589725561439991, -0.00561780110001564, -0.005338345654308796, -0.005058890208601952, -0.004779435694217682, -0.004499981179833412, -0.004220525734126568, -0.0039410702884197235, -0.003661615774035454, -0.003382161259651184, -0.0031027058139443398, -0.0028232503682374954, -0.0025437958538532257, -0.002264341339468956, -0.0019848858937621117, -0.0017054304480552673, -0.0014259759336709976, -0.001146521419286728, -0.0008670669049024582, -0.0005876105278730392, -0.00030815601348876953, -2.8701499104499817e-05, 0.00025075487792491913, 0.0005302093923091888, 0.0008096639066934586]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0004982381360605359, -0.0004882418143097311, -0.00047824549255892634, -0.00046824917080812156, -0.0004582528490573168, -0.000448256527306512, -0.0004382602055557072, -0.00042826388380490243, -0.00041826756205409765, -0.00040827124030329287, -0.0003982749185524881, -0.0003882785968016833, -0.0003782822750508785, -0.0003682859241962433, -0.00035828963154926896, -0.0003482932806946337, -0.0003382969880476594, -0.00032830063719302416, -0.00031830434454604983, -0.0003083079936914146, -0.00029831170104444027, -0.00028831535018980503, -0.0002783190575428307, -0.00026832270668819547, -0.0002583263849373907, -0.0002483300631865859, -0.00023833374143578112, -0.00022833741968497634, -0.00021834109793417156, -0.00020834477618336678, -0.000198348454432562, -0.0001883521326817572, -0.00017835581093095243, -0.00016835948918014765, -0.00015836316742934287, -0.00014836684567853808, -0.0001383705239277333, -0.00012837420217692852, -0.00011837788042612374, -0.00010838155867531896, -9.838523692451417e-05, -8.838891517370939e-05, -7.839259342290461e-05, -6.839627167209983e-05, -5.839994992129505e-05, -4.8403628170490265e-05, -3.840730641968548e-05, -2.84109846688807e-05, -1.8414633814245462e-05, -8.418341167271137e-06, 1.5780096873641014e-06, 1.1574302334338427e-05, 2.1570653188973665e-05, 3.156694583594799e-05, 4.156329669058323e-05, 5.1559589337557554e-05, 6.155594019219279e-05, 7.155223283916712e-05, 8.154858369380236e-05, 9.154487634077668e-05, 0.00010154122719541192, 0.00011153751984238625, 0.00012153387069702148, 0.0001315301633439958, 0.00014152651419863105]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 8.0, 5.0, 3.0, 5.0, 4.0, 1.0, 1.0, 9.0, 16.0, 236.0, 17.0, 24.0, 73.0, 22.0, 6.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.005999865010380745, -0.005859211552888155, -0.005718557629734278, -0.005577904172241688, -0.0054372502490878105, -0.0052965967915952206, -0.005155943334102631, -0.005015289410948753, -0.004874635953456163, -0.0047339824959635735, -0.004593328572809696, -0.004452675115317106, -0.004312021657824516, -0.004171367734670639, -0.004030714277178049, -0.0038900605868548155, -0.003749406896531582, -0.0036087532062083483, -0.0034680995158851147, -0.0033274460583925247, -0.003186792368069291, -0.0030461386777460575, -0.0029054852202534676, -0.002764831529930234, -0.0026241778396070004, -0.0024835241492837667, -0.002342870458960533, -0.002202217001467943, -0.0020615635439753532, -0.001920909620821476, -0.001780256163328886, -0.0016396022401750088, -0.0014989487826824188, -0.0013582953251898289, -0.0012176414020359516, -0.0010769879445433617, -0.0009363340213894844, -0.0007956805638968945, -0.0006550271064043045, -0.0005143731832504272, -0.0003737197257578373, -0.00023306626826524734, -9.241234511137009e-05, 4.8241112381219864e-05, 0.00018889456987380981, 0.00032954849302768707, 0.000470201950520277, 0.0006108558736741543, 0.0007515093311667442, 0.0008921627886593342, 0.0010328167118132114, 0.0011734701693058014, 0.0013141240924596786, 0.0014547775499522686, 0.0015954310074448586, 0.0017360849305987358, 0.0018767379224300385, 0.0020173918455839157, 0.002158045768737793, 0.0022986996918916702, 0.002439352683722973, 0.00258000660687685, 0.0027206605300307274, 0.00286131352186203, 0.0030019674450159073]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 6.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.009060660377144814, -0.008863868191838264, -0.00866707507520914, -0.008470282889902592, -0.008273490704596043, -0.008076698519289494, -0.00787990540266037, -0.007683113217353821, -0.007486321032047272, -0.007289528381079435, -0.007092735730111599, -0.00689594354480505, -0.0066991508938372135, -0.006502358242869377, -0.006305566057562828, -0.006108773872256279, -0.005911981221288443, -0.005715188570320606, -0.005518396385014057, -0.005321604199707508, -0.005124811548739672, -0.004928018897771835, -0.004731226712465286, -0.00453443406149745, -0.0043376414105296135, -0.004140849225223064, -0.003944056574255228, -0.003747264388948679, -0.0035504717379808426, -0.0033536795526742935, -0.003156886901706457, -0.002960094716399908, -0.0027633020654320717, -0.0025665094144642353, -0.0023697172291576862, -0.00217292457818985, -0.0019761323928833008, -0.0017793397419154644, -0.0015825475566089153, -0.001385754905641079, -0.0011889627203345299, -0.0009921696037054062, -0.0007953774183988571, -0.000598585233092308, -0.00040179304778575897, -0.00020499993115663528, -8.207745850086212e-06, 0.00018858443945646286, 0.00038537755608558655, 0.0005821697413921356, 0.0007789619266986847, 0.0009757541120052338, 0.0011725472286343575, 0.0013693394139409065, 0.0015661315992474556, 0.0017629237845540047, 0.0019597169011831284, 0.0021565090864896774, 0.0023533012717962265, 0.00255009438842535, 0.0027468865737318993, 0.0029436787590384483, 0.0031404709443449974, 0.003337264060974121, 0.00353405624628067]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 2.0, 5.0, 22.0, 3.0], "bins": [-0.041851650923490524, -0.04117807000875473, -0.040504489094018936, -0.03983090817928314, -0.039157330989837646, -0.03848375007510185, -0.03781016916036606, -0.037136588245630264, -0.03646300733089447, -0.035789426416158676, -0.03511584550142288, -0.03444226458668709, -0.033768683671951294, -0.0330951064825058, -0.032421525567770004, -0.03174794465303421, -0.031074363738298416, -0.030400782823562622, -0.029727201908826828, -0.029053622856736183, -0.02838004194200039, -0.027706461027264595, -0.02703288197517395, -0.026359301060438156, -0.025685720145702362, -0.025012139230966568, -0.024338558316230774, -0.02366497926414013, -0.022991398349404335, -0.02231781743466854, -0.021644238382577896, -0.020970657467842102, -0.020297076553106308, -0.019623495638370514, -0.01894991472363472, -0.018276335671544075, -0.01760275475680828, -0.016929173842072487, -0.016255594789981842, -0.015582013875246048, -0.014908432960510254, -0.01423485204577446, -0.013561271131038666, -0.012887692078948021, -0.012214111164212227, -0.011540530249476433, -0.010866951197385788, -0.010193370282649994, -0.0095197893679142, -0.008846208453178406, -0.008172627538442612, -0.007499046623706818, -0.0068254657089710236, -0.006151888519525528, -0.005478307604789734, -0.00480472669005394, -0.004131145775318146, -0.0034575648605823517, -0.0027839839458465576, -0.0021104030311107635, -0.001436825841665268, -0.0007632449269294739, -8.966401219367981e-05, 0.0005839169025421143, 0.0012574978172779083]}, "_runtime": 12200.558136701584, "_timestamp": 1585609570.1910062, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6875527501106262, "Value Loss": 0.015335584059357643, "_runtime": 12202.094641447067, "_timestamp": 1585609571.727511, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.68424391746521, "Value Loss": 0.012101123109459877, "_runtime": 12203.666960000992, "_timestamp": 1585609573.2998295, "_step": 300}
{"Episode reward": -99.88115828037122, "Episode length": 999, "Policy Loss": -0.6678152084350586, "Value Loss": 0.009280924685299397, "_runtime": 12205.09079837799, "_timestamp": 1585609574.7236679, "_step": 301}
{"Episode reward": 10.000000000000838, "Episode length": 900, "Policy Loss": 0.33389419317245483, "Value Loss": 10.826888084411621, "_runtime": 12206.663219451904, "_timestamp": 1585609576.296089, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6378222703933716, "Value Loss": 0.12353753298521042, "_runtime": 12208.255625724792, "_timestamp": 1585609577.8884952, "_step": 303}
{"Episode reward": -99.80000815987447, "Episode length": 999, "Policy Loss": -0.6231329441070557, "Value Loss": 0.006381028797477484, "_runtime": 12209.839110136032, "_timestamp": 1585609579.4719796, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.60919588804245, "Value Loss": 0.009680142626166344, "_runtime": 12211.404056549072, "_timestamp": 1585609581.036926, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.580379068851471, "Value Loss": 0.012490383349359035, "_runtime": 12212.309405326843, "_timestamp": 1585609581.9422748, "_step": 306}
{"Episode reward": 46.59999999999952, "Episode length": 534, "Policy Loss": 1.173342227935791, "Value Loss": 17.940513610839844, "_runtime": 12213.895836353302, "_timestamp": 1585609583.5287058, "_step": 307}
{"Episode reward": -99.88266077041486, "Episode length": 999, "Policy Loss": -0.5535479784011841, "Value Loss": 0.009009450674057007, "_runtime": 12215.47596335411, "_timestamp": 1585609585.1088328, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5395545363426208, "Value Loss": 0.01328050997108221, "_runtime": 12217.016332387924, "_timestamp": 1585609586.6492019, "_step": 309}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5117815732955933, "Value Loss": 0.04443027451634407, "_runtime": 12217.796312332153, "_timestamp": 1585609587.4291818, "_step": 310}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": 1.367194652557373, "Value Loss": 20.278104782104492, "_runtime": 12219.369049787521, "_timestamp": 1585609589.0019193, "_step": 311}
{"Episode reward": -99.84316259026387, "Episode length": 999, "Policy Loss": -0.4916696548461914, "Value Loss": 0.03623545169830322, "_runtime": 12220.782702684402, "_timestamp": 1585609590.4155722, "_step": 312}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": 0.4766346514225006, "Value Loss": 10.79375171661377, "_runtime": 12222.157258749008, "_timestamp": 1585609591.7901282, "_step": 313}
{"Episode reward": 10.400000000000816, "Episode length": 896, "Policy Loss": 0.5362779498100281, "Value Loss": 10.887052536010742, "_runtime": 12223.7446539402, "_timestamp": 1585609593.3775234, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4864014983177185, "Value Loss": 0.027763796970248222, "_runtime": 12225.312040567398, "_timestamp": 1585609594.94491, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49909886717796326, "Value Loss": 0.009579810313880444, "_runtime": 12226.880402088165, "_timestamp": 1585609596.5132716, "_step": 316}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4921889901161194, "Value Loss": 0.005266360938549042, "_runtime": 12228.470582485199, "_timestamp": 1585609598.103452, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4765775203704834, "Value Loss": 0.1072339415550232, "_runtime": 12229.702715396881, "_timestamp": 1585609599.3355849, "_step": 318}
{"Episode reward": 22.30000000000014, "Episode length": 777, "Policy Loss": 0.7108418345451355, "Value Loss": 12.409231185913086, "_runtime": 12231.288397550583, "_timestamp": 1585609600.921267, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46659794449806213, "Value Loss": 0.0030744990799576044, "_runtime": 12232.210715055466, "_timestamp": 1585609601.8435845, "_step": 320}
{"Episode reward": 43.499999999999474, "Episode length": 565, "Policy Loss": 1.1061426401138306, "Value Loss": 17.088239669799805, "_runtime": 12233.791491270065, "_timestamp": 1585609603.4243608, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47790616750717163, "Value Loss": 0.025628933683037758, "_runtime": 12235.372732162476, "_timestamp": 1585609605.0056016, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46727246046066284, "Value Loss": 0.02433372288942337, "_runtime": 12236.865943193436, "_timestamp": 1585609606.4988127, "_step": 323}
{"Episode reward": 6.300000000001049, "Episode length": 937, "Policy Loss": 0.4961387515068054, "Value Loss": 10.285052299499512, "_runtime": 12237.65272140503, "_timestamp": 1585609607.285591, "_step": 324}
{"Episode reward": 51.899999999999594, "Episode length": 481, "Policy Loss": 1.9164597988128662, "Value Loss": 20.15273094177246, "_runtime": 12238.068528175354, "_timestamp": 1585609607.7013977, "_step": 325}
{"Episode reward": 76.79999999999995, "Episode length": 232, "Policy Loss": 3.5219366550445557, "Value Loss": 41.75056076049805, "_runtime": 12239.629298686981, "_timestamp": 1585609609.2621682, "_step": 326}
{"Episode reward": -99.8837296485887, "Episode length": 999, "Policy Loss": -0.5309900641441345, "Value Loss": 0.01862931065261364, "_runtime": 12240.68246293068, "_timestamp": 1585609610.3153324, "_step": 327}
{"Episode reward": 32.09999999999958, "Episode length": 679, "Policy Loss": 0.7651496529579163, "Value Loss": 14.586222648620605, "_runtime": 12241.875073671341, "_timestamp": 1585609611.5079432, "_step": 328}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.5163832902908325, "Value Loss": 12.156073570251465, "_runtime": 12243.466223478317, "_timestamp": 1585609613.099093, "_step": 329}
{"Episode reward": -99.80015258788923, "Episode length": 999, "Policy Loss": -0.6588238477706909, "Value Loss": 0.0295665692538023, "_runtime": 12245.016157865524, "_timestamp": 1585609614.6490273, "_step": 330}
{"Episode reward": -99.80348821282247, "Episode length": 999, "Policy Loss": -0.6761579513549805, "Value Loss": 0.013086222112178802, "_runtime": 12246.546809196472, "_timestamp": 1585609616.1796787, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.709712028503418, "Value Loss": 0.008630485273897648, "_runtime": 12247.557166337967, "_timestamp": 1585609617.1900358, "_step": 332}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 1.0282506942749023, "Value Loss": 15.295799255371094, "_runtime": 12248.875324964523, "_timestamp": 1585609618.5081944, "_step": 333}
{"Episode reward": 17.100000000000435, "Episode length": 829, "Policy Loss": 0.5447322726249695, "Value Loss": 11.44391918182373, "_runtime": 12249.719137430191, "_timestamp": 1585609619.352007, "_step": 334}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 0.9032674431800842, "Value Loss": 18.389188766479492, "_runtime": 12251.284257411957, "_timestamp": 1585609620.917127, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8123071789741516, "Value Loss": 0.018178505823016167, "_runtime": 12252.853404521942, "_timestamp": 1585609622.486274, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8246711492538452, "Value Loss": 0.02787703275680542, "_runtime": 12254.395504713058, "_timestamp": 1585609624.0283742, "_step": 337}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8520786166191101, "Value Loss": 0.2380957007408142, "_runtime": 12255.977323532104, "_timestamp": 1585609625.610193, "_step": 338}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8649230599403381, "Value Loss": 0.17779138684272766, "_runtime": 12257.559678077698, "_timestamp": 1585609627.1925476, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8675758838653564, "Value Loss": 0.01014637853950262, "_runtime": 12258.22900724411, "_timestamp": 1585609627.8618767, "_step": 340}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.4758795499801636, "Value Loss": 23.762529373168945, "_runtime": 12259.817996740341, "_timestamp": 1585609629.4508662, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8500295281410217, "Value Loss": 0.07571534067392349, "_runtime": 12261.460965156555, "_timestamp": 1585609631.0938346, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8640727996826172, "Value Loss": 0.013183316215872765, "_runtime": 12262.985178470612, "_timestamp": 1585609632.618048, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8530774712562561, "Value Loss": 0.07543125003576279, "_runtime": 12264.587824583054, "_timestamp": 1585609634.220694, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8444404006004333, "Value Loss": 0.016756614670157433, "_runtime": 12266.202505350113, "_timestamp": 1585609635.8353748, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8278800249099731, "Value Loss": 0.00887212809175253, "_runtime": 12267.538780927658, "_timestamp": 1585609637.1716504, "_step": 346}
{"Episode reward": 14.90000000000056, "Episode length": 851, "Policy Loss": 0.2522715628147125, "Value Loss": 11.352742195129395, "_runtime": 12269.12525677681, "_timestamp": 1585609638.7581263, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7783527970314026, "Value Loss": 0.020304705947637558, "_runtime": 12270.715695858002, "_timestamp": 1585609640.3485653, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7517798542976379, "Value Loss": 0.013176444917917252, "_runtime": 12272.271090507507, "_timestamp": 1585609641.90396, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7318785786628723, "Value Loss": 0.010341903194785118, "_runtime": 12273.856458187103, "_timestamp": 1585609643.4893277, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7038864493370056, "Value Loss": 0.04810653626918793, "_runtime": 12274.90114569664, "_timestamp": 1585609644.5340152, "_step": 351}
{"Episode reward": 34.499999999999446, "Episode length": 655, "Policy Loss": 0.6853817701339722, "Value Loss": 14.615799903869629, "_runtime": 12275.654307365417, "_timestamp": 1585609645.2871768, "_step": 352}
{"Episode reward": 53.19999999999961, "Episode length": 468, "Policy Loss": 1.259095311164856, "Value Loss": 20.573938369750977, "_runtime": 12276.680965900421, "_timestamp": 1585609646.3138354, "_step": 353}
{"Episode reward": 35.51151327490746, "Episode length": 645, "Policy Loss": 0.7505226135253906, "Value Loss": 14.995833396911621, "_runtime": 12278.229405403137, "_timestamp": 1585609647.862275, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6329367756843567, "Value Loss": 0.005930091254413128, "_runtime": 12279.758999586105, "_timestamp": 1585609649.391869, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6175723075866699, "Value Loss": 0.017593905329704285, "_runtime": 12281.300957679749, "_timestamp": 1585609650.9338272, "_step": 356}
{"Episode reward": -99.83424649834492, "Episode length": 999, "Policy Loss": -0.6110142469406128, "Value Loss": 0.03133084252476692, "_runtime": 12282.856140136719, "_timestamp": 1585609652.4890096, "_step": 357}
{"Episode reward": -99.88807382583478, "Episode length": 999, "Policy Loss": -0.597419023513794, "Value Loss": 0.0067601450718939304, "_runtime": 12284.453435897827, "_timestamp": 1585609654.0863054, "_step": 358}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5684072971343994, "Value Loss": 0.03907318785786629, "_runtime": 12285.722745656967, "_timestamp": 1585609655.3556151, "_step": 359}
{"Episode reward": 19.400000000000304, "Episode length": 806, "Policy Loss": 0.7183988690376282, "Value Loss": 11.838247299194336, "_runtime": 12287.294027090073, "_timestamp": 1585609656.9268966, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5458607077598572, "Value Loss": 0.005097598768770695, "_runtime": 12288.031099319458, "_timestamp": 1585609657.6639688, "_step": 361}
{"Episode reward": 54.099999999999625, "Episode length": 459, "Policy Loss": 1.7151116132736206, "Value Loss": 20.87193489074707, "_runtime": 12289.0083963871, "_timestamp": 1585609658.6412659, "_step": 362}
{"Episode reward": 38.2999999999994, "Episode length": 617, "Policy Loss": 0.8883193135261536, "Value Loss": 15.457172393798828, "_runtime": 12289.631217956543, "_timestamp": 1585609659.2640874, "_step": 363}
{"Episode reward": 63.299999999999756, "Episode length": 367, "Policy Loss": 2.019667625427246, "Value Loss": 25.906776428222656, "_runtime": 12290.103515386581, "_timestamp": 1585609659.7363849, "_step": 364}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 2.9584453105926514, "Value Loss": 31.417503356933594, "_runtime": 12291.246428966522, "_timestamp": 1585609660.8792984, "_step": 365}
{"Episode reward": 25.199999999999974, "Episode length": 748, "Policy Loss": 0.5694007277488708, "Value Loss": 12.657844543457031, "_runtime": 12292.729342460632, "_timestamp": 1585609662.362212, "_step": 366}
{"Episode reward": 1.600000000001316, "Episode length": 984, "Policy Loss": 0.27325835824012756, "Value Loss": 9.896449089050293, "_runtime": 12293.909959554672, "_timestamp": 1585609663.542829, "_step": 367}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 0.3551802933216095, "Value Loss": 12.009417533874512, "_runtime": 12294.668031215668, "_timestamp": 1585609664.3009007, "_step": 368}
{"Episode reward": 51.49999999999959, "Episode length": 485, "Policy Loss": 1.1908495426177979, "Value Loss": 19.642959594726562, "_runtime": 12296.220976829529, "_timestamp": 1585609665.8538463, "_step": 369}
{"Episode reward": -99.80291228890279, "Episode length": 999, "Policy Loss": -0.8403563499450684, "Value Loss": 0.028714295476675034, "_runtime": 12297.75304722786, "_timestamp": 1585609667.3859167, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9136021733283997, "Value Loss": 0.33861446380615234, "_runtime": 12299.276625156403, "_timestamp": 1585609668.9094946, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9340027570724487, "Value Loss": 0.011784298345446587, "_runtime": 12300.855737686157, "_timestamp": 1585609670.4886072, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9714473485946655, "Value Loss": 0.09890474379062653, "_runtime": 12301.718398094177, "_timestamp": 1585609671.3512676, "_step": 373}
{"Episode reward": 45.699999999999505, "Episode length": 543, "Policy Loss": 1.0054152011871338, "Value Loss": 17.387243270874023, "_runtime": 12303.286752223969, "_timestamp": 1585609672.9196217, "_step": 374}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9809905886650085, "Value Loss": 0.5529448390007019, "_runtime": 12304.871227741241, "_timestamp": 1585609674.5040972, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0073089599609375, "Value Loss": 0.24718999862670898, "_runtime": 12305.611580610275, "_timestamp": 1585609675.24445, "_step": 376}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": 1.003278136253357, "Value Loss": 20.93323516845703, "_runtime": 12306.90319943428, "_timestamp": 1585609676.536069, "_step": 377}
{"Episode reward": 17.349283069372603, "Episode length": 827, "Policy Loss": 0.1591418981552124, "Value Loss": 11.527156829833984, "_runtime": 12307.693155765533, "_timestamp": 1585609677.3260252, "_step": 378}
{"Episode reward": 50.99999999999958, "Episode length": 490, "Policy Loss": 0.903428852558136, "Value Loss": 19.161340713500977, "_runtime": 12308.651955842972, "_timestamp": 1585609678.2848253, "_step": 379}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.719475507736206, "Value Loss": 16.036699295043945, "_runtime": 12309.524382352829, "_timestamp": 1585609679.1572518, "_step": 380}
{"Episode reward": 44.299999999999486, "Episode length": 557, "Policy Loss": 0.5980232357978821, "Value Loss": 16.87298011779785, "_runtime": 12310.21759724617, "_timestamp": 1585609679.8504667, "_step": 381}
{"Episode reward": 54.97383937239611, "Episode length": 451, "Policy Loss": 1.0376914739608765, "Value Loss": 20.99992561340332, "_runtime": 12310.72919011116, "_timestamp": 1585609680.3620596, "_step": 382}
{"Episode reward": 67.3999999999998, "Episode length": 326, "Policy Loss": 1.6913750171661377, "Value Loss": 29.221044540405273, "_runtime": 12312.259927034378, "_timestamp": 1585609681.8927965, "_step": 383}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0562704801559448, "Value Loss": 0.06654809415340424, "_runtime": 12313.774537801743, "_timestamp": 1585609683.4074073, "_step": 384}
{"Episode reward": -99.8098573923097, "Episode length": 999, "Policy Loss": -1.068494200706482, "Value Loss": 0.05335598811507225, "_runtime": 12315.276549816132, "_timestamp": 1585609684.9094193, "_step": 385}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0976734161376953, "Value Loss": 0.03953475132584572, "_runtime": 12316.848538160324, "_timestamp": 1585609686.4814076, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0862960815429688, "Value Loss": 0.02269800193607807, "_runtime": 12318.410905599594, "_timestamp": 1585609688.043775, "_step": 387}
{"Episode reward": -99.83876259326794, "Episode length": 999, "Policy Loss": -1.0844389200210571, "Value Loss": 0.023610174655914307, "_runtime": 12319.949455738068, "_timestamp": 1585609689.5823252, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0609471797943115, "Value Loss": 0.029052942991256714, "_runtime": 12321.452129602432, "_timestamp": 1585609691.084999, "_step": 389}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": -0.11493028700351715, "Value Loss": 10.120617866516113, "_runtime": 12323.023300170898, "_timestamp": 1585609692.6561697, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.014976978302002, "Value Loss": 0.02815549075603485, "_runtime": 12324.574980258942, "_timestamp": 1585609694.2078497, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9638397693634033, "Value Loss": 0.15642258524894714, "_runtime": 12325.31480717659, "_timestamp": 1585609694.9476767, "_step": 392}
{"Episode reward": 54.099999999999625, "Episode length": 459, "Policy Loss": 0.9333785772323608, "Value Loss": 20.63178253173828, "_runtime": 12326.877134799957, "_timestamp": 1585609696.5100043, "_step": 393}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9325988292694092, "Value Loss": 0.056848593056201935, "_runtime": 12328.44574713707, "_timestamp": 1585609698.0786166, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9105607867240906, "Value Loss": 0.02255592867732048, "_runtime": 12329.962969779968, "_timestamp": 1585609699.5958393, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8767015933990479, "Value Loss": 0.031347353011369705, "_runtime": 12331.579670667648, "_timestamp": 1585609701.2125401, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8321560025215149, "Value Loss": 0.03680281341075897, "_runtime": 12333.161279678345, "_timestamp": 1585609702.7941492, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7940801978111267, "Value Loss": 0.05706426501274109, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653, 0.036131601780653]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [8.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.036131601780653, 0.05657621845602989, 0.14928403496742249, 0.24199186265468597, 0.33469969034194946, 0.42740750312805176, 0.520115315914154, 0.6128231287002563, 0.7055309414863586, 0.7982387542724609, 0.8909465670585632, 0.9836543798446655, 1.0763622522354126, 1.1690700054168701, 1.2617778778076172, 1.3544856309890747, 1.4471935033798218, 1.5399013757705688, 1.6326091289520264, 1.7253170013427734, 1.818024754524231, 1.910732626914978, 2.0034403800964355, 2.0961482524871826, 2.1888561248779297, 2.2815639972686768, 2.3742716312408447, 2.466979503631592, 2.559687376022339, 2.652395248413086, 2.745102882385254, 2.837810754776001, 2.930518627166748, 3.023226499557495, 3.115934371948242, 3.20864200592041, 3.3013498783111572, 3.3940577507019043, 3.4867656230926514, 3.5794732570648193, 3.6721811294555664, 3.7648890018463135, 3.8575968742370605, 3.9503047466278076, 4.043012619018555, 4.135720729827881, 4.228428363800049, 4.321135997772217, 4.413844108581543, 4.506551742553711, 4.599259853363037, 4.691967487335205, 4.784675121307373, 4.877383232116699, 4.970090866088867, 5.062798500061035, 5.155506610870361, 5.248214244842529, 5.3409223556518555, 5.433629989624023, 5.526337623596191, 5.619045734405518, 5.7117533683776855, 5.804461479187012, 5.89716911315918]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.016138242557644844, -0.013140654191374779, -0.010143065825104713, -0.007145478390157223, -0.0041478900238871574, -0.0011503016576170921, 0.0018472857773303986, 0.004844874143600464, 0.00784246250987053, 0.010840050876140594, 0.01383763924241066, 0.016835225746035576, 0.01983281411230564, 0.022830402478575706, 0.025827990844845772, 0.028825579211115837, 0.03182316571474075, 0.03482075780630112, 0.037818342447280884, 0.04081593453884125, 0.043813519179821014, 0.04681111127138138, 0.049808695912361145, 0.05280628800392151, 0.055803872644901276, 0.05880146473646164, 0.061799049377441406, 0.06479664146900177, 0.06779422610998154, 0.0707918182015419, 0.07378940284252167, 0.07678699493408203, 0.0797845795750618, 0.08278216421604156, 0.08577975630760193, 0.0887773409485817, 0.09177493304014206, 0.09477251768112183, 0.09777010977268219, 0.10076769441366196, 0.10376528650522232, 0.10676287114620209, 0.10976046323776245, 0.11275805532932281, 0.11575563251972198, 0.11875322461128235, 0.12175081670284271, 0.12474840879440308, 0.12774598598480225, 0.1307435780763626, 0.13374117016792297, 0.13673874735832214, 0.1397363394498825, 0.14273393154144287, 0.14573152363300323, 0.1487291008234024, 0.15172669291496277, 0.15472428500652313, 0.1577218770980835, 0.16071945428848267, 0.16371704638004303, 0.1667146384716034, 0.16971223056316376, 0.17270980775356293, 0.1757073998451233]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [24.0, 31.0, 27.0, 10.0, 1.0, 0.0, 21.0, 5.0, 277.0, 38.0, 2.0, 3.0, 3.0, 6.0, 6.0, 0.0, 1.0, 5.0, 7.0, 6.0, 4.0, 1.0, 3.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0], "bins": [-0.17500834167003632, -0.1545494645833969, -0.1340906023979187, -0.1136317253112793, -0.09317284822463989, -0.07271397113800049, -0.05225510150194168, -0.031796231865882874, -0.01133735477924347, 0.009121522307395935, 0.02958039939403534, 0.05003926157951355, 0.07049813866615295, 0.09095700085163116, 0.11141587793827057, 0.13187475502490997, 0.15233363211154938, 0.17279250919818878, 0.19325138628482819, 0.2137102633714676, 0.234169140458107, 0.2546280026435852, 0.2750868797302246, 0.295545756816864, 0.3160046339035034, 0.33646345138549805, 0.35692232847213745, 0.37738120555877686, 0.39784008264541626, 0.41829895973205566, 0.43875783681869507, 0.4592167139053345, 0.4796755909919739, 0.5001344680786133, 0.5205933451652527, 0.5410522222518921, 0.5615110993385315, 0.5819699764251709, 0.6024288535118103, 0.6228877305984497, 0.6433466076850891, 0.6638054251670837, 0.6842643022537231, 0.7047231793403625, 0.725182056427002, 0.7456409335136414, 0.7660998106002808, 0.7865586876869202, 0.8070175647735596, 0.827476441860199, 0.8479352593421936, 0.8683941960334778, 0.8888530135154724, 0.9093119502067566, 0.9297707676887512, 0.9502297043800354, 0.97068852186203, 0.9911474585533142, 1.0116063356399536, 1.0320652723312378, 1.0525240898132324, 1.0729830265045166, 1.0934418439865112, 1.1139007806777954, 1.13435959815979]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [12.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.07351049035787582, -0.011631965637207031, 0.05024655908346176, 0.11212507635354996, 0.17400360107421875, 0.23588213324546814, 0.29776063561439514, 0.35963916778564453, 0.4215176999568939, 0.4833962023258209, 0.5452747941017151, 0.6071532964706421, 0.6690317988395691, 0.7309103608131409, 0.7927888631820679, 0.8546674251556396, 0.9165459275245667, 0.9784244894981384, 1.0403028726577759, 1.1021814346313477, 1.1640599966049194, 1.2259384393692017, 1.2878170013427734, 1.3496955633163452, 1.4115740060806274, 1.4734525680541992, 1.535331130027771, 1.5972096920013428, 1.659088134765625, 1.7209666967391968, 1.7828452587127686, 1.8447237014770508, 1.9066022634506226, 1.9684807062149048, 2.0303595066070557, 2.092237949371338, 2.15411639213562, 2.2159950733184814, 2.2778735160827637, 2.339751958847046, 2.4016306400299072, 2.4635090827941895, 2.5253875255584717, 2.587266206741333, 2.6491446495056152, 2.7110230922698975, 2.772901773452759, 2.834780216217041, 2.8966586589813232, 2.9585373401641846, 3.020415782928467, 3.082294464111328, 3.1441729068756104, 3.2060513496398926, 3.267930030822754, 3.329808473587036, 3.3916869163513184, 3.4535655975341797, 3.515444040298462, 3.577322483062744, 3.6392011642456055, 3.7010796070098877, 3.76295804977417, 3.8248367309570312, 3.8867151737213135]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 1.0, 5.0, 4.0, 9.0, 21.0, 5.0], "bins": [-0.9569839835166931, -0.9415525794029236, -0.926121175289154, -0.9106897115707397, -0.8952583074569702, -0.8798269033432007, -0.8643954992294312, -0.8489640951156616, -0.8335326313972473, -0.8181012272834778, -0.8026698231697083, -0.787238359451294, -0.7718069553375244, -0.7563755512237549, -0.7409441471099854, -0.7255127429962158, -0.7100813388824463, -0.6946499347686768, -0.6792184710502625, -0.6637870669364929, -0.6483556032180786, -0.6329241991043091, -0.6174927949905396, -0.60206139087677, -0.5866299867630005, -0.571198582649231, -0.5557671785354614, -0.5403357148170471, -0.5249043107032776, -0.5094728469848633, -0.49404147267341614, -0.4786100387573242, -0.4631786346435547, -0.44774723052978516, -0.4323158264160156, -0.4168843626976013, -0.4014529585838318, -0.38602155447006226, -0.3705901503562927, -0.3551586866378784, -0.3397272825241089, -0.32429587841033936, -0.3088644742965698, -0.2934330701828003, -0.278001606464386, -0.26257020235061646, -0.24713879823684692, -0.2317073941230774, -0.21627599000930786, -0.20084452629089355, -0.18541312217712402, -0.1699817180633545, -0.15455031394958496, -0.13911885023117065, -0.12368744611740112, -0.10825604200363159, -0.09282463788986206, -0.07739323377609253, -0.06196177005767822, -0.04653036594390869, -0.03109896183013916, -0.01566755771636963, -0.00023609399795532227, 0.015195310115814209, 0.03062671422958374]}, "_runtime": 12333.77022433281, "_timestamp": 1585609703.4030938, "_step": 398}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 1.5699927806854248, "Value Loss": 25.357593536376953, "_runtime": 12335.36254477501, "_timestamp": 1585609704.9954143, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.741316556930542, "Value Loss": 0.008869126439094543, "_runtime": 12336.935267925262, "_timestamp": 1585609706.5681374, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7090055346488953, "Value Loss": 0.008941208012402058, "_runtime": 12338.417099952698, "_timestamp": 1585609708.0499694, "_step": 401}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.19496382772922516, "Value Loss": 9.681602478027344, "_runtime": 12340.011220932007, "_timestamp": 1585609709.6440904, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6577853560447693, "Value Loss": 0.010495329275727272, "_runtime": 12340.978969097137, "_timestamp": 1585609710.6118386, "_step": 403}
{"Episode reward": 39.76736288070621, "Episode length": 603, "Policy Loss": 0.8751397728919983, "Value Loss": 15.247711181640625, "_runtime": 12342.270231246948, "_timestamp": 1585609711.9031007, "_step": 404}
{"Episode reward": 17.39135961532635, "Episode length": 827, "Policy Loss": 0.4553869664669037, "Value Loss": 11.553263664245605, "_runtime": 12342.898778915405, "_timestamp": 1585609712.5316484, "_step": 405}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 1.681344985961914, "Value Loss": 24.4019718170166, "_runtime": 12344.446642875671, "_timestamp": 1585609714.0795124, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6315250396728516, "Value Loss": 0.009508287534117699, "_runtime": 12346.024428367615, "_timestamp": 1585609715.6572978, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6391416192054749, "Value Loss": 0.014723431318998337, "_runtime": 12347.486987829208, "_timestamp": 1585609717.1198573, "_step": 408}
{"Episode reward": 4.3000000000011624, "Episode length": 957, "Policy Loss": 0.27758216857910156, "Value Loss": 9.879913330078125, "_runtime": 12348.519092559814, "_timestamp": 1585609718.151962, "_step": 409}
{"Episode reward": 36.09999999999937, "Episode length": 639, "Policy Loss": 0.6741138696670532, "Value Loss": 14.633443832397461, "_runtime": 12349.412010669708, "_timestamp": 1585609719.0448802, "_step": 410}
{"Episode reward": 43.69999999999948, "Episode length": 563, "Policy Loss": 0.8428547382354736, "Value Loss": 16.437686920166016, "_runtime": 12350.839039564133, "_timestamp": 1585609720.471909, "_step": 411}
{"Episode reward": 9.200000000000884, "Episode length": 908, "Policy Loss": 0.2497870922088623, "Value Loss": 10.193849563598633, "_runtime": 12352.401623725891, "_timestamp": 1585609722.0344932, "_step": 412}
{"Episode reward": -99.81688295006613, "Episode length": 999, "Policy Loss": -0.7003843784332275, "Value Loss": 0.24896541237831116, "_runtime": 12353.943837404251, "_timestamp": 1585609723.576707, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7195270657539368, "Value Loss": 0.019442813470959663, "_runtime": 12355.539484024048, "_timestamp": 1585609725.1723535, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7321747541427612, "Value Loss": 0.020614927634596825, "_runtime": 12357.119819402695, "_timestamp": 1585609726.752689, "_step": 415}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7326505780220032, "Value Loss": 0.01988285966217518, "_runtime": 12358.44458436966, "_timestamp": 1585609728.0774539, "_step": 416}
{"Episode reward": 16.000000000000497, "Episode length": 840, "Policy Loss": 0.29736799001693726, "Value Loss": 11.351583480834961, "_runtime": 12360.022542715073, "_timestamp": 1585609729.6554122, "_step": 417}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7265713214874268, "Value Loss": 0.01579773798584938, "_runtime": 12361.61103463173, "_timestamp": 1585609731.243904, "_step": 418}
{"Episode reward": -99.76035248041013, "Episode length": 999, "Policy Loss": -0.7247234582901001, "Value Loss": 0.012674503959715366, "_runtime": 12363.171468019485, "_timestamp": 1585609732.8043375, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7248041033744812, "Value Loss": 0.19697751104831696, "_runtime": 12364.747823476791, "_timestamp": 1585609734.380693, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6829301118850708, "Value Loss": 0.023064550012350082, "_runtime": 12366.317497730255, "_timestamp": 1585609735.9503672, "_step": 421}
{"Episode reward": -99.83510909676411, "Episode length": 999, "Policy Loss": -0.6635735034942627, "Value Loss": 0.039453137665987015, "_runtime": 12366.997087478638, "_timestamp": 1585609736.629957, "_step": 422}
{"Episode reward": 58.999999999999694, "Episode length": 410, "Policy Loss": 1.639935851097107, "Value Loss": 23.341764450073242, "_runtime": 12368.579992771149, "_timestamp": 1585609738.2128623, "_step": 423}
{"Episode reward": -99.80190947055677, "Episode length": 999, "Policy Loss": -0.6436730623245239, "Value Loss": 0.025650564581155777, "_runtime": 12370.158050060272, "_timestamp": 1585609739.7909195, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6326808929443359, "Value Loss": 0.015301425941288471, "_runtime": 12371.226710319519, "_timestamp": 1585609740.8595798, "_step": 425}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 0.647341251373291, "Value Loss": 13.367509841918945, "_runtime": 12372.71730184555, "_timestamp": 1585609742.3501713, "_step": 426}
{"Episode reward": 6.10000000000106, "Episode length": 939, "Policy Loss": 0.4798225164413452, "Value Loss": 10.11646556854248, "_runtime": 12374.014276504517, "_timestamp": 1585609743.647146, "_step": 427}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.4442874789237976, "Value Loss": 11.43689250946045, "_runtime": 12375.554791212082, "_timestamp": 1585609745.1876607, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5953394174575806, "Value Loss": 0.0232533048838377, "_runtime": 12377.115974664688, "_timestamp": 1585609746.7488441, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5825880765914917, "Value Loss": 0.05535474419593811, "_runtime": 12378.678674221039, "_timestamp": 1585609748.3115437, "_step": 430}
{"Episode reward": -99.81136756539205, "Episode length": 999, "Policy Loss": -0.5866953134536743, "Value Loss": 0.012788012623786926, "_runtime": 12380.29225564003, "_timestamp": 1585609749.9251251, "_step": 431}
{"Episode reward": -99.88940773606161, "Episode length": 999, "Policy Loss": -0.5550259351730347, "Value Loss": 0.05231575667858124, "_runtime": 12381.73810505867, "_timestamp": 1585609751.3709745, "_step": 432}
{"Episode reward": 9.300000000000878, "Episode length": 907, "Policy Loss": 0.3947848677635193, "Value Loss": 10.111251831054688, "_runtime": 12382.55245757103, "_timestamp": 1585609752.185327, "_step": 433}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 1.1895227432250977, "Value Loss": 17.977922439575195, "_runtime": 12384.127121448517, "_timestamp": 1585609753.759991, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5252346396446228, "Value Loss": 0.007713850121945143, "_runtime": 12385.700961589813, "_timestamp": 1585609755.333831, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5061671137809753, "Value Loss": 0.02314716950058937, "_runtime": 12387.236893415451, "_timestamp": 1585609756.869763, "_step": 436}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4985949695110321, "Value Loss": 0.018805818632245064, "_runtime": 12388.815410137177, "_timestamp": 1585609758.4482796, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4796040952205658, "Value Loss": 0.020254312083125114, "_runtime": 12390.384222269058, "_timestamp": 1585609760.0170918, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4677252471446991, "Value Loss": 0.0070943403989076614, "_runtime": 12391.388824939728, "_timestamp": 1585609761.0216944, "_step": 439}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 1.3127455711364746, "Value Loss": 14.99732494354248, "_runtime": 12392.956967830658, "_timestamp": 1585609762.5898373, "_step": 440}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42598456144332886, "Value Loss": 0.09789839386940002, "_runtime": 12394.558160543442, "_timestamp": 1585609764.19103, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.41870710253715515, "Value Loss": 0.010309072211384773, "_runtime": 12395.094366788864, "_timestamp": 1585609764.7272363, "_step": 442}
{"Episode reward": 68.09999999999982, "Episode length": 319, "Policy Loss": 2.527015209197998, "Value Loss": 29.110811233520508, "_runtime": 12396.68737912178, "_timestamp": 1585609766.3202486, "_step": 443}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4175976812839508, "Value Loss": 0.018657924607396126, "_runtime": 12398.269412994385, "_timestamp": 1585609767.9022825, "_step": 444}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4250408709049225, "Value Loss": 0.08442472666501999, "_runtime": 12399.779482603073, "_timestamp": 1585609769.412352, "_step": 445}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42435041069984436, "Value Loss": 0.015912413597106934, "_runtime": 12401.36964583397, "_timestamp": 1585609771.0025153, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42514339089393616, "Value Loss": 0.02657526731491089, "_runtime": 12402.480853557587, "_timestamp": 1585609772.113723, "_step": 447}
{"Episode reward": 30.39999999999968, "Episode length": 696, "Policy Loss": 0.8420056700706482, "Value Loss": 13.625386238098145, "_runtime": 12404.081596136093, "_timestamp": 1585609773.7144656, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4404154419898987, "Value Loss": 0.009565095417201519, "_runtime": 12404.469549417496, "_timestamp": 1585609774.102419, "_step": 449}
{"Episode reward": 78.69999999999997, "Episode length": 213, "Policy Loss": 3.80633282661438, "Value Loss": 42.37263107299805, "_runtime": 12406.042159557343, "_timestamp": 1585609775.675029, "_step": 450}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4854719042778015, "Value Loss": 0.009525040164589882, "_runtime": 12407.617735862732, "_timestamp": 1585609777.2506053, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5300689935684204, "Value Loss": 0.006452386267483234, "_runtime": 12408.469461917877, "_timestamp": 1585609778.1023314, "_step": 452}
{"Episode reward": 42.899999999999466, "Episode length": 571, "Policy Loss": 1.2942553758621216, "Value Loss": 16.21657371520996, "_runtime": 12410.048050642014, "_timestamp": 1585609779.6809201, "_step": 453}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5950648784637451, "Value Loss": 0.017273781821131706, "_runtime": 12411.624144077301, "_timestamp": 1585609781.2570136, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6234840750694275, "Value Loss": 0.011881894432008266, "_runtime": 12413.148154735565, "_timestamp": 1585609782.7810242, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6388418674468994, "Value Loss": 0.026745976880192757, "_runtime": 12414.734377384186, "_timestamp": 1585609784.3672469, "_step": 456}
{"Episode reward": -99.80020399689535, "Episode length": 999, "Policy Loss": -0.6389793753623962, "Value Loss": 0.026962246745824814, "_runtime": 12415.476311922073, "_timestamp": 1585609785.1091814, "_step": 457}
{"Episode reward": 54.29999999999963, "Episode length": 457, "Policy Loss": 1.5328257083892822, "Value Loss": 19.9444580078125, "_runtime": 12416.822650194168, "_timestamp": 1585609786.4555197, "_step": 458}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": 0.3552496135234833, "Value Loss": 10.480854034423828, "_runtime": 12418.413005113602, "_timestamp": 1585609788.0458746, "_step": 459}
{"Episode reward": -99.81726629733899, "Episode length": 999, "Policy Loss": -0.6682124137878418, "Value Loss": 0.029042497277259827, "_runtime": 12419.946902275085, "_timestamp": 1585609789.5797718, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6839344501495361, "Value Loss": 0.008560728281736374, "_runtime": 12421.505232810974, "_timestamp": 1585609791.1381023, "_step": 461}
{"Episode reward": 0.8000000000013614, "Episode length": 992, "Policy Loss": 0.20950935781002045, "Value Loss": 8.82365608215332, "_runtime": 12423.088431358337, "_timestamp": 1585609792.7213008, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6766791939735413, "Value Loss": 0.012949777767062187, "_runtime": 12424.649052381516, "_timestamp": 1585609794.2819219, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6765483617782593, "Value Loss": 0.05511903762817383, "_runtime": 12426.231464862823, "_timestamp": 1585609795.8643343, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6552935242652893, "Value Loss": 0.016101257875561714, "_runtime": 12427.86553144455, "_timestamp": 1585609797.498401, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6606850624084473, "Value Loss": 0.2536173462867737, "_runtime": 12429.435360193253, "_timestamp": 1585609799.0682297, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6181615591049194, "Value Loss": 0.013014786876738071, "_runtime": 12429.950657844543, "_timestamp": 1585609799.5835273, "_step": 467}
{"Episode reward": 69.89999999999985, "Episode length": 301, "Policy Loss": 2.2738986015319824, "Value Loss": 30.337677001953125, "_runtime": 12431.025451898575, "_timestamp": 1585609800.6583214, "_step": 468}
{"Episode reward": 32.89999999999954, "Episode length": 671, "Policy Loss": 0.7071545124053955, "Value Loss": 14.226481437683105, "_runtime": 12432.6074488163, "_timestamp": 1585609802.2403183, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6192598938941956, "Value Loss": 0.018703386187553406, "_runtime": 12434.136009216309, "_timestamp": 1585609803.7688787, "_step": 470}
{"Episode reward": -99.81690301895001, "Episode length": 999, "Policy Loss": -0.6104313135147095, "Value Loss": 0.04271756485104561, "_runtime": 12435.493738651276, "_timestamp": 1585609805.1266081, "_step": 471}
{"Episode reward": 12.60000000000069, "Episode length": 874, "Policy Loss": 0.35577836632728577, "Value Loss": 10.855652809143066, "_runtime": 12436.714876890182, "_timestamp": 1585609806.3477464, "_step": 472}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.4816320836544037, "Value Loss": 11.780332565307617, "_runtime": 12438.280235528946, "_timestamp": 1585609807.913105, "_step": 473}
{"Episode reward": -99.83548622131208, "Episode length": 999, "Policy Loss": -0.6211392879486084, "Value Loss": 0.02390369027853012, "_runtime": 12439.017021894455, "_timestamp": 1585609808.6498914, "_step": 474}
{"Episode reward": 54.199999999999626, "Episode length": 458, "Policy Loss": 1.1443513631820679, "Value Loss": 19.048851013183594, "_runtime": 12440.598694324493, "_timestamp": 1585609810.2315638, "_step": 475}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6463124752044678, "Value Loss": 0.023345237597823143, "_runtime": 12441.893485307693, "_timestamp": 1585609811.5263548, "_step": 476}
{"Episode reward": 18.800000000000338, "Episode length": 812, "Policy Loss": 0.439419686794281, "Value Loss": 11.20625114440918, "_runtime": 12443.328203678131, "_timestamp": 1585609812.9610732, "_step": 477}
{"Episode reward": 6.259231561423405, "Episode length": 938, "Policy Loss": 0.2574460804462433, "Value Loss": 9.771561622619629, "_runtime": 12444.93226981163, "_timestamp": 1585609814.5651393, "_step": 478}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6925597786903381, "Value Loss": 0.011119830422103405, "_runtime": 12446.499624490738, "_timestamp": 1585609816.132494, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7511946558952332, "Value Loss": 0.9756566882133484, "_runtime": 12448.001876115799, "_timestamp": 1585609817.6347456, "_step": 480}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": 0.16732250154018402, "Value Loss": 9.3485107421875, "_runtime": 12449.364480495453, "_timestamp": 1585609818.99735, "_step": 481}
{"Episode reward": 14.700000000000571, "Episode length": 853, "Policy Loss": 0.27061405777931213, "Value Loss": 11.154006958007812, "_runtime": 12450.982191562653, "_timestamp": 1585609820.615061, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7480179071426392, "Value Loss": 0.011148253455758095, "_runtime": 12452.573179006577, "_timestamp": 1585609822.2060485, "_step": 483}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7400118708610535, "Value Loss": 0.06711561232805252, "_runtime": 12453.923766374588, "_timestamp": 1585609823.5566359, "_step": 484}
{"Episode reward": 14.000000000000611, "Episode length": 860, "Policy Loss": 0.27236783504486084, "Value Loss": 10.529539108276367, "_runtime": 12455.511054039001, "_timestamp": 1585609825.1439235, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7357832193374634, "Value Loss": 0.029180195182561874, "_runtime": 12457.103893995285, "_timestamp": 1585609826.7367635, "_step": 486}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.708347737789154, "Value Loss": 0.16959702968597412, "_runtime": 12458.138328552246, "_timestamp": 1585609827.771198, "_step": 487}
{"Episode reward": 35.34563817977845, "Episode length": 647, "Policy Loss": 0.6169570088386536, "Value Loss": 14.23698616027832, "_runtime": 12459.731102705002, "_timestamp": 1585609829.3639722, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6883398294448853, "Value Loss": 0.03885304182767868, "_runtime": 12461.137325525284, "_timestamp": 1585609830.770195, "_step": 489}
{"Episode reward": 12.000000000000725, "Episode length": 880, "Policy Loss": 0.38076213002204895, "Value Loss": 10.959383964538574, "_runtime": 12462.397638082504, "_timestamp": 1585609832.0305076, "_step": 490}
{"Episode reward": 20.20000000000026, "Episode length": 798, "Policy Loss": 0.45392143726348877, "Value Loss": 11.951399803161621, "_runtime": 12463.106839179993, "_timestamp": 1585609832.7397087, "_step": 491}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.4653462171554565, "Value Loss": 22.38692283630371, "_runtime": 12464.692463874817, "_timestamp": 1585609834.3253334, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6282288432121277, "Value Loss": 0.017910420894622803, "_runtime": 12466.270003795624, "_timestamp": 1585609835.9028733, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6154539585113525, "Value Loss": 0.02547411434352398, "_runtime": 12467.807794570923, "_timestamp": 1585609837.440664, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6069121360778809, "Value Loss": 0.035188935697078705, "_runtime": 12469.01916384697, "_timestamp": 1585609838.6520333, "_step": 495}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 0.5232268571853638, "Value Loss": 11.63828182220459, "_runtime": 12470.615016460419, "_timestamp": 1585609840.247886, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5682811141014099, "Value Loss": 0.020074836909770966, "_runtime": 12471.775148391724, "_timestamp": 1585609841.4080179, "_step": 497}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 0.6131469011306763, "Value Loss": 12.473109245300293, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673, -0.0035861064679920673]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 7.0], "bins": [-0.5674777626991272, -0.5585548877716064, -0.5496320128440857, -0.5407091379165649, -0.5317862629890442, -0.5228633880615234, -0.5139405131340027, -0.5050176382064819, -0.4960947632789612, -0.48717188835144043, -0.4782490134239197, -0.4693261682987213, -0.46040329337120056, -0.4514804184436798, -0.44255754351615906, -0.4336346685886383, -0.42471179366111755, -0.4157889187335968, -0.40686604380607605, -0.3979431688785553, -0.38902029395103455, -0.3800974488258362, -0.37117457389831543, -0.3622516989707947, -0.3533288240432739, -0.3444059491157532, -0.3354830741882324, -0.32656019926071167, -0.3176373243331909, -0.30871444940567017, -0.2997915744781494, -0.29086869955062866, -0.2819458246231079, -0.27302294969558716, -0.2641000747680664, -0.25517719984054565, -0.2462543249130249, -0.23733144998550415, -0.2284085750579834, -0.21948570013046265, -0.2105628252029419, -0.20163998007774353, -0.19271710515022278, -0.18379423022270203, -0.17487135529518127, -0.16594848036766052, -0.15702560544013977, -0.14810273051261902, -0.13917985558509827, -0.13025698065757751, -0.12133410573005676, -0.11241123080253601, -0.10348835587501526, -0.0945654809474945, -0.08564260601997375, -0.076719731092453, -0.06779688596725464, -0.05887401103973389, -0.049951136112213135, -0.04102826118469238, -0.03210538625717163, -0.02318251132965088, -0.014259636402130127, -0.005336761474609375, 0.003586113452911377]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01743919402360916, -0.01714167930185795, -0.016844164580106735, -0.016546649858355522, -0.01624913513660431, -0.015951620414853096, -0.015654105693101883, -0.015356591902673244, -0.015059077180922031, -0.014761563390493393, -0.01446404866874218, -0.014166533946990967, -0.013869019225239754, -0.01357150450348854, -0.013273989781737328, -0.012976475059986115, -0.012678960338234901, -0.012381445616483688, -0.01208393182605505, -0.011786417104303837, -0.011488902382552624, -0.011191388592123985, -0.010893873870372772, -0.01059635914862156, -0.010298844426870346, -0.010001329705119133, -0.00970381498336792, -0.009406300261616707, -0.009108785539865494, -0.008811271749436855, -0.008513757027685642, -0.00821624230593443, -0.007918727584183216, -0.007621212862432003, -0.00732369814068079, -0.007026183418929577, -0.006728669628500938, -0.006431154906749725, -0.006133640184998512, -0.005836125463247299, -0.005538610741496086, -0.005241096019744873, -0.004943582229316235, -0.0046460675075650215, -0.0043485527858138084, -0.004051038064062595, -0.0037535233423113823, -0.0034560086205601692, -0.0031584948301315308, -0.0028609801083803177, -0.0025634653866291046, -0.0022659506648778915, -0.0019684359431266785, -0.0016709212213754654, -0.0013734064996242523, -0.0010758917778730392, -0.0007783770561218262, -0.0004808623343706131, -0.00018334947526454926, 0.00011416524648666382, 0.0004116799682378769, 0.00070919468998909, 0.001006709411740303, 0.0013042241334915161, 0.0016017388552427292]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 4.0, 7.0, 6.0, 5.0, 6.0, 4.0, 1.0, 0.0, 2.0, 5.0, 6.0, 2.0, 4.0, 11.0, 1.0, 10.0, 9.0, 22.0, 224.0, 40.0, 13.0, 12.0, 0.0, 6.0, 17.0, 27.0, 23.0, 20.0], "bins": [-0.09902073442935944, -0.09720201045274734, -0.09538328647613525, -0.09356456249952316, -0.09174584597349167, -0.08992712199687958, -0.08810839802026749, -0.0862896740436554, -0.0844709500670433, -0.08265222609043121, -0.08083350956439972, -0.07901477813720703, -0.07719606161117554, -0.07537733763456345, -0.07355861365795135, -0.07173988968133926, -0.06992116570472717, -0.06810244917869568, -0.06628371775150299, -0.0644650012254715, -0.0626462772488594, -0.060827553272247314, -0.05900882929563522, -0.05719010531902313, -0.05537138506770134, -0.05355266109108925, -0.05173393711447716, -0.049915216863155365, -0.048096492886543274, -0.04627776890993118, -0.04445904493331909, -0.0426403246819973, -0.04082160070538521, -0.03900287672877312, -0.037184156477451324, -0.03536543250083923, -0.03354670852422714, -0.03172798454761505, -0.02990926057100296, -0.02809053659439087, -0.026271820068359375, -0.024453096091747284, -0.022634372115135193, -0.020815648138523102, -0.01899692416191101, -0.01717820018529892, -0.015359476208686829, -0.013540759682655334, -0.011722035706043243, -0.009903311729431152, -0.008084587752819061, -0.00626586377620697, -0.004447139799594879, -0.002628415822982788, -0.0008096992969512939, 0.0010090246796607971, 0.002827748656272888, 0.004646472632884979, 0.00646519660949707, 0.008283920586109161, 0.010102644562721252, 0.011921361088752747, 0.013740085065364838, 0.015558809041976929, 0.01737753301858902]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 9.0, 3.0], "bins": [-0.38583698868751526, -0.3796560764312744, -0.37347516417503357, -0.3672942519187927, -0.36111336946487427, -0.3549324572086334, -0.3487515449523926, -0.34257063269615173, -0.3363897204399109, -0.33020880818367004, -0.3240278959274292, -0.31784701347351074, -0.3116660714149475, -0.30548518896102905, -0.2993042767047882, -0.29312336444854736, -0.2869424521923065, -0.2807615399360657, -0.27458062767982483, -0.268399715423584, -0.2622188329696655, -0.2560378909111023, -0.24985700845718384, -0.243676096200943, -0.23749518394470215, -0.2313142716884613, -0.22513335943222046, -0.2189524620771408, -0.21277154982089996, -0.20659063756465912, -0.20040974020957947, -0.19422882795333862, -0.18804791569709778, -0.18186700344085693, -0.1756860911846161, -0.16950519382953644, -0.1633242815732956, -0.15714336931705475, -0.1509624719619751, -0.14478155970573425, -0.1386006474494934, -0.13241973519325256, -0.12623882293701172, -0.12005791068077087, -0.11387702822685242, -0.10769611597061157, -0.10151520371437073, -0.09533429145812988, -0.08915337920188904, -0.0829724669456482, -0.07679155468940735, -0.0706106424331665, -0.06442973017692566, -0.0582488477230072, -0.05206793546676636, -0.04588702321052551, -0.03970611095428467, -0.03352519869804382, -0.02734428644180298, -0.021163374185562134, -0.014982491731643677, -0.008801579475402832, -0.0026206672191619873, 0.0035602450370788574, 0.009741157293319702]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 6.0, 8.0, 21.0, 6.0, 1.0, 2.0], "bins": [-0.03296806663274765, -0.03241990879178047, -0.031871747225522995, -0.03132358938455582, -0.03077542781829834, -0.030227268114686012, -0.029679108411073685, -0.029130948707461357, -0.02858278900384903, -0.028034629300236702, -0.027486469596624374, -0.026938309893012047, -0.02639015018939972, -0.02584199234843254, -0.025293830782175064, -0.024745672941207886, -0.02419751137495041, -0.02364935353398323, -0.023101191967725754, -0.022553034126758575, -0.0220048725605011, -0.02145671471953392, -0.020908553153276443, -0.020360395312309265, -0.019812235608696938, -0.01926407590508461, -0.018715916201472282, -0.018167756497859955, -0.017619596794247627, -0.0170714370906353, -0.016523277387022972, -0.015975117683410645, -0.015426957979798317, -0.01487879827618599, -0.014330638572573662, -0.013782478868961334, -0.013234319165349007, -0.012686159461736679, -0.012137999758124352, -0.011589840054512024, -0.011041680350899696, -0.010493520647287369, -0.009945360943675041, -0.009397201240062714, -0.008849041536450386, -0.008300881832838058, -0.007752722129225731, -0.007204562425613403, -0.006656404584646225, -0.006108244881033897, -0.00556008517742157, -0.005011925473809242, -0.004463765770196915, -0.003915606066584587, -0.0033674463629722595, -0.002819286659359932, -0.0022711269557476044, -0.0017229672521352768, -0.0011748075485229492, -0.0006266459822654724, -7.848814129829407e-05, 0.00046967342495918274, 0.001017831265926361, 0.0015659928321838379, 0.0021141506731510162]}, "_runtime": 12473.340648889542, "_timestamp": 1585609842.9735184, "_step": 498}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.539405345916748, "Value Loss": 0.014921018853783607, "_runtime": 12473.340648889542, "_timestamp": 1585609842.9735184, "_step": 499}
