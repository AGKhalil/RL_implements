{"Episode reward": 30.238316648124467, "Episode length": 918, "Policy Loss": -0.00840256828814745, "Value Loss": 10.995487213134766, "_runtime": 13355.686673879623, "_timestamp": 1585610725.3195434, "_step": 0}
{"Episode reward": 73.94529257929617, "Episode length": 281, "Policy Loss": 55.80887985229492, "Value Loss": 2629.597900390625, "_runtime": 13356.00432753563, "_timestamp": 1585610725.637197, "_step": 1}
{"Episode reward": 78.75115685798909, "Episode length": 217, "Policy Loss": -360.3517761230469, "Value Loss": 5713.07275390625, "_runtime": 13356.221066474915, "_timestamp": 1585610725.853936, "_step": 2}
{"Episode reward": 90.32377210882426, "Episode length": 98, "Policy Loss": 1438.082763671875, "Value Loss": 82086.625, "_runtime": 13356.586192369461, "_timestamp": 1585610726.2190619, "_step": 3}
{"Episode reward": 77.79245265451505, "Episode length": 236, "Policy Loss": -12.284234046936035, "Value Loss": 365.684814453125, "_runtime": 13358.11886048317, "_timestamp": 1585610727.75173, "_step": 4}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -15.251729965209961, "Value Loss": 112.47755432128906, "_runtime": 13358.644661664963, "_timestamp": 1585610728.2775311, "_step": 5}
{"Episode reward": 65.95745804087437, "Episode length": 344, "Policy Loss": 15.873515129089355, "Value Loss": 190.21839904785156, "_runtime": 13359.05213546753, "_timestamp": 1585610728.685005, "_step": 6}
{"Episode reward": 73.58801342322592, "Episode length": 266, "Policy Loss": 85.6094741821289, "Value Loss": 1956.0496826171875, "_runtime": 13359.484065771103, "_timestamp": 1585610729.1169353, "_step": 7}
{"Episode reward": 75.89999999999993, "Episode length": 241, "Policy Loss": 57.961238861083984, "Value Loss": 868.5004272460938, "_runtime": 13359.776953220367, "_timestamp": 1585610729.4098227, "_step": 8}
{"Episode reward": 81.20825425998774, "Episode length": 188, "Policy Loss": 52.51401901245117, "Value Loss": 446.62847900390625, "_runtime": 13360.442625284195, "_timestamp": 1585610730.0754948, "_step": 9}
{"Episode reward": 55.339033965556524, "Episode length": 447, "Policy Loss": 9.036198616027832, "Value Loss": 39.205780029296875, "_runtime": 13361.044109344482, "_timestamp": 1585610730.6769788, "_step": 10}
{"Episode reward": 60.24927793509386, "Episode length": 399, "Policy Loss": 4.970618724822998, "Value Loss": 25.511934280395508, "_runtime": 13362.527575969696, "_timestamp": 1585610732.1604455, "_step": 11}
{"Episode reward": -99.81435805157132, "Episode length": 999, "Policy Loss": 3.577805280685425, "Value Loss": 0.24469348788261414, "_runtime": 13364.050023078918, "_timestamp": 1585610733.6828926, "_step": 12}
{"Episode reward": -99.73474698869838, "Episode length": 999, "Policy Loss": 3.92857027053833, "Value Loss": 0.2760705053806305, "_runtime": 13365.576396465302, "_timestamp": 1585610735.209266, "_step": 13}
{"Episode reward": -99.86005682386319, "Episode length": 999, "Policy Loss": 4.203105449676514, "Value Loss": 0.3054008483886719, "_runtime": 13367.131553411484, "_timestamp": 1585610736.764423, "_step": 14}
{"Episode reward": -99.80350419022002, "Episode length": 999, "Policy Loss": 4.4686408042907715, "Value Loss": 0.3329833149909973, "_runtime": 13368.6860268116, "_timestamp": 1585610738.3188963, "_step": 15}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.696684837341309, "Value Loss": 0.3583430051803589, "_runtime": 13370.156767368317, "_timestamp": 1585610739.7896369, "_step": 16}
{"Episode reward": 5.6000000000010886, "Episode length": 944, "Policy Loss": 5.72527551651001, "Value Loss": 11.105998992919922, "_runtime": 13371.717930793762, "_timestamp": 1585610741.3508003, "_step": 17}
{"Episode reward": -99.74602721640701, "Episode length": 999, "Policy Loss": 5.1247453689575195, "Value Loss": 0.40325209498405457, "_runtime": 13373.314081668854, "_timestamp": 1585610742.9469512, "_step": 18}
{"Episode reward": -99.85658925510803, "Episode length": 999, "Policy Loss": 5.2674360275268555, "Value Loss": 0.4223918616771698, "_runtime": 13374.869963407516, "_timestamp": 1585610744.502833, "_step": 19}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.39949893951416, "Value Loss": 0.43967267870903015, "_runtime": 13376.428812265396, "_timestamp": 1585610746.0616817, "_step": 20}
{"Episode reward": -99.86567883640387, "Episode length": 999, "Policy Loss": 5.574519634246826, "Value Loss": 0.45520302653312683, "_runtime": 13376.960961341858, "_timestamp": 1585610746.5938308, "_step": 21}
{"Episode reward": 68.99999999999983, "Episode length": 310, "Policy Loss": 8.516763687133789, "Value Loss": 33.16869354248047, "_runtime": 13378.513605833054, "_timestamp": 1585610748.1464753, "_step": 22}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.776090145111084, "Value Loss": 0.4806098937988281, "_runtime": 13379.072915792465, "_timestamp": 1585610748.7057853, "_step": 23}
{"Episode reward": 67.29999999999981, "Episode length": 327, "Policy Loss": 8.350190162658691, "Value Loss": 31.59199333190918, "_runtime": 13380.587829351425, "_timestamp": 1585610750.2206988, "_step": 24}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.953203201293945, "Value Loss": 0.4992782771587372, "_runtime": 13382.172185897827, "_timestamp": 1585610751.8050554, "_step": 25}
{"Episode reward": -99.80215292572835, "Episode length": 999, "Policy Loss": 6.01262903213501, "Value Loss": 0.5065577030181885, "_runtime": 13383.68063378334, "_timestamp": 1585610753.3135033, "_step": 26}
{"Episode reward": -99.89280989169934, "Episode length": 999, "Policy Loss": 6.1000752449035645, "Value Loss": 0.5122888684272766, "_runtime": 13385.22414278984, "_timestamp": 1585610754.8570123, "_step": 27}
{"Episode reward": 1.6982907757176235, "Episode length": 984, "Policy Loss": 6.941810131072998, "Value Loss": 10.830516815185547, "_runtime": 13386.807992219925, "_timestamp": 1585610756.4408617, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.169125080108643, "Value Loss": 0.5205022096633911, "_runtime": 13388.358272314072, "_timestamp": 1585610757.9911418, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.2127366065979, "Value Loss": 0.5230370759963989, "_runtime": 13389.457484960556, "_timestamp": 1585610759.0903544, "_step": 30}
{"Episode reward": 30.499999999999673, "Episode length": 695, "Policy Loss": 7.441159725189209, "Value Loss": 15.121574401855469, "_runtime": 13390.655066728592, "_timestamp": 1585610760.2879362, "_step": 31}
{"Episode reward": 24.351092241704492, "Episode length": 757, "Policy Loss": 7.305607795715332, "Value Loss": 13.926959991455078, "_runtime": 13392.211642742157, "_timestamp": 1585610761.8445122, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.245297908782959, "Value Loss": 0.5251253843307495, "_runtime": 13392.920187234879, "_timestamp": 1585610762.5530567, "_step": 33}
{"Episode reward": 55.89999999999965, "Episode length": 441, "Policy Loss": 8.19079875946045, "Value Loss": 23.604473114013672, "_runtime": 13394.483769416809, "_timestamp": 1585610764.116639, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.261643409729004, "Value Loss": 0.5225737690925598, "_runtime": 13396.048627138138, "_timestamp": 1585610765.6814966, "_step": 35}
{"Episode reward": -99.8935168325887, "Episode length": 999, "Policy Loss": 6.262768268585205, "Value Loss": 0.5203686952590942, "_runtime": 13397.604142665863, "_timestamp": 1585610767.2370121, "_step": 36}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.241319179534912, "Value Loss": 0.5176439881324768, "_runtime": 13399.191202402115, "_timestamp": 1585610768.824072, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.216940402984619, "Value Loss": 0.5144978761672974, "_runtime": 13400.773784399033, "_timestamp": 1585610770.406654, "_step": 38}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.218744277954102, "Value Loss": 0.5109472274780273, "_runtime": 13402.328783512115, "_timestamp": 1585610771.961653, "_step": 39}
{"Episode reward": -99.87164531349995, "Episode length": 999, "Policy Loss": 6.205740928649902, "Value Loss": 0.5070908069610596, "_runtime": 13402.85970544815, "_timestamp": 1585610772.492575, "_step": 40}
{"Episode reward": 69.39999999999984, "Episode length": 306, "Policy Loss": 8.882258415222168, "Value Loss": 33.64603042602539, "_runtime": 13404.43243432045, "_timestamp": 1585610774.0653038, "_step": 41}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.1787567138671875, "Value Loss": 0.4980393350124359, "_runtime": 13405.567880153656, "_timestamp": 1585610775.2007496, "_step": 42}
{"Episode reward": 28.499999999999787, "Episode length": 715, "Policy Loss": 7.2980523109436035, "Value Loss": 14.675459861755371, "_runtime": 13407.086186885834, "_timestamp": 1585610776.7190564, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.121042728424072, "Value Loss": 0.48772338032722473, "_runtime": 13408.020283699036, "_timestamp": 1585610777.6531532, "_step": 44}
{"Episode reward": 42.099999999999454, "Episode length": 579, "Policy Loss": 7.489681243896484, "Value Loss": 17.993288040161133, "_runtime": 13409.584089517593, "_timestamp": 1585610779.216959, "_step": 45}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 6.046567916870117, "Value Loss": 0.4765034317970276, "_runtime": 13410.93299126625, "_timestamp": 1585610780.5658607, "_step": 46}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 7.077423095703125, "Value Loss": 12.176443099975586, "_runtime": 13412.116035223007, "_timestamp": 1585610781.7489047, "_step": 47}
{"Episode reward": 23.0000000000001, "Episode length": 770, "Policy Loss": 7.133979320526123, "Value Loss": 15.600420951843262, "_runtime": 13413.696390390396, "_timestamp": 1585610783.3292599, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.916676998138428, "Value Loss": 0.4584350287914276, "_runtime": 13414.328832149506, "_timestamp": 1585610783.9617016, "_step": 49}
{"Episode reward": 61.29999999999973, "Episode length": 387, "Policy Loss": 8.201162338256836, "Value Loss": 26.64533805847168, "_runtime": 13415.87835741043, "_timestamp": 1585610785.511227, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.849018096923828, "Value Loss": 0.44573405385017395, "_runtime": 13416.800585985184, "_timestamp": 1585610786.4334555, "_step": 51}
{"Episode reward": 42.99999999999947, "Episode length": 570, "Policy Loss": 7.295074462890625, "Value Loss": 18.215723037719727, "_runtime": 13417.684568166733, "_timestamp": 1585610787.3174376, "_step": 52}
{"Episode reward": 42.280655895173005, "Episode length": 578, "Policy Loss": 7.624850273132324, "Value Loss": 17.961570739746094, "_runtime": 13419.206971883774, "_timestamp": 1585610788.8398414, "_step": 53}
{"Episode reward": 2.883177185059836, "Episode length": 972, "Policy Loss": 6.579392910003662, "Value Loss": 10.848527908325195, "_runtime": 13420.776077270508, "_timestamp": 1585610790.4089468, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.6795430183410645, "Value Loss": 0.419353723526001, "_runtime": 13422.302946805954, "_timestamp": 1585610791.9358163, "_step": 55}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.6026716232299805, "Value Loss": 0.41273996233940125, "_runtime": 13423.818542480469, "_timestamp": 1585610793.451412, "_step": 56}
{"Episode reward": 3.7620284080517337, "Episode length": 963, "Policy Loss": 6.4819488525390625, "Value Loss": 10.922869682312012, "_runtime": 13424.517830371857, "_timestamp": 1585610794.1506999, "_step": 57}
{"Episode reward": 57.39999999999967, "Episode length": 426, "Policy Loss": 7.528733730316162, "Value Loss": 24.170621871948242, "_runtime": 13426.08512210846, "_timestamp": 1585610795.7179916, "_step": 58}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.509934425354004, "Value Loss": 0.3929939270019531, "_runtime": 13426.647971630096, "_timestamp": 1585610796.280841, "_step": 59}
{"Episode reward": 66.8999999999998, "Episode length": 331, "Policy Loss": 8.148761749267578, "Value Loss": 30.97355842590332, "_runtime": 13427.92879319191, "_timestamp": 1585610797.5616627, "_step": 60}
{"Episode reward": 16.200000000000486, "Episode length": 838, "Policy Loss": 6.429152488708496, "Value Loss": 12.459994316101074, "_runtime": 13428.845567703247, "_timestamp": 1585610798.4784372, "_step": 61}
{"Episode reward": 42.199999999999456, "Episode length": 578, "Policy Loss": 8.176349639892578, "Value Loss": 53.121028900146484, "_runtime": 13430.355655908585, "_timestamp": 1585610799.9885254, "_step": 62}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 5.334324359893799, "Value Loss": 0.3663244843482971, "_runtime": 13431.91984963417, "_timestamp": 1585610801.552719, "_step": 63}
{"Episode reward": -99.8080480813966, "Episode length": 999, "Policy Loss": 5.2726006507873535, "Value Loss": 0.3598424792289734, "_runtime": 13433.179858207703, "_timestamp": 1585610802.8127277, "_step": 64}
{"Episode reward": 17.600000000000406, "Episode length": 824, "Policy Loss": 6.264960765838623, "Value Loss": 12.648202896118164, "_runtime": 13434.424303770065, "_timestamp": 1585610804.0571733, "_step": 65}
{"Episode reward": 20.800000000000225, "Episode length": 792, "Policy Loss": 6.673823833465576, "Value Loss": 13.12183952331543, "_runtime": 13435.579535961151, "_timestamp": 1585610805.2124054, "_step": 66}
{"Episode reward": 27.39470528215155, "Episode length": 727, "Policy Loss": 6.696712970733643, "Value Loss": 14.256366729736328, "_runtime": 13437.026869297028, "_timestamp": 1585610806.6597388, "_step": 67}
{"Episode reward": 6.500000000001037, "Episode length": 935, "Policy Loss": 5.9730939865112305, "Value Loss": 11.153011322021484, "_runtime": 13437.84506058693, "_timestamp": 1585610807.47793, "_step": 68}
{"Episode reward": 48.399999999999544, "Episode length": 516, "Policy Loss": 6.791318893432617, "Value Loss": 19.92973518371582, "_runtime": 13439.40404844284, "_timestamp": 1585610809.036918, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.9973225593566895, "Value Loss": 0.32168102264404297, "_runtime": 13440.961985588074, "_timestamp": 1585610810.594855, "_step": 70}
{"Episode reward": -99.85728006362775, "Episode length": 999, "Policy Loss": 4.935457229614258, "Value Loss": 0.31564995646476746, "_runtime": 13441.9383456707, "_timestamp": 1585610811.5712152, "_step": 71}
{"Episode reward": 36.39999999999937, "Episode length": 636, "Policy Loss": 6.184993267059326, "Value Loss": 16.207937240600586, "_runtime": 13443.519565820694, "_timestamp": 1585610813.1524353, "_step": 72}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.842101573944092, "Value Loss": 0.3037804067134857, "_runtime": 13444.908042430878, "_timestamp": 1585610814.540912, "_step": 73}
{"Episode reward": 12.500000000000696, "Episode length": 875, "Policy Loss": 5.889012336730957, "Value Loss": 11.85137939453125, "_runtime": 13445.553122520447, "_timestamp": 1585610815.185992, "_step": 74}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 6.848341464996338, "Value Loss": 25.562658309936523, "_runtime": 13447.137909412384, "_timestamp": 1585610816.770779, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.707545280456543, "Value Loss": 0.28660446405410767, "_runtime": 13448.572200536728, "_timestamp": 1585610818.20507, "_step": 76}
{"Episode reward": 11.700000000000742, "Episode length": 883, "Policy Loss": 5.692412853240967, "Value Loss": 11.72614574432373, "_runtime": 13449.874459505081, "_timestamp": 1585610819.507329, "_step": 77}
{"Episode reward": 14.2000000000006, "Episode length": 858, "Policy Loss": 5.742023944854736, "Value Loss": 12.05288028717041, "_runtime": 13450.975878238678, "_timestamp": 1585610820.6087477, "_step": 78}
{"Episode reward": 30.999999999999645, "Episode length": 690, "Policy Loss": 5.8757710456848145, "Value Loss": 14.913477897644043, "_runtime": 13452.552217960358, "_timestamp": 1585610822.1850874, "_step": 79}
{"Episode reward": -99.80848322510579, "Episode length": 999, "Policy Loss": 4.505781650543213, "Value Loss": 0.26476940512657166, "_runtime": 13454.10279917717, "_timestamp": 1585610823.7356687, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.483538627624512, "Value Loss": 0.25941798090934753, "_runtime": 13455.6560485363, "_timestamp": 1585610825.288918, "_step": 81}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.415671348571777, "Value Loss": 0.2543138563632965, "_runtime": 13456.305113315582, "_timestamp": 1585610825.9379828, "_step": 82}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 6.761714458465576, "Value Loss": 26.213008880615234, "_runtime": 13457.566684484482, "_timestamp": 1585610827.199554, "_step": 83}
{"Episode reward": 19.700000000000287, "Episode length": 803, "Policy Loss": 5.5550384521484375, "Value Loss": 13.226095199584961, "_runtime": 13458.33228635788, "_timestamp": 1585610827.9651558, "_step": 84}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 6.1294331550598145, "Value Loss": 21.955137252807617, "_runtime": 13459.85832619667, "_timestamp": 1585610829.4911957, "_step": 85}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.243440628051758, "Value Loss": 0.23436057567596436, "_runtime": 13461.418986797333, "_timestamp": 1585610831.0518563, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.219245910644531, "Value Loss": 0.2295323759317398, "_runtime": 13462.337337970734, "_timestamp": 1585610831.9702075, "_step": 87}
{"Episode reward": 40.799999999999436, "Episode length": 592, "Policy Loss": 5.5629706382751465, "Value Loss": 17.276927947998047, "_runtime": 13463.905904531479, "_timestamp": 1585610833.538774, "_step": 88}
{"Episode reward": -99.80057650208333, "Episode length": 999, "Policy Loss": 4.1092915534973145, "Value Loss": 0.22028431296348572, "_runtime": 13464.554791212082, "_timestamp": 1585610834.1876607, "_step": 89}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 6.238379955291748, "Value Loss": 26.549318313598633, "_runtime": 13465.214354753494, "_timestamp": 1585610834.8472242, "_step": 90}
{"Episode reward": 58.118577575683275, "Episode length": 419, "Policy Loss": 6.156651973724365, "Value Loss": 24.2967529296875, "_runtime": 13466.804234743118, "_timestamp": 1585610836.4371042, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 4.003421783447266, "Value Loss": 0.2064751833677292, "_runtime": 13468.330386400223, "_timestamp": 1585610837.963256, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.951643228530884, "Value Loss": 0.20203407108783722, "_runtime": 13469.000913381577, "_timestamp": 1585610838.6337829, "_step": 93}
{"Episode reward": 57.29999999999967, "Episode length": 427, "Policy Loss": 5.924201488494873, "Value Loss": 23.82518768310547, "_runtime": 13470.583171367645, "_timestamp": 1585610840.2160408, "_step": 94}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.842426061630249, "Value Loss": 0.19341079890727997, "_runtime": 13471.641978263855, "_timestamp": 1585610841.2748477, "_step": 95}
{"Episode reward": 33.5999999999995, "Episode length": 664, "Policy Loss": 5.1143388748168945, "Value Loss": 15.380515098571777, "_runtime": 13473.208575487137, "_timestamp": 1585610842.841445, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.793311357498169, "Value Loss": 0.1850905567407608, "_runtime": 13474.793931722641, "_timestamp": 1585610844.4268012, "_step": 97}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.741319179534912, "Value Loss": 0.18108513951301575, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914, 0.038759469985961914]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.038759469985961914, 0.04433850944042206, 0.12743648886680603, 0.21053446829319, 0.293632447719574, 0.37673044204711914, 0.4598284065723419, 0.5429263710975647, 0.6260243654251099, 0.709122359752655, 0.7922203540802002, 0.8753182888031006, 0.9584162831306458, 1.041514277458191, 1.1246122121810913, 1.2077102661132812, 1.2908082008361816, 1.373906135559082, 1.457004189491272, 1.5401021242141724, 1.6232001781463623, 1.7062981128692627, 1.789396047592163, 1.872494101524353, 1.9555920362472534, 2.0386900901794434, 2.1217880249023438, 2.204885959625244, 2.2879838943481445, 2.371081829071045, 2.4541800022125244, 2.537277936935425, 2.620375871658325, 2.7034738063812256, 2.786571741104126, 2.8696699142456055, 2.952767848968506, 3.0358657836914062, 3.1189637184143066, 3.202061653137207, 3.2851598262786865, 3.368257761001587, 3.4513556957244873, 3.5344536304473877, 3.617551565170288, 3.7006494998931885, 3.783747673034668, 3.8668456077575684, 3.9499435424804688, 4.033041954040527, 4.1161394119262695, 4.199237823486328, 4.28233528137207, 4.365433692932129, 4.448531150817871, 4.53162956237793, 4.614727020263672, 4.6978254318237305, 4.780922889709473, 4.864021301269531, 4.94711971282959, 5.030217170715332, 5.113315582275391, 5.196413040161133, 5.279511451721191]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.08315343409776688, -0.08010154217481613, -0.07704964280128479, -0.07399775087833405, -0.0709458515048027, -0.06789395958185196, -0.06484206020832062, -0.06179016828536987, -0.05873827263712883, -0.05568637698888779, -0.052634481340646744, -0.0495825856924057, -0.046530693769454956, -0.04347879812121391, -0.04042690247297287, -0.03737500682473183, -0.034323111176490784, -0.03127121552824974, -0.028219319880008698, -0.025167424231767654, -0.02211552858352661, -0.019063636660575867, -0.016011737287044525, -0.01295984536409378, -0.009907953441143036, -0.006856054067611694, -0.0038041621446609497, -0.0007522627711296082, 0.0022996291518211365, 0.005351528525352478, 0.008403420448303223, 0.011455319821834564, 0.014507211744785309, 0.017559103667736053, 0.020611003041267395, 0.02366289496421814, 0.02671479433774948, 0.029766686260700226, 0.03281858563423157, 0.03587047755718231, 0.038922376930713654, 0.0419742688536644, 0.04502616077661514, 0.04807805269956589, 0.051129959523677826, 0.05418185144662857, 0.057233743369579315, 0.06028563529253006, 0.0633375272154808, 0.06638943403959274, 0.06944132596254349, 0.07249321788549423, 0.07554510980844498, 0.07859701663255692, 0.08164890855550766, 0.0847008004784584, 0.08775269240140915, 0.0908045843243599, 0.09385649114847183, 0.09690838307142258, 0.09996027499437332, 0.10301216691732407, 0.106064073741436, 0.10911596566438675, 0.1121678575873375]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 0.0, 1.0, 21.0, 15.0, 15.0, 32.0, 19.0, 14.0, 8.0, 0.0, 0.0, 6.0, 226.0, 1.0, 0.0, 0.0, 2.0, 11.0, 37.0, 15.0, 0.0, 3.0, 3.0, 4.0, 0.0, 1.0, 5.0, 5.0, 4.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 5.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-0.3047143816947937, -0.2939433753490448, -0.2831723392009735, -0.2724013328552246, -0.2616303265094757, -0.2508593201637268, -0.24008828401565552, -0.22931727766990662, -0.21854625642299652, -0.20777523517608643, -0.19700422883033752, -0.18623320758342743, -0.17546218633651733, -0.16469117999076843, -0.15392015874385834, -0.14314915239810944, -0.13237813115119934, -0.12160710990428925, -0.11083610355854034, -0.10006508231163025, -0.08929407596588135, -0.07852305471897125, -0.06775203347206116, -0.056981027126312256, -0.04620999097824097, -0.035438984632492065, -0.024667978286743164, -0.013896971940994263, -0.0031259357929229736, 0.007645070552825928, 0.01841607689857483, 0.029187113046646118, 0.03995811939239502, 0.05072912573814392, 0.06150016188621521, 0.07227116823196411, 0.08304217457771301, 0.0938132107257843, 0.1045842170715332, 0.1153552234172821, 0.126126229763031, 0.1368972659111023, 0.1476682722568512, 0.1584392786026001, 0.1692103147506714, 0.1799813210964203, 0.1907523274421692, 0.20152336359024048, 0.21229439973831177, 0.22306537628173828, 0.23383641242980957, 0.24460738897323608, 0.2553784251213074, 0.26614946126937866, 0.2769204378128052, 0.28769147396087646, 0.29846251010894775, 0.30923348665237427, 0.32000452280044556, 0.33077555894851685, 0.34154653549194336, 0.35231757164001465, 0.36308860778808594, 0.37385958433151245, 0.38463062047958374]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 4.0, 5.0, 0.0, 0.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0], "bins": [-0.5963585376739502, -0.5547700524330139, -0.5131815671920776, -0.47159308195114136, -0.4300045967102051, -0.3884161114692688, -0.3468276262283325, -0.30523914098739624, -0.26365065574645996, -0.22206217050552368, -0.1804736852645874, -0.13888520002365112, -0.09729671478271484, -0.055708229541778564, -0.014119744300842285, 0.027468740940093994, 0.06905722618103027, 0.11064571142196655, 0.15223419666290283, 0.1938226819038391, 0.2354111671447754, 0.27699965238571167, 0.31858813762664795, 0.36017662286758423, 0.4017651081085205, 0.44335365295410156, 0.48494207859039307, 0.5265305042266846, 0.5681190490722656, 0.6097075939178467, 0.6512960195541382, 0.6928844451904297, 0.7344729900360107, 0.7760615348815918, 0.8176499605178833, 0.8592383861541748, 0.9008269309997559, 0.9424154758453369, 0.9840039014816284, 1.02559232711792, 1.067180871963501, 1.108769416809082, 1.1503578424453735, 1.191946268081665, 1.233534812927246, 1.2751233577728271, 1.3167117834091187, 1.3583002090454102, 1.3998887538909912, 1.4414772987365723, 1.4830658435821533, 1.5246541500091553, 1.5662426948547363, 1.6078312397003174, 1.6494195461273193, 1.6910080909729004, 1.7325966358184814, 1.7741851806640625, 1.8157737255096436, 1.8573620319366455, 1.8989505767822266, 1.9405391216278076, 1.9821274280548096, 2.0237159729003906, 2.0653045177459717]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 6.0, 7.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], "bins": [-0.3737853765487671, -0.3665487468242645, -0.35931214690208435, -0.3520755171775818, -0.3448389172554016, -0.33760228753089905, -0.33036568760871887, -0.3231290578842163, -0.31589245796203613, -0.30865582823753357, -0.301419198513031, -0.29418259859085083, -0.28694596886634827, -0.2797093689441681, -0.2724727392196655, -0.26523613929748535, -0.2579995095729828, -0.2507628798484802, -0.24352627992630005, -0.23628966510295868, -0.2290530502796173, -0.22181642055511475, -0.21457980573177338, -0.207343190908432, -0.20010657608509064, -0.19286996126174927, -0.1856333464384079, -0.17839673161506653, -0.17116010189056396, -0.1639234870672226, -0.15668687224388123, -0.14945025742053986, -0.1422136425971985, -0.13497702777385712, -0.12774041295051575, -0.12050378322601318, -0.11326718330383301, -0.10603055357933044, -0.09879395365715027, -0.0915573239326477, -0.08432072401046753, -0.07708409428596497, -0.0698474645614624, -0.06261086463928223, -0.05537423491477966, -0.04813763499259949, -0.040901005268096924, -0.03366440534591675, -0.026427775621414185, -0.01919114589691162, -0.011954545974731445, -0.004717916250228882, 0.002518683671951294, 0.009755313396453857, 0.016991913318634033, 0.024228543043136597, 0.03146517276763916, 0.038701772689819336, 0.0459384024143219, 0.053175002336502075, 0.06041163206100464, 0.06764823198318481, 0.07488486170768738, 0.08212146162986755, 0.08935809135437012]}, "_runtime": 13475.904463529587, "_timestamp": 1585610845.537333, "_step": 98}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 4.875449180603027, "Value Loss": 14.340374946594238, "_runtime": 13477.460979700089, "_timestamp": 1585610847.0938492, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.6495206356048584, "Value Loss": 0.17335474491119385, "_runtime": 13478.128304243088, "_timestamp": 1585610847.7611737, "_step": 100}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 5.794808864593506, "Value Loss": 25.003068923950195, "_runtime": 13479.672968149185, "_timestamp": 1585610849.3058376, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.5893452167510986, "Value Loss": 0.16585205495357513, "_runtime": 13480.60343670845, "_timestamp": 1585610850.2363062, "_step": 102}
{"Episode reward": 41.59999999999945, "Episode length": 584, "Policy Loss": 5.209514617919922, "Value Loss": 17.423416137695312, "_runtime": 13482.121259212494, "_timestamp": 1585610851.7541287, "_step": 103}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.4855289459228516, "Value Loss": 0.15856701135635376, "_runtime": 13482.925592184067, "_timestamp": 1585610852.5584617, "_step": 104}
{"Episode reward": 50.19999999999957, "Episode length": 498, "Policy Loss": 5.261841773986816, "Value Loss": 20.393524169921875, "_runtime": 13484.475145339966, "_timestamp": 1585610854.1080148, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.4272756576538086, "Value Loss": 0.15152281522750854, "_runtime": 13485.30926823616, "_timestamp": 1585610854.9421377, "_step": 106}
{"Episode reward": 47.59999999999953, "Episode length": 524, "Policy Loss": 4.963049411773682, "Value Loss": 19.378995895385742, "_runtime": 13486.181057214737, "_timestamp": 1585610855.8139267, "_step": 107}
{"Episode reward": 43.29999999999947, "Episode length": 567, "Policy Loss": 4.7993083000183105, "Value Loss": 17.915555953979492, "_runtime": 13487.748596429825, "_timestamp": 1585610857.381466, "_step": 108}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.3102729320526123, "Value Loss": 0.1413096934556961, "_runtime": 13488.455323457718, "_timestamp": 1585610858.088193, "_step": 109}
{"Episode reward": 54.899999999999636, "Episode length": 451, "Policy Loss": 5.129835605621338, "Value Loss": 22.47574234008789, "_runtime": 13489.075049638748, "_timestamp": 1585610858.7079191, "_step": 110}
{"Episode reward": 59.5999999999997, "Episode length": 404, "Policy Loss": 5.267836093902588, "Value Loss": 25.068946838378906, "_runtime": 13490.641605854034, "_timestamp": 1585610860.2744753, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.1795990467071533, "Value Loss": 0.13143056631088257, "_runtime": 13492.08243894577, "_timestamp": 1585610861.7153084, "_step": 112}
{"Episode reward": 5.100000000001117, "Episode length": 949, "Policy Loss": 4.001234531402588, "Value Loss": 10.74111557006836, "_runtime": 13492.852832317352, "_timestamp": 1585610862.4857018, "_step": 113}
{"Episode reward": 50.128870336710975, "Episode length": 499, "Policy Loss": 5.077273845672607, "Value Loss": 20.307022094726562, "_runtime": 13493.967999219894, "_timestamp": 1585610863.6008687, "_step": 114}
{"Episode reward": 29.099999999999753, "Episode length": 709, "Policy Loss": 4.315446376800537, "Value Loss": 14.324922561645508, "_runtime": 13495.52383685112, "_timestamp": 1585610865.1567063, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 3.0367884635925293, "Value Loss": 0.11894159764051437, "_runtime": 13496.649977445602, "_timestamp": 1585610866.282847, "_step": 116}
{"Episode reward": 26.615217088162794, "Episode length": 734, "Policy Loss": 4.141110897064209, "Value Loss": 13.832815170288086, "_runtime": 13498.234719276428, "_timestamp": 1585610867.8675888, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.960786819458008, "Value Loss": 0.11309245973825455, "_runtime": 13499.81745505333, "_timestamp": 1585610869.4503245, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.9288599491119385, "Value Loss": 0.11030302196741104, "_runtime": 13501.35153889656, "_timestamp": 1585610870.9844084, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8637869358062744, "Value Loss": 0.10762597620487213, "_runtime": 13502.940505027771, "_timestamp": 1585610872.5733745, "_step": 120}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.8358421325683594, "Value Loss": 0.10504607111215591, "_runtime": 13504.067746400833, "_timestamp": 1585610873.700616, "_step": 121}
{"Episode reward": 29.274013900756586, "Episode length": 708, "Policy Loss": 3.985281467437744, "Value Loss": 14.317395210266113, "_runtime": 13504.687066555023, "_timestamp": 1585610874.319936, "_step": 122}
{"Episode reward": 62.79999999999975, "Episode length": 372, "Policy Loss": 5.019667625427246, "Value Loss": 27.151844024658203, "_runtime": 13506.250055551529, "_timestamp": 1585610875.882925, "_step": 123}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.7464957237243652, "Value Loss": 0.09755375981330872, "_runtime": 13506.748563051224, "_timestamp": 1585610876.3814325, "_step": 124}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 5.531826972961426, "Value Loss": 33.7462272644043, "_runtime": 13508.267485141754, "_timestamp": 1585610877.9003546, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.6738452911376953, "Value Loss": 0.09261149168014526, "_runtime": 13509.844771623611, "_timestamp": 1585610879.477641, "_step": 126}
{"Episode reward": -99.86198294497886, "Episode length": 999, "Policy Loss": 2.631453514099121, "Value Loss": 0.09023451805114746, "_runtime": 13511.344584703445, "_timestamp": 1585610880.9774542, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.609574794769287, "Value Loss": 0.08790840208530426, "_runtime": 13512.918194055557, "_timestamp": 1585610882.5510635, "_step": 128}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.568086624145508, "Value Loss": 0.08569660782814026, "_runtime": 13513.817040681839, "_timestamp": 1585610883.4499102, "_step": 129}
{"Episode reward": 44.48540148138949, "Episode length": 556, "Policy Loss": 4.039174556732178, "Value Loss": 18.173294067382812, "_runtime": 13515.375879764557, "_timestamp": 1585610885.0087492, "_step": 130}
{"Episode reward": -99.80811053663352, "Episode length": 999, "Policy Loss": 2.508254289627075, "Value Loss": 0.08149689435958862, "_runtime": 13516.43836760521, "_timestamp": 1585610886.071237, "_step": 131}
{"Episode reward": 33.19999999999952, "Episode length": 668, "Policy Loss": 3.754138231277466, "Value Loss": 15.133780479431152, "_runtime": 13517.9708173275, "_timestamp": 1585610887.6036868, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4391465187072754, "Value Loss": 0.07733702659606934, "_runtime": 13519.545540571213, "_timestamp": 1585610889.17841, "_step": 133}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.4058218002319336, "Value Loss": 0.07537218928337097, "_runtime": 13520.38093996048, "_timestamp": 1585610890.0138094, "_step": 134}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 3.9662630558013916, "Value Loss": 19.00796127319336, "_runtime": 13521.995235681534, "_timestamp": 1585610891.6281052, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.3545398712158203, "Value Loss": 0.07157150655984879, "_runtime": 13523.571523427963, "_timestamp": 1585610893.204393, "_step": 136}
{"Episode reward": -99.84230079650739, "Episode length": 999, "Policy Loss": 2.3207712173461914, "Value Loss": 0.06977212429046631, "_runtime": 13525.099597215652, "_timestamp": 1585610894.7324667, "_step": 137}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2904651165008545, "Value Loss": 0.06797657161951065, "_runtime": 13526.6745865345, "_timestamp": 1585610896.307456, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2581992149353027, "Value Loss": 0.06627856940031052, "_runtime": 13528.251705408096, "_timestamp": 1585610897.884575, "_step": 139}
{"Episode reward": -99.81541655100743, "Episode length": 999, "Policy Loss": 2.2461163997650146, "Value Loss": 0.06469309329986572, "_runtime": 13529.822286844254, "_timestamp": 1585610899.4551563, "_step": 140}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.2141289710998535, "Value Loss": 0.06306585669517517, "_runtime": 13531.284703016281, "_timestamp": 1585610900.9175725, "_step": 141}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": 3.088447093963623, "Value Loss": 10.98503303527832, "_runtime": 13532.864429473877, "_timestamp": 1585610902.497299, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.149127960205078, "Value Loss": 0.06001327186822891, "_runtime": 13534.442262649536, "_timestamp": 1585610904.0751321, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1332223415374756, "Value Loss": 0.05854211747646332, "_runtime": 13536.019425868988, "_timestamp": 1585610905.6522954, "_step": 144}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.097074270248413, "Value Loss": 0.05711841210722923, "_runtime": 13537.594383239746, "_timestamp": 1585610907.2272527, "_step": 145}
{"Episode reward": -99.80103149413922, "Episode length": 999, "Policy Loss": 2.0753109455108643, "Value Loss": 0.05579764023423195, "_runtime": 13538.409924030304, "_timestamp": 1585610908.0427935, "_step": 146}
{"Episode reward": 49.29999999999956, "Episode length": 507, "Policy Loss": 3.671173572540283, "Value Loss": 19.870311737060547, "_runtime": 13539.990589380264, "_timestamp": 1585610909.6234589, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0305495262145996, "Value Loss": 0.05302798002958298, "_runtime": 13541.569013357162, "_timestamp": 1585610911.2018828, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.0062806606292725, "Value Loss": 0.05169769003987312, "_runtime": 13542.996867656708, "_timestamp": 1585610912.6297371, "_step": 149}
{"Episode reward": 6.833294018731536, "Episode length": 933, "Policy Loss": 3.6809682846069336, "Value Loss": 10.81674575805664, "_runtime": 13543.6269800663, "_timestamp": 1585610913.2598495, "_step": 150}
{"Episode reward": 62.29999999999974, "Episode length": 377, "Policy Loss": 4.216808795928955, "Value Loss": 26.691869735717773, "_runtime": 13544.744140386581, "_timestamp": 1585610914.3770099, "_step": 151}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 3.636024236679077, "Value Loss": 14.731568336486816, "_runtime": 13546.298137664795, "_timestamp": 1585610915.9310071, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.8996806144714355, "Value Loss": 0.04641880840063095, "_runtime": 13547.319483041763, "_timestamp": 1585610916.9523525, "_step": 153}
{"Episode reward": 32.72350157350256, "Episode length": 673, "Policy Loss": 3.16943097114563, "Value Loss": 14.967536926269531, "_runtime": 13547.924242258072, "_timestamp": 1585610917.5571117, "_step": 154}
{"Episode reward": 62.48123138993953, "Episode length": 376, "Policy Loss": 4.049872875213623, "Value Loss": 26.75103187561035, "_runtime": 13549.178623914719, "_timestamp": 1585610918.8114934, "_step": 155}
{"Episode reward": 19.700000000000287, "Episode length": 803, "Policy Loss": 3.3000881671905518, "Value Loss": 22.316783905029297, "_runtime": 13550.555746793747, "_timestamp": 1585610920.1886163, "_step": 156}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": 2.8055598735809326, "Value Loss": 11.209712982177734, "_runtime": 13552.062664031982, "_timestamp": 1585610921.6955335, "_step": 157}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7546995878219604, "Value Loss": 0.03981131315231323, "_runtime": 13553.618059396744, "_timestamp": 1585610923.2509289, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7199960947036743, "Value Loss": 0.0385623462498188, "_runtime": 13554.369913339615, "_timestamp": 1585610924.0027828, "_step": 159}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 3.46107816696167, "Value Loss": 21.441762924194336, "_runtime": 13555.924401521683, "_timestamp": 1585610925.557271, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.673710823059082, "Value Loss": 0.036171264946460724, "_runtime": 13557.503777265549, "_timestamp": 1585610927.1366467, "_step": 161}
{"Episode reward": -99.89375307559827, "Episode length": 999, "Policy Loss": 1.6452486515045166, "Value Loss": 0.03503214940428734, "_runtime": 13558.684801101685, "_timestamp": 1585610928.3176706, "_step": 162}
{"Episode reward": 22.507472133636597, "Episode length": 775, "Policy Loss": 2.7149055004119873, "Value Loss": 12.984731674194336, "_runtime": 13560.248786211014, "_timestamp": 1585610929.8816557, "_step": 163}
{"Episode reward": -99.72279672771553, "Episode length": 999, "Policy Loss": 1.5974717140197754, "Value Loss": 0.03294947370886803, "_runtime": 13561.789048910141, "_timestamp": 1585610931.4219184, "_step": 164}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": 2.480107069015503, "Value Loss": 10.293314933776855, "_runtime": 13563.156236410141, "_timestamp": 1585610932.789106, "_step": 165}
{"Episode reward": 11.20000000000077, "Episode length": 888, "Policy Loss": 2.487633466720581, "Value Loss": 11.331681251525879, "_runtime": 13564.73080587387, "_timestamp": 1585610934.3636754, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.5269972085952759, "Value Loss": 0.029847992584109306, "_runtime": 13566.299339532852, "_timestamp": 1585610935.932209, "_step": 167}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4885540008544922, "Value Loss": 0.028905224055051804, "_runtime": 13567.85292840004, "_timestamp": 1585610937.485798, "_step": 168}
{"Episode reward": -99.85652499347786, "Episode length": 999, "Policy Loss": 1.474236011505127, "Value Loss": 0.028026573359966278, "_runtime": 13569.455261945724, "_timestamp": 1585610939.0881314, "_step": 169}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4479048252105713, "Value Loss": 0.02715800702571869, "_runtime": 13570.698973178864, "_timestamp": 1585610940.3318427, "_step": 170}
{"Episode reward": 21.000000000000213, "Episode length": 790, "Policy Loss": 2.471344470977783, "Value Loss": 12.725667953491211, "_runtime": 13572.269121170044, "_timestamp": 1585610941.9019907, "_step": 171}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.4002028703689575, "Value Loss": 0.025529801845550537, "_runtime": 13573.84884929657, "_timestamp": 1585610943.4817188, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3833141326904297, "Value Loss": 0.02475259266793728, "_runtime": 13575.413619279861, "_timestamp": 1585610945.0464888, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3592180013656616, "Value Loss": 0.02401161380112171, "_runtime": 13576.982738494873, "_timestamp": 1585610946.615608, "_step": 174}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3462135791778564, "Value Loss": 0.023303451016545296, "_runtime": 13578.545784950256, "_timestamp": 1585610948.1786544, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.3270554542541504, "Value Loss": 0.022626522928476334, "_runtime": 13580.116576910019, "_timestamp": 1585610949.7494464, "_step": 176}
{"Episode reward": -99.80398341566185, "Episode length": 999, "Policy Loss": 1.30570387840271, "Value Loss": 0.022015396505594254, "_runtime": 13581.674663305283, "_timestamp": 1585610951.3075328, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2864664793014526, "Value Loss": 0.021354973316192627, "_runtime": 13583.24127149582, "_timestamp": 1585610952.874141, "_step": 178}
{"Episode reward": -99.85224085002997, "Episode length": 999, "Policy Loss": 1.2694364786148071, "Value Loss": 0.02077323943376541, "_runtime": 13584.815031766891, "_timestamp": 1585610954.4479012, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2507359981536865, "Value Loss": 0.020182479172945023, "_runtime": 13586.383541345596, "_timestamp": 1585610956.0164108, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2350246906280518, "Value Loss": 0.019628679379820824, "_runtime": 13587.9514336586, "_timestamp": 1585610957.5843031, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.215938687324524, "Value Loss": 0.01909470371901989, "_runtime": 13589.521212100983, "_timestamp": 1585610959.1540816, "_step": 182}
{"Episode reward": -99.8040470123277, "Episode length": 999, "Policy Loss": 1.20381498336792, "Value Loss": 0.018614938482642174, "_runtime": 13591.06268787384, "_timestamp": 1585610960.6955574, "_step": 183}
{"Episode reward": 2.000000000001293, "Episode length": 980, "Policy Loss": 2.159545660018921, "Value Loss": 10.249629974365234, "_runtime": 13592.671917676926, "_timestamp": 1585610962.3047872, "_step": 184}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1587183475494385, "Value Loss": 0.017572343349456787, "_runtime": 13593.301720142365, "_timestamp": 1585610962.9345896, "_step": 185}
{"Episode reward": 62.19999999999974, "Episode length": 378, "Policy Loss": 3.3445279598236084, "Value Loss": 26.541221618652344, "_runtime": 13594.87422657013, "_timestamp": 1585610964.507096, "_step": 186}
{"Episode reward": -99.80137043148139, "Episode length": 999, "Policy Loss": 1.1349552869796753, "Value Loss": 0.01657288521528244, "_runtime": 13596.452121257782, "_timestamp": 1585610966.0849907, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.1138986349105835, "Value Loss": 0.016019415110349655, "_runtime": 13597.97046327591, "_timestamp": 1585610967.6033328, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0961202383041382, "Value Loss": 0.01552501879632473, "_runtime": 13599.545874118805, "_timestamp": 1585610969.1787436, "_step": 189}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0771108865737915, "Value Loss": 0.015052885748445988, "_runtime": 13601.11452126503, "_timestamp": 1585610970.7473907, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.062025547027588, "Value Loss": 0.014600935392081738, "_runtime": 13602.679769039154, "_timestamp": 1585610972.3126385, "_step": 191}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.0471551418304443, "Value Loss": 0.01416813861578703, "_runtime": 13602.949221611023, "_timestamp": 1585610972.582091, "_step": 192}
{"Episode reward": 87.60000000000004, "Episode length": 124, "Policy Loss": 7.69514274597168, "Value Loss": 80.84805297851562, "_runtime": 13604.519863843918, "_timestamp": 1585610974.1527333, "_step": 193}
{"Episode reward": -99.80861886888603, "Episode length": 999, "Policy Loss": 1.0126349925994873, "Value Loss": 0.013186824508011341, "_runtime": 13605.646487951279, "_timestamp": 1585610975.2793574, "_step": 194}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 2.1483709812164307, "Value Loss": 14.188639640808105, "_runtime": 13607.154636383057, "_timestamp": 1585610976.7875059, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.964121401309967, "Value Loss": 0.012053605169057846, "_runtime": 13608.759148836136, "_timestamp": 1585610978.3920183, "_step": 196}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.9409053325653076, "Value Loss": 0.011542733758687973, "_runtime": 13609.87103509903, "_timestamp": 1585610979.5039046, "_step": 197}
{"Episode reward": 29.279299992322663, "Episode length": 709, "Policy Loss": 2.093404531478882, "Value Loss": 14.14517879486084, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864, 0.04412977397441864]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-0.0442998968064785, 0.0521906279027462, 0.1486811488866806, 0.2451716661453247, 0.34166219830513, 0.4381527304649353, 0.5346432328224182, 0.6311337947845459, 0.7276242971420288, 0.8241147994995117, 0.9206053614616394, 1.017095923423767, 1.11358642578125, 1.210076928138733, 1.3065675497055054, 1.4030580520629883, 1.4995485544204712, 1.596039056777954, 1.692529559135437, 1.7890201807022095, 1.8855106830596924, 1.9820010662078857, 2.078491687774658, 2.1749823093414307, 2.271472692489624, 2.3679633140563965, 2.46445369720459, 2.5609443187713623, 2.6574349403381348, 2.753925323486328, 2.8504159450531006, 2.946906328201294, 3.0433969497680664, 3.139887571334839, 3.2363779544830322, 3.3328685760498047, 3.429358959197998, 3.5258495807647705, 3.622340202331543, 3.7188305854797363, 3.815321207046509, 3.911811590194702, 4.008301734924316, 4.104792594909668, 4.201282978057861, 4.297773361206055, 4.394264221191406, 4.4907546043396, 4.587244987487793, 4.6837358474731445, 4.780226230621338, 4.876716613769531, 4.973206996917725, 5.069697856903076, 5.1661882400512695, 5.262678623199463, 5.3591694831848145, 5.455659866333008, 5.552150249481201, 5.648641109466553, 5.745131492614746, 5.8416218757629395, 5.938112258911133, 6.034603118896484, 6.131093502044678]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.10392794013023376, -0.10030844062566757, -0.09668894112110138, -0.09306943416595459, -0.0894499346613884, -0.0858304351568222, -0.08221093565225601, -0.07859143614768982, -0.07497192919254303, -0.07135242968797684, -0.06773293018341064, -0.06411342322826385, -0.06049392744898796, -0.05687442421913147, -0.05325492471456528, -0.049635421484708786, -0.04601592198014259, -0.0423964224755764, -0.03877691924571991, -0.03515741974115372, -0.031537920236587524, -0.027918413281440735, -0.024298913776874542, -0.02067941427230835, -0.017059914767742157, -0.013440415263175964, -0.009820908308029175, -0.006201408803462982, -0.0025819092988967896, 0.001037590205669403, 0.004657097160816193, 0.008276596665382385, 0.011896096169948578, 0.01551559567451477, 0.019135095179080963, 0.022754594683647156, 0.026374101638793945, 0.029993608593940735, 0.03361310064792633, 0.03723260760307312, 0.040852099657058716, 0.044471606612205505, 0.048091113567352295, 0.05171060562133789, 0.05533011257648468, 0.058949604630470276, 0.06256911158561707, 0.06618861854076385, 0.06980811059474945, 0.07342761754989624, 0.07704710960388184, 0.08066661655902863, 0.08428612351417542, 0.08790561556816101, 0.0915251225233078, 0.09514462947845459, 0.09876412153244019, 0.10238362848758698, 0.10600312054157257, 0.10962262749671936, 0.11324213445186615, 0.11686162650585175, 0.12048113346099854, 0.12410062551498413, 0.12772013247013092]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 4.0, 5.0, 30.0, 19.0, 42.0, 20.0, 16.0, 0.0, 0.0, 224.0, 0.0, 0.0, 1.0, 14.0, 26.0, 33.0, 5.0, 9.0, 1.0, 4.0, 6.0, 2.0, 3.0, 4.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], "bins": [-0.4660491943359375, -0.4497355818748474, -0.4334219992160797, -0.4171083867549896, -0.40079477429389954, -0.38448119163513184, -0.36816757917404175, -0.35185396671295166, -0.3355403542518616, -0.31922677159309387, -0.3029131591320038, -0.2865995764732361, -0.270285964012146, -0.2539723515510559, -0.23765875399112701, -0.22134514153003693, -0.20503154397010803, -0.18871793150901794, -0.17240434885025024, -0.15609073638916016, -0.13977712392807007, -0.12346354126930237, -0.10714992880821228, -0.09083631634712219, -0.07452273368835449, -0.058209121227264404, -0.041895508766174316, -0.02558189630508423, -0.009268313646316528, 0.00704529881477356, 0.023358911275863647, 0.03967249393463135, 0.055986106395721436, 0.07229971885681152, 0.08861333131790161, 0.1049269437789917, 0.12124049663543701, 0.1375541090965271, 0.1538677215576172, 0.17018133401870728, 0.18649494647979736, 0.20280855894088745, 0.21912211179733276, 0.23543572425842285, 0.25174933671951294, 0.268062949180603, 0.2843765616416931, 0.3006901741027832, 0.3170037269592285, 0.3333173394203186, 0.3496309518814087, 0.3659445643424988, 0.38225817680358887, 0.39857178926467896, 0.41488540172576904, 0.43119895458221436, 0.44751256704330444, 0.46382617950439453, 0.4801397919654846, 0.4964534044265747, 0.5127670168876648, 0.5290805697441101, 0.5453941822052002, 0.5617078542709351, 0.5780214071273804]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.6933978199958801, -0.6445460915565491, -0.5956944227218628, -0.5468426942825317, -0.49799099564552307, -0.4491392970085144, -0.40028756856918335, -0.3514358699321747, -0.302584171295166, -0.25373247265815735, -0.20488077402114868, -0.15602904558181763, -0.10717731714248657, -0.05832564830780029, -0.009473919868469238, 0.03937774896621704, 0.0882294774055481, 0.13708120584487915, 0.18593287467956543, 0.23478460311889648, 0.28363627195358276, 0.3324880003929138, 0.3813397288322449, 0.4301914572715759, 0.479043185710907, 0.5278947949409485, 0.5767465233802795, 0.6255982518196106, 0.6744499802589417, 0.7233017086982727, 0.7721533179283142, 0.8210050463676453, 0.8698567748069763, 0.9187085032463074, 0.9675602316856384, 1.0164117813110352, 1.0652635097503662, 1.1141152381896973, 1.1629669666290283, 1.2118186950683594, 1.2606704235076904, 1.3095221519470215, 1.3583738803863525, 1.4072256088256836, 1.4560773372650146, 1.5049290657043457, 1.5537807941436768, 1.6026325225830078, 1.6514842510223389, 1.7003357410430908, 1.7491874694824219, 1.798039197921753, 1.846890926361084, 1.895742654800415, 1.944594383239746, 1.9934461116790771, 2.042297840118408, 2.0911495685577393, 2.1400012969970703, 2.1888527870178223, 2.2377045154571533, 2.2865562438964844, 2.3354079723358154, 2.3842597007751465, 2.4331114292144775]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 8.0, 10.0, 17.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.0502212047576904, -1.0292750597000122, -1.008328914642334, -0.9873827695846558, -0.9664366245269775, -0.9454904794692993, -0.9245443344116211, -0.9035981893539429, -0.8826520442962646, -0.8617058992385864, -0.8407597541809082, -0.8198135495185852, -0.798867404460907, -0.7779212594032288, -0.7569751143455505, -0.7360289692878723, -0.7150828242301941, -0.6941366791725159, -0.6731905341148376, -0.6522443890571594, -0.6312982439994812, -0.6103520393371582, -0.58940589427948, -0.5684597492218018, -0.5475136041641235, -0.5265674591064453, -0.5056213140487671, -0.48467516899108887, -0.46372902393341064, -0.4427828788757324, -0.4218367338180542, -0.400890588760376, -0.37994444370269775, -0.35899829864501953, -0.3380521535873413, -0.3171060085296631, -0.29615986347198486, -0.27521371841430664, -0.2542675733566284, -0.2333214282989502, -0.21237528324127197, -0.19142907857894897, -0.17048293352127075, -0.14953678846359253, -0.1285906434059143, -0.10764449834823608, -0.08669835329055786, -0.06575220823287964, -0.04480600357055664, -0.023859858512878418, -0.0029137134552001953, 0.018032431602478027, 0.03897857666015625, 0.05992472171783447, 0.0808708667755127, 0.10181701183319092, 0.12276315689086914, 0.14370930194854736, 0.16465544700622559, 0.1856015920639038, 0.20654773712158203, 0.22749388217926025, 0.24844002723693848, 0.2693861722946167, 0.2903323173522949]}, "_runtime": 13610.48911523819, "_timestamp": 1585610980.1219847, "_step": 198}
{"Episode reward": 61.899999999999736, "Episode length": 381, "Policy Loss": 3.2800374031066895, "Value Loss": 26.311344146728516, "_runtime": 13612.067951440811, "_timestamp": 1585610981.700821, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8816491365432739, "Value Loss": 0.010089922696352005, "_runtime": 13613.612189292908, "_timestamp": 1585610983.2450588, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8613181114196777, "Value Loss": 0.009627108462154865, "_runtime": 13615.162542819977, "_timestamp": 1585610984.7954123, "_step": 201}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.8440108299255371, "Value Loss": 0.009198191575706005, "_runtime": 13616.745160341263, "_timestamp": 1585610986.3780298, "_step": 202}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": 1.6669412851333618, "Value Loss": 10.047636985778809, "_runtime": 13618.316689491272, "_timestamp": 1585610987.949559, "_step": 203}
{"Episode reward": -99.80000518709281, "Episode length": 999, "Policy Loss": 0.8078789114952087, "Value Loss": 0.00843717996031046, "_runtime": 13619.859069347382, "_timestamp": 1585610989.4919388, "_step": 204}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7891197800636292, "Value Loss": 0.008045192807912827, "_runtime": 13621.436700344086, "_timestamp": 1585610991.0695698, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7686284780502319, "Value Loss": 0.007706668693572283, "_runtime": 13621.880982875824, "_timestamp": 1585610991.5138524, "_step": 206}
{"Episode reward": 75.09999999999992, "Episode length": 249, "Policy Loss": 4.0618486404418945, "Value Loss": 40.237144470214844, "_runtime": 13623.442595720291, "_timestamp": 1585610993.0754652, "_step": 207}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.7356747984886169, "Value Loss": 0.007020739838480949, "_runtime": 13624.8364944458, "_timestamp": 1585610994.469364, "_step": 208}
{"Episode reward": 12.300000000000708, "Episode length": 877, "Policy Loss": 1.6960750818252563, "Value Loss": 11.427836418151855, "_runtime": 13626.178413391113, "_timestamp": 1585610995.8112829, "_step": 209}
{"Episode reward": 10.600000000000804, "Episode length": 894, "Policy Loss": 1.6143279075622559, "Value Loss": 11.209817886352539, "_runtime": 13627.74525141716, "_timestamp": 1585610997.378121, "_step": 210}
{"Episode reward": -99.83131189346173, "Episode length": 999, "Policy Loss": 0.6827096343040466, "Value Loss": 0.00603159936144948, "_runtime": 13628.688544511795, "_timestamp": 1585610998.321414, "_step": 211}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 2.092163562774658, "Value Loss": 16.64212989807129, "_runtime": 13629.99866104126, "_timestamp": 1585610999.6315305, "_step": 212}
{"Episode reward": 15.60000000000052, "Episode length": 844, "Policy Loss": 1.625102162361145, "Value Loss": 11.871195793151855, "_runtime": 13631.04468870163, "_timestamp": 1585611000.6775582, "_step": 213}
{"Episode reward": 34.10087473839468, "Episode length": 660, "Policy Loss": 1.8965659141540527, "Value Loss": 15.178311347961426, "_runtime": 13632.580434322357, "_timestamp": 1585611002.2133038, "_step": 214}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.607306182384491, "Value Loss": 0.004810647573322058, "_runtime": 13634.128370761871, "_timestamp": 1585611003.7612402, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5932595133781433, "Value Loss": 0.00453890161588788, "_runtime": 13635.66358923912, "_timestamp": 1585611005.2964587, "_step": 216}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5758280158042908, "Value Loss": 0.004290535114705563, "_runtime": 13636.907459974289, "_timestamp": 1585611006.5403295, "_step": 217}
{"Episode reward": 20.799733375013105, "Episode length": 793, "Policy Loss": 1.6410224437713623, "Value Loss": 12.630496978759766, "_runtime": 13637.92173910141, "_timestamp": 1585611007.5546086, "_step": 218}
{"Episode reward": 36.09999999999937, "Episode length": 639, "Policy Loss": 1.8920621871948242, "Value Loss": 15.672683715820312, "_runtime": 13639.452267169952, "_timestamp": 1585611009.0851367, "_step": 219}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": 1.394673228263855, "Value Loss": 10.520439147949219, "_runtime": 13641.0071413517, "_timestamp": 1585611010.6400108, "_step": 220}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5146274566650391, "Value Loss": 0.0033838972449302673, "_runtime": 13642.545889377594, "_timestamp": 1585611012.1787589, "_step": 221}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.49624913930892944, "Value Loss": 0.0031814253889024258, "_runtime": 13643.934401035309, "_timestamp": 1585611013.5672705, "_step": 222}
{"Episode reward": 11.20000000000077, "Episode length": 888, "Policy Loss": 1.4701424837112427, "Value Loss": 11.276582717895508, "_runtime": 13645.497891187668, "_timestamp": 1585611015.1307607, "_step": 223}
{"Episode reward": -99.7681213632212, "Episode length": 999, "Policy Loss": 0.4655795991420746, "Value Loss": 0.002839131513610482, "_runtime": 13646.624503135681, "_timestamp": 1585611016.2573726, "_step": 224}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": 1.6057077646255493, "Value Loss": 14.062067031860352, "_runtime": 13648.176326751709, "_timestamp": 1585611017.8091962, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4394850432872772, "Value Loss": 0.0024818384554237127, "_runtime": 13649.754829645157, "_timestamp": 1585611019.3876991, "_step": 226}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.42485618591308594, "Value Loss": 0.0023300154134631157, "_runtime": 13651.296601772308, "_timestamp": 1585611020.9294713, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.41013103723526, "Value Loss": 0.0021918145939707756, "_runtime": 13652.86881327629, "_timestamp": 1585611022.5016828, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.401075541973114, "Value Loss": 0.0020658085122704506, "_runtime": 13654.450662851334, "_timestamp": 1585611024.0835323, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.39067867398262024, "Value Loss": 0.0019506022799760103, "_runtime": 13656.025403022766, "_timestamp": 1585611025.6582725, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3764576315879822, "Value Loss": 0.0018450022907927632, "_runtime": 13657.593259811401, "_timestamp": 1585611027.2261293, "_step": 231}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3678359091281891, "Value Loss": 0.001748078502714634, "_runtime": 13659.096882104874, "_timestamp": 1585611028.7297516, "_step": 232}
{"Episode reward": 5.200000000001111, "Episode length": 948, "Policy Loss": 1.2578585147857666, "Value Loss": 10.55879020690918, "_runtime": 13659.71787929535, "_timestamp": 1585611029.3507488, "_step": 233}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 2.5716605186462402, "Value Loss": 26.832481384277344, "_runtime": 13661.284310102463, "_timestamp": 1585611030.9171796, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.33575138449668884, "Value Loss": 0.0014579581329599023, "_runtime": 13662.90193104744, "_timestamp": 1585611032.5348005, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.32457298040390015, "Value Loss": 0.0013598193181678653, "_runtime": 13664.412336826324, "_timestamp": 1585611034.0452063, "_step": 236}
{"Episode reward": -99.8092388689504, "Episode length": 999, "Policy Loss": 0.3147403597831726, "Value Loss": 0.0012858009431511164, "_runtime": 13665.613551616669, "_timestamp": 1585611035.246421, "_step": 237}
{"Episode reward": 24.20000000000003, "Episode length": 758, "Policy Loss": 1.3967496156692505, "Value Loss": 13.202893257141113, "_runtime": 13667.192702293396, "_timestamp": 1585611036.8255718, "_step": 238}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2926647365093231, "Value Loss": 0.0011070758337154984, "_runtime": 13668.744374752045, "_timestamp": 1585611038.3772442, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.2819674015045166, "Value Loss": 0.001031678169965744, "_runtime": 13670.27248954773, "_timestamp": 1585611039.905359, "_step": 240}
{"Episode reward": 1.5000000000013216, "Episode length": 985, "Policy Loss": 1.1204122304916382, "Value Loss": 10.159549713134766, "_runtime": 13671.746960878372, "_timestamp": 1585611041.3798304, "_step": 241}
{"Episode reward": 7.100000000001003, "Episode length": 929, "Policy Loss": 1.1766438484191895, "Value Loss": 10.771597862243652, "_runtime": 13672.940221071243, "_timestamp": 1585611042.5730906, "_step": 242}
{"Episode reward": 23.70000000000006, "Episode length": 763, "Policy Loss": 1.3393672704696655, "Value Loss": 13.114526748657227, "_runtime": 13674.510467290878, "_timestamp": 1585611044.1433368, "_step": 243}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.24119266867637634, "Value Loss": 0.0007541092927567661, "_runtime": 13676.0899143219, "_timestamp": 1585611045.7227838, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23144088685512543, "Value Loss": 0.0006910605588927865, "_runtime": 13677.624905109406, "_timestamp": 1585611047.2577746, "_step": 245}
{"Episode reward": -99.80160242467979, "Episode length": 999, "Policy Loss": 0.22353360056877136, "Value Loss": 0.0006496421410702169, "_runtime": 13679.178900003433, "_timestamp": 1585611048.8117695, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.21317452192306519, "Value Loss": 0.0005849226145073771, "_runtime": 13680.485398054123, "_timestamp": 1585611050.1182675, "_step": 247}
{"Episode reward": 17.100000000000435, "Episode length": 829, "Policy Loss": 1.209679365158081, "Value Loss": 12.068900108337402, "_runtime": 13681.637868404388, "_timestamp": 1585611051.270738, "_step": 248}
{"Episode reward": 27.085790634155146, "Episode length": 730, "Policy Loss": 1.334128975868225, "Value Loss": 13.705253601074219, "_runtime": 13683.03763461113, "_timestamp": 1585611052.670504, "_step": 249}
{"Episode reward": 11.100000000000776, "Episode length": 889, "Policy Loss": 1.1138321161270142, "Value Loss": 11.25375747680664, "_runtime": 13683.641258478165, "_timestamp": 1585611053.274128, "_step": 250}
{"Episode reward": 62.499999999999744, "Episode length": 375, "Policy Loss": 2.372945785522461, "Value Loss": 26.677654266357422, "_runtime": 13684.986011981964, "_timestamp": 1585611054.6188815, "_step": 251}
{"Episode reward": 15.300000000000537, "Episode length": 847, "Policy Loss": 1.1727592945098877, "Value Loss": 11.811067581176758, "_runtime": 13686.090762138367, "_timestamp": 1585611055.7236316, "_step": 252}
{"Episode reward": 29.69999999999972, "Episode length": 703, "Policy Loss": 1.374096155166626, "Value Loss": 14.229876518249512, "_runtime": 13687.597133398056, "_timestamp": 1585611057.2300029, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.13657930493354797, "Value Loss": 0.00024235571618191898, "_runtime": 13689.155944347382, "_timestamp": 1585611058.7888138, "_step": 254}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.12401654571294785, "Value Loss": 0.00020159182895440608, "_runtime": 13690.700660943985, "_timestamp": 1585611060.3335304, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11361812800168991, "Value Loss": 0.00016760228027123958, "_runtime": 13692.090170621872, "_timestamp": 1585611061.72304, "_step": 256}
{"Episode reward": 11.000000000000782, "Episode length": 890, "Policy Loss": 1.0658612251281738, "Value Loss": 11.23873519897461, "_runtime": 13693.656512498856, "_timestamp": 1585611063.289382, "_step": 257}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.09323590248823166, "Value Loss": 0.0001126248316722922, "_runtime": 13694.511873960495, "_timestamp": 1585611064.1447434, "_step": 258}
{"Episode reward": 46.69999999999952, "Episode length": 533, "Policy Loss": 1.9849679470062256, "Value Loss": 18.7653865814209, "_runtime": 13696.071197271347, "_timestamp": 1585611065.7040668, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.07287340611219406, "Value Loss": 6.896633567521349e-05, "_runtime": 13697.639873504639, "_timestamp": 1585611067.272743, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.06330942362546921, "Value Loss": 5.169249197933823e-05, "_runtime": 13699.16629934311, "_timestamp": 1585611068.7991688, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.05452224239706993, "Value Loss": 3.814290539594367e-05, "_runtime": 13700.740042448044, "_timestamp": 1585611070.372912, "_step": 262}
{"Episode reward": 0.48350601047415864, "Episode length": 996, "Policy Loss": 0.8851126432418823, "Value Loss": 10.041254997253418, "_runtime": 13701.875008583069, "_timestamp": 1585611071.507878, "_step": 263}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": 1.3953945636749268, "Value Loss": 13.967698097229004, "_runtime": 13702.572275161743, "_timestamp": 1585611072.2051446, "_step": 264}
{"Episode reward": 57.19999999999967, "Episode length": 428, "Policy Loss": 2.189887762069702, "Value Loss": 23.36601448059082, "_runtime": 13704.141698360443, "_timestamp": 1585611073.7745678, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01746376045048237, "Value Loss": 3.949987785745179e-06, "_runtime": 13705.704025745392, "_timestamp": 1585611075.3368952, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.007515313569456339, "Value Loss": 7.383283104900329e-07, "_runtime": 13707.221187591553, "_timestamp": 1585611076.854057, "_step": 267}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0014158058911561966, "Value Loss": 2.5669578462839127e-08, "_runtime": 13708.573850154877, "_timestamp": 1585611078.2067196, "_step": 268}
{"Episode reward": 16.10000000000049, "Episode length": 839, "Policy Loss": 1.0115463733673096, "Value Loss": 11.918695449829102, "_runtime": 13710.138578891754, "_timestamp": 1585611079.7714484, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.018057383596897125, "Value Loss": 4.231558705214411e-06, "_runtime": 13711.701818943024, "_timestamp": 1585611081.3346884, "_step": 270}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.02581823244690895, "Value Loss": 8.627831448393408e-06, "_runtime": 13712.80971980095, "_timestamp": 1585611082.4425893, "_step": 271}
{"Episode reward": 29.399999999999736, "Episode length": 706, "Policy Loss": 1.248688817024231, "Value Loss": 14.163263320922852, "_runtime": 13713.663714647293, "_timestamp": 1585611083.2965841, "_step": 272}
{"Episode reward": 46.999999999999524, "Episode length": 530, "Policy Loss": 1.5042617321014404, "Value Loss": 18.86619758605957, "_runtime": 13715.130583286285, "_timestamp": 1585611084.7634528, "_step": 273}
{"Episode reward": 6.600000000001032, "Episode length": 934, "Policy Loss": 0.8541057109832764, "Value Loss": 10.705459594726562, "_runtime": 13716.534043550491, "_timestamp": 1585611086.166913, "_step": 274}
{"Episode reward": 9.900000000000844, "Episode length": 901, "Policy Loss": 0.9271280169487, "Value Loss": 11.097329139709473, "_runtime": 13718.059933423996, "_timestamp": 1585611087.692803, "_step": 275}
{"Episode reward": -99.80418570041516, "Episode length": 999, "Policy Loss": -0.0678585022687912, "Value Loss": 6.89029402565211e-05, "_runtime": 13719.39303970337, "_timestamp": 1585611089.0259092, "_step": 276}
{"Episode reward": 14.800487685204118, "Episode length": 852, "Policy Loss": 0.9058296084403992, "Value Loss": 11.73509407043457, "_runtime": 13720.950448989868, "_timestamp": 1585611090.5833185, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.08625100553035736, "Value Loss": 9.660075738793239e-05, "_runtime": 13722.505376815796, "_timestamp": 1585611092.1382463, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0942646861076355, "Value Loss": 0.00011533314682310447, "_runtime": 13723.974097251892, "_timestamp": 1585611093.6069667, "_step": 279}
{"Episode reward": 6.000000000001066, "Episode length": 940, "Policy Loss": 1.0162924528121948, "Value Loss": 10.635971069335938, "_runtime": 13725.535151481628, "_timestamp": 1585611095.168021, "_step": 280}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.10929986089468002, "Value Loss": 0.00015372833877336234, "_runtime": 13726.611892700195, "_timestamp": 1585611096.2447622, "_step": 281}
{"Episode reward": 31.7999999999996, "Episode length": 682, "Policy Loss": 1.1179982423782349, "Value Loss": 14.659065246582031, "_runtime": 13728.012438774109, "_timestamp": 1585611097.6453083, "_step": 282}
{"Episode reward": 10.800000000000793, "Episode length": 892, "Policy Loss": 0.7970876693725586, "Value Loss": 11.207809448242188, "_runtime": 13729.586203813553, "_timestamp": 1585611099.2190733, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13087265193462372, "Value Loss": 0.00022204456035979092, "_runtime": 13731.129320859909, "_timestamp": 1585611100.7621903, "_step": 284}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.13782091438770294, "Value Loss": 0.0002462012635078281, "_runtime": 13732.730340003967, "_timestamp": 1585611102.3632095, "_step": 285}
{"Episode reward": -99.81853664070228, "Episode length": 999, "Policy Loss": -0.14383190870285034, "Value Loss": 0.000272379198577255, "_runtime": 13734.31075835228, "_timestamp": 1585611103.9436278, "_step": 286}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15017898380756378, "Value Loss": 0.00028848822694271803, "_runtime": 13735.873493671417, "_timestamp": 1585611105.5063632, "_step": 287}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.153609499335289, "Value Loss": 0.00030644770595245063, "_runtime": 13737.451038122177, "_timestamp": 1585611107.0839076, "_step": 288}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.15854455530643463, "Value Loss": 0.0003222730883862823, "_runtime": 13739.020424127579, "_timestamp": 1585611108.6532936, "_step": 289}
{"Episode reward": -99.83614369779686, "Episode length": 999, "Policy Loss": -0.1598718911409378, "Value Loss": 0.0003377484390512109, "_runtime": 13740.58896613121, "_timestamp": 1585611110.2218356, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1636929214000702, "Value Loss": 0.0003477534628473222, "_runtime": 13742.15915942192, "_timestamp": 1585611111.792029, "_step": 291}
{"Episode reward": -99.82576256394246, "Episode length": 999, "Policy Loss": -0.16592063009738922, "Value Loss": 0.0003602736978791654, "_runtime": 13743.73910689354, "_timestamp": 1585611113.3719764, "_step": 292}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16799822449684143, "Value Loss": 0.0003655461478047073, "_runtime": 13745.3145673275, "_timestamp": 1585611114.9474368, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.16926351189613342, "Value Loss": 0.0003718454681802541, "_runtime": 13746.4183511734, "_timestamp": 1585611116.0512207, "_step": 294}
{"Episode reward": 30.89999999999965, "Episode length": 691, "Policy Loss": 1.0207505226135254, "Value Loss": 14.46651554107666, "_runtime": 13747.570617437363, "_timestamp": 1585611117.203487, "_step": 295}
{"Episode reward": 27.299999999999855, "Episode length": 727, "Policy Loss": 1.006126880645752, "Value Loss": 13.750107765197754, "_runtime": 13749.148057937622, "_timestamp": 1585611118.7809274, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.17698723077774048, "Value Loss": 0.0004037273465655744, "_runtime": 13750.698531627655, "_timestamp": 1585611120.331401, "_step": 297}
{"Episode reward": -99.73308264165978, "Episode length": 999, "Policy Loss": -0.17793741822242737, "Value Loss": 0.0004251276550348848, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392, -0.0009019864373840392]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 7.0], "bins": [-0.14756882190704346, -0.14524896442890167, -0.1429291069507599, -0.1406092494726181, -0.13828939199447632, -0.13596953451633453, -0.13364967703819275, -0.13132983446121216, -0.12900997698307037, -0.1266901195049286, -0.1243702620267868, -0.12205040454864502, -0.11973054707050323, -0.11741068959236145, -0.11509083211421967, -0.11277097463607788, -0.1104511171579361, -0.10813125967979431, -0.10581140965223312, -0.10349155217409134, -0.10117169469594955, -0.09885184466838837, -0.09653198719024658, -0.0942121297121048, -0.09189227223396301, -0.08957241475582123, -0.08725255727767944, -0.08493269979953766, -0.08261284232139587, -0.08029299229383469, -0.0779731348156929, -0.07565327733755112, -0.07333341985940933, -0.07101356238126755, -0.06869370490312576, -0.06637384742498398, -0.06405399739742279, -0.061734139919281006, -0.05941428244113922, -0.057094424962997437, -0.05477456748485565, -0.05245471000671387, -0.05013485997915268, -0.047815002501010895, -0.04549514502286911, -0.043175287544727325, -0.04085543006658554, -0.038535572588443756, -0.03621572256088257, -0.033895865082740784, -0.031576007604599, -0.029256150126457214, -0.02693629264831543, -0.024616435170173645, -0.02229657769203186, -0.019976720213890076, -0.01765686273574829, -0.015337005257606506, -0.013017162680625916, -0.01069730520248413, -0.008377447724342346, -0.0060575902462005615, -0.003737732768058777, -0.0014178752899169922, 0.0009019821882247925]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.002610523020848632, -0.002542155794799328, -0.0024737888015806675, -0.0024054215755313635, -0.002337054582312703, -0.002268687356263399, -0.0022003203630447388, -0.0021319531369954348, -0.0020635861437767744, -0.0019952189177274704, -0.00192685192450881, -0.001858484698459506, -0.0017901175888255239, -0.0017217504791915417, -0.0016533833695575595, -0.0015850162599235773, -0.0015166491502895951, -0.001448282040655613, -0.0013799149310216308, -0.0013115478213876486, -0.0012431807117536664, -0.0011748136021196842, -0.001106446492485702, -0.0010380793828517199, -0.0009697121568024158, -0.0009013450471684337, -0.0008329779375344515, -0.0007646108279004693, -0.0006962437182664871, -0.0006278767250478268, -0.0005595094989985228, -0.0004911425057798624, -0.0004227752797305584, -0.0003544080536812544, -0.00028604106046259403, -0.00021767383441329002, -0.00014930684119462967, -8.093961514532566e-05, -1.2572621926665306e-05, 5.57946041226387e-05, 0.00012416159734129906, 0.00019252882339060307, 0.0002608958166092634, 0.00032926304265856743, 0.0003976300358772278, 0.0004659972619265318, 0.0005343642551451921, 0.0006027314811944962, 0.0006710987072438002, 0.0007394657004624605, 0.0008078329265117645, 0.0008761999197304249, 0.0009445671457797289, 0.0010129341389983892, 0.0010813013650476933, 0.0011496683582663536, 0.0012180355843156576, 0.001286402577534318, 0.0013547695707529783, 0.001423137029632926, 0.0014915040228515863, 0.0015598710160702467, 0.001628238009288907, 0.0016966054681688547, 0.001764972461387515]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 32.0, 11.0, 19.0, 1.0, 0.0, 0.0, 0.0, 224.0, 0.0, 0.0, 0.0, 11.0, 12.0, 25.0, 30.0, 9.0, 18.0, 21.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 2.0, 4.0, 4.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 3.0], "bins": [-0.009184016846120358, -0.008937984704971313, -0.008691953495144844, -0.0084459213539958, -0.008199889212846756, -0.007953858003020287, -0.0077078258618712425, -0.007461794186383486, -0.007215762510895729, -0.006969730369746685, -0.006723698694258928, -0.006477667018771172, -0.0062316348776221275, -0.005985603202134371, -0.005739571526646614, -0.00549353938549757, -0.005247507710009813, -0.005001476034522057, -0.0047554438933730125, -0.004509412217885256, -0.004263380542397499, -0.004017348401248455, -0.0037713167257606983, -0.0035252850502729416, -0.0032792529091238976, -0.003033221233636141, -0.002787189558148384, -0.0025411578826606274, -0.0022951257415115833, -0.0020490940660238266, -0.0018030623905360699, -0.0015570302493870258, -0.001310998573899269, -0.001064966432750225, -0.0008189352229237556, -0.0005729030817747116, -0.00032687094062566757, -8.083973079919815e-05, 0.00016519241034984589, 0.0004112245514988899, 0.0006572557613253593, 0.0009032879024744034, 0.0011493200436234474, 0.0013953512534499168, 0.0016413833945989609, 0.001887415535748005, 0.0021334467455744743, 0.0023794788867235184, 0.0026255110278725624, 0.002871542237699032, 0.003117574378848076, 0.0033636055886745453, 0.0036096377298235893, 0.0038556698709726334, 0.004101701080799103, 0.004347733221948147, 0.004593765363097191, 0.00483979657292366, 0.005085828714072704, 0.005331860855221748, 0.005577892065048218, 0.005823924206197262, 0.006069956347346306, 0.006315987557172775, 0.006562019698321819]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 0.0, 2.0, 6.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04767313227057457, -0.04674810171127319, -0.04582307115197182, -0.04489804059267044, -0.04397301375865936, -0.043047983199357986, -0.04212295264005661, -0.041197922080755234, -0.04027289152145386, -0.03934786468744278, -0.038422830402851105, -0.03749780356884003, -0.03657277300953865, -0.035647742450237274, -0.0347227118909359, -0.03379768133163452, -0.032872654497623444, -0.03194762021303177, -0.03102259337902069, -0.030097562819719315, -0.029172532260417938, -0.02824750356376171, -0.027322473004460335, -0.02639744244515896, -0.02547241374850273, -0.024547383189201355, -0.02362235262989998, -0.022697322070598602, -0.021772293373942375, -0.020847262814641, -0.019922232255339622, -0.018997203558683395, -0.01807217299938202, -0.017147142440080643, -0.016222111880779266, -0.01529708132147789, -0.014372054487466812, -0.013447023928165436, -0.01252199336886406, -0.011596962809562683, -0.010671932250261307, -0.00974690169095993, -0.008821874856948853, -0.007896844297647476, -0.0069718137383461, -0.0060467831790447235, -0.005121752619743347, -0.004196722060441971, -0.003271695226430893, -0.0023466646671295166, -0.0014216341078281403, -0.0004966035485267639, 0.0004284270107746124, 0.0013534575700759888, 0.002278488129377365, 0.003203514963388443, 0.004128545522689819, 0.005053576081991196, 0.005978606641292572, 0.006903637200593948, 0.007828667759895325, 0.008753694593906403, 0.009678725153207779, 0.010603755712509155, 0.011528786271810532]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 10.0, 6.0, 1.0, 7.0, 9.0, 3.0, 2.0, 0.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0], "bins": [-0.011880413629114628, -0.011653449386358261, -0.011426486074924469, -0.011199521832168102, -0.01097255852073431, -0.010745594277977943, -0.010518630966544151, -0.010291666723787785, -0.010064703412353992, -0.009837739169597626, -0.009610775858163834, -0.009383811615407467, -0.0091568473726511, -0.008929884061217308, -0.008702920749783516, -0.00847595650702715, -0.008248992264270782, -0.00802202895283699, -0.007795065175741911, -0.0075681013986468315, -0.007341137621551752, -0.007114173844456673, -0.006887210067361593, -0.006660246290266514, -0.006433282047510147, -0.006206318270415068, -0.005979354493319988, -0.005752390716224909, -0.005525426939129829, -0.00529846316203475, -0.0050714993849396706, -0.004844535607844591, -0.004617571830749512, -0.004390608053654432, -0.004163644276559353, -0.003936680033802986, -0.003709716722369194, -0.0034827524796128273, -0.003255789168179035, -0.0030288249254226685, -0.0028018616139888763, -0.0025748973712325096, -0.0023479340597987175, -0.0021209698170423508, -0.0018940065056085587, -0.001667042262852192, -0.0014400789514183998, -0.001213114708662033, -0.0009861504659056664, -0.0007591871544718742, -0.0005322229117155075, -0.0003052596002817154, -7.829535752534866e-05, 0.00014866795390844345, 0.0003756321966648102, 0.0006025955080986023, 0.000829559750854969, 0.0010565230622887611, 0.0012834873050451279, 0.00151045061647892, 0.0017374148592352867, 0.001964378170669079, 0.0021913424134254456, 0.0024183057248592377, 0.0026452699676156044]}, "_runtime": 13752.244232177734, "_timestamp": 1585611121.8771017, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18128718435764313, "Value Loss": 0.0004291804216336459, "_runtime": 13753.81212568283, "_timestamp": 1585611123.4449952, "_step": 299}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18400776386260986, "Value Loss": 0.0004385962092783302, "_runtime": 13755.412424564362, "_timestamp": 1585611125.045294, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18633735179901123, "Value Loss": 0.00044595668441616, "_runtime": 13756.98770403862, "_timestamp": 1585611126.6205735, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1875091940164566, "Value Loss": 0.0004514314641710371, "_runtime": 13758.567035198212, "_timestamp": 1585611128.1999047, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.18748606741428375, "Value Loss": 0.0004551672318484634, "_runtime": 13759.182781934738, "_timestamp": 1585611128.8156514, "_step": 303}
{"Episode reward": 63.199999999999754, "Episode length": 368, "Policy Loss": 2.0447399616241455, "Value Loss": 27.162721633911133, "_runtime": 13760.748453855515, "_timestamp": 1585611130.3813233, "_step": 304}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.1911284327507019, "Value Loss": 0.0004739536962006241, "_runtime": 13762.33125114441, "_timestamp": 1585611131.9641206, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19440393149852753, "Value Loss": 0.0004879243206232786, "_runtime": 13763.84363746643, "_timestamp": 1585611133.476507, "_step": 306}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.19701503217220306, "Value Loss": 0.0004993444308638573, "_runtime": 13764.349386692047, "_timestamp": 1585611133.9822562, "_step": 307}
{"Episode reward": 71.09999999999987, "Episode length": 289, "Policy Loss": 2.6827034950256348, "Value Loss": 34.58700180053711, "_runtime": 13765.8905107975, "_timestamp": 1585611135.5233803, "_step": 308}
{"Episode reward": 1.4999342858804567, "Episode length": 986, "Policy Loss": 0.7528549432754517, "Value Loss": 10.137853622436523, "_runtime": 13767.084688186646, "_timestamp": 1585611136.7175577, "_step": 309}
{"Episode reward": 23.400000000000077, "Episode length": 766, "Policy Loss": 0.8624170422554016, "Value Loss": 13.049205780029297, "_runtime": 13768.586190462112, "_timestamp": 1585611138.21906, "_step": 310}
{"Episode reward": -99.85335845947127, "Episode length": 999, "Policy Loss": -0.21578875184059143, "Value Loss": 0.0006050187512300909, "_runtime": 13768.881920337677, "_timestamp": 1585611138.5147898, "_step": 311}
{"Episode reward": 85.70000000000005, "Episode length": 143, "Policy Loss": 5.576946258544922, "Value Loss": 69.89541625976562, "_runtime": 13769.383939743042, "_timestamp": 1585611139.0168092, "_step": 312}
{"Episode reward": 68.79999999999984, "Episode length": 312, "Policy Loss": 2.392089366912842, "Value Loss": 32.03486633300781, "_runtime": 13769.87462592125, "_timestamp": 1585611139.5074954, "_step": 313}
{"Episode reward": 69.99999999999986, "Episode length": 300, "Policy Loss": 2.51080322265625, "Value Loss": 33.448448181152344, "_runtime": 13771.364491224289, "_timestamp": 1585611140.9973607, "_step": 314}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2690110206604004, "Value Loss": 0.0009324583224952221, "_runtime": 13772.86870765686, "_timestamp": 1585611142.5015771, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2844051718711853, "Value Loss": 0.0010439060861244798, "_runtime": 13774.328234672546, "_timestamp": 1585611143.9611042, "_step": 316}
{"Episode reward": 2.900000000001242, "Episode length": 971, "Policy Loss": 0.5632436871528625, "Value Loss": 10.292824745178223, "_runtime": 13775.900315999985, "_timestamp": 1585611145.5331855, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3107883334159851, "Value Loss": 0.0012504548067227006, "_runtime": 13777.045509576797, "_timestamp": 1585611146.678379, "_step": 318}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": 0.8174058794975281, "Value Loss": 13.652504920959473, "_runtime": 13778.632054328918, "_timestamp": 1585611148.2649238, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.33460357785224915, "Value Loss": 0.0014421967789530754, "_runtime": 13780.167436599731, "_timestamp": 1585611149.800306, "_step": 320}
{"Episode reward": 2.466675876082263, "Episode length": 976, "Policy Loss": 0.6366260647773743, "Value Loss": 10.239436149597168, "_runtime": 13781.703965187073, "_timestamp": 1585611151.3368347, "_step": 321}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3549807369709015, "Value Loss": 0.0016172864707186818, "_runtime": 13782.73124742508, "_timestamp": 1585611152.364117, "_step": 322}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": 1.0588462352752686, "Value Loss": 15.373658180236816, "_runtime": 13783.684936523438, "_timestamp": 1585611153.317806, "_step": 323}
{"Episode reward": 39.999999999999424, "Episode length": 600, "Policy Loss": 0.9992381930351257, "Value Loss": 16.654401779174805, "_runtime": 13785.175513744354, "_timestamp": 1585611154.8083832, "_step": 324}
{"Episode reward": 4.299306911231255, "Episode length": 958, "Policy Loss": 0.5124928951263428, "Value Loss": 10.431260108947754, "_runtime": 13786.11769914627, "_timestamp": 1585611155.7505686, "_step": 325}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 1.1118050813674927, "Value Loss": 16.598535537719727, "_runtime": 13787.636394023895, "_timestamp": 1585611157.2692635, "_step": 326}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.39724454283714294, "Value Loss": 0.0020655919797718525, "_runtime": 13788.958202838898, "_timestamp": 1585611158.5910723, "_step": 327}
{"Episode reward": 16.000000000000497, "Episode length": 840, "Policy Loss": 0.8000673651695251, "Value Loss": 11.895856857299805, "_runtime": 13790.185163497925, "_timestamp": 1585611159.818033, "_step": 328}
{"Episode reward": 20.600000000000236, "Episode length": 794, "Policy Loss": 0.6364725232124329, "Value Loss": 12.584755897521973, "_runtime": 13791.727150917053, "_timestamp": 1585611161.3600204, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42693179845809937, "Value Loss": 0.002337940037250519, "_runtime": 13793.279813289642, "_timestamp": 1585611162.9126828, "_step": 330}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4328668415546417, "Value Loss": 0.0024175497237592936, "_runtime": 13794.825378417969, "_timestamp": 1585611164.458248, "_step": 331}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.43835464119911194, "Value Loss": 0.0024835020303726196, "_runtime": 13796.390754938126, "_timestamp": 1585611166.0236244, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44367825984954834, "Value Loss": 0.00253653503023088, "_runtime": 13797.567273378372, "_timestamp": 1585611167.2001429, "_step": 333}
{"Episode reward": 25.267291006073336, "Episode length": 749, "Policy Loss": 0.7431236505508423, "Value Loss": 13.340170860290527, "_runtime": 13799.139601707458, "_timestamp": 1585611168.7724712, "_step": 334}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4484952390193939, "Value Loss": 0.0026268064975738525, "_runtime": 13800.71568274498, "_timestamp": 1585611170.3485522, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45313969254493713, "Value Loss": 0.0026640824507921934, "_runtime": 13802.301298856735, "_timestamp": 1585611171.9341683, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4553607404232025, "Value Loss": 0.002690185559913516, "_runtime": 13802.576177597046, "_timestamp": 1585611172.209047, "_step": 337}
{"Episode reward": 86.90000000000003, "Episode length": 131, "Policy Loss": 5.812867641448975, "Value Loss": 76.25916290283203, "_runtime": 13803.474561452866, "_timestamp": 1585611173.107431, "_step": 338}
{"Episode reward": 43.09999999999947, "Episode length": 569, "Policy Loss": 1.0895359516143799, "Value Loss": 17.558835983276367, "_runtime": 13805.044325113297, "_timestamp": 1585611174.6771946, "_step": 339}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4772719442844391, "Value Loss": 0.0029593550134450197, "_runtime": 13806.537847042084, "_timestamp": 1585611176.1707165, "_step": 340}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.48728206753730774, "Value Loss": 0.003071630373597145, "_runtime": 13808.059631347656, "_timestamp": 1585611177.6925008, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4956628978252411, "Value Loss": 0.0031656306236982346, "_runtime": 13809.628735303879, "_timestamp": 1585611179.2616048, "_step": 342}
{"Episode reward": -99.80005266666272, "Episode length": 999, "Policy Loss": -0.4985105097293854, "Value Loss": 0.0032409406267106533, "_runtime": 13811.182859897614, "_timestamp": 1585611180.8157294, "_step": 343}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.503449559211731, "Value Loss": 0.0033027834724634886, "_runtime": 13812.348222970963, "_timestamp": 1585611181.9810925, "_step": 344}
{"Episode reward": 26.39274844527236, "Episode length": 737, "Policy Loss": 0.651400625705719, "Value Loss": 13.556147575378418, "_runtime": 13813.92689704895, "_timestamp": 1585611183.5597665, "_step": 345}
{"Episode reward": -99.81801480203727, "Episode length": 999, "Policy Loss": -0.5122011303901672, "Value Loss": 0.0033995513804256916, "_runtime": 13815.488509893417, "_timestamp": 1585611185.1213794, "_step": 346}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5169219374656677, "Value Loss": 0.0034417270217090845, "_runtime": 13817.038803815842, "_timestamp": 1585611186.6716733, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5178942084312439, "Value Loss": 0.0034673428162932396, "_runtime": 13818.597737789154, "_timestamp": 1585611188.2306073, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5177300572395325, "Value Loss": 0.003480329178273678, "_runtime": 13820.158940553665, "_timestamp": 1585611189.79181, "_step": 349}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.517571747303009, "Value Loss": 0.003481901716440916, "_runtime": 13821.72625875473, "_timestamp": 1585611191.3591282, "_step": 350}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5174480676651001, "Value Loss": 0.0034730725456029177, "_runtime": 13823.297227859497, "_timestamp": 1585611192.9300973, "_step": 351}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.516141951084137, "Value Loss": 0.0034549979027360678, "_runtime": 13824.897737979889, "_timestamp": 1585611194.5306075, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5147024393081665, "Value Loss": 0.0034285923466086388, "_runtime": 13826.121108055115, "_timestamp": 1585611195.7539775, "_step": 353}
{"Episode reward": 22.900000000000105, "Episode length": 771, "Policy Loss": 0.7730739116668701, "Value Loss": 12.958436012268066, "_runtime": 13826.762010097504, "_timestamp": 1585611196.3948796, "_step": 354}
{"Episode reward": 61.899999999999736, "Episode length": 381, "Policy Loss": 1.6948717832565308, "Value Loss": 26.219541549682617, "_runtime": 13828.325405597687, "_timestamp": 1585611197.958275, "_step": 355}
{"Episode reward": -99.84723206162313, "Episode length": 999, "Policy Loss": -0.5143802165985107, "Value Loss": 0.003392521757632494, "_runtime": 13829.889117002487, "_timestamp": 1585611199.5219865, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5118398070335388, "Value Loss": 0.003403007285669446, "_runtime": 13830.580544233322, "_timestamp": 1585611200.2134137, "_step": 357}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 1.3306065797805786, "Value Loss": 22.298786163330078, "_runtime": 13831.63293004036, "_timestamp": 1585611201.2657995, "_step": 358}
{"Episode reward": 33.19999999999952, "Episode length": 668, "Policy Loss": 0.7068504095077515, "Value Loss": 14.956002235412598, "_runtime": 13833.039055109024, "_timestamp": 1585611202.6719246, "_step": 359}
{"Episode reward": 10.893359564245543, "Episode length": 892, "Policy Loss": 0.4044243097305298, "Value Loss": 11.201056480407715, "_runtime": 13834.55320239067, "_timestamp": 1585611204.1860719, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5206223130226135, "Value Loss": 0.0035076658241450787, "_runtime": 13836.090484380722, "_timestamp": 1585611205.7233539, "_step": 361}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5222212672233582, "Value Loss": 0.0035373815335333347, "_runtime": 13837.639045715332, "_timestamp": 1585611207.2719152, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5238593816757202, "Value Loss": 0.0035537932999432087, "_runtime": 13839.19887137413, "_timestamp": 1585611208.8317409, "_step": 363}
{"Episode reward": -99.88314982056478, "Episode length": 999, "Policy Loss": -0.5250781178474426, "Value Loss": 0.003556161653250456, "_runtime": 13839.881566762924, "_timestamp": 1585611209.5144362, "_step": 364}
{"Episode reward": 58.498117423057245, "Episode length": 416, "Policy Loss": 1.4468672275543213, "Value Loss": 24.013370513916016, "_runtime": 13841.459903240204, "_timestamp": 1585611211.0927727, "_step": 365}
{"Episode reward": -99.70799298286299, "Episode length": 999, "Policy Loss": -0.5217140316963196, "Value Loss": 0.003572626505047083, "_runtime": 13841.971707820892, "_timestamp": 1585611211.6045773, "_step": 366}
{"Episode reward": 70.49999999999986, "Episode length": 295, "Policy Loss": 2.25009822845459, "Value Loss": 33.86128234863281, "_runtime": 13843.497833013535, "_timestamp": 1585611213.1307025, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5339070558547974, "Value Loss": 0.0036523109301924706, "_runtime": 13844.465403795242, "_timestamp": 1585611214.0982733, "_step": 368}
{"Episode reward": 39.69999999999942, "Episode length": 603, "Policy Loss": 0.8452602624893188, "Value Loss": 16.567296981811523, "_runtime": 13845.973022460938, "_timestamp": 1585611215.605892, "_step": 369}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5390443205833435, "Value Loss": 0.003758369479328394, "_runtime": 13846.80133342743, "_timestamp": 1585611216.434203, "_step": 370}
{"Episode reward": 47.99999999999954, "Episode length": 520, "Policy Loss": 1.0463143587112427, "Value Loss": 19.210859298706055, "_runtime": 13848.347322940826, "_timestamp": 1585611217.9801924, "_step": 371}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5444900393486023, "Value Loss": 0.0038659723941236734, "_runtime": 13849.950473546982, "_timestamp": 1585611219.583343, "_step": 372}
{"Episode reward": -99.7490910459296, "Episode length": 999, "Policy Loss": -0.5461992621421814, "Value Loss": 0.0039055657107383013, "_runtime": 13851.473172187805, "_timestamp": 1585611221.1060417, "_step": 373}
{"Episode reward": -99.87558298706868, "Episode length": 999, "Policy Loss": -0.55228590965271, "Value Loss": 0.003939980641007423, "_runtime": 13852.859831094742, "_timestamp": 1585611222.4927006, "_step": 374}
{"Episode reward": 12.019912218675742, "Episode length": 881, "Policy Loss": 0.37673163414001465, "Value Loss": 11.34040641784668, "_runtime": 13854.423172473907, "_timestamp": 1585611224.056042, "_step": 375}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5559355020523071, "Value Loss": 0.003981142304837704, "_runtime": 13855.989319562912, "_timestamp": 1585611225.622189, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5525065660476685, "Value Loss": 0.00399020267650485, "_runtime": 13856.482189893723, "_timestamp": 1585611226.1150594, "_step": 377}
{"Episode reward": 71.19999999999987, "Episode length": 288, "Policy Loss": 2.3580305576324463, "Value Loss": 34.6823616027832, "_runtime": 13858.03694152832, "_timestamp": 1585611227.669811, "_step": 378}
{"Episode reward": -99.80030174851278, "Episode length": 999, "Policy Loss": -0.5580809712409973, "Value Loss": 0.004034748766571283, "_runtime": 13859.597257614136, "_timestamp": 1585611229.230127, "_step": 379}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5635386109352112, "Value Loss": 0.004071609582751989, "_runtime": 13861.031895637512, "_timestamp": 1585611230.6647651, "_step": 380}
{"Episode reward": 4.800000000001134, "Episode length": 952, "Policy Loss": 0.3007641136646271, "Value Loss": 10.494847297668457, "_runtime": 13862.148221731186, "_timestamp": 1585611231.7810912, "_step": 381}
{"Episode reward": 29.814834499358838, "Episode length": 702, "Policy Loss": 0.6300215125083923, "Value Loss": 14.230835914611816, "_runtime": 13863.463413476944, "_timestamp": 1585611233.096283, "_step": 382}
{"Episode reward": 16.50000000000047, "Episode length": 835, "Policy Loss": 0.4882064461708069, "Value Loss": 11.96475601196289, "_runtime": 13864.608591556549, "_timestamp": 1585611234.241461, "_step": 383}
{"Episode reward": 26.696396861970314, "Episode length": 734, "Policy Loss": 0.6653342247009277, "Value Loss": 13.610496520996094, "_runtime": 13866.0638692379, "_timestamp": 1585611235.6967387, "_step": 384}
{"Episode reward": 6.10000000000106, "Episode length": 939, "Policy Loss": 0.3059674799442291, "Value Loss": 10.639973640441895, "_runtime": 13867.215463399887, "_timestamp": 1585611236.848333, "_step": 385}
{"Episode reward": 26.799999999999883, "Episode length": 732, "Policy Loss": 0.5560710430145264, "Value Loss": 13.64754867553711, "_runtime": 13868.093790769577, "_timestamp": 1585611237.7266603, "_step": 386}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.8937132358551025, "Value Loss": 17.77439308166504, "_runtime": 13869.647193670273, "_timestamp": 1585611239.2800632, "_step": 387}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5859227180480957, "Value Loss": 0.004465122707188129, "_runtime": 13871.193519353867, "_timestamp": 1585611240.8263888, "_step": 388}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5906279683113098, "Value Loss": 0.004528272897005081, "_runtime": 13872.441321134567, "_timestamp": 1585611242.0741906, "_step": 389}
{"Episode reward": 20.70000000000023, "Episode length": 793, "Policy Loss": 0.5190622210502625, "Value Loss": 12.597875595092773, "_runtime": 13873.201386213303, "_timestamp": 1585611242.8342557, "_step": 390}
{"Episode reward": 53.09999999999961, "Episode length": 469, "Policy Loss": 1.2036172151565552, "Value Loss": 21.297788619995117, "_runtime": 13874.772470712662, "_timestamp": 1585611244.4053402, "_step": 391}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6020790934562683, "Value Loss": 0.004700588062405586, "_runtime": 13876.103954076767, "_timestamp": 1585611245.7368236, "_step": 392}
{"Episode reward": 14.600000000000577, "Episode length": 854, "Policy Loss": 0.3698751926422119, "Value Loss": 11.69821834564209, "_runtime": 13877.620987653732, "_timestamp": 1585611247.2538571, "_step": 393}
{"Episode reward": -99.8202675819383, "Episode length": 999, "Policy Loss": -0.6100298762321472, "Value Loss": 0.0048127127811312675, "_runtime": 13879.204415798187, "_timestamp": 1585611248.8372853, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6107933521270752, "Value Loss": 0.004857657942920923, "_runtime": 13880.759922504425, "_timestamp": 1585611250.392792, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6147735714912415, "Value Loss": 0.00487878592684865, "_runtime": 13882.317965745926, "_timestamp": 1585611251.9508352, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6132619380950928, "Value Loss": 0.004882513545453548, "_runtime": 13883.889744520187, "_timestamp": 1585611253.522614, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6108116507530212, "Value Loss": 0.004870562348514795, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656, 0.00433253264054656]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.00433253264054656, 0.004684228915721178, 0.013700990006327629, 0.022717751562595367, 0.031734514981508255, 0.040751274675130844, 0.04976803809404373, 0.05878480151295662, 0.06780155748128891, 0.0768183171749115, 0.08583507686853409, 0.09485184401273727, 0.10386860370635986, 0.11288536339998245, 0.12190213054418564, 0.13091889023780823, 0.1399356573820114, 0.1489524245262146, 0.1579691767692566, 0.16698594391345978, 0.17600269615650177, 0.18501946330070496, 0.19403623044490814, 0.20305298268795013, 0.21206974983215332, 0.2210865169763565, 0.2301032692193985, 0.23912003636360168, 0.24813680350780487, 0.25715354084968567, 0.26617029309272766, 0.27518707513809204, 0.28420382738113403, 0.293220579624176, 0.3022373616695404, 0.3112541139125824, 0.3202708661556244, 0.32928764820098877, 0.33830440044403076, 0.34732115268707275, 0.35633790493011475, 0.3653546869754791, 0.3743714392185211, 0.3833881914615631, 0.3924049735069275, 0.4014217257499695, 0.4104384779930115, 0.41945526003837585, 0.42847201228141785, 0.43748876452445984, 0.4465055465698242, 0.4555222988128662, 0.4645390510559082, 0.4735558331012726, 0.4825725853443146, 0.49158933758735657, 0.500606119632721, 0.5096228718757629, 0.5186396241188049, 0.5276563763618469, 0.5366731286048889, 0.5456899404525757, 0.5547066926956177, 0.5637234449386597, 0.5727401971817017]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.009964284487068653, -0.009612667374312878, -0.009261051192879677, -0.008909434080123901, -0.0085578178986907, -0.008206200785934925, -0.007854584604501724, -0.007502967491745949, -0.007151350378990173, -0.0067997341975569725, -0.006448117084801197, -0.006096500437706709, -0.005744883790612221, -0.005393267143517733, -0.005041650030761957, -0.004690033383667469, -0.004338416736572981, -0.003986800089478493, -0.0036351834423840046, -0.003283566329628229, -0.002931949682533741, -0.002580333035439253, -0.0022287163883447647, -0.0018770992755889893, -0.0015254830941557884, -0.001173865981400013, -0.0008222497999668121, -0.0004706326872110367, -0.00011901557445526123, 0.0002326006069779396, 0.0005842177197337151, 0.0009358339011669159, 0.0012874510139226913, 0.0016390681266784668, 0.0019906843081116676, 0.002342301420867443, 0.002693917602300644, 0.0030455347150564194, 0.003397151827812195, 0.0037487680092453957, 0.004100385122001171, 0.004452001303434372, 0.004803618416190147, 0.005155235528945923, 0.005506851710379124, 0.005858468823134899, 0.006210085935890675, 0.006561701186001301, 0.006913318298757076, 0.007264935411512852, 0.007616552524268627, 0.007968169637024403, 0.008319784887135029, 0.008671401999890804, 0.00902301911264658, 0.009374636225402355, 0.00972625333815813, 0.010077868588268757, 0.010429485701024532, 0.010781102813780308, 0.011132719926536083, 0.011484337039291859, 0.011835952289402485, 0.01218756940215826, 0.012539186514914036]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 5.0, 0.0, 20.0, 9.0, 22.0, 35.0, 15.0, 21.0, 5.0, 2.0, 0.0, 224.0, 1.0, 3.0, 5.0, 11.0, 35.0, 6.0, 14.0, 4.0, 2.0, 2.0, 3.0, 4.0, 7.0, 2.0, 1.0, 1.0, 7.0, 3.0, 4.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0], "bins": [-0.03756879270076752, -0.036243077367544174, -0.03491735830903053, -0.03359164297580719, -0.03226592391729355, -0.030940208584070206, -0.029614493250846863, -0.02828877605497837, -0.02696305885910988, -0.025637341663241386, -0.024311624467372894, -0.02298590913414955, -0.02166019193828106, -0.020334474742412567, -0.019008759409189224, -0.017683042213320732, -0.01635732501745224, -0.015031607821583748, -0.013705890625715256, -0.012380175292491913, -0.01105445809662342, -0.009728740900754929, -0.008403025567531586, -0.007077308371663094, -0.0057515911757946014, -0.0044258758425712585, -0.003100156784057617, -0.0017744414508342743, -0.0004487261176109314, 0.00087699294090271, 0.002202708274126053, 0.003528427332639694, 0.004854142665863037, 0.00617985799908638, 0.007505577057600021, 0.008831292390823364, 0.010157011449337006, 0.011482726782560349, 0.012808442115783691, 0.014134161174297333, 0.015459876507520676, 0.01678559184074402, 0.01811131089925766, 0.019437026232481003, 0.020762741565704346, 0.022088460624217987, 0.02341417595744133, 0.02473989501595497, 0.026065610349178314, 0.027391329407691956, 0.028717041015625, 0.03004276007413864, 0.03136847913265228, 0.03269419074058533, 0.03401990979909897, 0.03534562885761261, 0.036671340465545654, 0.037997059524059296, 0.03932277858257294, 0.04064849764108658, 0.04197420924901962, 0.043299928307533264, 0.044625647366046906, 0.04595135897397995, 0.04727707803249359]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.050509482622146606, -0.04608384892344475, -0.04165821522474289, -0.03723258525133133, -0.03280694782733917, -0.028381315991282463, -0.023955684155225754, -0.019530050456523895, -0.015104416757822037, -0.010678783059120178, -0.00625314936041832, -0.0018275156617164612, 0.002598114311695099, 0.007023748010396957, 0.011449381709098816, 0.015875019133090973, 0.020300649106502533, 0.024726279079914093, 0.02915191650390625, 0.03357754647731781, 0.03800318390130997, 0.04242881387472153, 0.046854451298713684, 0.051280081272125244, 0.055705711245536804, 0.06013134866952896, 0.06455697864294052, 0.06898261606693268, 0.07340824604034424, 0.0778338760137558, 0.08225952088832855, 0.08668515086174011, 0.09111078083515167, 0.09553641080856323, 0.09996204078197479, 0.10438768565654755, 0.1088133156299591, 0.11323894560337067, 0.11766457557678223, 0.12209022045135498, 0.12651585042476654, 0.1309414803981781, 0.13536711037158966, 0.13979274034500122, 0.14421838521957397, 0.14864401519298553, 0.1530696451663971, 0.15749527513980865, 0.16192090511322021, 0.16634654998779297, 0.17077217996120453, 0.1751978099346161, 0.17962343990802765, 0.1840490847826004, 0.18847471475601196, 0.19290034472942352, 0.19732597470283508, 0.20175161957740784, 0.2061772346496582, 0.21060287952423096, 0.2150285243988037, 0.21945413947105408, 0.22387978434562683, 0.2283053994178772, 0.23273104429244995]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 6.0, 3.0, 2.0, 4.0, 1.0, 5.0, 1.0, 3.0, 1.0], "bins": [-0.05550484359264374, -0.05446866899728775, -0.053432490676641464, -0.05239631608128548, -0.05136013776063919, -0.0503239631652832, -0.049287788569927216, -0.04825161024928093, -0.04721543565392494, -0.046179257333278656, -0.04514308273792267, -0.04410690814256668, -0.04307073354721069, -0.04203455522656441, -0.04099838063120842, -0.039962202310562134, -0.038926027715206146, -0.03788985311985016, -0.03685367479920387, -0.035817500203847885, -0.0347813218832016, -0.03374514728784561, -0.032708972692489624, -0.031672798097133636, -0.03063661977648735, -0.029600443318486214, -0.028564266860485077, -0.02752809226512909, -0.026491915807127953, -0.025455739349126816, -0.024419564753770828, -0.023383386433124542, -0.022347211837768555, -0.021311037242412567, -0.02027485892176628, -0.019238684326410294, -0.018202506005764008, -0.01716633141040802, -0.016130156815052032, -0.015093978494405746, -0.014057803899049759, -0.013021629303693771, -0.011985450983047485, -0.010949276387691498, -0.00991310179233551, -0.008876923471689224, -0.007840748876333237, -0.006804570555686951, -0.005768395960330963, -0.004732221364974976, -0.0036960430443286896, -0.002659868448972702, -0.001623690128326416, -0.0005875155329704285, 0.0004486590623855591, 0.001484837383031845, 0.0025210119783878326, 0.00355718657374382, 0.004593364894390106, 0.005629539489746094, 0.006665714085102081, 0.007701888680458069, 0.008738070726394653, 0.009774245321750641, 0.010810419917106628]}, "_runtime": 13885.45465183258, "_timestamp": 1585611255.0875213, "_step": 398}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6146466732025146, "Value Loss": 0.004844443406909704, "_runtime": 13887.019438505173, "_timestamp": 1585611256.652308, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6108996272087097, "Value Loss": 0.004805751610547304, "_runtime": 13888.593157291412, "_timestamp": 1585611258.2260268, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6082890629768372, "Value Loss": 0.004755901172757149, "_runtime": 13890.171083211899, "_timestamp": 1585611259.8039527, "_step": 401}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6025751829147339, "Value Loss": 0.004696208517998457, "_runtime": 13891.664650917053, "_timestamp": 1585611261.2975204, "_step": 402}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": 0.26549747586250305, "Value Loss": 10.461601257324219, "_runtime": 13893.232894659042, "_timestamp": 1585611262.8657641, "_step": 403}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5936322808265686, "Value Loss": 0.00457466347143054, "_runtime": 13893.823063373566, "_timestamp": 1585611263.4559329, "_step": 404}
{"Episode reward": 64.09999999999977, "Episode length": 359, "Policy Loss": 1.708130955696106, "Value Loss": 27.822254180908203, "_runtime": 13895.209094047546, "_timestamp": 1585611264.8419635, "_step": 405}
{"Episode reward": 13.07313541770047, "Episode length": 870, "Policy Loss": 0.36325913667678833, "Value Loss": 11.4833402633667, "_runtime": 13896.227687835693, "_timestamp": 1585611265.8605573, "_step": 406}
{"Episode reward": 35.399999999999395, "Episode length": 646, "Policy Loss": 0.6931925415992737, "Value Loss": 15.463619232177734, "_runtime": 13897.740481615067, "_timestamp": 1585611267.373351, "_step": 407}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5896387100219727, "Value Loss": 0.004521637223660946, "_runtime": 13899.287649393082, "_timestamp": 1585611268.9205189, "_step": 408}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.594202995300293, "Value Loss": 0.0045247129164636135, "_runtime": 13900.438241243362, "_timestamp": 1585611270.0711107, "_step": 409}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 0.517148494720459, "Value Loss": 13.39134407043457, "_runtime": 13901.975578784943, "_timestamp": 1585611271.6084483, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5922892093658447, "Value Loss": 0.004516988061368465, "_runtime": 13902.919819355011, "_timestamp": 1585611272.5526888, "_step": 411}
{"Episode reward": 40.28873919099512, "Episode length": 598, "Policy Loss": 0.7936528325080872, "Value Loss": 16.70448112487793, "_runtime": 13903.895131111145, "_timestamp": 1585611273.5280006, "_step": 412}
{"Episode reward": 37.09999999999938, "Episode length": 629, "Policy Loss": 1.154268503189087, "Value Loss": 15.881424903869629, "_runtime": 13905.445855379105, "_timestamp": 1585611275.0787249, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5914038419723511, "Value Loss": 0.0045486390590667725, "_runtime": 13906.43750166893, "_timestamp": 1585611276.0703712, "_step": 414}
{"Episode reward": 35.899999999999366, "Episode length": 641, "Policy Loss": 0.694983184337616, "Value Loss": 15.584124565124512, "_runtime": 13906.934471607208, "_timestamp": 1585611276.567341, "_step": 415}
{"Episode reward": 68.69999999999983, "Episode length": 313, "Policy Loss": 2.3285980224609375, "Value Loss": 31.910194396972656, "_runtime": 13907.90782213211, "_timestamp": 1585611277.5406916, "_step": 416}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.7195376753807068, "Value Loss": 16.034099578857422, "_runtime": 13909.110569000244, "_timestamp": 1585611278.7434385, "_step": 417}
{"Episode reward": 21.500000000000185, "Episode length": 785, "Policy Loss": 0.4733775854110718, "Value Loss": 12.726031303405762, "_runtime": 13910.603908777237, "_timestamp": 1585611280.2367783, "_step": 418}
{"Episode reward": -99.80049438476422, "Episode length": 999, "Policy Loss": -0.613229513168335, "Value Loss": 0.0048704929649829865, "_runtime": 13911.767375946045, "_timestamp": 1585611281.4002454, "_step": 419}
{"Episode reward": 23.50000000000007, "Episode length": 765, "Policy Loss": 0.5387158989906311, "Value Loss": 13.058444023132324, "_runtime": 13913.135006189346, "_timestamp": 1585611282.7678757, "_step": 420}
{"Episode reward": 10.700000000000799, "Episode length": 893, "Policy Loss": 0.3330467939376831, "Value Loss": 11.187344551086426, "_runtime": 13914.667439460754, "_timestamp": 1585611284.300309, "_step": 421}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6281403303146362, "Value Loss": 0.0051191821694374084, "_runtime": 13916.19782614708, "_timestamp": 1585611285.8306956, "_step": 422}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6304737329483032, "Value Loss": 0.00517978286370635, "_runtime": 13917.16912317276, "_timestamp": 1585611286.8019927, "_step": 423}
{"Episode reward": 38.0999999999994, "Episode length": 619, "Policy Loss": 0.689223051071167, "Value Loss": 16.136951446533203, "_runtime": 13917.839811563492, "_timestamp": 1585611287.472681, "_step": 424}
{"Episode reward": 57.699999999999676, "Episode length": 423, "Policy Loss": 1.7105060815811157, "Value Loss": 23.611587524414062, "_runtime": 13919.428997039795, "_timestamp": 1585611289.0618665, "_step": 425}
{"Episode reward": -99.83582151084998, "Episode length": 999, "Policy Loss": -0.6438475251197815, "Value Loss": 0.0053572822362184525, "_runtime": 13920.287344455719, "_timestamp": 1585611289.920214, "_step": 426}
{"Episode reward": 44.59999999999949, "Episode length": 554, "Policy Loss": 0.8424213528633118, "Value Loss": 18.02939796447754, "_runtime": 13921.785537481308, "_timestamp": 1585611291.418407, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6530315279960632, "Value Loss": 0.005509629845619202, "_runtime": 13923.338762283325, "_timestamp": 1585611292.9716318, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6577939391136169, "Value Loss": 0.0055672526359558105, "_runtime": 13924.850852251053, "_timestamp": 1585611294.4837217, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.656035304069519, "Value Loss": 0.005601105745881796, "_runtime": 13926.406563520432, "_timestamp": 1585611296.039433, "_step": 430}
{"Episode reward": -99.77977986335615, "Episode length": 999, "Policy Loss": -0.656688392162323, "Value Loss": 0.0056025180965662, "_runtime": 13927.984503984451, "_timestamp": 1585611297.6173735, "_step": 431}
{"Episode reward": -99.88487285524467, "Episode length": 999, "Policy Loss": -0.6589133739471436, "Value Loss": 0.005603601690381765, "_runtime": 13929.34826874733, "_timestamp": 1585611298.9811382, "_step": 432}
{"Episode reward": 13.424077028036763, "Episode length": 866, "Policy Loss": 0.5357284545898438, "Value Loss": 11.535676956176758, "_runtime": 13930.796664476395, "_timestamp": 1585611300.429534, "_step": 433}
{"Episode reward": 7.300000000000992, "Episode length": 927, "Policy Loss": 0.2278047502040863, "Value Loss": 10.7769775390625, "_runtime": 13932.37826347351, "_timestamp": 1585611302.011133, "_step": 434}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6581663489341736, "Value Loss": 0.005564406979829073, "_runtime": 13933.925441265106, "_timestamp": 1585611303.5583107, "_step": 435}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6541687846183777, "Value Loss": 0.0055430554784834385, "_runtime": 13935.481451511383, "_timestamp": 1585611305.114321, "_step": 436}
{"Episode reward": -99.73210609294334, "Episode length": 999, "Policy Loss": -0.6495280861854553, "Value Loss": 0.005494692362844944, "_runtime": 13937.051298618317, "_timestamp": 1585611306.684168, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.648678719997406, "Value Loss": 0.005453562829643488, "_runtime": 13938.629568338394, "_timestamp": 1585611308.2624378, "_step": 438}
{"Episode reward": -99.84487953185895, "Episode length": 999, "Policy Loss": -0.6456646919250488, "Value Loss": 0.005383868236094713, "_runtime": 13939.466740131378, "_timestamp": 1585611309.0996096, "_step": 439}
{"Episode reward": 48.29999999999954, "Episode length": 517, "Policy Loss": 0.9634869694709778, "Value Loss": 19.319454193115234, "_runtime": 13940.742931842804, "_timestamp": 1585611310.3758013, "_step": 440}
{"Episode reward": 19.396736049652404, "Episode length": 807, "Policy Loss": 0.3804045617580414, "Value Loss": 12.378828048706055, "_runtime": 13942.360381126404, "_timestamp": 1585611311.9932506, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6376713514328003, "Value Loss": 0.005252032075077295, "_runtime": 13943.839891195297, "_timestamp": 1585611313.4727607, "_step": 442}
{"Episode reward": 3.1820421453577694, "Episode length": 969, "Policy Loss": 0.3551176190376282, "Value Loss": 10.310210227966309, "_runtime": 13945.396498918533, "_timestamp": 1585611315.0293684, "_step": 443}
{"Episode reward": -99.82780914306501, "Episode length": 999, "Policy Loss": -0.6296107769012451, "Value Loss": 0.005182929337024689, "_runtime": 13946.892071008682, "_timestamp": 1585611316.5249405, "_step": 444}
{"Episode reward": 4.9693809613596756, "Episode length": 951, "Policy Loss": 0.24026040732860565, "Value Loss": 10.505285263061523, "_runtime": 13948.117147445679, "_timestamp": 1585611317.750017, "_step": 445}
{"Episode reward": 21.900000000000162, "Episode length": 781, "Policy Loss": 0.42236751317977905, "Value Loss": 12.790884017944336, "_runtime": 13949.681198120117, "_timestamp": 1585611319.3140676, "_step": 446}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6268339157104492, "Value Loss": 0.005106330383569002, "_runtime": 13951.260751247406, "_timestamp": 1585611320.8936207, "_step": 447}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6283870935440063, "Value Loss": 0.005078256595879793, "_runtime": 13952.250960350037, "_timestamp": 1585611321.8838298, "_step": 448}
{"Episode reward": 36.69999999999938, "Episode length": 633, "Policy Loss": 0.6983423829078674, "Value Loss": 15.780393600463867, "_runtime": 13953.823282003403, "_timestamp": 1585611323.4561515, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6222463846206665, "Value Loss": 0.0050188289023935795, "_runtime": 13954.94893169403, "_timestamp": 1585611324.5818012, "_step": 450}
{"Episode reward": 29.29999999999974, "Episode length": 707, "Policy Loss": 0.5596708655357361, "Value Loss": 14.129276275634766, "_runtime": 13956.486724853516, "_timestamp": 1585611326.1195943, "_step": 451}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.619060754776001, "Value Loss": 0.004974370822310448, "_runtime": 13957.11751127243, "_timestamp": 1585611326.7503808, "_step": 452}
{"Episode reward": 61.199999999999726, "Episode length": 388, "Policy Loss": 1.6021974086761475, "Value Loss": 25.74188804626465, "_runtime": 13958.357912063599, "_timestamp": 1585611327.9907815, "_step": 453}
{"Episode reward": 19.799796003103538, "Episode length": 803, "Policy Loss": 0.4133480489253998, "Value Loss": 12.44070816040039, "_runtime": 13959.916278123856, "_timestamp": 1585611329.5491476, "_step": 454}
{"Episode reward": -99.85669031143048, "Episode length": 999, "Policy Loss": -0.6216135621070862, "Value Loss": 0.004993586800992489, "_runtime": 13961.43023943901, "_timestamp": 1585611331.063109, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6268673539161682, "Value Loss": 0.005009005777537823, "_runtime": 13962.530066490173, "_timestamp": 1585611332.162936, "_step": 456}
{"Episode reward": 29.86367995589943, "Episode length": 702, "Policy Loss": 0.5822562575340271, "Value Loss": 14.229849815368652, "_runtime": 13964.104580402374, "_timestamp": 1585611333.73745, "_step": 457}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6219683885574341, "Value Loss": 0.005012954119592905, "_runtime": 13964.580351829529, "_timestamp": 1585611334.2132213, "_step": 458}
{"Episode reward": 71.49999999999987, "Episode length": 285, "Policy Loss": 2.313500165939331, "Value Loss": 35.043060302734375, "_runtime": 13965.45154094696, "_timestamp": 1585611335.0844104, "_step": 459}
{"Episode reward": 43.89999999999948, "Episode length": 561, "Policy Loss": 1.3972604274749756, "Value Loss": 17.80499267578125, "_runtime": 13966.923092126846, "_timestamp": 1585611336.5559616, "_step": 460}
{"Episode reward": 8.300000000000935, "Episode length": 917, "Policy Loss": 0.29197439551353455, "Value Loss": 10.894614219665527, "_runtime": 13967.489679574966, "_timestamp": 1585611337.122549, "_step": 461}
{"Episode reward": 63.09999999999975, "Episode length": 369, "Policy Loss": 1.6381175518035889, "Value Loss": 27.06627655029297, "_runtime": 13968.793209552765, "_timestamp": 1585611338.426079, "_step": 462}
{"Episode reward": 13.700000000000628, "Episode length": 863, "Policy Loss": 0.31325799226760864, "Value Loss": 11.575850486755371, "_runtime": 13970.350188016891, "_timestamp": 1585611339.9830575, "_step": 463}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6519013047218323, "Value Loss": 0.005484207067638636, "_runtime": 13971.856034755707, "_timestamp": 1585611341.4889042, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.655202329158783, "Value Loss": 0.005579429212957621, "_runtime": 13973.413037061691, "_timestamp": 1585611343.0459065, "_step": 465}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6620468497276306, "Value Loss": 0.005646629724651575, "_runtime": 13974.98590373993, "_timestamp": 1585611344.6187732, "_step": 466}
{"Episode reward": -99.80019419342139, "Episode length": 999, "Policy Loss": -0.6590230464935303, "Value Loss": 0.005682847928255796, "_runtime": 13976.546046972275, "_timestamp": 1585611346.1789165, "_step": 467}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6651487946510315, "Value Loss": 0.005705620162189007, "_runtime": 13977.748928308487, "_timestamp": 1585611347.3817978, "_step": 468}
{"Episode reward": 24.500000000000014, "Episode length": 755, "Policy Loss": 0.5040619373321533, "Value Loss": 13.230740547180176, "_runtime": 13979.337061166763, "_timestamp": 1585611348.9699306, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6635368466377258, "Value Loss": 0.005713363643735647, "_runtime": 13980.91558790207, "_timestamp": 1585611350.5484574, "_step": 470}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6659753918647766, "Value Loss": 0.005703925620764494, "_runtime": 13982.475153923035, "_timestamp": 1585611352.1080234, "_step": 471}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.664029598236084, "Value Loss": 0.005675655324012041, "_runtime": 13984.054610490799, "_timestamp": 1585611353.68748, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6583298444747925, "Value Loss": 0.005630585830658674, "_runtime": 13984.901131868362, "_timestamp": 1585611354.5340014, "_step": 473}
{"Episode reward": 46.89999999999952, "Episode length": 531, "Policy Loss": 1.0385650396347046, "Value Loss": 18.80986785888672, "_runtime": 13986.484345197678, "_timestamp": 1585611356.1172147, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6570628881454468, "Value Loss": 0.0055461423471570015, "_runtime": 13988.0739300251, "_timestamp": 1585611357.7067995, "_step": 475}
{"Episode reward": -99.84629712700703, "Episode length": 999, "Policy Loss": -0.6522394418716431, "Value Loss": 0.0054997969418764114, "_runtime": 13989.647718667984, "_timestamp": 1585611359.2805882, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6482654809951782, "Value Loss": 0.0054486701264977455, "_runtime": 13991.221204996109, "_timestamp": 1585611360.8540745, "_step": 477}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6423354744911194, "Value Loss": 0.0053793033584952354, "_runtime": 13992.051586151123, "_timestamp": 1585611361.6844556, "_step": 478}
{"Episode reward": 49.099999999999554, "Episode length": 509, "Policy Loss": 1.2170491218566895, "Value Loss": 19.62303352355957, "_runtime": 13992.569172382355, "_timestamp": 1585611362.2020419, "_step": 479}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 2.1793007850646973, "Value Loss": 32.74456787109375, "_runtime": 13994.144924879074, "_timestamp": 1585611363.7777944, "_step": 480}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6380010843276978, "Value Loss": 0.005285709630697966, "_runtime": 13995.68224978447, "_timestamp": 1585611365.3151193, "_step": 481}
{"Episode reward": -99.80979616641858, "Episode length": 999, "Policy Loss": -0.6404760479927063, "Value Loss": 0.005287583917379379, "_runtime": 13996.880073785782, "_timestamp": 1585611366.5129433, "_step": 482}
{"Episode reward": 20.50000000000024, "Episode length": 795, "Policy Loss": 0.3992217779159546, "Value Loss": 12.565591812133789, "_runtime": 13998.466962337494, "_timestamp": 1585611368.0998318, "_step": 483}
{"Episode reward": -99.80305140167334, "Episode length": 999, "Policy Loss": -0.6370591521263123, "Value Loss": 0.005277890712022781, "_runtime": 13999.072155952454, "_timestamp": 1585611368.7050254, "_step": 484}
{"Episode reward": 64.06683072447754, "Episode length": 360, "Policy Loss": 1.6636713743209839, "Value Loss": 27.742692947387695, "_runtime": 14000.615638017654, "_timestamp": 1585611370.2485075, "_step": 485}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6397932767868042, "Value Loss": 0.005303993355482817, "_runtime": 14001.975272893906, "_timestamp": 1585611371.6081424, "_step": 486}
{"Episode reward": 13.50000000000064, "Episode length": 865, "Policy Loss": 0.3131573796272278, "Value Loss": 11.549135208129883, "_runtime": 14002.386437416077, "_timestamp": 1585611372.019307, "_step": 487}
{"Episode reward": 73.6999999999999, "Episode length": 263, "Policy Loss": 2.501471519470215, "Value Loss": 37.97254180908203, "_runtime": 14003.941881895065, "_timestamp": 1585611373.5747514, "_step": 488}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.651178240776062, "Value Loss": 0.00544691039249301, "_runtime": 14005.51341342926, "_timestamp": 1585611375.146283, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.652797281742096, "Value Loss": 0.005520711652934551, "_runtime": 14006.583886146545, "_timestamp": 1585611376.2167556, "_step": 490}
{"Episode reward": 28.399999999999793, "Episode length": 716, "Policy Loss": 0.5186338424682617, "Value Loss": 13.951220512390137, "_runtime": 14008.104843616486, "_timestamp": 1585611377.737713, "_step": 491}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": 0.2040153294801712, "Value Loss": 10.215250015258789, "_runtime": 14008.620396137238, "_timestamp": 1585611378.2532656, "_step": 492}
{"Episode reward": 70.09999999999985, "Episode length": 299, "Policy Loss": 2.517192840576172, "Value Loss": 33.400062561035156, "_runtime": 14009.410499572754, "_timestamp": 1585611379.043369, "_step": 493}
{"Episode reward": 48.59999999999955, "Episode length": 514, "Policy Loss": 1.4103139638900757, "Value Loss": 19.431394577026367, "_runtime": 14010.978467941284, "_timestamp": 1585611380.6113374, "_step": 494}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6801596283912659, "Value Loss": 0.005962996743619442, "_runtime": 14012.483695030212, "_timestamp": 1585611382.1165645, "_step": 495}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.683303713798523, "Value Loss": 0.006075682584196329, "_runtime": 14013.25100684166, "_timestamp": 1585611382.8838763, "_step": 496}
{"Episode reward": 52.4999999999996, "Episode length": 475, "Policy Loss": 1.0365066528320312, "Value Loss": 21.025728225708008, "_runtime": 14014.81945514679, "_timestamp": 1585611384.4523246, "_step": 497}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6960490942001343, "Value Loss": 0.006266605108976364, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198, -0.16176453232765198]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0], "bins": [-22.152570724487305, -21.803909301757812, -21.45524787902832, -21.106586456298828, -20.757925033569336, -20.409263610839844, -20.06060218811035, -19.71194076538086, -19.363279342651367, -19.014617919921875, -18.665956497192383, -18.31729507446289, -17.968631744384766, -17.619972229003906, -17.27130889892578, -16.922649383544922, -16.573986053466797, -16.225326538085938, -15.876664161682129, -15.528002738952637, -15.179341316223145, -14.830678939819336, -14.482017517089844, -14.133357048034668, -13.78469467163086, -13.436033248901367, -13.087371826171875, -12.738710403442383, -12.39004898071289, -12.041387557983398, -11.692726135253906, -11.344064712524414, -10.995403289794922, -10.64674186706543, -10.298080444335938, -9.949419021606445, -9.600757598876953, -9.252096176147461, -8.903434753417969, -8.554773330688477, -8.206111907958984, -7.857449531555176, -7.508788108825684, -7.160126686096191, -6.811465263366699, -6.462803840637207, -6.114143371582031, -5.765481948852539, -5.416818618774414, -5.068157196044922, -4.71949577331543, -4.3708343505859375, -4.022172927856445, -3.673511505126953, -3.324850082397461, -2.9761886596679688, -2.6275272369384766, -2.2788658142089844, -1.9302043914794922, -1.58154296875, -1.2328815460205078, -0.8842201232910156, -0.5355587005615234, -0.18689727783203125, 0.16176414489746094]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.4681782126426697, -0.455081582069397, -0.44198495149612427, -0.42888832092285156, -0.41579169034957886, -0.40269505977630615, -0.38959845900535583, -0.37650182843208313, -0.3634051978588104, -0.3503085672855377, -0.337211936712265, -0.3241153359413147, -0.311018705368042, -0.2979220747947693, -0.2848254442214966, -0.2717288136482239, -0.25863218307495117, -0.24553555250167847, -0.23243892192840576, -0.21934230625629425, -0.20624566078186035, -0.19314906001091003, -0.18005242943763733, -0.16695579886436462, -0.15385916829109192, -0.1407625377178192, -0.1276659071445465, -0.1145692765712738, -0.10147267580032349, -0.08837604522705078, -0.07527941465377808, -0.06218278408050537, -0.049086153507232666, -0.03598952293395996, -0.022892892360687256, -0.00979626178741455, 0.0033003687858581543, 0.01639696955680847, 0.029493600130081177, 0.04259026050567627, 0.055686891078948975, 0.0687834620475769, 0.08188009262084961, 0.09497672319412231, 0.10807335376739502, 0.12116998434066772, 0.13426661491394043, 0.14736324548721313, 0.16045987606048584, 0.17355650663375854, 0.18665313720703125, 0.19974976778030396, 0.21284639835357666, 0.22594302892684937, 0.23903965950012207, 0.2521362900733948, 0.2652328610420227, 0.2783294916152954, 0.2914261221885681, 0.3045227527618408, 0.3176193833351135, 0.33071601390838623, 0.34381264448165894, 0.35690927505493164, 0.37000590562820435]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 6.0, 0.0, 1.0, 8.0, 4.0, 4.0, 8.0, 15.0, 30.0, 27.0, 4.0, 1.0, 0.0, 224.0, 0.0, 0.0, 10.0, 22.0, 43.0, 20.0, 27.0, 14.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0], "bins": [-2.1803135871887207, -2.11923885345459, -2.058164119720459, -1.9970895051956177, -1.9360147714614868, -1.874940037727356, -1.8138654232025146, -1.7527906894683838, -1.691715955734253, -1.630641222000122, -1.5695664882659912, -1.50849187374115, -1.447417140007019, -1.3863424062728882, -1.3252677917480469, -1.264193058013916, -1.2031183242797852, -1.1420435905456543, -1.0809688568115234, -1.0198942422866821, -0.9588195085525513, -0.8977447748184204, -0.8366701602935791, -0.7755954265594482, -0.7145206928253174, -0.6534459590911865, -0.5923712253570557, -0.5312966108322144, -0.4702218770980835, -0.40914714336395264, -0.34807252883911133, -0.28699779510498047, -0.2259230613708496, -0.16484832763671875, -0.10377359390258789, -0.04269886016845703, 0.018375873565673828, 0.07945036888122559, 0.14052510261535645, 0.2015998363494873, 0.26267457008361816, 0.323749303817749, 0.3848240375518799, 0.44589877128601074, 0.5069732666015625, 0.5680480003356934, 0.6291227340698242, 0.6901974678039551, 0.7512722015380859, 0.8123469352722168, 0.8734216690063477, 0.9344964027404785, 0.9955711364746094, 1.0566456317901611, 1.117720365524292, 1.1787950992584229, 1.2398698329925537, 1.3009445667266846, 1.3620193004608154, 1.4230940341949463, 1.484168529510498, 1.545243263244629, 1.6063179969787598, 1.6673927307128906, 1.7284674644470215]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-8.883672714233398, -8.705389022827148, -8.527106285095215, -8.348822593688965, -8.170539855957031, -7.992256164550781, -7.813972473144531, -7.6356892585754395, -7.457406044006348, -7.279122829437256, -7.100839614868164, -6.922555923461914, -6.744272708892822, -6.5659894943237305, -6.3877058029174805, -6.209422588348389, -6.031139373779297, -5.852856159210205, -5.674572944641113, -5.496289253234863, -5.3180060386657715, -5.13972282409668, -4.96143913269043, -4.783155918121338, -4.604872703552246, -4.426589488983154, -4.2483062744140625, -4.0700225830078125, -3.8917393684387207, -3.713456153869629, -3.535172462463379, -3.356889247894287, -3.1786060333251953, -3.0003228187561035, -2.8220396041870117, -2.6437559127807617, -2.46547269821167, -2.287189483642578, -2.108905792236328, -1.9306225776672363, -1.7523393630981445, -1.5740561485290527, -1.395772933959961, -1.217489242553711, -1.0392060279846191, -0.8609228134155273, -0.6826391220092773, -0.5043563842773438, -0.32607269287109375, -0.14778900146484375, 0.030493736267089844, 0.20877742767333984, 0.38706016540527344, 0.5653438568115234, 0.7436275482177734, 0.921910285949707, 1.100193977355957, 1.278477668762207, 1.4567604064941406, 1.6350440979003906, 1.8133277893066406, 1.9916105270385742, 2.169894218444824, 2.348176956176758, 2.526460647583008]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 30.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-1.3098806142807007, -1.2184710502624512, -1.127061367034912, -1.0356518030166626, -0.9442422389984131, -0.8528326749801636, -0.7614230513572693, -0.670013427734375, -0.5786038637161255, -0.487194299697876, -0.3957846760749817, -0.3043750524520874, -0.2129654884338379, -0.12155592441558838, -0.030146241188049316, 0.061263322830200195, 0.1526728868484497, 0.24408245086669922, 0.33549201488494873, 0.4269016981124878, 0.5183112621307373, 0.6097208261489868, 0.7011305093765259, 0.7925399541854858, 0.8839496374130249, 0.975359320640564, 1.066768765449524, 1.158178448677063, 1.249588131904602, 1.340997576713562, 1.432407259941101, 1.523816704750061, 1.6152263879776, 1.7066360712051392, 1.7980455160140991, 1.8894551992416382, 1.9808646440505981, 2.0722742080688477, 2.1636838912963867, 2.255093574523926, 2.346503257751465, 2.437912940979004, 2.5293221473693848, 2.620731830596924, 2.712141513824463, 2.803551197052002, 2.894960403442383, 2.986370086669922, 3.077779769897461, 3.169189453125, 3.260599136352539, 3.35200834274292, 3.443418025970459, 3.534827709197998, 3.626237392425537, 3.717647075653076, 3.8090567588806152, 3.900465965270996, 3.991875648498535, 4.083285331726074, 4.174695014953613, 4.266104698181152, 4.357513904571533, 4.448923587799072, 4.540333271026611]}, "_runtime": 14015.393207073212, "_timestamp": 1585611385.0260766, "_step": 498}
{"Episode reward": 65.09999999999978, "Episode length": 349, "Policy Loss": 1.9210072755813599, "Value Loss": 28.61394500732422, "_runtime": 14015.393207073212, "_timestamp": 1585611385.0260766, "_step": 499}
