{"Episode reward": -38.62308233654989, "Episode length": 999, "Policy Loss": -0.03885025158524513, "Value Loss": 0.005159379448741674, "_runtime": 6130.549278497696, "_timestamp": 1585576046.3939118, "_step": 0}
{"Episode reward": -98.48853299092748, "Episode length": 999, "Policy Loss": -0.2578744888305664, "Value Loss": 1.8986691236495972, "_runtime": 6131.514981031418, "_timestamp": 1585576047.3596144, "_step": 1}
{"Episode reward": 35.78687031778328, "Episode length": 644, "Policy Loss": 0.9588594436645508, "Value Loss": 16.578533172607422, "_runtime": 6133.152662992477, "_timestamp": 1585576048.9972963, "_step": 2}
{"Episode reward": -99.7266173377852, "Episode length": 999, "Policy Loss": -0.5567444562911987, "Value Loss": 0.9838351011276245, "_runtime": 6134.718103885651, "_timestamp": 1585576050.5627372, "_step": 3}
{"Episode reward": -99.48111630054055, "Episode length": 999, "Policy Loss": -0.5204825401306152, "Value Loss": 1.8752975463867188, "_runtime": 6135.719774723053, "_timestamp": 1585576051.564408, "_step": 4}
{"Episode reward": 34.99999999999942, "Episode length": 650, "Policy Loss": 0.5281556844711304, "Value Loss": 15.337644577026367, "_runtime": 6136.147953271866, "_timestamp": 1585576051.9925866, "_step": 5}
{"Episode reward": 76.60351170708886, "Episode length": 234, "Policy Loss": 1.901952862739563, "Value Loss": 43.62246322631836, "_runtime": 6137.040445804596, "_timestamp": 1585576052.8850791, "_step": 6}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.5058354735374451, "Value Loss": 17.44938850402832, "_runtime": 6138.590842962265, "_timestamp": 1585576054.4354763, "_step": 7}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7722039222717285, "Value Loss": 0.30238234996795654, "_runtime": 6139.9831647872925, "_timestamp": 1585576055.8277981, "_step": 8}
{"Episode reward": 7.993424675777575, "Episode length": 921, "Policy Loss": 0.17712150514125824, "Value Loss": 11.164445877075195, "_runtime": 6141.5445964336395, "_timestamp": 1585576057.3892298, "_step": 9}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8247056007385254, "Value Loss": 0.050013039261102676, "_runtime": 6143.130685806274, "_timestamp": 1585576058.9753191, "_step": 10}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8430984020233154, "Value Loss": 0.22724318504333496, "_runtime": 6144.682926893234, "_timestamp": 1585576060.5275602, "_step": 11}
{"Episode reward": -99.82475692993118, "Episode length": 999, "Policy Loss": -1.0905401706695557, "Value Loss": 0.5096715092658997, "_runtime": 6146.274081707001, "_timestamp": 1585576062.118715, "_step": 12}
{"Episode reward": -99.80657767206291, "Episode length": 999, "Policy Loss": -0.9992212653160095, "Value Loss": 0.12103034555912018, "_runtime": 6147.055402755737, "_timestamp": 1585576062.900036, "_step": 13}
{"Episode reward": 52.58963038176258, "Episode length": 476, "Policy Loss": -0.6660158038139343, "Value Loss": 20.994888305664062, "_runtime": 6148.627990961075, "_timestamp": 1585576064.4726243, "_step": 14}
{"Episode reward": -99.81893822103599, "Episode length": 999, "Policy Loss": -1.167642593383789, "Value Loss": 0.06804486364126205, "_runtime": 6150.116203784943, "_timestamp": 1585576065.9608371, "_step": 15}
{"Episode reward": 6.692445209959189, "Episode length": 936, "Policy Loss": -0.21787211298942566, "Value Loss": 10.795454978942871, "_runtime": 6151.660199403763, "_timestamp": 1585576067.5048327, "_step": 16}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0647168159484863, "Value Loss": 0.06424123793840408, "_runtime": 6153.25400853157, "_timestamp": 1585576069.0986419, "_step": 17}
{"Episode reward": -99.68521143942932, "Episode length": 999, "Policy Loss": -1.0495258569717407, "Value Loss": 0.026980167254805565, "_runtime": 6154.738775968552, "_timestamp": 1585576070.5834093, "_step": 18}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": 0.06767860054969788, "Value Loss": 10.877297401428223, "_runtime": 6156.330667972565, "_timestamp": 1585576072.1753013, "_step": 19}
{"Episode reward": -99.80159008651832, "Episode length": 999, "Policy Loss": -1.0043057203292847, "Value Loss": 0.03505586460232735, "_runtime": 6157.437269449234, "_timestamp": 1585576073.2819028, "_step": 20}
{"Episode reward": 33.48076847754369, "Episode length": 666, "Policy Loss": 0.19814535975456238, "Value Loss": 15.127957344055176, "_runtime": 6159.044193744659, "_timestamp": 1585576074.888827, "_step": 21}
{"Episode reward": -99.80597835928062, "Episode length": 999, "Policy Loss": -0.9584757685661316, "Value Loss": 0.02080906555056572, "_runtime": 6160.278369426727, "_timestamp": 1585576076.1230028, "_step": 22}
{"Episode reward": 22.900000000000105, "Episode length": 771, "Policy Loss": 0.2936021089553833, "Value Loss": 13.003544807434082, "_runtime": 6161.828217744827, "_timestamp": 1585576077.672851, "_step": 23}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9179937839508057, "Value Loss": 0.014388803392648697, "_runtime": 6163.352830886841, "_timestamp": 1585576079.1974642, "_step": 24}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": -0.12558923661708832, "Value Loss": 10.466273307800293, "_runtime": 6164.680947780609, "_timestamp": 1585576080.5255811, "_step": 25}
{"Episode reward": 15.736333548650663, "Episode length": 843, "Policy Loss": -0.02571083791553974, "Value Loss": 11.758084297180176, "_runtime": 6165.635036230087, "_timestamp": 1585576081.4796696, "_step": 26}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": 0.3662431836128235, "Value Loss": 16.570096969604492, "_runtime": 6167.228040218353, "_timestamp": 1585576083.0726736, "_step": 27}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9094312191009521, "Value Loss": 0.053635839372873306, "_runtime": 6168.798600912094, "_timestamp": 1585576084.6432343, "_step": 28}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8993192911148071, "Value Loss": 0.10913223773241043, "_runtime": 6170.346279382706, "_timestamp": 1585576086.1909127, "_step": 29}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8475434184074402, "Value Loss": 0.16398939490318298, "_runtime": 6171.924889087677, "_timestamp": 1585576087.7695224, "_step": 30}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8261628150939941, "Value Loss": 0.025965718552470207, "_runtime": 6173.508501529694, "_timestamp": 1585576089.3531349, "_step": 31}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7760754823684692, "Value Loss": 0.014922735281288624, "_runtime": 6175.084513425827, "_timestamp": 1585576090.9291468, "_step": 32}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7166772484779358, "Value Loss": 0.026066655293107033, "_runtime": 6176.678203582764, "_timestamp": 1585576092.522837, "_step": 33}
{"Episode reward": -99.72897642424657, "Episode length": 999, "Policy Loss": -0.6595388650894165, "Value Loss": 0.016180308535695076, "_runtime": 6178.260520935059, "_timestamp": 1585576094.1051543, "_step": 34}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5936939716339111, "Value Loss": 0.013950936496257782, "_runtime": 6179.839939117432, "_timestamp": 1585576095.6845725, "_step": 35}
{"Episode reward": -99.81579509386653, "Episode length": 999, "Policy Loss": -0.5557374954223633, "Value Loss": 0.03624695912003517, "_runtime": 6181.471860170364, "_timestamp": 1585576097.3164935, "_step": 36}
{"Episode reward": -99.81433836966613, "Episode length": 999, "Policy Loss": -0.5187840461730957, "Value Loss": 0.05383312702178955, "_runtime": 6183.070552110672, "_timestamp": 1585576098.9151855, "_step": 37}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5263539552688599, "Value Loss": 0.060735393315553665, "_runtime": 6184.65234708786, "_timestamp": 1585576100.4969804, "_step": 38}
{"Episode reward": -99.80527928033705, "Episode length": 999, "Policy Loss": -0.43542760610580444, "Value Loss": 0.027122242376208305, "_runtime": 6186.254302740097, "_timestamp": 1585576102.098936, "_step": 39}
{"Episode reward": -99.81453329473594, "Episode length": 999, "Policy Loss": -0.42653998732566833, "Value Loss": 0.007598822470754385, "_runtime": 6187.29811835289, "_timestamp": 1585576103.1427517, "_step": 40}
{"Episode reward": 35.49999999999939, "Episode length": 645, "Policy Loss": 0.6329118609428406, "Value Loss": 15.623353958129883, "_runtime": 6188.566908597946, "_timestamp": 1585576104.411542, "_step": 41}
{"Episode reward": 19.423652754643214, "Episode length": 807, "Policy Loss": 0.6622568368911743, "Value Loss": 12.39847183227539, "_runtime": 6190.164957523346, "_timestamp": 1585576106.0095909, "_step": 42}
{"Episode reward": -99.87606130875507, "Episode length": 999, "Policy Loss": -0.46793586015701294, "Value Loss": 0.05991179496049881, "_runtime": 6191.725960016251, "_timestamp": 1585576107.5705934, "_step": 43}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5679560303688049, "Value Loss": 0.03263023868203163, "_runtime": 6192.351610660553, "_timestamp": 1585576108.196244, "_step": 44}
{"Episode reward": 62.09999999999974, "Episode length": 379, "Policy Loss": 1.5408695936203003, "Value Loss": 26.05142593383789, "_runtime": 6193.892065525055, "_timestamp": 1585576109.7366989, "_step": 45}
{"Episode reward": 2.300000000001276, "Episode length": 977, "Policy Loss": 0.19004149734973907, "Value Loss": 10.120345115661621, "_runtime": 6195.475292444229, "_timestamp": 1585576111.3199258, "_step": 46}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7457846403121948, "Value Loss": 0.0792364627122879, "_runtime": 6197.002583026886, "_timestamp": 1585576112.8472164, "_step": 47}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8833091855049133, "Value Loss": 0.1649159938097, "_runtime": 6198.594852924347, "_timestamp": 1585576114.4394863, "_step": 48}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9272935390472412, "Value Loss": 0.19732078909873962, "_runtime": 6200.19019985199, "_timestamp": 1585576116.0348332, "_step": 49}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9104745388031006, "Value Loss": 0.07685144990682602, "_runtime": 6201.7679669857025, "_timestamp": 1585576117.6126003, "_step": 50}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8836443424224854, "Value Loss": 0.021534323692321777, "_runtime": 6203.382386207581, "_timestamp": 1585576119.2270195, "_step": 51}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9038717150688171, "Value Loss": 0.040663182735443115, "_runtime": 6205.018021821976, "_timestamp": 1585576120.8626552, "_step": 52}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8739784955978394, "Value Loss": 0.020048480480909348, "_runtime": 6206.338251113892, "_timestamp": 1585576122.1828845, "_step": 53}
{"Episode reward": 16.800000000000452, "Episode length": 832, "Policy Loss": 0.22610583901405334, "Value Loss": 12.068198204040527, "_runtime": 6207.937048435211, "_timestamp": 1585576123.7816818, "_step": 54}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8108929991722107, "Value Loss": 0.010310361161828041, "_runtime": 6208.683170795441, "_timestamp": 1585576124.5278041, "_step": 55}
{"Episode reward": 54.49999999999963, "Episode length": 455, "Policy Loss": 1.2064275741577148, "Value Loss": 21.961429595947266, "_runtime": 6210.251813173294, "_timestamp": 1585576126.0964465, "_step": 56}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7629344463348389, "Value Loss": 0.008575797080993652, "_runtime": 6211.858282804489, "_timestamp": 1585576127.7029161, "_step": 57}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7334965467453003, "Value Loss": 0.009280442260205746, "_runtime": 6213.364108324051, "_timestamp": 1585576129.2087417, "_step": 58}
{"Episode reward": 2.600000000001259, "Episode length": 974, "Policy Loss": 0.2813917100429535, "Value Loss": 10.244065284729004, "_runtime": 6214.750066757202, "_timestamp": 1585576130.5947, "_step": 59}
{"Episode reward": 12.892442870140755, "Episode length": 872, "Policy Loss": 0.4565354585647583, "Value Loss": 11.475674629211426, "_runtime": 6216.345750331879, "_timestamp": 1585576132.1903837, "_step": 60}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6011021137237549, "Value Loss": 0.03760818764567375, "_runtime": 6217.412296295166, "_timestamp": 1585576133.2569296, "_step": 61}
{"Episode reward": 33.999999999999474, "Episode length": 660, "Policy Loss": 0.9497345685958862, "Value Loss": 15.061727523803711, "_runtime": 6218.457895278931, "_timestamp": 1585576134.3025286, "_step": 62}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 0.9297349452972412, "Value Loss": 15.248845100402832, "_runtime": 6220.058027744293, "_timestamp": 1585576135.902661, "_step": 63}
{"Episode reward": -99.86506690978864, "Episode length": 999, "Policy Loss": -0.48245835304260254, "Value Loss": 0.010349078103899956, "_runtime": 6221.622435569763, "_timestamp": 1585576137.467069, "_step": 64}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4542164206504822, "Value Loss": 0.003112879814580083, "_runtime": 6222.488143205643, "_timestamp": 1585576138.3327765, "_step": 65}
{"Episode reward": 45.93190526962231, "Episode length": 541, "Policy Loss": 1.2932358980178833, "Value Loss": 18.3956241607666, "_runtime": 6224.001699924469, "_timestamp": 1585576139.8463333, "_step": 66}
{"Episode reward": 5.000000000001123, "Episode length": 950, "Policy Loss": 0.5476132035255432, "Value Loss": 10.4556884765625, "_runtime": 6225.578882455826, "_timestamp": 1585576141.4235158, "_step": 67}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47057780623435974, "Value Loss": 0.013112775981426239, "_runtime": 6227.13365483284, "_timestamp": 1585576142.9782882, "_step": 68}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.46903347969055176, "Value Loss": 0.10325832664966583, "_runtime": 6228.758759260178, "_timestamp": 1585576144.6033926, "_step": 69}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4700469672679901, "Value Loss": 0.07775956392288208, "_runtime": 6229.924821138382, "_timestamp": 1585576145.7694545, "_step": 70}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 0.8446089625358582, "Value Loss": 13.497513771057129, "_runtime": 6231.501041173935, "_timestamp": 1585576147.3456745, "_step": 71}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40828824043273926, "Value Loss": 0.008734446950256824, "_runtime": 6233.08499455452, "_timestamp": 1585576148.929628, "_step": 72}
{"Episode reward": -99.85794718265393, "Episode length": 999, "Policy Loss": -0.3909551203250885, "Value Loss": 0.006565472576767206, "_runtime": 6234.652061223984, "_timestamp": 1585576150.4966946, "_step": 73}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3555683493614197, "Value Loss": 0.003508390625938773, "_runtime": 6236.154470682144, "_timestamp": 1585576151.999104, "_step": 74}
{"Episode reward": 4.70000000000114, "Episode length": 953, "Policy Loss": 0.6885135173797607, "Value Loss": 10.493013381958008, "_runtime": 6237.749577045441, "_timestamp": 1585576153.5942104, "_step": 75}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3751943111419678, "Value Loss": 0.013348930515348911, "_runtime": 6238.8400592803955, "_timestamp": 1585576154.6846926, "_step": 76}
{"Episode reward": 31.699999999999605, "Episode length": 683, "Policy Loss": 1.0042222738265991, "Value Loss": 14.452695846557617, "_runtime": 6239.531765937805, "_timestamp": 1585576155.3763993, "_step": 77}
{"Episode reward": 57.49999999999967, "Episode length": 425, "Policy Loss": 1.7904486656188965, "Value Loss": 22.95586585998535, "_runtime": 6241.11744427681, "_timestamp": 1585576156.9620776, "_step": 78}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6045028567314148, "Value Loss": 0.08215770870447159, "_runtime": 6242.676331758499, "_timestamp": 1585576158.520965, "_step": 79}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7277833223342896, "Value Loss": 0.3048604726791382, "_runtime": 6244.200669288635, "_timestamp": 1585576160.0453026, "_step": 80}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8111635446548462, "Value Loss": 0.14638863503932953, "_runtime": 6244.829014778137, "_timestamp": 1585576160.673648, "_step": 81}
{"Episode reward": 62.19999999999974, "Episode length": 378, "Policy Loss": 1.8848527669906616, "Value Loss": 25.832015991210938, "_runtime": 6246.408690690994, "_timestamp": 1585576162.253324, "_step": 82}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8069207072257996, "Value Loss": 0.11677374690771103, "_runtime": 6247.976115226746, "_timestamp": 1585576163.8207486, "_step": 83}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7243356108665466, "Value Loss": 0.02066054940223694, "_runtime": 6249.497654676437, "_timestamp": 1585576165.342288, "_step": 84}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6840026378631592, "Value Loss": 0.024315260350704193, "_runtime": 6250.515607118607, "_timestamp": 1585576166.3602405, "_step": 85}
{"Episode reward": 36.79999999999938, "Episode length": 632, "Policy Loss": 0.8783401250839233, "Value Loss": 15.625537872314453, "_runtime": 6252.123396873474, "_timestamp": 1585576167.9680302, "_step": 86}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5802485942840576, "Value Loss": 0.019045624881982803, "_runtime": 6253.693156719208, "_timestamp": 1585576169.53779, "_step": 87}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5388944745063782, "Value Loss": 0.011921827681362629, "_runtime": 6255.243558168411, "_timestamp": 1585576171.0881915, "_step": 88}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.506077229976654, "Value Loss": 0.010186998173594475, "_runtime": 6256.824771165848, "_timestamp": 1585576172.6694045, "_step": 89}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47946590185165405, "Value Loss": 0.012083126232028008, "_runtime": 6257.957242965698, "_timestamp": 1585576173.8018763, "_step": 90}
{"Episode reward": 29.49999999999973, "Episode length": 705, "Policy Loss": 1.6194380521774292, "Value Loss": 14.120950698852539, "_runtime": 6259.544735431671, "_timestamp": 1585576175.3893688, "_step": 91}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.42489007115364075, "Value Loss": 0.003538319142535329, "_runtime": 6261.139091491699, "_timestamp": 1585576176.9837248, "_step": 92}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40035414695739746, "Value Loss": 0.002732187742367387, "_runtime": 6262.357387542725, "_timestamp": 1585576178.202021, "_step": 93}
{"Episode reward": 22.500000000000128, "Episode length": 775, "Policy Loss": 0.9369359612464905, "Value Loss": 12.810224533081055, "_runtime": 6262.966017246246, "_timestamp": 1585576178.8106506, "_step": 94}
{"Episode reward": 64.29999999999977, "Episode length": 357, "Policy Loss": 2.936331033706665, "Value Loss": 27.705419540405273, "_runtime": 6263.465462446213, "_timestamp": 1585576179.3100958, "_step": 95}
{"Episode reward": 70.79999999999987, "Episode length": 292, "Policy Loss": 3.015223979949951, "Value Loss": 33.57271194458008, "_runtime": 6265.03377866745, "_timestamp": 1585576180.878412, "_step": 96}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.44363346695899963, "Value Loss": 0.14330066740512848, "_runtime": 6266.146980762482, "_timestamp": 1585576181.991614, "_step": 97}
{"Episode reward": 27.599999999999838, "Episode length": 724, "Policy Loss": 0.8177257776260376, "Value Loss": 13.498391151428223, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813, -0.0032019689679145813]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.9838132858276367, -0.9683911800384521, -0.9529690742492676, -0.937546968460083, -0.9221248626708984, -0.9067026972770691, -0.8912805914878845, -0.8758584856987, -0.8604363799095154, -0.8450142741203308, -0.8295921683311462, -0.8141700029373169, -0.7987478971481323, -0.7833257913589478, -0.7679036855697632, -0.7524815797805786, -0.737059473991394, -0.7216373682022095, -0.7062152624130249, -0.6907931566238403, -0.6753710508346558, -0.6599489450454712, -0.6445267796516418, -0.6291046738624573, -0.6136825680732727, -0.5982604622840881, -0.5828383564949036, -0.5674161911010742, -0.5519940853118896, -0.5365719795227051, -0.5211498737335205, -0.5057277679443359, -0.49030566215515137, -0.4748835563659668, -0.4594614505767822, -0.44403934478759766, -0.4286172389984131, -0.41319507360458374, -0.39777296781539917, -0.3823508620262146, -0.36692875623703003, -0.35150665044784546, -0.3360845446586609, -0.3206624388694763, -0.305240273475647, -0.2898181676864624, -0.27439606189727783, -0.25897395610809326, -0.2435518503189087, -0.22812974452972412, -0.21270763874053955, -0.19728553295135498, -0.1818634271621704, -0.16644126176834106, -0.1510191559791565, -0.13559705018997192, -0.12017494440078735, -0.10475283861160278, -0.08933073282241821, -0.07390862703323364, -0.0584864616394043, -0.04306435585021973, -0.027642250061035156, -0.012220144271850586, 0.0032019615173339844]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.01282764133065939, -0.012627209536731243, -0.012426777742803097, -0.01222634594887495, -0.012025914154946804, -0.011825481429696083, -0.011625049635767937, -0.01142461784183979, -0.011224186047911644, -0.011023754253983498, -0.010823322460055351, -0.010622890666127205, -0.010422458872199059, -0.010222027078270912, -0.010021595284342766, -0.009821162559092045, -0.009620730765163898, -0.009420298971235752, -0.009219867177307606, -0.00901943538337946, -0.008819003589451313, -0.008618570864200592, -0.008418139070272446, -0.0082177072763443, -0.008017275482416153, -0.007816843688488007, -0.00761641189455986, -0.007415980100631714, -0.0072155483067035675, -0.007015116512775421, -0.0068146842531859875, -0.006614252459257841, -0.006413820665329695, -0.006213388871401548, -0.006012957077473402, -0.005812524817883968, -0.005612093023955822, -0.005411661230027676, -0.005211229436099529, -0.005010797642171383, -0.0048103658482432365, -0.00460993405431509, -0.004409501329064369, -0.004209069535136223, -0.0040086377412080765, -0.00380820594727993, -0.0036077741533517838, -0.0034073423594236374, -0.003206910565495491, -0.0030064787715673447, -0.0028060469776391983, -0.0026056142523884773, -0.002405182458460331, -0.0022047506645321846, -0.0020043188706040382, -0.0018038870766758919, -0.0016034552827477455, -0.0014030234888195992, -0.0012025916948914528, -0.0010021599009633064, -0.0008017271757125854, -0.0006012953817844391, -0.0004008635878562927, -0.00020043179392814636, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 4.0, 5.0, 8.0, 8.0, 9.0, 6.0, 7.0, 6.0, 5.0, 3.0, 5.0, 8.0, 3.0, 5.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 320.0, 0.0, 0.0, 0.0, 1.0, 33.0, 21.0, 1.0, 10.0], "bins": [-0.08639830350875854, -0.08484333753585815, -0.08328837156295776, -0.08173340559005737, -0.08017843961715698, -0.07862347364425659, -0.0770685076713562, -0.07551354169845581, -0.07395857572555542, -0.07240360975265503, -0.07084864377975464, -0.06929367780685425, -0.06773871183395386, -0.06618374586105347, -0.06462877243757248, -0.06307380646467209, -0.0615188404917717, -0.05996387451887131, -0.05840890854597092, -0.056853942573070526, -0.055298976600170135, -0.053744010627269745, -0.052189044654369354, -0.050634078681468964, -0.04907911270856857, -0.04752414673566818, -0.04596918076276779, -0.0444142110645771, -0.04285924509167671, -0.04130427911877632, -0.03974931314587593, -0.03819434717297554, -0.03663938120007515, -0.03508441522717476, -0.03352944925427437, -0.03197448328137398, -0.030419517308473587, -0.028864551335573196, -0.027309581637382507, -0.025754615664482117, -0.024199649691581726, -0.022644683718681335, -0.021089717745780945, -0.019534751772880554, -0.017979785799980164, -0.016424819827079773, -0.014869853854179382, -0.013314887881278992, -0.011759921908378601, -0.01020495593547821, -0.00864998996257782, -0.007095023989677429, -0.005540058016777039, -0.003985092043876648, -0.0024301186203956604, -0.0008751526474952698, 0.0006798133254051208, 0.0022347792983055115, 0.003789745271205902, 0.005344711244106293, 0.006899677217006683, 0.008454643189907074, 0.010009609162807465, 0.011564575135707855, 0.013119541108608246]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 7.0, 1.0, 1.0], "bins": [-0.33957821130752563, -0.33404865860939026, -0.32851913571357727, -0.3229895830154419, -0.3174600601196289, -0.31193050742149353, -0.30640098452568054, -0.30087143182754517, -0.2953419089317322, -0.2898123562335968, -0.2842828333377838, -0.27875328063964844, -0.27322375774383545, -0.2676942050457001, -0.2621646523475647, -0.2566351294517517, -0.2511056065559387, -0.24557605385780334, -0.24004651606082916, -0.23451697826385498, -0.2289874404668808, -0.22345790266990662, -0.21792834997177124, -0.21239882707595825, -0.20686927437782288, -0.2013397365808487, -0.1958101987838745, -0.19028066098690033, -0.18475112318992615, -0.17922158539295197, -0.17369204759597778, -0.1681625097990036, -0.16263297200202942, -0.15710343420505524, -0.15157389640808105, -0.14604435861110687, -0.1405148208141327, -0.1349852830171585, -0.12945574522018433, -0.12392620742321014, -0.11839666962623596, -0.11286711692810059, -0.1073375791311264, -0.10180804133415222, -0.09627850353717804, -0.09074896574020386, -0.08521944284439087, -0.0796898901462555, -0.07416033744812012, -0.06863081455230713, -0.06310126185417175, -0.057571738958358765, -0.05204218626022339, -0.0465126633644104, -0.040983110666275024, -0.035453587770462036, -0.02992403507232666, -0.024394512176513672, -0.018864959478378296, -0.013335436582565308, -0.007805883884429932, -0.0022763609886169434, 0.0032531917095184326, 0.008782714605331421, 0.014312267303466797]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 21.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 2.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 4.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.03147144243121147, -0.019312452524900436, -0.007153462618589401, 0.005005527287721634, 0.01716451719403267, 0.029323507100343704, 0.04148249700665474, 0.053641486912965775, 0.06580047309398651, 0.07795946300029755, 0.09011845290660858, 0.10227744281291962, 0.11443643271923065, 0.1265954226255417, 0.13875441253185272, 0.15091340243816376, 0.1630723923444748, 0.17523138225078583, 0.18739037215709686, 0.1995493620634079, 0.21170835196971893, 0.22386734187602997, 0.236026331782341, 0.24818532168865204, 0.26034432649612427, 0.2725033164024353, 0.28466230630874634, 0.2968212962150574, 0.3089802861213684, 0.32113927602767944, 0.3332982659339905, 0.3454572558403015, 0.35761624574661255, 0.3697752356529236, 0.3819342255592346, 0.39409321546554565, 0.4062522053718567, 0.4184111952781677, 0.43057018518447876, 0.4427291750907898, 0.45488816499710083, 0.46704715490341187, 0.4792061448097229, 0.49136513471603394, 0.503524124622345, 0.515683114528656, 0.527842104434967, 0.5400010943412781, 0.5521600842475891, 0.5643190741539001, 0.5764780640602112, 0.5886370539665222, 0.6007960438728333, 0.6129550337791443, 0.6251140236854553, 0.6372730135917664, 0.6494320034980774, 0.6615909934043884, 0.6737499833106995, 0.6859089732170105, 0.6980679631233215, 0.7102269530296326, 0.7223859429359436, 0.7345449328422546, 0.7467039227485657]}, "_runtime": 6266.622469425201, "_timestamp": 1585576182.4671028, "_step": 98}
{"Episode reward": 69.19999999999985, "Episode length": 308, "Policy Loss": 2.5282504558563232, "Value Loss": 31.02498435974121, "_runtime": 6268.189110517502, "_timestamp": 1585576184.0337439, "_step": 99}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6899783611297607, "Value Loss": 0.2757399082183838, "_runtime": 6269.742848873138, "_timestamp": 1585576185.5874822, "_step": 100}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7629395723342896, "Value Loss": 0.01220171619206667, "_runtime": 6271.262921571732, "_timestamp": 1585576187.107555, "_step": 101}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8529399037361145, "Value Loss": 0.06039448827505112, "_runtime": 6272.838380813599, "_timestamp": 1585576188.6830142, "_step": 102}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8708229660987854, "Value Loss": 0.024910759180784225, "_runtime": 6273.944900512695, "_timestamp": 1585576189.7895339, "_step": 103}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.4313028156757355, "Value Loss": 13.942986488342285, "_runtime": 6275.119623184204, "_timestamp": 1585576190.9642565, "_step": 104}
{"Episode reward": 25.59999999999995, "Episode length": 744, "Policy Loss": 0.34545233845710754, "Value Loss": 12.980786323547363, "_runtime": 6276.754396915436, "_timestamp": 1585576192.5990303, "_step": 105}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9900862574577332, "Value Loss": 0.26149433851242065, "_runtime": 6278.089756011963, "_timestamp": 1585576193.9343894, "_step": 106}
{"Episode reward": 14.100000000000605, "Episode length": 859, "Policy Loss": 0.2216482162475586, "Value Loss": 11.501016616821289, "_runtime": 6278.529254198074, "_timestamp": 1585576194.3738875, "_step": 107}
{"Episode reward": 74.1999999999999, "Episode length": 258, "Policy Loss": 3.070081949234009, "Value Loss": 37.81385040283203, "_runtime": 6279.819287061691, "_timestamp": 1585576195.6639204, "_step": 108}
{"Episode reward": 18.900000000000333, "Episode length": 811, "Policy Loss": 0.2282923310995102, "Value Loss": 11.92954158782959, "_runtime": 6281.041331768036, "_timestamp": 1585576196.885965, "_step": 109}
{"Episode reward": 22.600000000000122, "Episode length": 774, "Policy Loss": 0.2835794687271118, "Value Loss": 12.67249584197998, "_runtime": 6282.517543792725, "_timestamp": 1585576198.3621771, "_step": 110}
{"Episode reward": 2.802811980248734, "Episode length": 972, "Policy Loss": -0.05642108991742134, "Value Loss": 9.980331420898438, "_runtime": 6284.094820261002, "_timestamp": 1585576199.9394536, "_step": 111}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.070568561553955, "Value Loss": 0.0133952172473073, "_runtime": 6285.627112388611, "_timestamp": 1585576201.4717457, "_step": 112}
{"Episode reward": 2.4000000000012705, "Episode length": 976, "Policy Loss": -0.13496533036231995, "Value Loss": 9.969559669494629, "_runtime": 6287.1884088516235, "_timestamp": 1585576203.0330422, "_step": 113}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1606223583221436, "Value Loss": 0.12697289884090424, "_runtime": 6288.773758172989, "_timestamp": 1585576204.6183915, "_step": 114}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1872222423553467, "Value Loss": 0.07526615262031555, "_runtime": 6290.3576917648315, "_timestamp": 1585576206.202325, "_step": 115}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.150305986404419, "Value Loss": 0.044343817979097366, "_runtime": 6291.814148902893, "_timestamp": 1585576207.6587822, "_step": 116}
{"Episode reward": 7.700000000000969, "Episode length": 923, "Policy Loss": -0.07502733916044235, "Value Loss": 10.672821998596191, "_runtime": 6293.420535326004, "_timestamp": 1585576209.2651687, "_step": 117}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0999358892440796, "Value Loss": 0.01962195336818695, "_runtime": 6295.025918960571, "_timestamp": 1585576210.8705523, "_step": 118}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0789148807525635, "Value Loss": 0.018631314858794212, "_runtime": 6296.600476980209, "_timestamp": 1585576212.4451103, "_step": 119}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0452218055725098, "Value Loss": 0.017505083233118057, "_runtime": 6297.4166514873505, "_timestamp": 1585576213.2612848, "_step": 120}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 0.9648354649543762, "Value Loss": 20.026185989379883, "_runtime": 6298.874833345413, "_timestamp": 1585576214.7194667, "_step": 121}
{"Episode reward": 8.700000000000912, "Episode length": 913, "Policy Loss": -0.006495476700365543, "Value Loss": 10.586699485778809, "_runtime": 6300.485771417618, "_timestamp": 1585576216.3304048, "_step": 122}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0624407529830933, "Value Loss": 0.023840313777327538, "_runtime": 6301.758205413818, "_timestamp": 1585576217.6028388, "_step": 123}
{"Episode reward": 17.500000000000412, "Episode length": 825, "Policy Loss": 0.3666439652442932, "Value Loss": 11.567995071411133, "_runtime": 6302.919819116592, "_timestamp": 1585576218.7644525, "_step": 124}
{"Episode reward": 27.099999999999866, "Episode length": 729, "Policy Loss": 0.28749388456344604, "Value Loss": 13.293140411376953, "_runtime": 6304.503025054932, "_timestamp": 1585576220.3476584, "_step": 125}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9202057719230652, "Value Loss": 0.01171183306723833, "_runtime": 6306.055583000183, "_timestamp": 1585576221.9002163, "_step": 126}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7993594408035278, "Value Loss": 0.014438657090067863, "_runtime": 6307.622508049011, "_timestamp": 1585576223.4671414, "_step": 127}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6985132098197937, "Value Loss": 0.03608858212828636, "_runtime": 6309.197673082352, "_timestamp": 1585576225.0423064, "_step": 128}
{"Episode reward": -99.84201546311239, "Episode length": 999, "Policy Loss": -0.5288982391357422, "Value Loss": 0.043526820838451385, "_runtime": 6310.773775100708, "_timestamp": 1585576226.6184084, "_step": 129}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4074695408344269, "Value Loss": 0.018394697457551956, "_runtime": 6311.577350139618, "_timestamp": 1585576227.4219835, "_step": 130}
{"Episode reward": 50.89999999999958, "Episode length": 491, "Policy Loss": 1.5884432792663574, "Value Loss": 18.8687801361084, "_runtime": 6312.322809934616, "_timestamp": 1585576228.1674433, "_step": 131}
{"Episode reward": 54.39999999999963, "Episode length": 456, "Policy Loss": 1.8563766479492188, "Value Loss": 20.599590301513672, "_runtime": 6313.904471158981, "_timestamp": 1585576229.7491045, "_step": 132}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.11027002334594727, "Value Loss": 0.009908424690365791, "_runtime": 6315.023539066315, "_timestamp": 1585576230.8681724, "_step": 133}
{"Episode reward": 27.799999999999827, "Episode length": 722, "Policy Loss": 1.4405792951583862, "Value Loss": 12.816004753112793, "_runtime": 6315.624944925308, "_timestamp": 1585576231.4695783, "_step": 134}
{"Episode reward": 61.899999999999736, "Episode length": 381, "Policy Loss": 2.3837063312530518, "Value Loss": 24.565404891967773, "_runtime": 6317.192070245743, "_timestamp": 1585576233.0367036, "_step": 135}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.006994063500314951, "Value Loss": 0.0416153259575367, "_runtime": 6318.191897153854, "_timestamp": 1585576234.0365305, "_step": 136}
{"Episode reward": 36.89999999999938, "Episode length": 631, "Policy Loss": 1.4706686735153198, "Value Loss": 14.719137191772461, "_runtime": 6318.86413359642, "_timestamp": 1585576234.708767, "_step": 137}
{"Episode reward": 56.59999999999966, "Episode length": 434, "Policy Loss": 2.0741567611694336, "Value Loss": 21.975650787353516, "_runtime": 6320.428545951843, "_timestamp": 1585576236.2731793, "_step": 138}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2180931717157364, "Value Loss": 0.035424839705228806, "_runtime": 6321.644739866257, "_timestamp": 1585576237.4893732, "_step": 139}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 0.8744869232177734, "Value Loss": 11.928421974182129, "_runtime": 6322.1269245147705, "_timestamp": 1585576237.9715579, "_step": 140}
{"Episode reward": 69.09999999999984, "Episode length": 309, "Policy Loss": 2.397695302963257, "Value Loss": 28.133554458618164, "_runtime": 6323.711389780045, "_timestamp": 1585576239.5560231, "_step": 141}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5814183354377747, "Value Loss": 0.0059815943241119385, "_runtime": 6325.263651847839, "_timestamp": 1585576241.1082852, "_step": 142}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7318704128265381, "Value Loss": 0.00840715877711773, "_runtime": 6326.768499135971, "_timestamp": 1585576242.6131325, "_step": 143}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8486977219581604, "Value Loss": 0.0177996177226305, "_runtime": 6328.326366186142, "_timestamp": 1585576244.1709995, "_step": 144}
{"Episode reward": 1.4000000000013273, "Episode length": 986, "Policy Loss": -0.031727347522974014, "Value Loss": 9.344398498535156, "_runtime": 6329.035062551498, "_timestamp": 1585576244.879696, "_step": 145}
{"Episode reward": 56.999999999999666, "Episode length": 430, "Policy Loss": 1.3716179132461548, "Value Loss": 20.024450302124023, "_runtime": 6330.60035610199, "_timestamp": 1585576246.4449894, "_step": 146}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8343929648399353, "Value Loss": 0.03863411769270897, "_runtime": 6332.166461467743, "_timestamp": 1585576248.0110948, "_step": 147}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7604473829269409, "Value Loss": 0.6325874328613281, "_runtime": 6333.691616535187, "_timestamp": 1585576249.5362499, "_step": 148}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8454759120941162, "Value Loss": 0.040177978575229645, "_runtime": 6334.472445011139, "_timestamp": 1585576250.3170784, "_step": 149}
{"Episode reward": 52.1999999999996, "Episode length": 478, "Policy Loss": 0.7746384143829346, "Value Loss": 18.613706588745117, "_runtime": 6335.957679986954, "_timestamp": 1585576251.8023133, "_step": 150}
{"Episode reward": 7.000000000001009, "Episode length": 930, "Policy Loss": -0.3659938871860504, "Value Loss": 9.794234275817871, "_runtime": 6337.526779651642, "_timestamp": 1585576253.371413, "_step": 151}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6760329008102417, "Value Loss": 0.09200640767812729, "_runtime": 6339.0688581466675, "_timestamp": 1585576254.9134915, "_step": 152}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.954914927482605, "Value Loss": 0.053308360278606415, "_runtime": 6340.658410310745, "_timestamp": 1585576256.5030437, "_step": 153}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.1165735721588135, "Value Loss": 0.30848321318626404, "_runtime": 6342.240140914917, "_timestamp": 1585576258.0847743, "_step": 154}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.075687885284424, "Value Loss": 0.12687283754348755, "_runtime": 6343.815920591354, "_timestamp": 1585576259.660554, "_step": 155}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.9300063848495483, "Value Loss": 0.11502421647310257, "_runtime": 6345.409799337387, "_timestamp": 1585576261.2544327, "_step": 156}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.681366205215454, "Value Loss": 0.0776941105723381, "_runtime": 6346.772590637207, "_timestamp": 1585576262.617224, "_step": 157}
{"Episode reward": 14.500000000000583, "Episode length": 855, "Policy Loss": -0.2782185971736908, "Value Loss": 12.888294219970703, "_runtime": 6348.391187667847, "_timestamp": 1585576264.235821, "_step": 158}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9369556903839111, "Value Loss": 0.09621001034975052, "_runtime": 6349.455384492874, "_timestamp": 1585576265.3000178, "_step": 159}
{"Episode reward": 34.29999999999946, "Episode length": 657, "Policy Loss": 0.7217485904693604, "Value Loss": 12.731820106506348, "_runtime": 6351.034432411194, "_timestamp": 1585576266.8790658, "_step": 160}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2917811870574951, "Value Loss": 0.2975572943687439, "_runtime": 6352.024663925171, "_timestamp": 1585576267.8692973, "_step": 161}
{"Episode reward": 39.19999999999941, "Episode length": 608, "Policy Loss": 1.1303997039794922, "Value Loss": 15.168045997619629, "_runtime": 6353.601907253265, "_timestamp": 1585576269.4465406, "_step": 162}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3729330599308014, "Value Loss": 0.005154233891516924, "_runtime": 6355.181897878647, "_timestamp": 1585576271.0265312, "_step": 163}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4288331866264343, "Value Loss": 0.03955860808491707, "_runtime": 6356.7378885746, "_timestamp": 1585576272.582522, "_step": 164}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4641701877117157, "Value Loss": 0.02179543487727642, "_runtime": 6357.347126245499, "_timestamp": 1585576273.1917596, "_step": 165}
{"Episode reward": 63.899999999999764, "Episode length": 361, "Policy Loss": 2.2044341564178467, "Value Loss": 25.252174377441406, "_runtime": 6358.933866977692, "_timestamp": 1585576274.7785003, "_step": 166}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5340294241905212, "Value Loss": 0.08151841163635254, "_runtime": 6359.450350046158, "_timestamp": 1585576275.2949834, "_step": 167}
{"Episode reward": 69.49999999999984, "Episode length": 305, "Policy Loss": 2.529374599456787, "Value Loss": 30.67296028137207, "_runtime": 6360.903389215469, "_timestamp": 1585576276.7480226, "_step": 168}
{"Episode reward": 5.300000000001106, "Episode length": 947, "Policy Loss": 0.14630094170570374, "Value Loss": 8.913273811340332, "_runtime": 6362.397635936737, "_timestamp": 1585576278.2422693, "_step": 169}
{"Episode reward": 6.400000000001043, "Episode length": 936, "Policy Loss": 0.03195570781826973, "Value Loss": 10.19652271270752, "_runtime": 6363.921155929565, "_timestamp": 1585576279.7657893, "_step": 170}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9055321216583252, "Value Loss": 0.02188367396593094, "_runtime": 6365.104342699051, "_timestamp": 1585576280.948976, "_step": 171}
{"Episode reward": 25.699999999999946, "Episode length": 743, "Policy Loss": 0.40805238485336304, "Value Loss": 12.610502243041992, "_runtime": 6366.688635587692, "_timestamp": 1585576282.533269, "_step": 172}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9885366559028625, "Value Loss": 0.03468799963593483, "_runtime": 6368.263350486755, "_timestamp": 1585576284.1079838, "_step": 173}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9884259700775146, "Value Loss": 0.24284671247005463, "_runtime": 6369.274187088013, "_timestamp": 1585576285.1188204, "_step": 174}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 0.5084785223007202, "Value Loss": 13.59228801727295, "_runtime": 6370.8645186424255, "_timestamp": 1585576286.709152, "_step": 175}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0016396045684814, "Value Loss": 0.14641642570495605, "_runtime": 6372.481142759323, "_timestamp": 1585576288.325776, "_step": 176}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9414145946502686, "Value Loss": 0.3383145332336426, "_runtime": 6374.041556835175, "_timestamp": 1585576289.8861902, "_step": 177}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8300250172615051, "Value Loss": 0.05281415209174156, "_runtime": 6375.635318279266, "_timestamp": 1585576291.4799516, "_step": 178}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6955068707466125, "Value Loss": 0.011666391976177692, "_runtime": 6377.229405403137, "_timestamp": 1585576293.0740387, "_step": 179}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5049490928649902, "Value Loss": 0.4404675364494324, "_runtime": 6378.812557458878, "_timestamp": 1585576294.6571908, "_step": 180}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5362905859947205, "Value Loss": 0.0062330337241292, "_runtime": 6380.410022735596, "_timestamp": 1585576296.254656, "_step": 181}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5278578400611877, "Value Loss": 0.05876999348402023, "_runtime": 6381.997251749039, "_timestamp": 1585576297.841885, "_step": 182}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5101013779640198, "Value Loss": 0.03807665407657623, "_runtime": 6382.775351285934, "_timestamp": 1585576298.6199846, "_step": 183}
{"Episode reward": 52.099999999999596, "Episode length": 479, "Policy Loss": 1.452451467514038, "Value Loss": 17.659751892089844, "_runtime": 6383.2776136398315, "_timestamp": 1585576299.122247, "_step": 184}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 2.5063939094543457, "Value Loss": 30.335485458374023, "_runtime": 6384.752529382706, "_timestamp": 1585576300.5971627, "_step": 185}
{"Episode reward": 6.998872131110247, "Episode length": 931, "Policy Loss": 0.3775378465652466, "Value Loss": 9.092362403869629, "_runtime": 6385.545688390732, "_timestamp": 1585576301.3903217, "_step": 186}
{"Episode reward": 49.49999999999956, "Episode length": 505, "Policy Loss": 1.4436492919921875, "Value Loss": 20.170143127441406, "_runtime": 6387.063688278198, "_timestamp": 1585576302.9083216, "_step": 187}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8450465202331543, "Value Loss": 0.03200504183769226, "_runtime": 6388.654657363892, "_timestamp": 1585576304.4992907, "_step": 188}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1366695165634155, "Value Loss": 0.6041669249534607, "_runtime": 6389.760917425156, "_timestamp": 1585576305.6055508, "_step": 189}
{"Episode reward": 28.499999999999787, "Episode length": 715, "Policy Loss": 0.007393592968583107, "Value Loss": 12.680948257446289, "_runtime": 6391.320142507553, "_timestamp": 1585576307.1647758, "_step": 190}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3821417093276978, "Value Loss": 0.21181876957416534, "_runtime": 6392.21204161644, "_timestamp": 1585576308.056675, "_step": 191}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.40444353222846985, "Value Loss": 17.072479248046875, "_runtime": 6393.168073654175, "_timestamp": 1585576309.012707, "_step": 192}
{"Episode reward": 39.09999999999941, "Episode length": 609, "Policy Loss": 0.3559676706790924, "Value Loss": 14.053421020507812, "_runtime": 6393.551217556, "_timestamp": 1585576309.395851, "_step": 193}
{"Episode reward": 78.59999999999997, "Episode length": 214, "Policy Loss": 3.5690059661865234, "Value Loss": 41.63911819458008, "_runtime": 6395.104679107666, "_timestamp": 1585576310.9493124, "_step": 194}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6179424524307251, "Value Loss": 0.018756888806819916, "_runtime": 6396.698707342148, "_timestamp": 1585576312.5433407, "_step": 195}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21918396651744843, "Value Loss": 0.23909679055213928, "_runtime": 6397.288831710815, "_timestamp": 1585576313.133465, "_step": 196}
{"Episode reward": 61.49999999999973, "Episode length": 385, "Policy Loss": 2.308873414993286, "Value Loss": 23.39463233947754, "_runtime": 6398.8532910346985, "_timestamp": 1585576314.6979244, "_step": 197}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.528206467628479, "Value Loss": 0.07133150845766068, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335, -0.0019345153123140335]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.25037774443626404, -0.24643535912036896, -0.24249298870563507, -0.23855060338974, -0.2346082329750061, -0.23066584765911102, -0.22672346234321594, -0.22278109192848206, -0.21883870661258698, -0.2148963361978531, -0.210953950881958, -0.20701158046722412, -0.20306919515132904, -0.19912680983543396, -0.19518443942070007, -0.191242054104805, -0.1872996687889099, -0.18335729837417603, -0.17941492795944214, -0.17547252774238586, -0.17153015732765198, -0.1675877869129181, -0.163645401597023, -0.15970301628112793, -0.15576064586639404, -0.15181826055049896, -0.14787587523460388, -0.14393350481987, -0.1399911344051361, -0.13604874908924103, -0.13210636377334595, -0.12816399335861206, -0.12422160804271698, -0.1202792227268219, -0.11633685231208801, -0.11239446699619293, -0.10845209658145905, -0.10450971126556396, -0.10056732594966888, -0.096624955534935, -0.09268257021903992, -0.08874019980430603, -0.08479781448841095, -0.08085542917251587, -0.07691305875778198, -0.0729706734418869, -0.06902830302715302, -0.06508591771125793, -0.06114354729652405, -0.05720116198062897, -0.05325877666473389, -0.04931640625, -0.04537402093410492, -0.04143165051937103, -0.03748926520347595, -0.03354687988758087, -0.029604509472846985, -0.025662124156951904, -0.021719753742218018, -0.017777368426322937, -0.013834983110427856, -0.00989261269569397, -0.005950227379798889, -0.0020078569650650024, 0.0019345283508300781]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.007752625271677971, -0.007631490472704172, -0.007510355673730373, -0.007389220874756575, -0.007268086075782776, -0.007146951276808977, -0.007025816477835178, -0.006904682144522667, -0.006783546879887581, -0.006662412546575069, -0.006541277281939983, -0.006420142948627472, -0.006299008149653673, -0.006177873350679874, -0.006056738551706076, -0.005935603752732277, -0.005814468953758478, -0.005693334154784679, -0.005572199355810881, -0.005451064556837082, -0.005329929757863283, -0.005208794958889484, -0.005087660625576973, -0.004966525360941887, -0.0048453910276293755, -0.004724255762994289, -0.004603121429681778, -0.004481986165046692, -0.0043608518317341805, -0.004239717032760382, -0.004118582233786583, -0.003997447434812784, -0.0038763126358389854, -0.0037551778368651867, -0.003634043037891388, -0.003512908238917589, -0.0033917734399437904, -0.0032706386409699917, -0.003149503841996193, -0.003028369043022394, -0.0029072342440485954, -0.002786099910736084, -0.0026649651117622852, -0.0025438303127884865, -0.0024226955138146877, -0.002301560714840889, -0.0021804259158670902, -0.0020592911168932915, -0.0019381563179194927, -0.001817021518945694, -0.0016958867199718952, -0.0015747519209980965, -0.0014536171220242977, -0.001332482323050499, -0.0012113475240767002, -0.0010902127251029015, -0.00096907839179039, -0.0008479435928165913, -0.0007268087938427925, -0.0006056739948689938, -0.000484539195895195, -0.00036340439692139626, -0.0002422695979475975, -0.00012113479897379875, 0.0]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 1.0, 6.0, 6.0, 6.0, 6.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 5.0, 8.0, 2.0, 2.0, 3.0, 8.0, 10.0, 1.0, 9.0, 1.0, 0.0, 6.0, 320.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 34.0, 16.0, 2.0, 0.0, 3.0, 8.0], "bins": [-0.025568215176463127, -0.025053713470697403, -0.02453920990228653, -0.024024708196520805, -0.02351020649075508, -0.022995704784989357, -0.022481201216578484, -0.02196669951081276, -0.021452197805047035, -0.02093769609928131, -0.020423192530870438, -0.019908690825104713, -0.01939418911933899, -0.018879685550928116, -0.01836518384516239, -0.017850682139396667, -0.017336178570985794, -0.01682167686522007, -0.016307175159454346, -0.015792671591043472, -0.015278170816600323, -0.014763668179512024, -0.0142491664737463, -0.013734663836658001, -0.013220161199569702, -0.012705659493803978, -0.01219115685671568, -0.011676655150949955, -0.011162152513861656, -0.010647650808095932, -0.010133148171007633, -0.009618645533919334, -0.00910414382815361, -0.008589642122387886, -0.008075138553977013, -0.0075606368482112885, -0.007046135142445564, -0.00653163343667984, -0.006017129868268967, -0.0055026281625032425, -0.004988126456737518, -0.004473622888326645, -0.003959121182560921, -0.0034446194767951965, -0.0029301177710294724, -0.002415614202618599, -0.0019011124968528748, -0.0013866107910871506, -0.0008721072226762772, -0.000357605516910553, 0.0001568961888551712, 0.0006713978946208954, 0.0011859014630317688, 0.001700403168797493, 0.002214904874563217, 0.0027294065803289413, 0.0032439101487398148, 0.003758411854505539, 0.004272913560271263, 0.0047874171286821365, 0.005301918834447861, 0.005816420540213585, 0.006330924108624458, 0.006845423951745033, 0.007359927520155907]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.20599937438964844, -0.20234152674674988, -0.19868367910385132, -0.19502583146095276, -0.191367968916893, -0.18771012127399445, -0.1840522736310959, -0.18039442598819733, -0.17673657834529877, -0.1730787307024002, -0.16942086815834045, -0.1657630205154419, -0.16210517287254333, -0.15844732522964478, -0.15478947758674622, -0.15113162994384766, -0.1474737823009491, -0.14381593465805054, -0.14015808701515198, -0.13650023937225342, -0.13284237682819366, -0.1291845291852951, -0.12552668154239655, -0.12186883389949799, -0.11821097880601883, -0.11455313116312027, -0.11089528352022171, -0.10723742842674255, -0.103579580783844, -0.09992173314094543, -0.09626388549804688, -0.09260603040456772, -0.08894818276166916, -0.0852903351187706, -0.08163248002529144, -0.07797463238239288, -0.07431678473949432, -0.07065893709659576, -0.0670010894536972, -0.06334324181079865, -0.05968537926673889, -0.05602753162384033, -0.05236968398094177, -0.04871183633804321, -0.04505398869514465, -0.041396141052246094, -0.037738293409347534, -0.03408043086528778, -0.03042258322238922, -0.02676473557949066, -0.023106887936592102, -0.019449040293693542, -0.015791192650794983, -0.012133345007896423, -0.00847548246383667, -0.00481763482093811, -0.0011597871780395508, 0.002498060464859009, 0.006155908107757568, 0.009813755750656128, 0.013471603393554688, 0.01712946593761444, 0.020787313580513, 0.02444516122341156, 0.02810300886631012]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 11.0, 6.0, 3.0, 6.0, 3.0, 3.0, 0.0, 3.0, 0.0, 4.0], "bins": [-0.28148558735847473, -0.2763371765613556, -0.27118876576423645, -0.2660403549671173, -0.26089194416999817, -0.25574353337287903, -0.2505951523780823, -0.24544672667980194, -0.2402983158826828, -0.23514991998672485, -0.2300015091896057, -0.22485309839248657, -0.21970468759536743, -0.2145562767982483, -0.20940786600112915, -0.20425945520401, -0.19911104440689087, -0.19396263360977173, -0.18881423771381378, -0.18366582691669464, -0.1785174161195755, -0.17336902022361755, -0.1682206094264984, -0.16307219862937927, -0.15792378783226013, -0.152775377035141, -0.14762696623802185, -0.1424785554409027, -0.13733014464378357, -0.13218174874782562, -0.12703333795070648, -0.12188492715358734, -0.1167365163564682, -0.11158810555934906, -0.10643969476222992, -0.10129128396511078, -0.09614288806915283, -0.09099447727203369, -0.08584606647491455, -0.08069765567779541, -0.07554924488067627, -0.07040083408355713, -0.06525243818759918, -0.06010402739048004, -0.0549556165933609, -0.04980720579624176, -0.04465879499912262, -0.03951038420200348, -0.03436198830604553, -0.02921357750892639, -0.02406516671180725, -0.01891675591468811, -0.01376834511756897, -0.008619934320449829, -0.0034715235233306885, 0.0016768872737884521, 0.006825298070907593, 0.011973708868026733, 0.017122089862823486, 0.022270500659942627, 0.027418911457061768, 0.03256732225418091, 0.03771573305130005, 0.04286414384841919, 0.04801255464553833]}, "_runtime": 6400.429551124573, "_timestamp": 1585576316.2741845, "_step": 198}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9407088160514832, "Value Loss": 0.531033456325531, "_runtime": 6401.943399906158, "_timestamp": 1585576317.7880332, "_step": 199}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.212599515914917, "Value Loss": 0.05825710669159889, "_runtime": 6403.533499956131, "_timestamp": 1585576319.3781333, "_step": 200}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.410726547241211, "Value Loss": 0.022159747779369354, "_runtime": 6404.276517868042, "_timestamp": 1585576320.1211512, "_step": 201}
{"Episode reward": 55.19999999999964, "Episode length": 448, "Policy Loss": 0.37426885962486267, "Value Loss": 19.440473556518555, "_runtime": 6405.403227329254, "_timestamp": 1585576321.2478607, "_step": 202}
{"Episode reward": 28.79999999999977, "Episode length": 712, "Policy Loss": -0.37226107716560364, "Value Loss": 13.054656982421875, "_runtime": 6407.001530408859, "_timestamp": 1585576322.8461637, "_step": 203}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8404901027679443, "Value Loss": 0.29708242416381836, "_runtime": 6408.08203959465, "_timestamp": 1585576323.926673, "_step": 204}
{"Episode reward": 30.19999999999969, "Episode length": 698, "Policy Loss": -0.5928544998168945, "Value Loss": 12.42673110961914, "_runtime": 6409.62726354599, "_timestamp": 1585576325.471897, "_step": 205}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7027490139007568, "Value Loss": 0.6840935945510864, "_runtime": 6410.256630182266, "_timestamp": 1585576326.1012635, "_step": 206}
{"Episode reward": 62.69999999999975, "Episode length": 373, "Policy Loss": 0.8554294109344482, "Value Loss": 24.053871154785156, "_runtime": 6411.698936462402, "_timestamp": 1585576327.5435698, "_step": 207}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": -0.18127425014972687, "Value Loss": 9.08623218536377, "_runtime": 6413.274579048157, "_timestamp": 1585576329.1192124, "_step": 208}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8617256283760071, "Value Loss": 0.008733347058296204, "_runtime": 6414.797889471054, "_timestamp": 1585576330.6425228, "_step": 209}
{"Episode reward": -99.86705114841321, "Episode length": 999, "Policy Loss": -0.5931296944618225, "Value Loss": 0.02302449941635132, "_runtime": 6416.396204471588, "_timestamp": 1585576332.2408378, "_step": 210}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.36259204149246216, "Value Loss": 0.04242374002933502, "_runtime": 6416.855628013611, "_timestamp": 1585576332.7002614, "_step": 211}
{"Episode reward": 73.39999999999989, "Episode length": 266, "Policy Loss": 3.127760171890259, "Value Loss": 32.30404281616211, "_runtime": 6418.433178663254, "_timestamp": 1585576334.277812, "_step": 212}
{"Episode reward": -99.82408087253431, "Episode length": 999, "Policy Loss": -0.004557056352496147, "Value Loss": 0.013012214563786983, "_runtime": 6420.052629709244, "_timestamp": 1585576335.897263, "_step": 213}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.1286109983921051, "Value Loss": 0.005991247016936541, "_runtime": 6421.181127071381, "_timestamp": 1585576337.0257604, "_step": 214}
{"Episode reward": 25.899999999999935, "Episode length": 741, "Policy Loss": 1.3769279718399048, "Value Loss": 11.54200553894043, "_runtime": 6422.77499461174, "_timestamp": 1585576338.619628, "_step": 215}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.23770494759082794, "Value Loss": 0.04695072025060654, "_runtime": 6424.111900568008, "_timestamp": 1585576339.956534, "_step": 216}
{"Episode reward": 16.30000000000048, "Episode length": 837, "Policy Loss": 1.3092434406280518, "Value Loss": 11.022089958190918, "_runtime": 6425.665756702423, "_timestamp": 1585576341.51039, "_step": 217}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.08721253275871277, "Value Loss": 0.01577024534344673, "_runtime": 6427.253937005997, "_timestamp": 1585576343.0985703, "_step": 218}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.01855866052210331, "Value Loss": 0.5779473781585693, "_runtime": 6428.837952613831, "_timestamp": 1585576344.682586, "_step": 219}
{"Episode reward": -99.84580011367657, "Episode length": 999, "Policy Loss": 0.015292195603251457, "Value Loss": 0.05651989206671715, "_runtime": 6430.0753309726715, "_timestamp": 1585576345.9199643, "_step": 220}
{"Episode reward": 21.700000000000173, "Episode length": 783, "Policy Loss": 1.1099926233291626, "Value Loss": 10.950246810913086, "_runtime": 6431.674536943436, "_timestamp": 1585576347.5191703, "_step": 221}
{"Episode reward": -99.81587524413922, "Episode length": 999, "Policy Loss": -0.0735948383808136, "Value Loss": 0.06742174178361893, "_runtime": 6433.282889842987, "_timestamp": 1585576349.1275232, "_step": 222}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.22477541863918304, "Value Loss": 0.03314341604709625, "_runtime": 6434.810336112976, "_timestamp": 1585576350.6549695, "_step": 223}
{"Episode reward": 2.8000000000012477, "Episode length": 972, "Policy Loss": 0.6687160134315491, "Value Loss": 8.77541446685791, "_runtime": 6436.402596950531, "_timestamp": 1585576352.2472303, "_step": 224}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4797891676425934, "Value Loss": 0.0029005713295191526, "_runtime": 6437.998428344727, "_timestamp": 1585576353.8430617, "_step": 225}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.591996967792511, "Value Loss": 0.007977639324963093, "_runtime": 6439.434987545013, "_timestamp": 1585576355.279621, "_step": 226}
{"Episode reward": 9.250355315209319, "Episode length": 908, "Policy Loss": 0.2776680886745453, "Value Loss": 9.801298141479492, "_runtime": 6441.0376443862915, "_timestamp": 1585576356.8822777, "_step": 227}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.630796492099762, "Value Loss": 0.4104801118373871, "_runtime": 6442.673771381378, "_timestamp": 1585576358.5184047, "_step": 228}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5279841423034668, "Value Loss": 0.12487368285655975, "_runtime": 6444.2627737522125, "_timestamp": 1585576360.107407, "_step": 229}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49779894948005676, "Value Loss": 0.04790249094367027, "_runtime": 6445.8546895980835, "_timestamp": 1585576361.699323, "_step": 230}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.47709882259368896, "Value Loss": 0.1760743409395218, "_runtime": 6447.387070655823, "_timestamp": 1585576363.231704, "_step": 231}
{"Episode reward": 4.500000000001151, "Episode length": 955, "Policy Loss": 0.5548907518386841, "Value Loss": 9.233558654785156, "_runtime": 6448.218626022339, "_timestamp": 1585576364.0632594, "_step": 232}
{"Episode reward": 49.29999999999956, "Episode length": 507, "Policy Loss": 1.1090928316116333, "Value Loss": 16.696474075317383, "_runtime": 6449.292588472366, "_timestamp": 1585576365.1372218, "_step": 233}
{"Episode reward": 32.19999999999958, "Episode length": 678, "Policy Loss": 0.4849925935268402, "Value Loss": 11.823770523071289, "_runtime": 6450.881489515305, "_timestamp": 1585576366.7261229, "_step": 234}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.854783296585083, "Value Loss": 0.30288439989089966, "_runtime": 6452.431857347488, "_timestamp": 1585576368.2764907, "_step": 235}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9607334733009338, "Value Loss": 0.05160683020949364, "_runtime": 6453.989383459091, "_timestamp": 1585576369.8340168, "_step": 236}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.032515525817871, "Value Loss": 0.015345785766839981, "_runtime": 6455.582280635834, "_timestamp": 1585576371.426914, "_step": 237}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.056312918663025, "Value Loss": 0.05388994514942169, "_runtime": 6456.3701548576355, "_timestamp": 1585576372.2147882, "_step": 238}
{"Episode reward": 51.79999999999959, "Episode length": 482, "Policy Loss": 0.6594502329826355, "Value Loss": 18.942689895629883, "_runtime": 6457.960719823837, "_timestamp": 1585576373.8053532, "_step": 239}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0074025392532349, "Value Loss": 0.020807068794965744, "_runtime": 6458.975870609283, "_timestamp": 1585576374.820504, "_step": 240}
{"Episode reward": 36.88207833766875, "Episode length": 632, "Policy Loss": 0.498211532831192, "Value Loss": 13.089487075805664, "_runtime": 6460.526238679886, "_timestamp": 1585576376.370872, "_step": 241}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8295579552650452, "Value Loss": 0.07752276957035065, "_runtime": 6462.112550497055, "_timestamp": 1585576377.9571838, "_step": 242}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7692310810089111, "Value Loss": 0.03681979328393936, "_runtime": 6463.578883886337, "_timestamp": 1585576379.4235172, "_step": 243}
{"Episode reward": 6.500000000001037, "Episode length": 935, "Policy Loss": 0.12950584292411804, "Value Loss": 8.475820541381836, "_runtime": 6465.154246807098, "_timestamp": 1585576380.9988801, "_step": 244}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6561084389686584, "Value Loss": 0.045823536813259125, "_runtime": 6465.897675991058, "_timestamp": 1585576381.7423093, "_step": 245}
{"Episode reward": 55.09999999999964, "Episode length": 449, "Policy Loss": 1.36038339138031, "Value Loss": 19.163856506347656, "_runtime": 6467.517918348312, "_timestamp": 1585576383.3625517, "_step": 246}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6399646401405334, "Value Loss": 0.007650043815374374, "_runtime": 6469.116804122925, "_timestamp": 1585576384.9614375, "_step": 247}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6731597185134888, "Value Loss": 0.09133705496788025, "_runtime": 6470.648565769196, "_timestamp": 1585576386.493199, "_step": 248}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6337831616401672, "Value Loss": 0.0721290335059166, "_runtime": 6472.248396396637, "_timestamp": 1585576388.0930297, "_step": 249}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5875542759895325, "Value Loss": 0.27795082330703735, "_runtime": 6473.826975822449, "_timestamp": 1585576389.6716092, "_step": 250}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.534583330154419, "Value Loss": 0.029171496629714966, "_runtime": 6475.127024173737, "_timestamp": 1585576390.9716575, "_step": 251}
{"Episode reward": 18.089551448822405, "Episode length": 820, "Policy Loss": 0.6764471530914307, "Value Loss": 10.594820976257324, "_runtime": 6476.507815122604, "_timestamp": 1585576392.3524485, "_step": 252}
{"Episode reward": 13.700000000000628, "Episode length": 863, "Policy Loss": 0.5815016031265259, "Value Loss": 9.939408302307129, "_runtime": 6478.097580194473, "_timestamp": 1585576393.9422135, "_step": 253}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2883007824420929, "Value Loss": 0.1030130460858345, "_runtime": 6478.447657585144, "_timestamp": 1585576394.292291, "_step": 254}
{"Episode reward": 81.0, "Episode length": 190, "Policy Loss": 4.17555046081543, "Value Loss": 44.34345626831055, "_runtime": 6480.034335136414, "_timestamp": 1585576395.8789685, "_step": 255}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.40923163294792175, "Value Loss": 0.38018134236335754, "_runtime": 6481.6228902339935, "_timestamp": 1585576397.4675236, "_step": 256}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49991005659103394, "Value Loss": 0.11306547373533249, "_runtime": 6482.525682687759, "_timestamp": 1585576398.370316, "_step": 257}
{"Episode reward": 40.39999999999943, "Episode length": 596, "Policy Loss": 0.9247028827667236, "Value Loss": 15.078387260437012, "_runtime": 6484.1165766716, "_timestamp": 1585576399.96121, "_step": 258}
{"Episode reward": -99.84249155521253, "Episode length": 999, "Policy Loss": -0.647412121295929, "Value Loss": 0.08515358716249466, "_runtime": 6485.70409655571, "_timestamp": 1585576401.54873, "_step": 259}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7199894785881042, "Value Loss": 0.01561008021235466, "_runtime": 6487.232887983322, "_timestamp": 1585576403.0775213, "_step": 260}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7467581629753113, "Value Loss": 0.015497874468564987, "_runtime": 6488.83158493042, "_timestamp": 1585576404.6762183, "_step": 261}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.752364993095398, "Value Loss": 0.0115429712459445, "_runtime": 6490.118209123611, "_timestamp": 1585576405.9628425, "_step": 262}
{"Episode reward": 19.5000000000003, "Episode length": 805, "Policy Loss": 0.3701966404914856, "Value Loss": 11.637129783630371, "_runtime": 6491.719611883163, "_timestamp": 1585576407.5642452, "_step": 263}
{"Episode reward": 0.40000000000138414, "Episode length": 996, "Policy Loss": -0.005782268941402435, "Value Loss": 8.071104049682617, "_runtime": 6492.634489297867, "_timestamp": 1585576408.4791226, "_step": 264}
{"Episode reward": 44.49999999999949, "Episode length": 555, "Policy Loss": 0.6003511548042297, "Value Loss": 14.933528900146484, "_runtime": 6494.219611167908, "_timestamp": 1585576410.0642445, "_step": 265}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5861823558807373, "Value Loss": 0.09060758352279663, "_runtime": 6495.812024354935, "_timestamp": 1585576411.6566577, "_step": 266}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5075988173484802, "Value Loss": 0.03474199026823044, "_runtime": 6496.609146356583, "_timestamp": 1585576412.4537797, "_step": 267}
{"Episode reward": 49.99999999999957, "Episode length": 500, "Policy Loss": 1.4184391498565674, "Value Loss": 18.343395233154297, "_runtime": 6498.205856561661, "_timestamp": 1585576414.05049, "_step": 268}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5077289342880249, "Value Loss": 0.0659516304731369, "_runtime": 6499.786598920822, "_timestamp": 1585576415.6312323, "_step": 269}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5220240950584412, "Value Loss": 0.014706913381814957, "_runtime": 6500.435679197311, "_timestamp": 1585576416.2803125, "_step": 270}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.6640024185180664, "Value Loss": 20.4406795501709, "_runtime": 6502.031826257706, "_timestamp": 1585576417.8764596, "_step": 271}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5970771908760071, "Value Loss": 0.1534544825553894, "_runtime": 6502.951505422592, "_timestamp": 1585576418.7961388, "_step": 272}
{"Episode reward": 43.39999999999947, "Episode length": 566, "Policy Loss": 1.1194971799850464, "Value Loss": 16.458131790161133, "_runtime": 6503.58652639389, "_timestamp": 1585576419.4311597, "_step": 273}
{"Episode reward": 59.4999999999997, "Episode length": 405, "Policy Loss": 1.3627359867095947, "Value Loss": 20.99264144897461, "_runtime": 6504.000310897827, "_timestamp": 1585576419.8449442, "_step": 274}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 2.999974250793457, "Value Loss": 33.321624755859375, "_runtime": 6505.547105789185, "_timestamp": 1585576421.3917391, "_step": 275}
{"Episode reward": -99.84409790038923, "Episode length": 999, "Policy Loss": -1.1027402877807617, "Value Loss": 0.015868276357650757, "_runtime": 6507.088784694672, "_timestamp": 1585576422.933418, "_step": 276}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2978509664535522, "Value Loss": 0.08793461322784424, "_runtime": 6508.604071140289, "_timestamp": 1585576424.4487045, "_step": 277}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4467257261276245, "Value Loss": 0.09432322531938553, "_runtime": 6510.200660705566, "_timestamp": 1585576426.045294, "_step": 278}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.552013874053955, "Value Loss": 0.1874777376651764, "_runtime": 6511.779425144196, "_timestamp": 1585576427.6240585, "_step": 279}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7111895084381104, "Value Loss": 0.09425437450408936, "_runtime": 6512.866235494614, "_timestamp": 1585576428.7108688, "_step": 280}
{"Episode reward": 31.09999999999964, "Episode length": 689, "Policy Loss": -1.028965711593628, "Value Loss": 31.667011260986328, "_runtime": 6514.464901208878, "_timestamp": 1585576430.3095345, "_step": 281}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0040323734283447, "Value Loss": 0.10512642562389374, "_runtime": 6516.1018216609955, "_timestamp": 1585576431.946455, "_step": 282}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.31832990050315857, "Value Loss": 0.21632780134677887, "_runtime": 6517.6595594882965, "_timestamp": 1585576433.5041928, "_step": 283}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.11435479670763016, "Value Loss": 0.3964550793170929, "_runtime": 6519.047363519669, "_timestamp": 1585576434.8919969, "_step": 284}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": 1.2971612215042114, "Value Loss": 11.950718879699707, "_runtime": 6520.635869264603, "_timestamp": 1585576436.4805026, "_step": 285}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4355454444885254, "Value Loss": 0.015746647492051125, "_runtime": 6521.125065326691, "_timestamp": 1585576436.9696987, "_step": 286}
{"Episode reward": 71.79999999999987, "Episode length": 282, "Policy Loss": 4.688661575317383, "Value Loss": 33.05255889892578, "_runtime": 6522.488924741745, "_timestamp": 1585576438.333558, "_step": 287}
{"Episode reward": 13.400000000000645, "Episode length": 866, "Policy Loss": 1.6335712671279907, "Value Loss": 12.3971529006958, "_runtime": 6523.23283290863, "_timestamp": 1585576439.0774662, "_step": 288}
{"Episode reward": 55.055316519736884, "Episode length": 450, "Policy Loss": 2.2719390392303467, "Value Loss": 21.38372802734375, "_runtime": 6524.066131830215, "_timestamp": 1585576439.9107652, "_step": 289}
{"Episode reward": 44.79999999999949, "Episode length": 552, "Policy Loss": 1.5970855951309204, "Value Loss": 17.57282829284668, "_runtime": 6525.643134355545, "_timestamp": 1585576441.4877677, "_step": 290}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3436368703842163, "Value Loss": 0.10773751884698868, "_runtime": 6527.150620937347, "_timestamp": 1585576442.9952543, "_step": 291}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": 0.6349769830703735, "Value Loss": 10.142709732055664, "_runtime": 6527.6040296554565, "_timestamp": 1585576443.448663, "_step": 292}
{"Episode reward": 72.49999999999989, "Episode length": 275, "Policy Loss": 4.414477348327637, "Value Loss": 36.27507781982422, "_runtime": 6529.179257392883, "_timestamp": 1585576445.0238907, "_step": 293}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7134342193603516, "Value Loss": 0.006944043096154928, "_runtime": 6530.6339910030365, "_timestamp": 1585576446.4786243, "_step": 294}
{"Episode reward": 8.000000000000952, "Episode length": 920, "Policy Loss": 0.2638716995716095, "Value Loss": 10.907464027404785, "_runtime": 6532.1529767513275, "_timestamp": 1585576447.99761, "_step": 295}
{"Episode reward": -99.82480506896833, "Episode length": 999, "Policy Loss": -0.7703706622123718, "Value Loss": 0.014834768138825893, "_runtime": 6533.749443292618, "_timestamp": 1585576449.5940766, "_step": 296}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7621288299560547, "Value Loss": 0.021757610142230988, "_runtime": 6534.40815615654, "_timestamp": 1585576450.2527895, "_step": 297}
{"Episode reward": 60.29999999999971, "Episode length": 397, "Policy Loss": 1.6555289030075073, "Value Loss": 25.248865127563477, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [-0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185, -0.00036857512895949185]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.051675945520401, -0.05086274817585945, -0.0500495545566082, -0.04923635721206665, -0.0484231635928154, -0.04760996624827385, -0.0467967726290226, -0.04598357528448105, -0.0451703816652298, -0.04435718432068825, -0.0435439869761467, -0.04273079335689545, -0.041917599737644196, -0.041104402393102646, -0.040291205048561096, -0.039478011429309845, -0.038664814084768295, -0.037851620465517044, -0.037038423120975494, -0.03622522950172424, -0.035412032157182693, -0.034598834812641144, -0.03378564119338989, -0.03297244757413864, -0.03215925022959709, -0.03134605288505554, -0.03053285926580429, -0.02971966192126274, -0.02890646643936634, -0.02809327095746994, -0.02728007547557354, -0.02646687999367714, -0.02565368451178074, -0.02484048902988434, -0.024027293547987938, -0.023214098066091537, -0.022400902584195137, -0.021587707102298737, -0.020774509757757187, -0.019961316138505936, -0.019148118793964386, -0.018334925174713135, -0.017521727830171585, -0.016708530485630035, -0.015895336866378784, -0.015082139521837234, -0.014268945902585983, -0.013455748558044434, -0.012642554938793182, -0.011829357594251633, -0.011016163975000381, -0.010202966630458832, -0.00938977301120758, -0.008576575666666031, -0.007763378322124481, -0.00695018470287323, -0.00613698735833168, -0.005323793739080429, -0.004510596394538879, -0.003697402775287628, -0.0028842054307460785, -0.0020710118114948273, -0.0012578144669532776, -0.00044462084770202637, 0.0003685764968395233]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0], "bins": [-0.0014771218411624432, -0.0014540418051183224, -0.0014309617690742016, -0.0014078817330300808, -0.00138480169698596, -0.0013617216609418392, -0.0013386416248977184, -0.0013155615888535976, -0.0012924815528094769, -0.001269401516765356, -0.0012463214807212353, -0.0012232414446771145, -0.0012001614086329937, -0.001177081372588873, -0.0011540012201294303, -0.0011309211840853095, -0.0011078411480411887, -0.001084761111997068, -0.0010616810759529471, -0.0010386010399088264, -0.0010155210038647056, -0.0009924409678205848, -0.000969360931776464, -0.0009462808957323432, -0.0009232008596882224, -0.0009001208236441016, -0.0008770407875999808, -0.0008539606933481991, -0.0008308806573040783, -0.0008078006212599576, -0.0007847205852158368, -0.000761640549171716, -0.0007385605131275952, -0.0007154804770834744, -0.0006924004410393536, -0.0006693204049952328, -0.000646240368951112, -0.0006231603329069912, -0.0006000802386552095, -0.0005770002026110888, -0.000553920166566968, -0.0005308401305228472, -0.0005077600944787264, -0.0004846800584346056, -0.0004616000223904848, -0.000438519986346364, -0.00041543995030224323, -0.00039235991425812244, -0.00036927987821400166, -0.00034619984216988087, -0.0003231198061257601, -0.0003000397700816393, -0.0002769597340375185, -0.0002538796979933977, -0.0002307995455339551, -0.0002077195094898343, -0.00018463947344571352, -0.00016155943740159273, -0.00013847940135747194, -0.00011539936531335115, -9.231932926923037e-05, -6.923929322510958e-05, -4.615925718098879e-05, -2.3079221136868e-05, 8.149072527885437e-10]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 1.0, 5.0, 7.0, 3.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 6.0, 5.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 8.0, 8.0, 8.0, 0.0, 1.0, 8.0, 4.0, 5.0, 4.0, 0.0, 1.0, 5.0, 320.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 20.0, 20.0, 8.0, 2.0, 2.0, 3.0, 4.0], "bins": [-0.004781203344464302, -0.004684407729655504, -0.004587612580507994, -0.004490816965699196, -0.004394021816551685, -0.0042972262017428875, -0.00420043058693409, -0.004103635437786579, -0.004006839822977781, -0.003910044673830271, -0.003813249059021473, -0.0037164536770433187, -0.0036196582950651646, -0.0035228626802563667, -0.003426067531108856, -0.0033292719163000584, -0.003232476534321904, -0.00313568115234375, -0.003038885537534952, -0.0029420903883874416, -0.002845294773578644, -0.0027484993916004896, -0.0026517040096223354, -0.0025549086276441813, -0.002458113245666027, -0.0023613176308572292, -0.002264522248879075, -0.002167726866900921, -0.0020709314849227667, -0.0019741361029446125, -0.0018773404881358147, -0.0017805451061576605, -0.0016837497241795063, -0.0015869543422013521, -0.001490158960223198, -0.0013933633454144, -0.001296567963436246, -0.0011997725814580917, -0.0011029771994799376, -0.0010061818175017834, -0.0009093862026929855, -0.000812591053545475, -0.0007157954387366772, -0.0006189998239278793, -0.0005222046747803688, -0.00042540905997157097, -0.00032861391082406044, -0.0002318182960152626, -0.00013502314686775208, -3.822753205895424e-05, 5.85680827498436e-05, 0.00015536323189735413, 0.00025215884670615196, 0.0003489539958536625, 0.00044574961066246033, 0.0005425452254712582, 0.0006393403746187687, 0.0007361359894275665, 0.0008329311385750771, 0.0009297267533838749, 0.0010265223681926727, 0.0011233175173401833, 0.001220113132148981, 0.0013169082812964916, 0.0014137038961052895]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03925298899412155, -0.03849044814705849, -0.03772790729999542, -0.03696536645293236, -0.03620282560586929, -0.03544028475880623, -0.034677743911743164, -0.0339151993393898, -0.033152658492326736, -0.03239011764526367, -0.03162757679820061, -0.030865035951137543, -0.030102495104074478, -0.029339954257011414, -0.02857741340994835, -0.027814872562885284, -0.02705233171582222, -0.026289790868759155, -0.02552724815905094, -0.024764707311987877, -0.024002166464924812, -0.023239625617861748, -0.022477084770798683, -0.02171454206109047, -0.020952001214027405, -0.02018946036696434, -0.019426919519901276, -0.01866437867283821, -0.017901837825775146, -0.017139295116066933, -0.016376754269003868, -0.015614213421940804, -0.014851672574877739, -0.014089131727814674, -0.01332659088075161, -0.012564050033688545, -0.011801507323980331, -0.011038966476917267, -0.010276425629854202, -0.009513884782791138, -0.008751343935728073, -0.007988803088665009, -0.007226262241601944, -0.006463721394538879, -0.005701180547475815, -0.004938635975122452, -0.004176095128059387, -0.0034135542809963226, -0.002651013433933258, -0.0018884725868701935, -0.001125931739807129, -0.00036339089274406433, 0.00039914995431900024, 0.0011616908013820648, 0.0019242316484451294, 0.002686772495508194, 0.0034493133425712585, 0.004211854189634323, 0.004974398761987686, 0.005736939609050751, 0.006499480456113815, 0.00726202130317688, 0.008024562150239944, 0.008787102997303009, 0.009549643844366074]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 7.0, 4.0, 8.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 6.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0], "bins": [-0.0430610291659832, -0.0420038215816021, -0.04094661772251129, -0.03988941013813019, -0.038832202553749084, -0.03777499496936798, -0.036717791110277176, -0.03566058352589607, -0.03460337966680527, -0.033546172082424164, -0.03248896449804306, -0.03143175691366196, -0.03037455305457115, -0.029317345470190048, -0.028260139748454094, -0.02720293216407299, -0.026145726442337036, -0.025088520720601082, -0.02403131313621998, -0.022974107414484024, -0.02191689983010292, -0.020859694108366966, -0.019802488386631012, -0.01874528080224991, -0.017688075080513954, -0.016630869358778, -0.015573661774396896, -0.014516456052660942, -0.013459250330924988, -0.012402042746543884, -0.01134483516216278, -0.010287631303071976, -0.009230423718690872, -0.008173216134309769, -0.007116012275218964, -0.00605880469083786, -0.005001597106456757, -0.0039443932473659515, -0.002887185662984848, -0.0018299780786037445, -0.000772770494222641, 0.00028443336486816406, 0.0013416409492492676, 0.002398848533630371, 0.003456052392721176, 0.00451325997710228, 0.005570467561483383, 0.006627671420574188, 0.007684879004955292, 0.008742086589336395, 0.0097992904484272, 0.010856498032808304, 0.011913705617189407, 0.012970909476280212, 0.014028117060661316, 0.01508532464504242, 0.016142528504133224, 0.017199736088514328, 0.01825694367289543, 0.019314151257276535, 0.02037135884165764, 0.021428558975458145, 0.02248576655983925, 0.023542974144220352, 0.024600181728601456]}, "_runtime": 6535.963530302048, "_timestamp": 1585576451.8081636, "_step": 298}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7046975493431091, "Value Loss": 0.04072469472885132, "_runtime": 6536.7207467556, "_timestamp": 1585576452.56538, "_step": 299}
{"Episode reward": 54.49999999999963, "Episode length": 455, "Policy Loss": 1.5326480865478516, "Value Loss": 21.97921371459961, "_runtime": 6538.267128229141, "_timestamp": 1585576454.1117616, "_step": 300}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.648340106010437, "Value Loss": 0.06742516160011292, "_runtime": 6539.846746444702, "_timestamp": 1585576455.6913798, "_step": 301}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.663688063621521, "Value Loss": 0.08622842282056808, "_runtime": 6541.418399095535, "_timestamp": 1585576457.2630324, "_step": 302}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6383723616600037, "Value Loss": 0.04661334678530693, "_runtime": 6543.020852565765, "_timestamp": 1585576458.865486, "_step": 303}
{"Episode reward": -99.82534296512463, "Episode length": 999, "Policy Loss": -0.6037151217460632, "Value Loss": 0.02379281260073185, "_runtime": 6544.022054433823, "_timestamp": 1585576459.8666878, "_step": 304}
{"Episode reward": 38.4999999999994, "Episode length": 615, "Policy Loss": 1.1158219575881958, "Value Loss": 16.06050682067871, "_runtime": 6545.59895157814, "_timestamp": 1585576461.443585, "_step": 305}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5522816181182861, "Value Loss": 0.028083359822630882, "_runtime": 6545.977356910706, "_timestamp": 1585576461.8219903, "_step": 306}
{"Episode reward": 79.29999999999998, "Episode length": 207, "Policy Loss": 4.008080959320068, "Value Loss": 47.54594039916992, "_runtime": 6547.5324449539185, "_timestamp": 1585576463.3770783, "_step": 307}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.564439058303833, "Value Loss": 0.07708325982093811, "_runtime": 6549.128084659576, "_timestamp": 1585576464.972718, "_step": 308}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6315374970436096, "Value Loss": 0.13457411527633667, "_runtime": 6550.64382481575, "_timestamp": 1585576466.4884582, "_step": 309}
{"Episode reward": -99.71807215809683, "Episode length": 999, "Policy Loss": -0.6806809306144714, "Value Loss": 0.2949747145175934, "_runtime": 6551.623792886734, "_timestamp": 1585576467.4684262, "_step": 310}
{"Episode reward": 39.79999999999942, "Episode length": 602, "Policy Loss": 1.0584808588027954, "Value Loss": 16.367515563964844, "_runtime": 6552.473613739014, "_timestamp": 1585576468.318247, "_step": 311}
{"Episode reward": 47.799999999999535, "Episode length": 522, "Policy Loss": 1.2267361879348755, "Value Loss": 18.783695220947266, "_runtime": 6554.058111906052, "_timestamp": 1585576469.9027452, "_step": 312}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6473683714866638, "Value Loss": 0.05371502786874771, "_runtime": 6555.623890399933, "_timestamp": 1585576471.4685237, "_step": 313}
{"Episode reward": -99.89000895023206, "Episode length": 999, "Policy Loss": -0.6633376479148865, "Value Loss": 0.0532195083796978, "_runtime": 6556.127380371094, "_timestamp": 1585576471.9720137, "_step": 314}
{"Episode reward": 68.9771956443785, "Episode length": 311, "Policy Loss": 2.536328077316284, "Value Loss": 31.733461380004883, "_runtime": 6557.705495595932, "_timestamp": 1585576473.550129, "_step": 315}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6938796043395996, "Value Loss": 0.03916574642062187, "_runtime": 6558.519600152969, "_timestamp": 1585576474.3642335, "_step": 316}
{"Episode reward": 49.39999999999956, "Episode length": 506, "Policy Loss": 1.1668024063110352, "Value Loss": 19.496109008789062, "_runtime": 6560.032975196838, "_timestamp": 1585576475.8776085, "_step": 317}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7324290871620178, "Value Loss": 0.08483992516994476, "_runtime": 6560.787208557129, "_timestamp": 1585576476.631842, "_step": 318}
{"Episode reward": 53.499999999999616, "Episode length": 465, "Policy Loss": 1.2776399850845337, "Value Loss": 21.11574935913086, "_runtime": 6562.339574098587, "_timestamp": 1585576478.1842074, "_step": 319}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8199425935745239, "Value Loss": 0.2919386327266693, "_runtime": 6563.904708147049, "_timestamp": 1585576479.7493415, "_step": 320}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8006108999252319, "Value Loss": 0.11403553187847137, "_runtime": 6565.429994344711, "_timestamp": 1585576481.2746277, "_step": 321}
{"Episode reward": 0.2000000000013955, "Episode length": 998, "Policy Loss": 0.11186481267213821, "Value Loss": 9.900884628295898, "_runtime": 6567.010940074921, "_timestamp": 1585576482.8555734, "_step": 322}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7876768112182617, "Value Loss": 0.015365328639745712, "_runtime": 6568.591285943985, "_timestamp": 1585576484.4359193, "_step": 323}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7846441864967346, "Value Loss": 0.014242368750274181, "_runtime": 6570.195124387741, "_timestamp": 1585576486.0397577, "_step": 324}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.788727343082428, "Value Loss": 0.006567330099642277, "_runtime": 6571.446257829666, "_timestamp": 1585576487.2908912, "_step": 325}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.5055716633796692, "Value Loss": 12.752751350402832, "_runtime": 6572.418935060501, "_timestamp": 1585576488.2635684, "_step": 326}
{"Episode reward": 39.09999999999941, "Episode length": 609, "Policy Loss": 0.9002946019172668, "Value Loss": 16.49176025390625, "_runtime": 6573.987091779709, "_timestamp": 1585576489.8317251, "_step": 327}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8007345199584961, "Value Loss": 0.00783313624560833, "_runtime": 6575.553237199783, "_timestamp": 1585576491.3978705, "_step": 328}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8265966773033142, "Value Loss": 0.0076879397965967655, "_runtime": 6577.104551076889, "_timestamp": 1585576492.9491844, "_step": 329}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.836137592792511, "Value Loss": 0.013083736412227154, "_runtime": 6578.3606197834015, "_timestamp": 1585576494.2052531, "_step": 330}
{"Episode reward": 21.200000000000202, "Episode length": 788, "Policy Loss": 0.36546051502227783, "Value Loss": 12.621233940124512, "_runtime": 6578.891129255295, "_timestamp": 1585576494.7357626, "_step": 331}
{"Episode reward": 68.39999999999984, "Episode length": 316, "Policy Loss": 2.1334803104400635, "Value Loss": 31.376588821411133, "_runtime": 6580.4633622169495, "_timestamp": 1585576496.3079956, "_step": 332}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9336574077606201, "Value Loss": 0.02372748591005802, "_runtime": 6582.028440237045, "_timestamp": 1585576497.8730736, "_step": 333}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9605149626731873, "Value Loss": 0.04077238216996193, "_runtime": 6583.434063434601, "_timestamp": 1585576499.2786968, "_step": 334}
{"Episode reward": 7.200000000000998, "Episode length": 928, "Policy Loss": 0.042912572622299194, "Value Loss": 10.702454566955566, "_runtime": 6585.018477678299, "_timestamp": 1585576500.863111, "_step": 335}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0189080238342285, "Value Loss": 0.0694163367152214, "_runtime": 6586.595019817352, "_timestamp": 1585576502.4396532, "_step": 336}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.008202314376831, "Value Loss": 0.09306658804416656, "_runtime": 6588.059935331345, "_timestamp": 1585576503.9045687, "_step": 337}
{"Episode reward": 5.9000000000010715, "Episode length": 941, "Policy Loss": 0.032576028257608414, "Value Loss": 10.49492359161377, "_runtime": 6588.469678401947, "_timestamp": 1585576504.3143117, "_step": 338}
{"Episode reward": 77.19999999999996, "Episode length": 228, "Policy Loss": 3.0787956714630127, "Value Loss": 43.185401916503906, "_runtime": 6589.409867048264, "_timestamp": 1585576505.2545004, "_step": 339}
{"Episode reward": 41.29999999999944, "Episode length": 587, "Policy Loss": 0.7703113555908203, "Value Loss": 16.80321502685547, "_runtime": 6590.826800107956, "_timestamp": 1585576506.6714334, "_step": 340}
{"Episode reward": 9.80000000000085, "Episode length": 902, "Policy Loss": -0.07338205724954605, "Value Loss": 10.976227760314941, "_runtime": 6592.350047588348, "_timestamp": 1585576508.194681, "_step": 341}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1767998933792114, "Value Loss": 0.043050557374954224, "_runtime": 6593.933462381363, "_timestamp": 1585576509.7780957, "_step": 342}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.189109206199646, "Value Loss": 0.3992537260055542, "_runtime": 6594.8162631988525, "_timestamp": 1585576510.6608965, "_step": 343}
{"Episode reward": 45.2999999999995, "Episode length": 547, "Policy Loss": 0.5257261395454407, "Value Loss": 17.91812515258789, "_runtime": 6596.386204242706, "_timestamp": 1585576512.2308376, "_step": 344}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.259637475013733, "Value Loss": 0.14605753123760223, "_runtime": 6597.989654779434, "_timestamp": 1585576513.8342881, "_step": 345}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2990548610687256, "Value Loss": 0.02314654551446438, "_runtime": 6598.970501422882, "_timestamp": 1585576514.8151348, "_step": 346}
{"Episode reward": 37.69999999999939, "Episode length": 623, "Policy Loss": 0.18883880972862244, "Value Loss": 15.872771263122559, "_runtime": 6600.544739484787, "_timestamp": 1585576516.3893728, "_step": 347}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.313663125038147, "Value Loss": 0.019003188237547874, "_runtime": 6602.14115858078, "_timestamp": 1585576517.985792, "_step": 348}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3206921815872192, "Value Loss": 0.018374497070908546, "_runtime": 6603.698454380035, "_timestamp": 1585576519.5430877, "_step": 349}
{"Episode reward": -99.86561949252942, "Episode length": 999, "Policy Loss": -1.3101544380187988, "Value Loss": 0.019510988146066666, "_runtime": 6605.261642932892, "_timestamp": 1585576521.1062763, "_step": 350}
{"Episode reward": 1.5000000000013216, "Episode length": 985, "Policy Loss": -0.04011842608451843, "Value Loss": 10.08505916595459, "_runtime": 6605.907141923904, "_timestamp": 1585576521.7517753, "_step": 351}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 1.1347029209136963, "Value Loss": 25.56539535522461, "_runtime": 6607.474862337112, "_timestamp": 1585576523.3194957, "_step": 352}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.23562753200531, "Value Loss": 0.018659748136997223, "_runtime": 6609.04679942131, "_timestamp": 1585576524.8914328, "_step": 353}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2019461393356323, "Value Loss": 0.031013019382953644, "_runtime": 6610.583400726318, "_timestamp": 1585576526.428034, "_step": 354}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1363469362258911, "Value Loss": 0.045377518981695175, "_runtime": 6612.170222043991, "_timestamp": 1585576528.0148554, "_step": 355}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0823792219161987, "Value Loss": 0.036660462617874146, "_runtime": 6613.748591423035, "_timestamp": 1585576529.5932248, "_step": 356}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0442487001419067, "Value Loss": 0.01579485647380352, "_runtime": 6615.329900026321, "_timestamp": 1585576531.1745334, "_step": 357}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9847086071968079, "Value Loss": 0.019613368436694145, "_runtime": 6616.748855352402, "_timestamp": 1585576532.5934887, "_step": 358}
{"Episode reward": 11.000000000000782, "Episode length": 890, "Policy Loss": 0.22506937384605408, "Value Loss": 11.083109855651855, "_runtime": 6618.365863323212, "_timestamp": 1585576534.2104967, "_step": 359}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.9000388979911804, "Value Loss": 0.023933259770274162, "_runtime": 6619.944728374481, "_timestamp": 1585576535.7893617, "_step": 360}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.8593451380729675, "Value Loss": 0.04224582016468048, "_runtime": 6621.304146289825, "_timestamp": 1585576537.1487796, "_step": 361}
{"Episode reward": 14.554034513235678, "Episode length": 855, "Policy Loss": 0.6104755401611328, "Value Loss": 12.903016090393066, "_runtime": 6622.873679637909, "_timestamp": 1585576538.718313, "_step": 362}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7361316680908203, "Value Loss": 0.022613337263464928, "_runtime": 6624.464371919632, "_timestamp": 1585576540.3090053, "_step": 363}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.686820387840271, "Value Loss": 0.04442800581455231, "_runtime": 6625.279233455658, "_timestamp": 1585576541.1238668, "_step": 364}
{"Episode reward": 49.199999999999555, "Episode length": 508, "Policy Loss": 1.260948896408081, "Value Loss": 19.29929542541504, "_runtime": 6626.861301422119, "_timestamp": 1585576542.7059348, "_step": 365}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.599138081073761, "Value Loss": 0.1047390028834343, "_runtime": 6628.188908576965, "_timestamp": 1585576544.033542, "_step": 366}
{"Episode reward": 15.700000000000514, "Episode length": 843, "Policy Loss": 0.6301666498184204, "Value Loss": 11.652447700500488, "_runtime": 6629.732882499695, "_timestamp": 1585576545.5775158, "_step": 367}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.49582546949386597, "Value Loss": 0.15423955023288727, "_runtime": 6631.321338415146, "_timestamp": 1585576547.1659718, "_step": 368}
{"Episode reward": -99.87880029678205, "Episode length": 999, "Policy Loss": -0.416517436504364, "Value Loss": 0.05292906612157822, "_runtime": 6631.963983535767, "_timestamp": 1585576547.8086169, "_step": 369}
{"Episode reward": 61.099999999999724, "Episode length": 389, "Policy Loss": 2.5368571281433105, "Value Loss": 25.298521041870117, "_runtime": 6633.52853012085, "_timestamp": 1585576549.3731635, "_step": 370}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.37009233236312866, "Value Loss": 0.010284433141350746, "_runtime": 6634.557022094727, "_timestamp": 1585576550.4016554, "_step": 371}
{"Episode reward": 36.19999999999937, "Episode length": 638, "Policy Loss": 1.1006830930709839, "Value Loss": 15.14509105682373, "_runtime": 6636.0906364917755, "_timestamp": 1585576551.9352698, "_step": 372}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.34154048562049866, "Value Loss": 0.009362696669995785, "_runtime": 6637.676512479782, "_timestamp": 1585576553.5211458, "_step": 373}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.323723167181015, "Value Loss": 0.06115252897143364, "_runtime": 6639.165773391724, "_timestamp": 1585576555.0104067, "_step": 374}
{"Episode reward": 3.880816626549958, "Episode length": 962, "Policy Loss": 0.6395978927612305, "Value Loss": 10.09066390991211, "_runtime": 6640.778156757355, "_timestamp": 1585576556.62279, "_step": 375}
{"Episode reward": -99.70702590942244, "Episode length": 999, "Policy Loss": -0.32703858613967896, "Value Loss": 0.05659869313240051, "_runtime": 6642.358086824417, "_timestamp": 1585576558.2027202, "_step": 376}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.337689608335495, "Value Loss": 0.053841374814510345, "_runtime": 6643.935408115387, "_timestamp": 1585576559.7800415, "_step": 377}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3480229377746582, "Value Loss": 0.01881261356174946, "_runtime": 6644.71763586998, "_timestamp": 1585576560.5622692, "_step": 378}
{"Episode reward": 52.3999999999996, "Episode length": 476, "Policy Loss": 1.7453076839447021, "Value Loss": 20.377159118652344, "_runtime": 6645.257267475128, "_timestamp": 1585576561.1019008, "_step": 379}
{"Episode reward": 68.29999999999983, "Episode length": 317, "Policy Loss": 2.5394389629364014, "Value Loss": 29.993976593017578, "_runtime": 6646.837260246277, "_timestamp": 1585576562.6818936, "_step": 380}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4100963771343231, "Value Loss": 0.15287549793720245, "_runtime": 6648.380224466324, "_timestamp": 1585576564.2248578, "_step": 381}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5096176862716675, "Value Loss": 0.011127891950309277, "_runtime": 6649.906368732452, "_timestamp": 1585576565.751002, "_step": 382}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5634071826934814, "Value Loss": 0.007809854112565517, "_runtime": 6651.440593719482, "_timestamp": 1585576567.285227, "_step": 383}
{"Episode reward": 3.7000000000011966, "Episode length": 963, "Policy Loss": 0.39390161633491516, "Value Loss": 9.993749618530273, "_runtime": 6652.433105230331, "_timestamp": 1585576568.2777386, "_step": 384}
{"Episode reward": 37.999999999999396, "Episode length": 620, "Policy Loss": 0.9804089665412903, "Value Loss": 15.075234413146973, "_runtime": 6652.834088563919, "_timestamp": 1585576568.678722, "_step": 385}
{"Episode reward": 77.09999999999995, "Episode length": 229, "Policy Loss": 3.471224308013916, "Value Loss": 40.831817626953125, "_runtime": 6654.4160623550415, "_timestamp": 1585576570.2606957, "_step": 386}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7979737520217896, "Value Loss": 0.07438956201076508, "_runtime": 6655.403820991516, "_timestamp": 1585576571.2484543, "_step": 387}
{"Episode reward": 37.49999999999939, "Episode length": 625, "Policy Loss": 0.5367817282676697, "Value Loss": 14.905128479003906, "_runtime": 6656.888333559036, "_timestamp": 1585576572.732967, "_step": 388}
{"Episode reward": 1.300000000001333, "Episode length": 987, "Policy Loss": -0.06117620691657066, "Value Loss": 9.314330101013184, "_runtime": 6658.466673135757, "_timestamp": 1585576574.3113065, "_step": 389}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.193329095840454, "Value Loss": 0.01905657909810543, "_runtime": 6660.0134370327, "_timestamp": 1585576575.8580704, "_step": 390}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.285799503326416, "Value Loss": 0.025023948401212692, "_runtime": 6661.529724121094, "_timestamp": 1585576577.3743575, "_step": 391}
{"Episode reward": 2.7000000000012534, "Episode length": 973, "Policy Loss": -0.43312808871269226, "Value Loss": 9.332300186157227, "_runtime": 6662.2678554058075, "_timestamp": 1585576578.1124887, "_step": 392}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": 0.6135011911392212, "Value Loss": 21.302270889282227, "_runtime": 6663.51952290535, "_timestamp": 1585576579.3641562, "_step": 393}
{"Episode reward": 21.300000000000196, "Episode length": 787, "Policy Loss": 0.029733816161751747, "Value Loss": 11.247448921203613, "_runtime": 6665.128427743912, "_timestamp": 1585576580.973061, "_step": 394}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.446229338645935, "Value Loss": 0.1697104126214981, "_runtime": 6666.655345439911, "_timestamp": 1585576582.4999788, "_step": 395}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5184824466705322, "Value Loss": 0.0645451620221138, "_runtime": 6668.2303347587585, "_timestamp": 1585576584.074968, "_step": 396}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5170708894729614, "Value Loss": 0.20742186903953552, "_runtime": 6669.803771734238, "_timestamp": 1585576585.648405, "_step": 397}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4891287088394165, "Value Loss": 0.3072274327278137, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094, 0.04602888226509094]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.04602888226509094, 0.172291561961174, 0.39061200618743896, 0.6089324951171875, 0.8272528648376465, 1.045573353767395, 1.2638938426971436, 1.4822142124176025, 1.700534701347351, 1.9188551902770996, 2.1371755599975586, 2.3554959297180176, 2.5738165378570557, 2.7921369075775146, 3.0104572772979736, 3.2287778854370117, 3.4470982551574707, 3.6654186248779297, 3.8837392330169678, 4.102059364318848, 4.320379734039307, 4.538700103759766, 4.757020473480225, 4.975341320037842, 5.193661689758301, 5.41198205947876, 5.630302429199219, 5.848622798919678, 6.066943168640137, 6.285264015197754, 6.503584384918213, 6.721904754638672, 6.940225124359131, 7.15854549407959, 7.376865863800049, 7.595186233520508, 7.813507080078125, 8.031826972961426, 8.250147819519043, 8.46846866607666, 8.686788558959961, 8.905109405517578, 9.123429298400879, 9.341750144958496, 9.560070037841797, 9.778390884399414, 9.996711730957031, 10.215031623840332, 10.43335247039795, 10.65167236328125, 10.869993209838867, 11.088313102722168, 11.306633949279785, 11.524954795837402, 11.743274688720703, 11.96159553527832, 12.179915428161621, 12.398236274719238, 12.616557121276855, 12.834877014160156, 13.053197860717773, 13.271517753601074, 13.489838600158691, 13.708158493041992, 13.92647933959961]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1.105491431729888e-08, 0.002882434753701091, 0.00576488021761179, 0.00864732638001442, 0.011529771611094475, 0.01441221684217453, 0.017294663935899734, 0.02017710916697979, 0.023059554398059845, 0.0259419996291399, 0.028824444860219955, 0.03170689195394516, 0.034589339047670364, 0.03747178241610527, 0.040354229509830475, 0.04323667287826538, 0.046119119971990585, 0.04900156706571579, 0.051884010434150696, 0.0547664575278759, 0.057648900896310806, 0.06053134799003601, 0.06341379880905151, 0.06629624217748642, 0.06917869299650192, 0.07206113636493683, 0.07494357973337173, 0.07782602310180664, 0.08070847392082214, 0.08359091728925705, 0.08647336065769196, 0.08935581147670746, 0.09223825484514236, 0.09512069821357727, 0.09800314903259277, 0.10088559240102768, 0.10376803576946259, 0.10665048658847809, 0.109532929956913, 0.1124153733253479, 0.1152978166937828, 0.11818026751279831, 0.12106271088123322, 0.12394515424966812, 0.12682759761810303, 0.12971004843711853, 0.13259248435497284, 0.13547493517398834, 0.13835738599300385, 0.14123982191085815, 0.14412227272987366, 0.14700470864772797, 0.14988715946674347, 0.15276961028575897, 0.15565204620361328, 0.15853449702262878, 0.1614169478416443, 0.1642993837594986, 0.1671818345785141, 0.1700642853975296, 0.1729467213153839, 0.17582917213439941, 0.17871162295341492, 0.18159405887126923, 0.18447650969028473]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [11.0, 0.0, 0.0, 28.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 12.0, 10.0, 11.0, 14.0, 11.0, 7.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.18300969898700714, -0.1668911576271057, -0.15077261626720428, -0.13465407490730286, -0.11853554099798203, -0.1024169996380806, -0.08629846572875977, -0.07017992436885834, -0.05406138300895691, -0.03794284164905548, -0.021824300289154053, -0.0057057589292526245, 0.01041276752948761, 0.026531308889389038, 0.042649850249290466, 0.058768391609191895, 0.07488693296909332, 0.09100545942783356, 0.10712401568889618, 0.12324254214763641, 0.13936109840869904, 0.15547962486743927, 0.1715981811285019, 0.18771670758724213, 0.20383523404598236, 0.21995379030704498, 0.23607231676578522, 0.25219088792800903, 0.26830941438674927, 0.2844279408454895, 0.30054646730422974, 0.31666505336761475, 0.332783579826355, 0.3489021062850952, 0.36502063274383545, 0.38113921880722046, 0.3972577452659607, 0.4133762717247009, 0.42949479818344116, 0.44561338424682617, 0.4617319107055664, 0.47785043716430664, 0.4939689636230469, 0.5100874900817871, 0.5262060761451721, 0.5423246026039124, 0.5584431290626526, 0.5745616555213928, 0.5906801819801331, 0.6067987680435181, 0.6229172945022583, 0.6390358209609985, 0.6551543474197388, 0.6712729334831238, 0.687391459941864, 0.7035099864006042, 0.7196285128593445, 0.7357470393180847, 0.7518656253814697, 0.76798415184021, 0.7841026782989502, 0.8002212047576904, 0.8163397908210754, 0.8324583172798157, 0.8485768437385559]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 1.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.19850003719329834, -0.11879072338342667, -0.03908140957355499, 0.040627896785736084, 0.12033721804618835, 0.20004653930664062, 0.2797558307647705, 0.35946518182754517, 0.43917447328567505, 0.5188837647438049, 0.5985931158065796, 0.6783024072647095, 0.7580116987228394, 0.8377209901809692, 0.9174304008483887, 0.9971396923065186, 1.0768489837646484, 1.1565582752227783, 1.2362675666809082, 1.3159769773483276, 1.3956862688064575, 1.4753955602645874, 1.5551048517227173, 1.6348141431808472, 1.714523434638977, 1.7942328453063965, 1.8739420175552368, 1.9536515474319458, 2.0333609580993652, 2.113070011138916, 2.192779541015625, 2.272488594055176, 2.3521981239318848, 2.4319071769714355, 2.5116167068481445, 2.5913257598876953, 2.6710352897644043, 2.750744342803955, 2.830453872680664, 2.910163402557373, 2.989872455596924, 3.069581985473633, 3.1492910385131836, 3.2290005683898926, 3.3087096214294434, 3.3884191513061523, 3.468128204345703, 3.547837734222412, 3.627546787261963, 3.707256317138672, 3.786965847015381, 3.8666749000549316, 3.9463839530944824, 4.026093482971191, 4.1058030128479, 4.185512065887451, 4.26522159576416, 4.344930648803711, 4.42464017868042, 4.504349231719971, 4.58405876159668, 4.6637678146362305, 4.7434773445129395, 4.82318639755249, 4.902895927429199]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 22.0, 1.0, 11.0, 2.0, 3.0, 4.0], "bins": [-2.0478551387786865, -2.012885093688965, -1.9779151678085327, -1.9429452419281006, -1.9079753160476685, -1.8730053901672363, -1.8380353450775146, -1.8030654191970825, -1.7680954933166504, -1.7331254482269287, -1.6981555223464966, -1.6631855964660645, -1.6282155513763428, -1.5932456254959106, -1.5582756996154785, -1.5233056545257568, -1.4883357286453247, -1.4533658027648926, -1.418395757675171, -1.3834258317947388, -1.3484559059143066, -1.313485860824585, -1.2785159349441528, -1.2435460090637207, -1.208575963973999, -1.173606038093567, -1.1386361122131348, -1.103666067123413, -1.068696141242981, -1.0337262153625488, -0.9987562894821167, -0.963786244392395, -0.9288163185119629, -0.8938463926315308, -0.8588763475418091, -0.823906421661377, -0.7889364957809448, -0.7539664506912231, -0.718996524810791, -0.6840265989303589, -0.6490566730499268, -0.6140866279602051, -0.579116702079773, -0.5441467761993408, -0.5091767311096191, -0.474206805229187, -0.4392368793487549, -0.4042668342590332, -0.3692969083786011, -0.33432698249816895, -0.29935693740844727, -0.26438701152801514, -0.229417085647583, -0.19444704055786133, -0.1594771146774292, -0.12450718879699707, -0.08953714370727539, -0.05456721782684326, -0.019597291946411133, 0.015372753143310547, 0.050342559814453125, 0.0853126049041748, 0.12028264999389648, 0.15525245666503906, 0.19022250175476074]}, "_runtime": 6670.6971390247345, "_timestamp": 1585576586.5417724, "_step": 398}
{"Episode reward": 44.69999999999949, "Episode length": 553, "Policy Loss": 0.0811697468161583, "Value Loss": 15.412849426269531, "_runtime": 6672.27712392807, "_timestamp": 1585576588.1217573, "_step": 399}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.2824325561523438, "Value Loss": 0.13614189624786377, "_runtime": 6673.862465381622, "_timestamp": 1585576589.7070987, "_step": 400}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1384025812149048, "Value Loss": 0.033893320709466934, "_runtime": 6674.129135608673, "_timestamp": 1585576589.973769, "_step": 401}
{"Episode reward": 85.70000000000005, "Episode length": 143, "Policy Loss": 5.675552845001221, "Value Loss": 69.3476333618164, "_runtime": 6675.706614732742, "_timestamp": 1585576591.551248, "_step": 402}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4173818826675415, "Value Loss": 0.059273891150951385, "_runtime": 6677.280923604965, "_timestamp": 1585576593.125557, "_step": 403}
{"Episode reward": -99.81195106506208, "Episode length": 999, "Policy Loss": -1.6360200643539429, "Value Loss": 1.3562986850738525, "_runtime": 6678.783486366272, "_timestamp": 1585576594.6281197, "_step": 404}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8499183654785156, "Value Loss": 0.26587188243865967, "_runtime": 6680.26118850708, "_timestamp": 1585576596.1058218, "_step": 405}
{"Episode reward": 7.999264979363446, "Episode length": 922, "Policy Loss": -0.4749451279640198, "Value Loss": 14.330105781555176, "_runtime": 6681.839621067047, "_timestamp": 1585576597.6842544, "_step": 406}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.6732994318008423, "Value Loss": 0.03660605102777481, "_runtime": 6682.328493356705, "_timestamp": 1585576598.1731267, "_step": 407}
{"Episode reward": 71.29999999999987, "Episode length": 287, "Policy Loss": 1.5880868434906006, "Value Loss": 33.237945556640625, "_runtime": 6683.692216157913, "_timestamp": 1585576599.5368495, "_step": 408}
{"Episode reward": 13.30000000000065, "Episode length": 867, "Policy Loss": -0.043128229677677155, "Value Loss": 11.755745887756348, "_runtime": 6684.874717473984, "_timestamp": 1585576600.7193508, "_step": 409}
{"Episode reward": 25.399999999999963, "Episode length": 746, "Policy Loss": 0.4792359471321106, "Value Loss": 12.992595672607422, "_runtime": 6686.3914103508, "_timestamp": 1585576602.2360437, "_step": 410}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6367745995521545, "Value Loss": 0.14716552197933197, "_runtime": 6687.959161996841, "_timestamp": 1585576603.8037953, "_step": 411}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4453919529914856, "Value Loss": 0.005835511721670628, "_runtime": 6689.561317443848, "_timestamp": 1585576605.4059508, "_step": 412}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.309140145778656, "Value Loss": 0.03778493404388428, "_runtime": 6691.121257305145, "_timestamp": 1585576606.9658906, "_step": 413}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.21265631914138794, "Value Loss": 0.1277010440826416, "_runtime": 6692.713807821274, "_timestamp": 1585576608.5584412, "_step": 414}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.0737416222691536, "Value Loss": 0.08133789896965027, "_runtime": 6693.433190345764, "_timestamp": 1585576609.2778237, "_step": 415}
{"Episode reward": 56.49999999999966, "Episode length": 435, "Policy Loss": 2.314943313598633, "Value Loss": 22.633222579956055, "_runtime": 6694.514037847519, "_timestamp": 1585576610.3586712, "_step": 416}
{"Episode reward": 31.59999999999961, "Episode length": 684, "Policy Loss": 1.5414162874221802, "Value Loss": 14.400729179382324, "_runtime": 6695.143392801285, "_timestamp": 1585576610.9880261, "_step": 417}
{"Episode reward": 62.39999999999974, "Episode length": 376, "Policy Loss": 2.7823798656463623, "Value Loss": 25.964815139770508, "_runtime": 6696.678979873657, "_timestamp": 1585576612.5236132, "_step": 418}
{"Episode reward": -99.81282745003561, "Episode length": 999, "Policy Loss": 0.3121773302555084, "Value Loss": 0.04796084016561508, "_runtime": 6698.234077692032, "_timestamp": 1585576614.078711, "_step": 419}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.4309012293815613, "Value Loss": 0.00970607902854681, "_runtime": 6699.762696504593, "_timestamp": 1585576615.6073298, "_step": 420}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.5568647980690002, "Value Loss": 0.06522990763187408, "_runtime": 6700.171696424484, "_timestamp": 1585576616.0163298, "_step": 421}
{"Episode reward": 77.49999999999996, "Episode length": 225, "Policy Loss": 4.828285217285156, "Value Loss": 41.87908935546875, "_runtime": 6701.753499031067, "_timestamp": 1585576617.5981324, "_step": 422}
{"Episode reward": -99.80149011611799, "Episode length": 999, "Policy Loss": 0.7329652309417725, "Value Loss": 0.016087882220745087, "_runtime": 6703.332768201828, "_timestamp": 1585576619.1774015, "_step": 423}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.73042893409729, "Value Loss": 0.021966444328427315, "_runtime": 6704.846530199051, "_timestamp": 1585576620.6911635, "_step": 424}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.6649433374404907, "Value Loss": 0.03901994600892067, "_runtime": 6706.273324728012, "_timestamp": 1585576622.117958, "_step": 425}
{"Episode reward": 10.100000000000833, "Episode length": 899, "Policy Loss": 1.7770113945007324, "Value Loss": 14.024072647094727, "_runtime": 6707.848767518997, "_timestamp": 1585576623.6934009, "_step": 426}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.2060359716415405, "Value Loss": 0.24927446246147156, "_runtime": 6709.420475721359, "_timestamp": 1585576625.265109, "_step": 427}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7752450704574585, "Value Loss": 0.8912135362625122, "_runtime": 6711.0083293914795, "_timestamp": 1585576626.8529627, "_step": 428}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 1.7219514846801758, "Value Loss": 5.954070091247559, "_runtime": 6712.638158798218, "_timestamp": 1585576628.4827921, "_step": 429}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 2.1906356811523438, "Value Loss": 2.2819650173187256, "_runtime": 6713.424776792526, "_timestamp": 1585576629.2694101, "_step": 430}
{"Episode reward": 51.49999999999959, "Episode length": 485, "Policy Loss": 4.339587688446045, "Value Loss": 36.37363052368164, "_runtime": 6715.017821073532, "_timestamp": 1585576630.8624544, "_step": 431}
{"Episode reward": -99.891871476172, "Episode length": 999, "Policy Loss": 1.2661023139953613, "Value Loss": 0.07034889608621597, "_runtime": 6716.6003448963165, "_timestamp": 1585576632.4449782, "_step": 432}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": 0.3360998034477234, "Value Loss": 0.013953839428722858, "_runtime": 6718.137037038803, "_timestamp": 1585576633.9816704, "_step": 433}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.4931515157222748, "Value Loss": 0.007395852357149124, "_runtime": 6719.053130149841, "_timestamp": 1585576634.8977635, "_step": 434}
{"Episode reward": 43.79999999999948, "Episode length": 562, "Policy Loss": 0.5841144919395447, "Value Loss": 17.917781829833984, "_runtime": 6720.277467250824, "_timestamp": 1585576636.1221006, "_step": 435}
{"Episode reward": 22.700000000000117, "Episode length": 773, "Policy Loss": -0.48984289169311523, "Value Loss": 13.6712007522583, "_runtime": 6721.324738025665, "_timestamp": 1585576637.1693714, "_step": 436}
{"Episode reward": 33.799999999999486, "Episode length": 662, "Policy Loss": -0.6777243614196777, "Value Loss": 17.190183639526367, "_runtime": 6722.883227348328, "_timestamp": 1585576638.7278607, "_step": 437}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5258467197418213, "Value Loss": 0.3406117260456085, "_runtime": 6724.452990531921, "_timestamp": 1585576640.2976239, "_step": 438}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.5260910987854004, "Value Loss": 0.9355036020278931, "_runtime": 6725.993352651596, "_timestamp": 1585576641.837986, "_step": 439}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6355724334716797, "Value Loss": 0.11008838564157486, "_runtime": 6726.904434680939, "_timestamp": 1585576642.749068, "_step": 440}
{"Episode reward": 43.599999999999476, "Episode length": 564, "Policy Loss": -0.9360948801040649, "Value Loss": 17.408409118652344, "_runtime": 6728.482578277588, "_timestamp": 1585576644.3272116, "_step": 441}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -2.6143620014190674, "Value Loss": 0.5802237391471863, "_runtime": 6729.154501914978, "_timestamp": 1585576644.9991353, "_step": 442}
{"Episode reward": 59.3999999999997, "Episode length": 406, "Policy Loss": 0.03828928619623184, "Value Loss": 24.298599243164062, "_runtime": 6730.1299204826355, "_timestamp": 1585576645.9745538, "_step": 443}
{"Episode reward": 37.59999999999939, "Episode length": 624, "Policy Loss": -0.9139343500137329, "Value Loss": 16.588626861572266, "_runtime": 6731.568292140961, "_timestamp": 1585576647.4129255, "_step": 444}
{"Episode reward": 8.100000000000946, "Episode length": 919, "Policy Loss": -0.7800825834274292, "Value Loss": 11.116081237792969, "_runtime": 6732.289836645126, "_timestamp": 1585576648.13447, "_step": 445}
{"Episode reward": 53.59999999999962, "Episode length": 464, "Policy Loss": 0.7587407827377319, "Value Loss": 21.206863403320312, "_runtime": 6732.99235367775, "_timestamp": 1585576648.836987, "_step": 446}
{"Episode reward": 55.69999999999965, "Episode length": 443, "Policy Loss": 1.0407791137695312, "Value Loss": 22.230545043945312, "_runtime": 6733.970812082291, "_timestamp": 1585576649.8154454, "_step": 447}
{"Episode reward": 38.79999999999941, "Episode length": 612, "Policy Loss": 0.7301046252250671, "Value Loss": 16.278059005737305, "_runtime": 6735.500844240189, "_timestamp": 1585576651.3454776, "_step": 448}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7415082454681396, "Value Loss": 0.026721343398094177, "_runtime": 6737.056740760803, "_timestamp": 1585576652.901374, "_step": 449}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6404800415039062, "Value Loss": 0.015358374454081059, "_runtime": 6738.129351139069, "_timestamp": 1585576653.9739845, "_step": 450}
{"Episode reward": 31.199999999999633, "Episode length": 688, "Policy Loss": 0.789396345615387, "Value Loss": 14.853466033935547, "_runtime": 6739.407961368561, "_timestamp": 1585576655.2525947, "_step": 451}
{"Episode reward": 18.200000000000372, "Episode length": 818, "Policy Loss": 0.5505117177963257, "Value Loss": 12.246732711791992, "_runtime": 6740.982233762741, "_timestamp": 1585576656.826867, "_step": 452}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6470193266868591, "Value Loss": 0.11255801469087601, "_runtime": 6742.129110574722, "_timestamp": 1585576657.973744, "_step": 453}
{"Episode reward": 26.69999999999989, "Episode length": 733, "Policy Loss": 1.3026317358016968, "Value Loss": 13.834305763244629, "_runtime": 6743.680184841156, "_timestamp": 1585576659.5248182, "_step": 454}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.7020830512046814, "Value Loss": 0.34071269631385803, "_runtime": 6745.252111196518, "_timestamp": 1585576661.0967445, "_step": 455}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.5133556723594666, "Value Loss": 0.5479307174682617, "_runtime": 6745.917315006256, "_timestamp": 1585576661.7619483, "_step": 456}
{"Episode reward": 59.05007970333069, "Episode length": 410, "Policy Loss": 1.7364006042480469, "Value Loss": 25.37227439880371, "_runtime": 6746.676404237747, "_timestamp": 1585576662.5210376, "_step": 457}
{"Episode reward": 52.99999999999961, "Episode length": 470, "Policy Loss": 1.8330472707748413, "Value Loss": 22.210351943969727, "_runtime": 6747.11154460907, "_timestamp": 1585576662.956178, "_step": 458}
{"Episode reward": 74.99999999999991, "Episode length": 250, "Policy Loss": 3.291145086288452, "Value Loss": 40.357330322265625, "_runtime": 6748.636177301407, "_timestamp": 1585576664.4808106, "_step": 459}
{"Episode reward": -99.8032639503465, "Episode length": 999, "Policy Loss": -0.9076875448226929, "Value Loss": 0.01998814195394516, "_runtime": 6750.172023534775, "_timestamp": 1585576666.0166569, "_step": 460}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.1882035732269287, "Value Loss": 0.04961388558149338, "_runtime": 6751.683900356293, "_timestamp": 1585576667.5285337, "_step": 461}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4142775535583496, "Value Loss": 0.11358916014432907, "_runtime": 6753.258066415787, "_timestamp": 1585576669.1026998, "_step": 462}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.643720269203186, "Value Loss": 0.06592810899019241, "_runtime": 6754.8195695877075, "_timestamp": 1585576670.664203, "_step": 463}
{"Episode reward": 0.9000000000013557, "Episode length": 991, "Policy Loss": -0.7794818878173828, "Value Loss": 10.436267852783203, "_runtime": 6756.378221035004, "_timestamp": 1585576672.2228544, "_step": 464}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8160731792449951, "Value Loss": 0.29427623748779297, "_runtime": 6757.835294008255, "_timestamp": 1585576673.6799273, "_step": 465}
{"Episode reward": 9.161968207360204, "Episode length": 909, "Policy Loss": -0.6592137217521667, "Value Loss": 11.207991600036621, "_runtime": 6759.419047355652, "_timestamp": 1585576675.2636807, "_step": 466}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.8480496406555176, "Value Loss": 0.236122265458107, "_runtime": 6760.8073852062225, "_timestamp": 1585576676.6520185, "_step": 467}
{"Episode reward": 14.2000000000006, "Episode length": 858, "Policy Loss": -0.6910132169723511, "Value Loss": 11.489405632019043, "_runtime": 6762.399211406708, "_timestamp": 1585576678.2438447, "_step": 468}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.772363543510437, "Value Loss": 0.21204447746276855, "_runtime": 6763.982394933701, "_timestamp": 1585576679.8270283, "_step": 469}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.7621798515319824, "Value Loss": 0.3387208878993988, "_runtime": 6765.535651683807, "_timestamp": 1585576681.380285, "_step": 470}
{"Episode reward": 1.00000000000135, "Episode length": 990, "Policy Loss": -0.7371890544891357, "Value Loss": 10.045063018798828, "_runtime": 6766.623361349106, "_timestamp": 1585576682.4679947, "_step": 471}
{"Episode reward": 32.29999999999957, "Episode length": 677, "Policy Loss": -0.18847247958183289, "Value Loss": 14.836159706115723, "_runtime": 6768.2063155174255, "_timestamp": 1585576684.0509489, "_step": 472}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.5025466680526733, "Value Loss": 0.1598929762840271, "_runtime": 6769.796776533127, "_timestamp": 1585576685.6414099, "_step": 473}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.4529240131378174, "Value Loss": 0.09326371550559998, "_runtime": 6771.358772277832, "_timestamp": 1585576687.2034056, "_step": 474}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.3303598165512085, "Value Loss": 0.05872934311628342, "_runtime": 6772.567433357239, "_timestamp": 1585576688.4120667, "_step": 475}
{"Episode reward": 24.40000000000002, "Episode length": 756, "Policy Loss": 0.00809474103152752, "Value Loss": 13.807149887084961, "_runtime": 6774.143442630768, "_timestamp": 1585576689.988076, "_step": 476}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -1.0891849994659424, "Value Loss": 0.02619197964668274, "_runtime": 6775.6428990364075, "_timestamp": 1585576691.4875324, "_step": 477}
{"Episode reward": 5.500000000001094, "Episode length": 945, "Policy Loss": 0.18384595215320587, "Value Loss": 10.649810791015625, "_runtime": 6776.37685251236, "_timestamp": 1585576692.2214859, "_step": 478}
{"Episode reward": 54.49999999999963, "Episode length": 455, "Policy Loss": 1.3356750011444092, "Value Loss": 21.82889747619629, "_runtime": 6777.950658559799, "_timestamp": 1585576693.795292, "_step": 479}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.6715109944343567, "Value Loss": 0.19062958657741547, "_runtime": 6779.031685829163, "_timestamp": 1585576694.8763192, "_step": 480}
{"Episode reward": 32.69999999999955, "Episode length": 673, "Policy Loss": 1.013466477394104, "Value Loss": 14.885955810546875, "_runtime": 6779.653971910477, "_timestamp": 1585576695.4986053, "_step": 481}
{"Episode reward": 59.699999999999704, "Episode length": 403, "Policy Loss": 1.8525300025939941, "Value Loss": 24.43435287475586, "_runtime": 6781.222332715988, "_timestamp": 1585576697.066966, "_step": 482}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.45604392886161804, "Value Loss": 0.04456407576799393, "_runtime": 6782.780401945114, "_timestamp": 1585576698.6250353, "_step": 483}
{"Episode reward": 0.5000000000013785, "Episode length": 995, "Policy Loss": 0.5568569898605347, "Value Loss": 9.941549301147461, "_runtime": 6783.6124567985535, "_timestamp": 1585576699.4570901, "_step": 484}
{"Episode reward": 46.399999999999515, "Episode length": 536, "Policy Loss": 1.515520691871643, "Value Loss": 18.42755699157715, "_runtime": 6784.650085926056, "_timestamp": 1585576700.4947193, "_step": 485}
{"Episode reward": 34.79999999999943, "Episode length": 652, "Policy Loss": 1.1792844533920288, "Value Loss": 15.136810302734375, "_runtime": 6785.994519948959, "_timestamp": 1585576701.8391533, "_step": 486}
{"Episode reward": 16.900000000000446, "Episode length": 831, "Policy Loss": 0.918895959854126, "Value Loss": 11.941622734069824, "_runtime": 6787.172109365463, "_timestamp": 1585576703.0167427, "_step": 487}
{"Episode reward": 23.84480699896818, "Episode length": 762, "Policy Loss": 0.9479398131370544, "Value Loss": 12.954475402832031, "_runtime": 6788.448985815048, "_timestamp": 1585576704.2936192, "_step": 488}
{"Episode reward": 17.7000000000004, "Episode length": 823, "Policy Loss": 0.8491767048835754, "Value Loss": 12.06331729888916, "_runtime": 6790.013110160828, "_timestamp": 1585576705.8577435, "_step": 489}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.2898302376270294, "Value Loss": 0.12518317997455597, "_runtime": 6790.650621414185, "_timestamp": 1585576706.4952548, "_step": 490}
{"Episode reward": 59.99999999999971, "Episode length": 400, "Policy Loss": 2.159142017364502, "Value Loss": 24.72629165649414, "_runtime": 6792.212005853653, "_timestamp": 1585576708.0566392, "_step": 491}
{"Episode reward": -99.86287994384625, "Episode length": 999, "Policy Loss": -0.3287584185600281, "Value Loss": 0.020395729690790176, "_runtime": 6793.801469802856, "_timestamp": 1585576709.6461031, "_step": 492}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32894784212112427, "Value Loss": 0.02882775478065014, "_runtime": 6795.329323768616, "_timestamp": 1585576711.173957, "_step": 493}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.32419353723526, "Value Loss": 0.02730073593556881, "_runtime": 6796.868939161301, "_timestamp": 1585576712.7135725, "_step": 494}
{"Episode reward": 2.200000000001282, "Episode length": 978, "Policy Loss": 0.6450551748275757, "Value Loss": 10.153846740722656, "_runtime": 6798.4542026519775, "_timestamp": 1585576714.298836, "_step": 495}
{"Episode reward": -99.81461718082288, "Episode length": 999, "Policy Loss": -0.335649311542511, "Value Loss": 0.005011276341974735, "_runtime": 6800.024669647217, "_timestamp": 1585576715.869303, "_step": 496}
{"Episode reward": -99.8999999999986, "Episode length": 999, "Policy Loss": -0.3455164134502411, "Value Loss": 0.005525005981326103, "_runtime": 6800.583164215088, "_timestamp": 1585576716.4277976, "_step": 497}
{"Episode reward": 67.19999999999982, "Episode length": 328, "Policy Loss": 2.6791958808898926, "Value Loss": 30.313440322875977, "gradients/fc.2.bias": {"_type": "histogram", "values": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "bins": [0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958, 0.0024834992364048958]}, "gradients/fc.2.weight": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-0.0024834992364048958, 0.012231879867613316, 0.0269472599029541, 0.041662637144327164, 0.056378018110990524, 0.07109339535236359, 0.08580876886844635, 0.10052414983510971, 0.11523953080177307, 0.12995490431785583, 0.1446702927350998, 0.15938566625118256, 0.17410103976726532, 0.18881642818450928, 0.20353180170059204, 0.218247190117836, 0.23296256363391876, 0.24767793715000153, 0.2623933255672455, 0.27710872888565063, 0.2918241024017334, 0.30653947591781616, 0.3212548494338989, 0.3359702229499817, 0.35068559646606445, 0.3654009997844696, 0.38011637330055237, 0.39483174681663513, 0.4095471203327179, 0.42426249384880066, 0.4389778971672058, 0.4536932706832886, 0.46840864419937134, 0.4831240177154541, 0.49783939123153687, 0.5125547647476196, 0.5272701382637024, 0.5419855117797852, 0.5567009449005127, 0.5714163184165955, 0.5861316919326782, 0.600847065448761, 0.6155624389648438, 0.6302778124809265, 0.6449931859970093, 0.659708559513092, 0.6744239330291748, 0.6891393065452576, 0.7038546800613403, 0.7185701131820679, 0.7332854866981506, 0.7480008602142334, 0.7627162337303162, 0.7774316072463989, 0.7921469807624817, 0.8068623542785645, 0.8215777277946472, 0.83629310131073, 0.8510084748268127, 0.8657239079475403, 0.880439281463623, 0.8951546549797058, 0.9098700284957886, 0.9245854020118713, 0.9393007755279541]}, "gradients/fc.1.bias": {"_type": "histogram", "values": [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [0.0, 0.0001555421040393412, 0.0003110842080786824, 0.00046662631211802363, 0.0006221684161573648, 0.0007777105201967061, 0.0009332526242360473, 0.0010887947864830494, 0.0012443368323147297, 0.00139987887814641, 0.0015554210403934121, 0.0017109632026404142, 0.0018665052484720945, 0.002022047294303775, 0.002177589572966099, 0.002333131618797779, 0.0024886736646294594, 0.0026442157104611397, 0.00279975775629282, 0.002955300034955144, 0.0031108420807868242, 0.0032663841266185045, 0.0034219264052808285, 0.0035774684511125088, 0.003733010496944189, 0.0038885525427758694, 0.00404409458860755, 0.00419963663443923, 0.004355179145932198, 0.004510721191763878, 0.004666263237595558, 0.0048218052834272385, 0.004977347329258919, 0.005132889375090599, 0.005288431420922279, 0.00544397346675396, 0.00559951551258564, 0.0057550580240786076, 0.005910600069910288, 0.006066142115741968, 0.0062216841615736485, 0.006377226207405329, 0.006532768253237009, 0.006688310299068689, 0.006843852810561657, 0.006999394856393337, 0.0071549369022250175, 0.007310478948056698, 0.007466020993888378, 0.0076215630397200584, 0.007777105085551739, 0.007932647131383419, 0.0080881891772151, 0.00824373122304678, 0.00839927326887846, 0.00855481531471014, 0.008710358291864395, 0.008865900337696075, 0.009021442383527756, 0.009176984429359436, 0.009332526475191116, 0.009488068521022797, 0.009643610566854477, 0.009799152612686157, 0.009954694658517838]}, "gradients/fc.1.weight": {"_type": "histogram", "values": [11.0, 0.0, 7.0, 43.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 320.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 6.0, 13.0, 22.0, 18.0, 12.0, 12.0, 9.0, 2.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 6.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.010064562782645226, -0.00908350944519043, -0.008102456107735634, -0.007121403701603413, -0.006140350364148617, -0.005159297026693821, -0.004178244154900312, -0.003197191283106804, -0.002216137945652008, -0.0012350846081972122, -0.0002540312707424164, 0.0007270211353898048, 0.0017080744728446007, 0.0026891278102993965, 0.0036701802164316177, 0.004651233553886414, 0.005632286891341209, 0.006613340228796005, 0.007594393566250801, 0.008575446903705597, 0.009556500241160393, 0.01053755171597004, 0.011518605053424835, 0.012499658390879631, 0.013480711728334427, 0.014461765065789223, 0.015442818403244019, 0.016423871740698814, 0.01740492321550846, 0.018385976552963257, 0.019367029890418053, 0.02034808322787285, 0.021329136565327644, 0.02231018804013729, 0.023291243240237236, 0.024272294715046883, 0.025253349915146828, 0.026234401389956474, 0.02721545659005642, 0.028196508064866066, 0.02917756326496601, 0.030158614739775658, 0.031139666214585304, 0.0321207195520401, 0.033101774752140045, 0.03408282995223999, 0.03506387770175934, 0.03604493290185928, 0.03702598810195923, 0.03800703585147858, 0.03898809105157852, 0.03996914625167847, 0.04095020145177841, 0.04193124920129776, 0.042912304401397705, 0.04389335960149765, 0.044874407351017, 0.04585546255111694, 0.04683651775121689, 0.047817572951316833, 0.04879862070083618, 0.04977967590093613, 0.05076073110103607, 0.05174178630113602, 0.052722834050655365]}, "gradients/fc.0.bias": {"_type": "histogram", "values": [1.0, 0.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.010443031787872314, -0.006144543178379536, -0.001846054568886757, 0.002452434040606022, 0.006750922650098801, 0.011049412190914154, 0.015347899869084358, 0.019646387547254562, 0.023944877088069916, 0.02824336662888527, 0.03254185616970062, 0.03684034198522568, 0.04113883152604103, 0.045437321066856384, 0.04973580688238144, 0.05403430014848709, 0.058332785964012146, 0.0626312717795372, 0.06692976504564285, 0.07122825086116791, 0.07552674412727356, 0.07982522994279861, 0.08412371575832367, 0.08842220902442932, 0.09272069483995438, 0.09701918065547943, 0.10131767392158508, 0.10561615973711014, 0.10991464555263519, 0.11421313881874084, 0.1185116320848465, 0.12281011044979095, 0.1271086037158966, 0.13140709698200226, 0.13570557534694672, 0.14000406861305237, 0.14430256187915802, 0.14860104024410248, 0.15289953351020813, 0.15719802677631378, 0.16149652004241943, 0.1657949984073639, 0.17009349167346954, 0.1743919849395752, 0.17869046330451965, 0.1829889565706253, 0.18728744983673096, 0.19158592820167542, 0.19588442146778107, 0.20018291473388672, 0.20448139309883118, 0.20877988636493683, 0.21307837963104248, 0.21737685799598694, 0.2216753512620926, 0.22597384452819824, 0.2302723228931427, 0.23457081615924835, 0.238869309425354, 0.24316778779029846, 0.2474662959575653, 0.25176477432250977, 0.2560632526874542, 0.26036176085472107, 0.2646602392196655]}, "gradients/fc.0.weight": {"_type": "histogram", "values": [1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 13.0, 5.0, 4.0], "bins": [-0.12381292879581451, -0.12180201709270477, -0.11979110538959503, -0.11778019368648529, -0.11576928198337555, -0.11375837028026581, -0.11174745857715607, -0.10973654687404633, -0.10772563517093658, -0.10571472346782684, -0.1037038117647171, -0.10169289261102676, -0.09968198090791702, -0.09767106920480728, -0.09566015750169754, -0.0936492457985878, -0.09163833409547806, -0.08962742239236832, -0.08761651068925858, -0.08560559898614883, -0.08359468728303909, -0.08158376812934875, -0.07957285642623901, -0.07756194472312927, -0.07555103302001953, -0.07354012131690979, -0.07152920961380005, -0.06951829791069031, -0.06750738620758057, -0.06549647450447083, -0.06348556280136108, -0.06147465109825134, -0.0594637393951416, -0.05745282769203186, -0.05544191598892212, -0.05343100428581238, -0.05142009258270264, -0.049409180879592896, -0.047398269176483154, -0.04538735747337341, -0.04337644577026367, -0.041365526616573334, -0.03935461491346359, -0.03734370321035385, -0.03533279150724411, -0.03332187980413437, -0.03131096810102463, -0.029300056397914886, -0.027289144694805145, -0.025278232991695404, -0.023267321288585663, -0.02125640958547592, -0.01924549788236618, -0.01723458617925644, -0.015223674476146698, -0.013212762773036957, -0.011201843619346619, -0.009190931916236877, -0.007180020213127136, -0.005169108510017395, -0.003158196806907654, -0.0011472851037979126, 0.0008636265993118286, 0.00287453830242157, 0.004885450005531311]}, "_runtime": 6801.265220165253, "_timestamp": 1585576717.1098535, "_step": 498}
{"Episode reward": 58.19999999999968, "Episode length": 418, "Policy Loss": 1.8355803489685059, "Value Loss": 23.667858123779297, "_runtime": 6801.265220165253, "_timestamp": 1585576717.1098535, "_step": 499}
